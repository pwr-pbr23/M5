/*
file: concurrenthashmap
written by doug lea. adapted and released, under explicit
permission, from jdk1.2 hashmap.java and hashtable.java which
carries the following copyright:
* copyright 1997 by sun microsystems, inc.,
* 901 san antonio road, palo alto, california, 94303, u.s.a.
* all rights reserved.
*
* this software is the confidential and proprietary information
* of sun microsystems, inc. ("confidential information").  you
* shall not disclose such confidential information and shall use
* it only in accordance with the terms of the license agreement
* you entered into with sun.
history:
date       who                what
26nov2000  dl               created, based on concurrentreaderhashmap
12jan2001  dl               public release
17nov2001  dl               minor tunings
24oct2003  dl               segment implements iclusterable
*/
package org apache wicket util concurrent
import java io ioexception
import java io serializable
import java util abstractcollection
import java util abstractmap
import java util abstractset
import java util collection
import java util enumeration
import java util iterator
import java util map
import java util nosuchelementexception
import java util set
import org apache wicket iclusterable
/**
* a version of hashtable supporting concurrency for both retrievals and
* updates:
*
* <dl>
* <dt> retrievals
*
* <dd> retrievals may overlap updates. (this is the same policy as
* concurrentreaderhashmap.) successful retrievals using get(key) and
* containskey(key) usually run without locking. unsuccessful retrievals (i.e.,
* when the key is not present) do involve brief synchronization (locking).
* because retrieval operations can ordinarily overlap with update operations
* (i.e., put, remove, and their derivatives), retrievals can only be guaranteed
* to return the results of the most recently <em>completed</em> operations
* holding upon their onset. retrieval operations may or may not return results
* reflecting in-progress writing operations. however, the retrieval operations
* do always return consistent results -- either those holding before any single
* modification or after it, but never a nonsense result. for aggregate
* operations such as putall and clear, concurrent reads may reflect insertion
* or removal of only some entries.
* <p>
*
* iterators and enumerations (i.e., those returned by keyset().iterator(),
* entryset().iterator(), values().iterator(), keys(), and elements()) return
* elements reflecting the state of the hash table at some point at or since the
* creation of the iterator/enumeration. they will return at most one instance
* of each element (via next()/nextelement()), but might or might not reflect
* puts and removes that have been processed since they were created. they do
* <em>not</em> throw concurrentmodificationexception. however, these
* iterators are designed to be used by only one thread at a time. passing an
* iterator across multiple threads may lead to unpredictable results if the
* table is being concurrently modified.
* <p>
*
*
* <dt> updates
*
* <dd> this class supports a hard-wired preset <em>concurrency
* level</em> of
* 32. this allows a maximum of 32 put and/or remove operations to proceed
* concurrently. this level is an upper bound on concurrency, not a guarantee,
* since it interacts with how well-strewn elements are across bins of the
* table. (the preset value in part reflects the fact that even on large
* multiprocessors, factors other than synchronization tend to be bottlenecks
* when more than 32 threads concurrently attempt updates.) additionally,
* operations triggering internal resizing and clearing do not execute
* concurrently with any operation.
* <p>
*
* there is <em>not</em> any support for locking the entire table to prevent
* updates. this makes it imposssible, for example, to add an element only if it
* is not already present, since another thread may be in the process of doing
* the same thing. if you need such capabilities, consider instead using the
* concurrentreaderhashmap class.
*
* </dl>
*
* because of how concurrency control is split up, the size() and isempty()
* methods require accumulations across 32 control segments, and so might be
* slightly slower than you expect.
* <p>
*
* this class may be used as a direct replacement for java.util.hashtable in any
* application that does not rely on the ability to lock the entire table to
* prevent updates. as of this writing, it performs much faster than hashtable
* in typical multi-threaded applications with multiple readers and writers.
* like hashtable but unlike java.util.hashmap, this class does not allow
* <tt>null</tt> to be used as a key or value.
* <p>
*
* implementation note: a slightly faster implementation of this class will be
* possible once planned java memory model revisions are in place.
*
* <p>[<a
* href="http://gee.cs.oswego.edu/dl/classes/edu/oswego/cs/dl/util/concurrent/intro.html">
* introduction to this package. </a>]
*
*/
public class concurrenthashmap extends abstractmap implements map  cloneable  serializable
private static final long serialversionuid   1l
/*
* the basic strategy is an optimistic-style scheme based on the guarantee
* that the hash table and its lists are always kept in a consistent enough
* state to be read without locking:
*
* read operations first proceed without locking, by traversing the
* apparently correct list of the apparently correct bin. if an entry is
* found, but not invalidated (value field null), it is returned. if not
* found, operations must recheck (after a memory barrier) to make sure they
* are using both the right list and the right table (which can change under
* resizes). if invalidated, reads must acquire main update lock to wait out
* the update, and then re-traverse.
*
* all list additions are at the front of each bin, making it easy to check
* changes, and also fast to traverse. entry next pointers are never
* assigned. remove() builds new nodes when necessary to preserve this.
*
* remove() (also clear()) invalidates removed nodes to alert read
* operations that they must wait out the full modifications.
*
* locking for puts, removes (and, when necessary gets, etc) is controlled
* by segments, each covering a portion of the table. during operations
* requiring global exclusivity (mainly resize and clear), all of these
* locks are acquired at once. note that these segments are not contiguous --
* they are based on the least 5 bits of hashcodes. this ensures that the
* same segment controls the same slots before and after resizing, which is
* necessary for supporting concurrent retrievals. this comes at the price
* of a mismatch of logical vs physical locality, but this seems not to be a
* performance problem in practice.
*
*/
/**
* the hash table data.
*/
protected transient entry table
/**
* the number of concurrency control segments. the value can be at most 32
* since ints are used as bitsets over segments. emprically, it doesn't seem
* to pay to decrease it either, so the value should be at least 32. in
* other words, do not redefine this :-)
*/
protected static final int concurrency_level   32
/**
* mask value for indexing into segments
*/
protected static final int segment_mask   concurrency_level   1
/**
* bookkeeping for each concurrency control segment. each segment contains a
* local count of the number of elements in its region. however, the main
* use of a segment is for its lock.
*/
protected final static class segment implements iclusterable
private static final long serialversionuid   1l
/**
* the number of elements in this segment's region. it is always updated
* within synchronized blocks.
*/
protected int count
/**
* get the count under synch.
* @return count under sync
*/
protected synchronized int getcount
return count
/**
* force a synchronization
*/
protected synchronized void synch
/**
* the array of concurrency control segments.
*/
protected final segment segments   new segment
/**
* the default initial number of table slots for this table (32). used when
* not otherwise specified in constructor.
*/
public static final int default_initial_capacity   32
/**
* the minimum capacity, used if a lower value is implicitly specified by
* either of the constructors with arguments. must be a power of two.
*/
private static final int minimum_capacity   32
/**
* the maximum capacity, used if a higher value is implicitly specified by
* either of the constructors with arguments. must be a power of two <= 1<<30.
*/
private static final int maximum_capacity   1 << 30
/**
* the default load factor for this table (0.75) used when not otherwise
* specified in constructor.
*/
public static final float default_load_factor   0 75f
/**
* the load factor for the hash table.
*
* @serial
*/
protected final float loadfactor
/**
* per-segment resize threshold.
*
* @serial
*/
protected int threshold
/**
* number of segments voting for resize. the table is doubled when 1/4 of
* the segments reach threshold. volatile but updated without synch since
* this is just a heuristic.
*/
protected transient volatile int votesforresize
/**
* return the number of set bits in w. for a derivation of this algorithm,
* see "algorithms and data structures with applications to graphics and
* geometry", by jurg nievergelt and klaus hinrichs, prentice hall, 1993.
* see also notes by torsten sillke at
* http://www.mathematik.uni-bielefeld.de/~sillke/problems/bitcount
* @param w arg
* @return number of set bits
*/
protected static int bitcount int w
w     0xaaaaaaaa   w  >>> 1
w    w   0x33333333      w >>> 2    0x33333333
w    w    w >>> 4     0x0f0f0f0f
w    w >>> 8
w    w >>> 16
return w   0xff
/**
* returns the appropriate capacity (power of two) for the specified initial
* capacity argument.
* @param initialcapacity the initial capacity
* @return appropriate capacity
*/
private int p2capacity int initialcapacity
int cap   initialcapacity
// compute the appropriate capacity
int result
if  cap > maximum_capacity    cap < 0
result   maximum_capacity
else
result   minimum_capacity
while  result < cap
result <<  1
return result
/**
* return hash code for object x. since we are using power-of-two tables, it
* is worth the effort to improve hashcode via the same multiplicative
* scheme as used in identityhashmap.
* @param x
* @return hash code
*/
protected static int hash object x
int h   x hashcode
// multiply by 127 (quickly, via shifts), and mix in some high
// bits to help guard against bunching of codes that are
// consecutive or equally spaced.
return   h << 7    h    h >>> 9     h >>> 17
/**
* check for equality of non-null references x and y.
* @param x ref
* @param y ref
* @return is equal
*/
protected boolean eq object x  object y
return x    y    x equals y
/**
* create table array and set the per-segment threshold *
* @param capacity
* @return table array
*/
protected entry newtable int capacity
threshold    int  capacity   loadfactor   concurrency_level    1
return new entry
/**
* constructs a new, empty map with the specified initial capacity and the
* specified load factor.
*
* @param initialcapacity
*            the initial capacity. the actual initial capacity is rounded
*            to the nearest power of two.
* @param loadfactor
*            the load factor threshold, used to control resizing. this
*            value is used in an approximate way: when at least a quarter
*            of the segments of the table reach per-segment threshold, or
*            one of the segments itself exceeds overall threshold, the
*            table is doubled. this will on average cause resizing when the
*            table-wide load factor is slightly less than the threshold. if
*            you'd like to avoid resizing, you can set this to a
*            ridiculously large value.
* @throws illegalargumentexception
*             if the load factor is nonpositive.
*/
public concurrenthashmap int initialcapacity  float loadfactor
if    loadfactor > 0
throw new illegalargumentexception     loadfactor
this loadfactor   loadfactor
for  int i   0  i < segments length    i
segments   new segment
int cap   p2capacity initialcapacity
table   newtable cap
/**
* constructs a new, empty map with the specified initial capacity and
* default load factor.
*
* @param initialcapacity
*            the initial capacity of the concurrenthashmap.
* @throws illegalargumentexception
*             if the initial maximum number of elements is less than zero.
*/
public concurrenthashmap int initialcapacity
this initialcapacity  default_load_factor
/**
* constructs a new, empty map with a default initial capacity and default
* load factor.
*/
public concurrenthashmap
this default_initial_capacity  default_load_factor
/**
* constructs a new map with the same mappings as the given map. the map is
* created with a capacity of twice the number of mappings in the given map
* or 32 (whichever is greater), and a default load factor.
* @param t map to copy
*/
public concurrenthashmap map t
this math max  int  t size     default_load_factor    1  minimum_capacity
default_load_factor
putall t
/**
* returns the number of key-value mappings in this map.
*
* @return the number of key-value mappings in this map.
*/
public int size
int c   0
for  int i   0  i < segments length    i
c    segments getcount
return c
/**
* returns <tt>true</tt> if this map contains no key-value mappings.
*
* @return <tt>true</tt> if this map contains no key-value mappings.
*/
public boolean isempty
for  int i   0  i < segments length    i
if  segments getcount      0
return false
return true
/**
* returns the value to which the specified key is mapped in this table.
*
* @param key
*            a key in the table.
* @return the value to which the key is mapped in this table;
*         <code>null</code> if the key is not mapped to any value in this
*         table.
* @exception nullpointerexception
*                if the key is <code>null</code>.
* @see #put(object, object)
*/
public object get object key
int hash   hash key      throws null pointer exception if key null
// try first without locking...
entry tab   table
int index   hash    tab length   1
entry first   tab
entry e
for  e   first  e    null  e   e next
if  e hash    hash    eq key  e key
object value   e value
if  value    null
return value
else
break
// recheck under synch if key apparently not there or interference
segment seg   segments
synchronized  seg
tab   table
index   hash    tab length   1
entry newfirst   tab
if  e    null    first    newfirst
for  e   newfirst  e    null  e   e next
if  e hash    hash    eq key  e key
return e value
return null
/**
* tests if the specified object is a key in this table.
*
* @param key
*            possible key.
* @return <code>true</code> if and only if the specified object is a key
*         in this table, as determined by the <tt>equals</tt> method;
*         <code>false</code> otherwise.
* @exception nullpointerexception
*                if the key is <code>null</code>.
* @see #contains(object)
*/
public boolean containskey object key
return get key     null
/**
* maps the specified <code>key</code> to the specified <code>value</code>
* in this table. neither the key nor the value can be <code>null</code>.
* (note that this policy is the same as for java.util.hashtable, but unlike
* java.util.hashmap, which does accept nulls as valid keys and values.)
* <p>
*
* the value can be retrieved by calling the <code>get</code> method with
* a key that is equal to the original key.
*
* @param key
*            the table key.
* @param value
*            the value.
* @return the previous value of the specified key in this table, or
*         <code>null</code> if it did not have one.
* @exception nullpointerexception
*                if the key or value is <code>null</code>.
* @see object#equals(object)
* @see #get(object)
*/
public object put object key  object value
if  value    null
throw new illegalargumentexception
int hash   hash key
segment seg   segments
int segcount
entry tab
int votes
synchronized  seg
tab   table
int index   hash    tab length   1
entry first   tab
for  entry e   first  e    null  e   e next
if  e hash    hash    eq key  e key
object oldvalue   e value
e value   value
return oldvalue
// add to front of list
entry newentry   new entry hash  key  value  first
tab   newentry
if   segcount     seg count  < threshold
return null
int bit    1 <<  hash   segment_mask
votes   votesforresize
if   votes   bit     0
votes   votesforresize    bit
// attempt resize if 1/4 segs vote,
// or if this seg itself reaches the overall threshold.
// (the latter check is just a safeguard to avoid pathological cases.)
if  bitcount votes  >  concurrency_level   4    segcount >  threshold   concurrency_level
resize 0  tab
return null
/**
* gather all locks in order to call rehash, by recursing within synch
* blocks for each segment index.
*
* @param index
*            the current segment. initially call value must be 0
* @param assumedtab
*            the state of table on first call to resize. if this changes on
*            any call, the attempt is aborted because the table has already
*            been resized by another thread.
*/
protected void resize int index  entry assumedtab
segment seg   segments
synchronized  seg
if  assumedtab    table
int next   index   1
if  next < segments length
resize next  assumedtab
else
rehash
/**
* rehashes the contents of this map into a new table with a larger
* capacity.
*/
protected void rehash
votesforresize   0     reset
entry oldtable   table
int oldcapacity   oldtable length
if  oldcapacity >  maximum_capacity
threshold   integer max_value     avoid retriggering
return
int newcapacity   oldcapacity << 1
entry newtable   newtable newcapacity
int mask   newcapacity   1
/*
* reclassify nodes in each list to new map. because we are using
* power-of-two expansion, the elements from each bin must either stay
* at same index, or move to oldcapacity+index. we also eliminate
* unnecessary node creation by catching cases where old nodes can be
* reused because their next fields won't change. statistically, at the
* default threshhold, only about one-sixth of them need cloning. (the
* nodes they replace will be garbage collectable as soon as they are no
* longer referenced by any reader thread that may be in the midst of
* traversing table right now.)
*/
for  int i   0  i < oldcapacity  i
// we need to guarantee that any existing reads of old map can
// proceed. so we cannot yet null out each bin.
entry e   oldtable
if  e    null
int idx   e hash   mask
entry next   e next
// single node on list
if  next    null
newtable   e
else
// reuse trailing consecutive sequence of all same bit
entry lastrun   e
int lastidx   idx
for  entry last   next  last    null  last   last next
int k   last hash   mask
if  k    lastidx
lastidx   k
lastrun   last
newtable   lastrun
// clone all remaining nodes
for  entry p   e  p    lastrun  p   p next
int k   p hash   mask
newtable   new entry p hash  p key  p value  newtable
table   newtable
/**
* removes the key (and its corresponding value) from this table. this
* method does nothing if the key is not in the table.
*
* @param key
*            the key that needs to be removed.
* @return the value to which the key had been mapped in this table, or
*         <code>null</code> if the key did not have a mapping.
* @exception nullpointerexception
*                if the key is <code>null</code>.
*/
public object remove object key
return remove key  null
/**
* removes the (key, value) pair from this table. this method does nothing
* if the key is not in the table, or if the key is associated with a
* different value. this method is needed by entryset.
*
* @param key
*            the key that needs to be removed.
* @param value
*            the associated value. if the value is null, it means "any
*            value".
* @return the value to which the key had been mapped in this table, or
*         <code>null</code> if the key did not have a mapping.
* @exception nullpointerexception
*                if the key is <code>null</code>.
*/
protected object remove object key  object value
/*
* find the entry, then 1. set value field to null, to force get() to
* retry 2. rebuild the list without this entry. all entries following
* removed node can stay in list, but all preceeding ones need to be
* cloned. traversals rely on this strategy to ensure that elements will
* not be repeated during iteration.
*/
int hash   hash key
segment seg   segments
synchronized  seg
entry tab   table
int index   hash    tab length   1
entry first   tab
entry e   first
for
if  e    null
return null
if  e hash    hash    eq key  e key
break
e   e next
object oldvalue   e value
if  value    null     value equals oldvalue
return null
e value   null
entry head   e next
for  entry p   first  p    e  p   p next
head   new entry p hash  p key  p value  head
tab   head
seg count
return oldvalue
/**
* returns <tt>true</tt> if this map maps one or more keys to the
* specified value. note: this method requires a full internal traversal of
* the hash table, and so is much slower than method <tt>containskey</tt>.
*
* @param value
*            value whose presence in this map is to be tested.
* @return <tt>true</tt> if this map maps one or more keys to the
*         specified value.
* @exception nullpointerexception
*                if the value is <code>null</code>.
*/
public boolean containsvalue object value
if  value    null
throw new illegalargumentexception
for  int s   0  s < segments length    s
segment seg   segments
entry tab
synchronized  seg
tab   table
for  int i   s  i < tab length  i    segments length
for  entry e   tab  e    null  e   e next
if  value equals e value
return true
return false
/**
* tests if some key maps into the specified value in this table. this
* operation is more expensive than the <code>containskey</code> method.
* <p>
*
* note that this method is identical in functionality to containsvalue,
* (which is part of the map interface in the collections framework).
*
* @param value
*            a value to search for.
* @return <code>true</code> if and only if some key maps to the
*         <code>value</code> argument in this table as determined by the
*         <tt>equals</tt> method; <code>false</code> otherwise.
* @exception nullpointerexception
*                if the value is <code>null</code>.
* @see #containskey(object)
* @see #containsvalue(object)
* @see map
*/
public boolean contains object value
return containsvalue value
/**
* copies all of the mappings from the specified map to this one.
*
* these mappings replace any mappings that this map had for any of the keys
* currently in the specified map.
*
* @param t
*            mappings to be stored in this map.
*/
public void putall map t
int n   t size
if  n    0
return
// expand enough to hold at least n elements without resizing.
// we can only resize table by factor of two at a time.
// it is faster to rehash with fewer elements, so do it now.
for
entry tab
int max
synchronized  segments
must synch on some segment  pick 0
tab   table
max   threshold   concurrency_level
if  n < max
break
resize 0  tab
for  iterator it   t entryset   iterator    it hasnext
map entry entry    map entry it next
put entry getkey    entry getvalue
/**
* removes all mappings from this map.
*/
public void clear
// we don't need all locks at once so long as locks
// are obtained in low to high order
for  int s   0  s < segments length    s
segment seg   segments
synchronized  seg
entry tab   table
for  int i   s  i < tab length  i    segments length
for  entry e   tab  e    null  e   e next
e value   null
tab   null
seg count   0
/**
* returns a shallow copy of this <tt>concurrenthashmap</tt> instance: the
* keys and values themselves are not cloned.
*
* @return a shallow copy of this map.
*/
public object clone
// we cannot call super.clone, since it would share final segments
// array,
// and there's no way to reassign finals.
return new concurrenthashmap this
// views
protected transient set keyset   null
protected transient set entryset   null
protected transient collection values   null
/**
* returns a set view of the keys contained in this map. the set is backed
* by the map, so changes to the map are reflected in the set, and
* vice-versa. the set supports element removal, which removes the
* corresponding mapping from this map, via the <tt>iterator.remove</tt>,
* <tt>set.remove</tt>, <tt>removeall</tt>, <tt>retainall</tt>, and
* <tt>clear</tt> operations. it does not support the <tt>add</tt> or
* <tt>addall</tt> operations.
*
* @return a set view of the keys contained in this map.
*/
public set keyset
set ks   keyset
return  ks    null  ? ks    keyset   new keyset
private class keyset extends abstractset
/**
* @see java.util.set#iterator()
*/
public iterator iterator
return new keyiterator
/**
* @see java.util.set#size()
*/
public int size
return concurrenthashmap this size
/**
* @see java.util.set#contains(java.lang.object)
*/
public boolean contains object o
return concurrenthashmap this containskey o
/**
* @see java.util.set#remove(java.lang.object)
*/
public boolean remove object o
return concurrenthashmap this remove o     null
/**
* @see java.util.set#clear()
*/
public void clear
concurrenthashmap this clear
/**
* returns a collection view of the values contained in this map. the
* collection is backed by the map, so changes to the map are reflected in
* the collection, and vice-versa. the collection supports element removal,
* which removes the corresponding mapping from this map, via the
* <tt>iterator.remove</tt>, <tt>collection.remove</tt>,
* <tt>removeall</tt>, <tt>retainall</tt>, and <tt>clear</tt>
* operations. it does not support the <tt>add</tt> or <tt>addall</tt>
* operations.
*
* @return a collection view of the values contained in this map.
*/
public collection values
collection vs   values
return  vs    null  ? vs    values   new values
private class values extends abstractcollection
/**
* @see java.util.abstractcollection#iterator()
*/
public iterator iterator
return new valueiterator
/**
* @see java.util.abstractcollection#size()
*/
public int size
return concurrenthashmap this size
/**
* @see java.util.abstractcollection#contains(java.lang.object)
*/
public boolean contains object o
return concurrenthashmap this containsvalue o
/**
* @see java.util.abstractcollection#clear()
*/
public void clear
concurrenthashmap this clear
/**
* returns a collection view of the mappings contained in this map. each
* element in the returned collection is a <tt>map.entry</tt>. the
* collection is backed by the map, so changes to the map are reflected in
* the collection, and vice-versa. the collection supports element removal,
* which removes the corresponding mapping from the map, via the
* <tt>iterator.remove</tt>, <tt>collection.remove</tt>,
* <tt>removeall</tt>, <tt>retainall</tt>, and <tt>clear</tt>
* operations. it does not support the <tt>add</tt> or <tt>addall</tt>
* operations.
*
* @return a collection view of the mappings contained in this map.
*/
public set entryset
set es   entryset
return  es    null  ? es    entryset   new entryset
private class entryset extends abstractset
/**
* @see java.util.set#iterator()
*/
public iterator iterator
return new hashiterator
/**
* @see java.util.set#contains(java.lang.object)
*/
public boolean contains object o
if    o instanceof map entry
return false
map entry entry    map entry o
object v   concurrenthashmap this get entry getkey
return v    null    v equals entry getvalue
/**
* @see java.util.set#remove(java.lang.object)
*/
public boolean remove object o
if    o instanceof map entry
return false
map entry e    map entry o
return concurrenthashmap this remove e getkey    e getvalue       null
/**
* @see java.util.set#size()
*/
public int size
return concurrenthashmap this size
/**
* @see java.util.set#clear()
*/
public void clear
concurrenthashmap this clear
/**
* returns an enumeration of the keys in this table.
*
* @return an enumeration of the keys in this table.
* @see enumeration
* @see #elements()
* @see #keyset()
* @see map
*/
public enumeration keys
return new keyiterator
/**
* returns an enumeration of the values in this table. use the enumeration
* methods on the returned object to fetch the elements sequentially.
*
* @return an enumeration of the values in this table.
* @see java.util.enumeration
* @see #keys()
* @see #values()
* @see map
*/
public enumeration elements
return new valueiterator
/**
* concurrenthashmap collision list entry.
*/
protected static class entry implements map entry
/*
* the use of volatile for value field ensures that we can detect status
* changes without synchronization. the other fields are never changed,
* and are marked as final.
*/
protected final object key
protected volatile object value
protected final int hash
protected final entry next
entry int hash  object key  object value  entry next
this value   value
this hash   hash
this key   key
this next   next
// map.entry ops
/**
* @see java.util.map.entry#getkey()
*/
public object getkey
return key
/**
* get the value. note: in an entryset or entryset.iterator, unless you
* can guarantee lack of concurrent modification,
* <tt>getvalue</tt> <em>might</em> return null, reflecting the fact
* that the entry has been concurrently removed. however, there are no
* assurances that concurrent removals will be reflected using this
* method.
*
* @return the current value, or null if the entry has been detectably
*         removed.
*/
public object getvalue
return value
/**
* set the value of this entry. note: in an entryset or
* entryset.iterator), unless you can guarantee lack of concurrent
* modification, <tt>setvalue</tt> is not strictly guaranteed to
* actually replace the value field obtained via the <tt>get</tt>
* operation of the underlying hash table in multithreaded applications.
* if iterator-wide synchronization is not used, and any other
* concurrent <tt>put</tt> or <tt>remove</tt> operations occur,
* sometimes even to <em>other</em> entries, then this change is not
* guaranteed to be reflected in the hash table. (it might, or it might
* not. there are no assurances either way.)
*
* @param value
*            the new value.
* @return the previous value, or null if entry has been detectably
*         removed.
* @exception nullpointerexception
*                if the value is <code>null</code>.
*
*/
public object setvalue object value
if  value    null
throw new illegalargumentexception
object oldvalue   this value
this value   value
return oldvalue
/**
* @see java.util.map.entry#equals(java.lang.object)
*/
public boolean equals object o
if    o instanceof map entry
return false
map entry e    map entry o
return  key equals e getkey       value equals e getvalue
/**
* @see java.util.map.entry#hashcode()
*/
public int hashcode
return key hashcode   ^ value hashcode
/**
* @see java.lang.object#tostring()
*/
public string tostring
return key       value
protected class hashiterator implements iterator  enumeration
protected final entry tab     snapshot of table
protected int index     current slot
protected entry entry   null     current node of slot
protected object currentkey     key for current node
protected object currentvalue     value for current node
protected entry lastreturned   null     last node returned by next
protected hashiterator
// force all segments to synch
synchronized  segments
tab   table
for  int i   1  i < segments length    i
segments synch
index   tab length   1
/**
* @see java.util.enumeration#hasmoreelements()
*/
public boolean hasmoreelements
return hasnext
/**
* @see java.util.enumeration#nextelement()
*/
public object nextelement
return next
/**
* @see java.util.iterator#hasnext()
*/
public boolean hasnext
/*
* currentkey and currentvalue are set here to ensure that next()
* returns normally if hasnext() returns true. this avoids surprises
* especially when final element is removed during traversal --
* instead, we just ignore the removal during current traversal.
*/
for
if  entry    null
object v   entry value
if  v    null
currentkey   entry key
currentvalue   v
return true
else
entry   entry next
while  entry    null    index >  0
entry   tab
if  entry    null
currentkey   currentvalue   null
return false
protected object returnvalueofnext
return entry
/**
* @see java.util.iterator#next()
*/
public object next
if  currentkey    null     hasnext
throw new nosuchelementexception
object result   returnvalueofnext
lastreturned   entry
currentkey   currentvalue   null
entry   entry next
return result
/**
* @see java.util.iterator#remove()
*/
public void remove
if  lastreturned    null
throw new illegalstateexception
concurrenthashmap this remove lastreturned key
lastreturned   null
protected class keyiterator extends hashiterator
protected object returnvalueofnext
return currentkey
protected class valueiterator extends hashiterator
protected object returnvalueofnext
return currentvalue
/**
* save the state of the <tt>concurrenthashmap</tt> instance to a stream
* (i.e., serialize it).
* @param s
* @throws ioexception
*
* @serialdata an estimate of the table size, followed by the key (object)
*             and value (object) for each key-value mapping, followed by a
*             null pair. the key-value mappings are emitted in no
*             particular order.
*/
private void writeobject java io objectoutputstream s  throws ioexception
// write out the loadfactor, and any hidden stuff
s defaultwriteobject
// write out capacity estimate. it is ok if this
// changes during the write, since it is only used by
// readobject to set initial capacity, to avoid needless resizings.
int cap
synchronized  segments
cap   table length
s writeint cap
// write out keys and values (alternating)
for  int k   0  k < segments length    k
segment seg   segments
entry tab
synchronized  seg
tab   table
for  int i   k  i < tab length  i    segments length
for  entry e   tab  e    null  e   e next
s writeobject e key
s writeobject e value
s writeobject null
s writeobject null
/**
* reconstitute the <tt>concurrenthashmap</tt> instance from a stream
* (i.e., deserialize it).
* @param s
* @throws ioexception
* @throws classnotfoundexception
*/
private void readobject java io objectinputstream s  throws ioexception  classnotfoundexception
// read in the threshold, loadfactor, and any hidden stuff
s defaultreadobject
int cap   s readint
table   newtable cap
for  int i   0  i < segments length    i
segments   new segment
// read the keys and values, and put the mappings in the table
for
object key   s readobject
object value   s readobject
if  key    null
break
put key  value