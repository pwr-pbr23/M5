/*
derby - class org.apache.derby.impl.sql.execute.insertresultset
licensed to the apache software foundation (asf) under one or more
contributor license agreements.  see the notice file distributed with
this work for additional information regarding copyright ownership.
the asf licenses this file to you under the apache license, version 2.0
(the "license"); you may not use this file except in compliance with
the license.  you may obtain a copy of the license at
http://www.apache.org/licenses/license-2.0
unless required by applicable law or agreed to in writing, software
distributed under the license is distributed on an "as is" basis,
without warranties or conditions of any kind, either express or implied.
see the license for the specific language governing permissions and
limitations under the license.
*/
package org apache derby impl sql execute
import java util enumeration
import java util hashmap
import java util hashtable
import java util properties
import java util vector
import org apache derby catalog types statisticsimpl
import org apache derby iapi db triggerexecutioncontext
import org apache derby iapi error standardexception
import org apache derby iapi reference sqlstate
import org apache derby iapi services context contextmanager
import org apache derby iapi services io formatablebitset
import org apache derby iapi services io streamstorable
import org apache derby iapi services loader generatedmethod
import org apache derby iapi services sanity sanitymanager
import org apache derby iapi sql activation
import org apache derby iapi sql languageproperties
import org apache derby iapi sql resultcolumndescriptor
import org apache derby iapi sql resultdescription
import org apache derby iapi sql resultset
import org apache derby iapi sql statementutil
import org apache derby iapi sql conn languageconnectioncontext
import org apache derby iapi sql depend dependencymanager
import org apache derby iapi sql dictionary columndescriptor
import org apache derby iapi sql dictionary conglomeratedescriptor
import org apache derby iapi sql dictionary constraintdescriptor
import org apache derby iapi sql dictionary datadescriptorgenerator
import org apache derby iapi sql dictionary datadictionary
import org apache derby iapi sql dictionary statisticsdescriptor
import org apache derby iapi sql dictionary tabledescriptor
import org apache derby iapi sql dictionary triggerdescriptor
import org apache derby iapi sql execute cursorresultset
import org apache derby iapi sql execute execindexrow
import org apache derby iapi sql execute execrow
import org apache derby iapi sql execute noputresultset
import org apache derby iapi sql execute rowchanger
import org apache derby iapi sql execute targetresultset
import org apache derby iapi store access columnordering
import org apache derby iapi store access conglomeratecontroller
import org apache derby iapi store access groupfetchscancontroller
import org apache derby iapi store access qualifier
import org apache derby iapi store access rowlocationretrowsource
import org apache derby iapi store access scancontroller
import org apache derby iapi store access sortcontroller
import org apache derby iapi store access sortobserver
import org apache derby iapi store access transactioncontroller
import org apache derby iapi types datavaluedescriptor
import org apache derby iapi types numberdatavalue
import org apache derby iapi types rowlocation
import org apache derby iapi util stringutil
/**
* insert the rows from the source into the specified
* base table. this will cause constraints to be checked
* and triggers to be executed based on the c's and t's
* compiled into the insert plan.
*/
class insertresultset extends dmlwriteresultset implements targetresultset
// resolve. embarassingly large public state. if we could move the replication
// code into the same package, then these variables could be protected.
// passed in at construction time
private	noputresultset			sourceresultset
noputresultset			savedsource
insertconstantaction	constants
private generatedmethod			checkgm
private long					heapconglom
//following is for jdbc3.0 feature auto generated keys resultset
private  resultset			autogeneratedkeysresultset
private	temporaryrowholderimpl	autogeneratedkeysrowsholder
// divined at run time
private	resultdescription 		resultdescription
private rowchanger 				rowchanger
private	transactioncontroller 	tc
private	execrow					row
boolean					userspecifiedbulkinsert
boolean					bulkinsertperformed
// bulkinsert
protected boolean				bulkinsert
private boolean					bulkinsertreplace
private boolean					firstrow   true
private	boolean				needtodropsort
/*
** this hashtable is used to convert an index conglomerate
** from it's old conglom number to the new one.  it is
** bulk insert specific.
*/
private hashtable				indexconversiontable
// indexedcols is 1-based
private formatablebitset					indexedcols
private conglomeratecontroller	bulkheapcc
protected datadictionary			dd
protected tabledescriptor			td
private execindexrow			indexrows
private execrow					fulltemplate
private	long					sortids
private rowlocationretrowsource
rowsources
private	scancontroller			bulkheapsc
private columnordering		ordering
private int		            collation
private sortcontroller		sorters
private	temporaryrowholderimpl	rowholder
private rowlocation				rl
private	boolean					hasbeforestatementtrigger
private	boolean					hasbeforerowtrigger
private	bulktablescanresultset	tablescan
private int						numopens
private boolean					firstexecute
// cached across open()s
private	fkinfo				fkinfoarray
private	triggerinfo				triggerinfo
private risetchecker 			fkchecker
private triggereventactivator	triggeractivator
/**
* keeps track of autoincrement values that are generated by
* getsetautoincrementvalues.
*/
private numberdatavalue				aicache
/**
* if set to true, implies that this (rep)insertresultset has generated
* autoincrement values. during refresh for example, the autoincrement
* values are not generated but sent from the source to target or
* vice-versa.
*/
protected boolean 				autoincrementgenerated
private long					identityval     support of identity_local_val function
private boolean					setidentity
/**
* returns the description of the inserted rows.
* revisit: do we want this to return null instead?
*/
public resultdescription getresultdescription
return resultdescription
// targetresultset interface
/**
* @see targetresultset#changedrow
*
* @exception standardexception thrown if cursor finish ed.
*/
public void changedrow execrow execrow  rowlocation rowlocation
throws standardexception
if  sanitymanager debug
sanitymanager assert bulkinsert
/* set up sorters, etc. if 1st row and there are indexes */
if  constants irgs length > 0
rowlocation rlclone    rowlocation  rowlocation cloneobject
// objectify any the streaming columns that are indexed.
for  int i   0  i < execrow getrowarray   length  i
if    constants indexedcols
continue
if  execrow getrowarray   instanceof streamstorable
datavaluedescriptor execrow getrowarray    getobject
// every index row will share the same row location, etc.
if  firstrow
firstrow   false
indexrows   new execindexrow
setupallsorts execrow getnewnullrow    rlclone
// put the row into the indexes
for  int index   0  index < constants irgs length  index
// get a new object array for the index
indexrows getnewobjectarray
// associate the index row with the source row
constants irgs getindexrow execrow
rlclone
indexrows
formatablebitset  null
// insert the index row into the matching sorter
sorters insert indexrows getrowarray
/**
* preprocess the source row.  apply any check constraints here.
* do an inplace cloning of all key columns.  for triggers, if
* we have a before row trigger, we fire it here if we can.
* this is useful for bulk insert where the store stands between
* the source and us.
*
* @param execrow	the source row.
*
* @return the preprocessed source row.
* @exception standardexception thrown on error
*/
public execrow preprocesssourcerow execrow execrow
throws standardexception
//system.out.println("preprocessrow is called ");
/*
** we can process before row triggers now.  all other
** triggers can only be fired after we have inserted
** all our rows.
*/
if  hasbeforerowtrigger
// resolve
// possibly dead code-- if there are triggers we don't do bulk insert.
rowholder truncate
rowholder insert execrow
triggeractivator notifyevent triggerevents before_insert
cursorresultset null
rowholder getresultset
if  checkgm    null     hasbeforestatementtrigger
evaluatecheckconstraints
// resolve - optimize the cloning
if  constants irgs length > 0
/* do in-place cloning of all of the key columns */
return execrow getclone indexedcols
else
return execrow
/**
*	run the check constraints against the current row. raise an error if
* a check constraint is violated.
*
* @exception standardexception thrown on error
*/
private	void	evaluatecheckconstraints
throws standardexception
if  checkgm    null
// evaluate the check constraints. the expression evaluation
// will throw an exception if there is a violation, so there
// is no need to check the result of the expression.
checkgm invoke activation
/*
* class interface
*
*/
/**
*
* @exception standardexception		thrown on error
*/
insertresultset noputresultset source
generatedmethod checkgm
activation activation
throws standardexception
super activation
sourceresultset   source
constants    insertconstantaction  constantaction
this checkgm   checkgm
heapconglom   constants conglomid
tc   activation gettransactioncontroller
fkinfoarray   constants getfkinfo
triggerinfo   constants gettriggerinfo
/*
** if we have a before statement trigger, then
** we cannot check constraints inline.
*/
hasbeforestatementtrigger    triggerinfo    null  ?
triggerinfo hastrigger true  false
false
hasbeforerowtrigger    triggerinfo    null  ?
triggerinfo hastrigger true  true
false
resultdescription   sourceresultset getresultdescription
// is this a bulkinsert or regular insert?
string insertmode   constants getproperty
rowlocation rla
if   rla   constants getautoincrowlocation       null
aicache
new numberdatavalue
for  int i   0  i < resultdescription getcolumncount    i
if  rla    null
continue
resultcolumndescriptor rcd
resultdescription getcolumndescriptor i   1
aicache    numberdatavalue rcd gettype   getnull
if  insertmode    null
if  stringutil sqlequalsignorecase insertmode
userspecifiedbulkinsert   true
else if  stringutil sqlequalsignorecase insertmode
userspecifiedbulkinsert   true
bulkinsertreplace   true
bulkinsert   true
/*
** for now, we don't allow bulk insert replace when
** there is a trigger.
*/
if  triggerinfo    null
triggerdescriptor td   triggerinfo gettriggerarray
throw standardexception newexception sqlstate lang_no_bulk_insert_replace_with_trigger_during_execution  constants gettablename    td getname
//system.out.println("new insertresultset " + sourceresultset.getclass());
/**
@exception standardexception standard derby error policy
*/
public void open   throws standardexception
setup
// remember if this is the 1st execution
firstexecute    rowchanger    null
autoincrementgenerated   false
dd   lcc getdatadictionary
/*
** verify the auto-generated key columns list(ie there are no invalid column
** names or positions). this is done at at execution time because for a precompiled
** insert statement, user can specify different column selections for
** auto-generated keys.
*/
if activation getautogeneratedkeysresultsetmode
if  activation getautogeneratedkeyscolumnindexes      null
verifyautogeneratedcolumnsindexes activation getautogeneratedkeyscolumnindexes
else  if  activation getautogeneratedkeyscolumnnames      null
verifyautogeneratedcolumnsnames activation getautogeneratedkeyscolumnnames
rowcount   0
if  numopens      0
sourceresultset opencore
else
sourceresultset reopencore
/* if the user specified bulkinsert (or replace) then we need
* to get an exclusive table lock on the table.  if it is a
* regular bulk insert then we need to check to see if the
* table is empty.  (if not empty, then we end up doing a row
* at a time insert.)
*/
if  userspecifiedbulkinsert
if    bulkinsertreplace
bulkinsert   verifybulkinsert
else
getexclusivetablelock
if  bulkinsert
// notify the source that we are the target
sourceresultset settargetresultset this
long basetableconglom   bulkinsertcore lcc  heapconglom
if  hasbeforestatementtrigger
tablescan   gettablescanresultset basetableconglom
// fire before trigger, do this before checking constraints
triggeractivator notifyevent triggerevents before_insert
cursorresultset null
tablescan
// if we have a check constraint, we have
// to do it the hard way now before we get
// to our after triggers.
if  checkgm    null
tablescan   gettablescanresultset basetableconglom
try
execrow currrow   null
while   currrow   tablescan getnextrowcore       null
// we have to set the source row so the check constraint
// sees the correct row.
sourceresultset setcurrentrow currrow
evaluatecheckconstraints
finally
sourceresultset clearcurrentrow
bulkvalidateforeignkeys tc  lcc getcontextmanager
// if we have an after trigger, let 'er rip
if   triggerinfo    null
triggerinfo hastrigger false  true
triggerinfo hastrigger false  false
triggeractivator notifyevent triggerevents after_insert
cursorresultset null
gettablescanresultset basetableconglom
bulkinsertperformed   true
else
row   getnextrowcore sourceresultset
normalinsertcore lcc  firstexecute
/* cache query plan text for source, before it gets blown away */
if  lcc getruntimestatisticsmode
/* savedsource nulled after run time statistics generation */
savedsource   sourceresultset
/* autogeneratedresultset for jdbc3. nulled after statement execution is over
(ie after it is saved off in localsatement object) */
if  activation getautogeneratedkeysresultsetmode
autogeneratedkeysresultset   autogeneratedkeysrowsholder getresultset
else
autogeneratedkeysresultset   null
cleanup
if  aicache    null
hashmap aihashtable   new hashmap
int numcolumns   aicache length
// this insert updated ai values, store them in some persistent
// place so that i can see these values.
for  int i   0  i < numcolumns  i
if  aicache    null
continue
aihashtable put autoincrementcounter makeidentity
constants getschemaname
constants gettablename
constants getcolumnname i
new long aicache getlong
internaltriggerexecutioncontext itec
internaltriggerexecutioncontext lcc gettriggerexecutioncontext
if  itec    null
lcc copyhashtabletoaiht aihashtable
else
itec copyhashtabletoaiht aihashtable
endtime   getcurrenttimemillis
/**
* clean up resources and call close on data members.
*/
public void close   throws standardexception
super close
if  autogeneratedkeysrowsholder    null
autogeneratedkeysrowsholder close
/**
* verify that the auto-generated columns list (by position) has valid
* column positions for the table.
*/
private void verifyautogeneratedcolumnsindexes int columnindexes
throws standardexception
int size   columnindexes length
tabledescriptor td   dd gettabledescriptor constants targetuuid
// all 1-based column ids.
for  int i   0  i < size  i
columndescriptor cd   td getcolumndescriptor columnindexes
if   verifyautogencolumn cd
throw standardexception newexception
sqlstate lang_invalid_autogen_column_position
new integer columnindexes   td getname
/**
* if user didn't provide columns list for auto-generated columns, then only include
* columns with auto-generated values in the resultset. those columns would be ones
* with default value defined.
*/
private int generatedcolumnpositionsarray
throws standardexception
tabledescriptor td   dd gettabledescriptor constants targetuuid
columndescriptor cd
int size   td getmaxcolumnid
int generatedcolumnpositionsarray   new int
int generatedcolumnnumbers   0
for  int i 0  i<size  i
generatedcolumnpositionsarray    1
for  int i 0  i<size  i
cd   td getcolumndescriptor i 1
if  cd isautoincrement        if the column has auto increment value
generatedcolumnnumbers
generatedcolumnpositionsarray   i 1
else if  cd getdefaultvalue      null    cd getdefaultinfo      null     default value
generatedcolumnnumbers
generatedcolumnpositionsarray   i 1
int returngeneratedcolumnpositionsarray   new int
for  int i 0  j 0  i<size  i
if  generatedcolumnpositionsarray     1
returngeneratedcolumnpositionsarray   generatedcolumnpositionsarray
return returngeneratedcolumnpositionsarray
/**
* remove duplicate columns from the array. then use this array to generate a sub-set
* of insert resultset to be returned for jdbc3.0 getgeneratedkeys() call.
*/
private int uniquecolumnpositionarray int columnindexes
throws standardexception
int size   columnindexes length
tabledescriptor td   dd gettabledescriptor constants targetuuid
//create an array of integer (the array size = number of columns in table)
// valid column positions are 1...getmaxcolumnid()
int uniquecolumnindexes   new int
int uniquecolumnnumbers   0
//at the end of following loop, the uniquecolumnindexes elements will not be 0 for user
//selected auto-generated columns.
for  int i 0  i<size  i
if  uniquecolumnindexes   1]    0
uniquecolumnnumbers
uniquecolumnindexes   1]   columnindexes
int returnuniquecolumnindexes   new int
//return just the column positions which are not marked 0 in the uniquecolumnindexes array
for  int i 0  j 0  i<uniquecolumnindexes length  i
if  uniquecolumnindexes    0
returnuniquecolumnindexes   uniquecolumnindexes
return returnuniquecolumnindexes
/**
* verify that the auto-generated columns list (by name) has valid
* column names for the table. if all the column names are valid,
* convert column names array to corresponding column positions array
* save that column positions array in activation. we do this to simplify the
* rest of the logic(it only has to deal with column positions here after).
*
* @exception standardexception		thrown on error if invalid column
* name in the list.
*/
private void verifyautogeneratedcolumnsnames string columnnames
throws standardexception
int size   columnnames length
int columnpositions   new int
tabledescriptor td   dd gettabledescriptor constants targetuuid
columndescriptor cd
for  int i   0  i < size  i
if  columnnames    null
throw standardexception newexception
sqlstate lang_invalid_autogen_column_name
columnnames  td getname
cd   td getcolumndescriptor columnnames
if   verifyautogencolumn cd
throw standardexception newexception
sqlstate lang_invalid_autogen_column_name
columnnames  td getname
columnpositions   cd getposition
activation setautogeneratedkeysresultsetinfo columnpositions  null
/**
* check that the received columndescriptor corresponds to a column
* for which it is possible to fetch auto-generated keys.
*/
private boolean verifyautogencolumn columndescriptor cd
/* derby currently gets generated keys by calling the
* identity_val_local() function (see "getgeneratedkeys()"
* as defined on embedstatement).  that function only
* considers autoincrement columns.  so if the column
* specified by the user is not autoincrement, we return
* false.
*/
return   cd    null     cd isautoincrement
/**
* @see resultset#getautogeneratedkeysresultset
*/
public resultset getautogeneratedkeysresultset
return autogeneratedkeysresultset
/**
* getsetautoincrementvalue will get the autoincrement value of the
* columnposition specified for the target table. if increment is
* non-zero we will also update the autoincrement value.
*
* @param columnposition	position of the column in the table (1-based)
* @param increment			amount of increment.
*
* @exception standardexception if anything goes wrong.
*/
public numberdatavalue
getsetautoincrementvalue int columnposition  long increment
throws standardexception
long startvalue   0
numberdatavalue dvd
int index   columnposition   1 	   all our indices are 0 based
/* as in db2, only for single row insert: insert into t1(c1) values (..) do
* we return the correct most recently generated identity column value.  for
* multiple row insert, or insert with sub-select, the return value is non-
* deterministic, and is the previous return value of the identity_val_local
* function, before the insert statement.  also, db2 can have at most 1 identity
* column per table.  the return value won't be affected either if derby
* table has more than one identity columns.
*/
setidentity      autoincrementgenerated     issourcerowresultset
autoincrementgenerated   true
if  bulkinsert
columndescriptor cd   td getcolumndescriptor columnposition
long ret
// for bulk insert we have the table descriptor
//			system.out.println("in bulk insert");
if  aicache isnull
if  bulkinsertreplace
startvalue   cd getautoincstart
else
dvd   dd getsetautoincrementvalue
constants autoincrowlocation
tc  false  aicache  true
startvalue   dvd getlong
lcc autoincrementcreatecounter td getschemaname
td getname
cd getcolumnname
new long startvalue
increment
columnposition
ret   lcc nextautoincrementvalue td getschemaname
td getname
cd getcolumnname
aicache setvalue ret
else
numberdatavalue newvalue
transactioncontroller nestedtc   null  tctouse   tc
try
nestedtc   tc startnestedusertransaction false
tctouse   nestedtc
catch  standardexception se
// if i cannot start a nested user transaction use the parent
// transaction to do all the work.
tctouse   tc
try
/* if tctouse == tc, then we are using parent xaction-- this
can happen if for some reason we couldn't start a nested
transaction
*/
newvalue   dd getsetautoincrementvalue
constants autoincrowlocation
tctouse  true  aicache   tctouse    tc
catch  standardexception se
if  tctouse    tc
/* we've using the parent xaction and we've timed out; just
throw an error and exit.
*/
throw se
if  se getmessageid   equals sqlstate lock_timeout
// if we couldn't do this with a nested xaction, retry with
// parent-- we need to wait this time!
newvalue   dd getsetautoincrementvalue
constants autoincrowlocation
tc  true  aicache  true
else if  se getmessageid   equals sqlstate lang_outside_range_for_datatype
// if we got an overflow error, throw a more meaningful
// error message
throw standardexception newexception
sqlstate lang_ai_overflow
se
constants gettablename
constants getcolumnname index
else throw se
finally
// no matter what, commit the nested transaction; if something
// bad happened in the child xaction lets not abort the parent
// here.
if  nestedtc    null
nestedtc commit
nestedtc destroy
aicache   newvalue
if  setidentity
identityval   newvalue getlong
return aicache
// is sourceresultset a rowresultset (values clause)?
private boolean issourcerowresultset
boolean isrow   false
if  sourceresultset instanceof normalizeresultset
isrow      normalizeresultset  sourceresultset  source instanceof rowresultset
return isrow
// checks if source result set is a rowresultset type.
private boolean issinglerowresultset
boolean isrow   false
if  sourceresultset instanceof rowresultset
isrow   true
else if  sourceresultset instanceof normalizeresultset
isrow      normalizeresultset  sourceresultset  source instanceof rowresultset
return isrow
// do the work for a "normal" insert
private void normalinsertcore languageconnectioncontext lcc  boolean firstexecute
throws standardexception
boolean setuseridentity   constants hasautoincrement      issinglerowresultset
boolean	firstdeferredrow   true
execrow	deferredrowbuffer   null
long user_autoinc 0
/* get or re-use the row changer.
* note: we need to set ourself as the top result set
* if this is not the 1st execution.  (done in constructor
* for 1st execution.)
*/
if  firstexecute
rowchanger   lcc getlanguageconnectionfactory   getexecutionfactory
getrowchanger
heapconglom
constants heapscoci
heapdcoci
constants irgs
constants indexcids
constants indexscocis
indexdcocis
0     number of columns in partial row meaningless for insert
tc
null    changed column ids
constants getstreamstorableheapcolids
activation
rowchanger setindexnames constants indexnames
else
lcc getstatementcontext   settopresultset this  subquerytrackingarray
/* decode lock mode for the execution isolation level */
int lockmode   decodelockmode constants lockmode
rowchanger open lockmode
/* the source does not know whether or not we are doing a
* deferred mode insert.  if we are, then we must clear the
* index scan info from the activation so that the row changer
* does not re-use that information (which won't be valid for
* a deferred mode insert).
*/
if  constants deferred
activation clearindexscaninfo
if  fkinfoarray    null
if  fkchecker    null
fkchecker   new risetchecker tc  fkinfoarray
else
fkchecker reopen
if  firstexecute    constants deferred
properties properties   new properties
// get the properties on the old heap
rowchanger getheapconglomeratecontroller   getinternaltablepropertyset properties
/*
** if deferred we save a copy of the entire row.
*/
rowholder   new temporaryrowholderimpl activation  properties
resultdescription
rowchanger setrowholder rowholder
int columnindexes   null
if  firstexecute    activation getautogeneratedkeysresultsetmode
resultdescription rd
properties properties   new properties
columnindexes   activation getautogeneratedkeyscolumnindexes
// get the properties on the old heap
rowchanger getheapconglomeratecontroller   getinternaltablepropertyset properties
if   columnindexes    null     use user provided column positions array
columnindexes   uniquecolumnpositionarray columnindexes
else     prepare array of auto generated keys for the table since user didn't provide any
columnindexes   generatedcolumnpositionsarray
rd   lcc getlanguagefactory   getresultdescription resultdescription columnindexes
autogeneratedkeysrowsholder
new temporaryrowholderimpl activation  properties  rd
while   row    null
if  activation getautogeneratedkeysresultsetmode
autogeneratedkeysrowsholder insert getcompactrow row  columnindexes
/*
** if we're doing a deferred insert, insert into the temporary
** conglomerate.  otherwise, insert directly into the permanent
** conglomerates using the rowchanger.
*/
if  constants deferred
rowholder insert row
else
// evaluate any check constraints on the row
evaluatecheckconstraints
if  fkchecker    null
fkchecker dofkcheck row
// objectify any streaming columns that are indexed.
if  constants irgs length > 0
datavaluedescriptor rowarray   row getrowarray
for  int i   0  i < rowarray length  i
//system.out.println("checking " + i);
if    constants indexedcols
continue
if  rowarray instanceof streamstorable
rowarray getobject
rowchanger insertrow row
rowcount
if setuseridentity
dd   lcc getdatadictionary
td   dd gettabledescriptor constants targetuuid
int maxcolumns   td getmaxcolumnid
int col
for col 1 col< maxcolumns col
columndescriptor cd   td getcolumndescriptor col
if cd isautoincrement
break
if col <  maxcolumns
datavaluedescriptor dvd   row clonecolumn col
user_autoinc   dvd getlong
// no need to do a next on a single row source
if  constants singlerowsource
row   null
else
row   getnextrowcore sourceresultset
/*
** if it's a deferred insert, scan the temporary conglomerate and
** insert the rows into the permanent conglomerates using rowchanger.
*/
if  constants deferred
if  triggerinfo    null
vector v   null
if  aicache    null
v   new vector
for  int i   0  i < aicache length  i
string s  t  c
if  aicache    null
continue
long initialvalue
lcc lastautoincrementvalue
s   constants getschemaname
t   constants gettablename
c   constants getcolumnname i
autoincrementcounter aic
new autoincrementcounter
initialvalue
constants getautoincincrement i
aicache getlong
s  t  c  i   1
v addelement aic
if  triggeractivator    null
triggeractivator   new triggereventactivator lcc
tc
constants targetuuid
triggerinfo
triggerexecutioncontext insert_event
activation
v
else
triggeractivator reopen
// fire before trigger, do this before checking constraints
triggeractivator notifyevent triggerevents before_insert
cursorresultset null
rowholder getresultset
cursorresultset rs   rowholder getresultset
try
rs open
while   deferredrowbuffer   rs getnextrow       null
// we have to set the source row so the check constraint
// sees the correct row.
sourceresultset setcurrentrow deferredrowbuffer
evaluatecheckconstraints
rowchanger insertrow deferredrowbuffer
finally
sourceresultset clearcurrentrow
rs close
if  fkchecker    null
/*
** second scan to make sure all the foreign key
** constraints are ok.  we have to do this after
** we have completed the inserts in case of self
** referencing constraints.
*/
rs   rowholder getresultset
try
rs open
while   deferredrowbuffer   rs getnextrow       null
fkchecker dofkcheck deferredrowbuffer
finally
rs close
// fire after trigger
if  triggeractivator    null
triggeractivator notifyevent triggerevents after_insert
cursorresultset null
rowholder getresultset
if  rowholder    null
rowholder close
// rowholder kept across opens
if  fkchecker    null
fkchecker close
fkchecker   null
if  setidentity
lcc setidentityvalue identityval
/*
* find the value of the identity column from the user inserted value
* and do a lcc.setidentityvalue(<user_value>);
*/
else if setuseridentity
lcc setidentityvalue user_autoinc
/**
* take the input row and return a new compact execrow
* using the column positions provided in columnindexes.
* copies references, no cloning.
*/
private execrow getcompactrow
execrow 					inputrow
int 						columnindexes
throws standardexception
execrow outrow
int numinputcols   inputrow ncolumns
if  columnindexes    null
outrow   new valuerow numinputcols
object src   inputrow getrowarray
object dst   outrow getrowarray
system arraycopy src  0  dst  0  src length
return outrow
int numoutputcols   columnindexes length
outrow   new valuerow numoutputcols
for  int i   0  i < numoutputcols  i
outrow setcolumn i 1
inputrow getcolumn columnindexes
return outrow
// do the work for a bulk insert
private long bulkinsertcore languageconnectioncontext lcc
long oldheapconglom
throws standardexception
fulltemplate   constants getemptyheaprow lcc
bulkheapcc   tc opencompiledconglomerate
false
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
constants heapscoci
heapdcoci
long newheapconglom
properties properties   new properties
// get the properties on the old heap
bulkheapcc getinternaltablepropertyset properties
if  triggerinfo    null
triggeractivator   new triggereventactivator lcc
tc
constants targetuuid
triggerinfo
triggerexecutioncontext insert_event
activation  null
/*
** if we have a before row trigger, then we
** are going to use a row holder pass to our
** trigger.
*/
if  hasbeforerowtrigger    rowholder    null
rowholder
new temporaryrowholderimpl activation  properties
resultdescription
// add any new properties or change the values of any existing properties
properties targetproperties   constants gettargetproperties
enumeration key   targetproperties keys
while  key hasmoreelements
string keyvalue    string  key nextelement
properties put keyvalue  targetproperties getproperty keyvalue
// are there indexes to be updated?
if  constants irgs length > 0
// tell source whether or not we need the rids back
sourceresultset setneedsrowlocation true
dd   lcc getdatadictionary
td   dd gettabledescriptor constants targetuuid
/* do the bulk insert - only okay to reuse the
* same conglomerate if bulkinsert.
*/
long loadedrowcount   new long
if  bulkinsertreplace
newheapconglom
tc createandloadconglomerate
fulltemplate getrowarray
null    column sort order   not required for heap
td getcolumncollationids
properties
transactioncontroller is_default
sourceresultset
loadedrowcount
else
newheapconglom
tc recreateandloadconglomerate
false
fulltemplate getrowarray
null    column sort order   not required for heap
td getcolumncollationids
properties
transactioncontroller is_default
oldheapconglom
sourceresultset
loadedrowcount
/* nothing else to do if we get back the same conglomerate number.
* (in 2.0 this means that 0 rows were inserted.)
*/
if  newheapconglom    oldheapconglom
return oldheapconglom
// find out how many rows were inserted
rowcount    int  loadedrowcount
// set the "estimated" row count
setestimatedrowcount newheapconglom
/*
** inform the data dictionary that we are about to write to it.
** there are several calls to data dictionary "get" methods here
** that might be done in "read" mode in the data dictionary, but
** it seemed safer to do this whole operation in "write" mode.
**
** we tell the data dictionary we're done writing at the end of
** the transaction.
*/
dd startwriting lcc
lcc autoincrementflushcache constants targetuuid
// invalidate any prepared statements that
// depended on this table (including this one)
dependencymanager dm   dd getdependencymanager
dm invalidatefor td  dependencymanager bulk_insert  lcc
// update all indexes
if  constants irgs length > 0
updateallindexes newheapconglom  constants  td  dd  fulltemplate
// drop the old conglomerate
bulkheapcc close
bulkheapcc   null
/* update the datadictionary
* resolve - this will change in 1.4 because we will get
* back the same conglomerate number
*/
// get the conglomeratedescriptor for the heap
conglomeratedescriptor cd   td getconglomeratedescriptor oldheapconglom
// update sys.sysconglomerates with new conglomerate #
dd updateconglomeratedescriptor cd  newheapconglom  tc
tc dropconglomerate oldheapconglom
// end resolve
return newheapconglom
/**
** bulk referential integrity checker
*/
private void bulkvalidateforeignkeys transactioncontroller tc  contextmanager cm
throws standardexception
fkinfo 			fkinfo
/*
** if there are no foreign keys, then nothing to worry
** about.
** with bulk insert replace, we still need to verify
** all non-self referencing foreign keys when
** there are no rows inserted into the table.
*/
if   indexrows    null     bulkinsertreplace
fkinfoarray    null
return
for  int i   0  i < fkinfoarray length  i
fkinfo   fkinfoarray
/* with regular bulk insert, we only need to check the
* foreign keys in the table we inserted into.  we need
* to get the new conglomerate #s for the foreign keys.
*
* with bulk insert replace, we need to check both the
* foreign keys in the table as well as any foreign keys
* on other tables referencing the table we inserted into.
* if the foreign key is self-referencing then we need to
* get the new conglomerate #, otherwise the conglomerate
* # is the same as the compile time conglomerate #.
* if the foreign key is self-referencing then we need to
* get the new conglomerate # for the primary key as it
* has changed.  however, if the foreign key is not self-referencing
* then we only need to get the new conglomerate # for
* the primary key if the primary key is on the table being
* inserted into.
*/
if  bulkinsertreplace
for  int index   0  index < fkinfo fkconglomnumbers length  index
/* no need to check foreign key if it is self referencing
* and there were no rows inserted on the replace, as both
* indexes will be empty.
*/
if  fkinfo fkisselfreferencing    indexrows    null
continue
long pkconglom
long fkconglom
if  fkinfo fkisselfreferencing
/* self-referencing foreign key.  both conglomerate
* #s have changed.
*/
pkconglom     long indexconversiontable get
new long fkinfo refconglomnumber    longvalue
fkconglom     long indexconversiontable get
new long fkinfo fkconglomnumbers    longvalue
else
/* non-self referencing foreign key.  at this point we
* don't know if the primary key or the foreign key is
* on this table.  so, for each one, we look to see
* if the old conglomerate # is in the conversion table.
* if so, then we get the new conglomerate #, otherwise
* we use the compile time conglomerate #.  this
* is very simple, though not very elegant.
*/
long pkconglomlong    long indexconversiontable get
new long fkinfo refconglomnumber
long fkconglomlong    long indexconversiontable get
new long fkinfo fkconglomnumbers
if  pkconglomlong    null
pkconglom   fkinfo refconglomnumber
else
pkconglom   pkconglomlong longvalue
if  fkconglomlong    null
fkconglom   fkinfo fkconglomnumbers
else
fkconglom   fkconglomlong longvalue
bulkvalidateforeignkeyscore
tc  cm  fkinfoarray  fkconglom  pkconglom
fkinfo fkconstraintnames
else
/*
** we have a fkinfo for each foreign key we are
** checking.  note that there are no primary key
** checks on insert, so we can always reference
** element[0] in the current fkinfo structure.
*/
if  sanitymanager debug
sanitymanager assert fkinfo type    fkinfo foreign_key
long fkconglom    long indexconversiontable get
new long fkinfo fkconglomnumbers
bulkvalidateforeignkeyscore
tc  cm  fkinfoarray  fkconglom longvalue
fkinfo refconglomnumber  fkinfo fkconstraintnames
private void bulkvalidateforeignkeyscore
transactioncontroller tc  contextmanager cm
fkinfo fkinfo  long fkconglom  long pkconglom
string fkconstraintname
throws standardexception
execrow 		            template
groupfetchscancontroller 	refscan   null
groupfetchscancontroller 	fkscan    null
try
template   makeindextemplate fkinfo  fulltemplate  cm
/*
** the indexes have been dropped and recreated, so
** we need to get the new index conglomerate number.
*/
fkscan
tc opengroupfetchscan
fkconglom
false                           hold
0  							    read only
tc mode_table 				    doesn't matter
//   already locked
tc isolation_read_committed     doesn't matter
//   already locked
formatablebitset null  				    retrieve all fields
datavaluedescriptor null     startkeyvalue
scancontroller ge               startsearchop
null                            qualifier
datavaluedescriptor null     stopkeyvalue
scancontroller gt               stopsearchop
if  sanitymanager debug
/*
** bulk insert replace calls this method regardless
** of whether or not any rows were inserted because
** it has to check any referencing foreign keys
** after the replace.  otherwise, we
** make sure that we actually have a row in the fk.
** if not, we have an error because we thought that
** since indexrows != null, we must have gotten some
** rows.
*/
if    bulkinsertreplace
sanitymanager assert fkscan next
/*
** crank up the scan again.
*/
fkscan reopenscan
datavaluedescriptor null        startkeyvalue
scancontroller ge                  startsearchop
null                               qualifier
datavaluedescriptor null        stopkeyvalue
scancontroller gt                  stopsearchop
/*
** open the referenced key scan.  use row locking on
** the referenced table unless it is self-referencing
** (in which case we don't need locks)
*/
refscan
tc opengroupfetchscan
pkconglom
false                        	   hold
0  								   read only
fkconglom    pkconglom  ?
tc mode_table
tc mode_record
tc isolation_read_committed 	   read committed is
//    good enough
formatablebitset null  					   retrieve all fields
datavaluedescriptor null        startkeyvalue
scancontroller ge             	   startsearchop
null                          	   qualifier
datavaluedescriptor null        stopkeyvalue
scancontroller gt             	   stopsearchop
/*
** give the scans to the bulk checker to do its
** magic.  it will do a merge on the two indexes.
*/
execrow firstfailedrow   template getclone
ribulkchecker richecker   new ribulkchecker refscan
fkscan
template
true  				   fail on 1st failure
conglomeratecontroller null
firstfailedrow
int numfailures   richecker docheck
if  numfailures > 0
standardexception se   standardexception newexception sqlstate lang_fk_violation  fkconstraintname
fkinfo tablename
statementutil typename fkinfo stmttype
rowutil tostring firstfailedrow  0  fkinfo colarray length   1
throw se
finally
if  fkscan    null
fkscan close
fkscan   null
if  refscan    null
refscan close
refscan   null
/**
* make a template row with the correct columns.
*/
private execrow makeindextemplate fkinfo fkinfo  execrow fulltemplate  contextmanager cm
throws standardexception
execrow newrow   rowutil getemptyindexrow fkinfo colarray length 1  lcc
datavaluedescriptor templatecolarray   fulltemplate getrowarray
datavaluedescriptor newrowcolarray     newrow getrowarray
int i
for  i   0  i < fkinfo colarray length  i
newrowcolarray
templatecolarray   1]  getclone
newrowcolarray
datavaluedescriptor  fkinfo rowlocation cloneobject
return newrow
/**
* set up to update all of the indexes on a table when doing a bulk insert
* on an empty table.
*
* @exception standardexception					thrown on error
*/
private void setupallsorts execrow sourcerow
rowlocation rl
throws standardexception
int					numindexes   constants irgs length
int					numcolumns   td getnumberofcolumns
ordering          new columnordering
collation         new int
needtodropsort    new boolean
sortids           new long
rowsources        new rowlocationretrowsource
// indexedcols is 1-based
indexedcols       new formatablebitset numcolumns   1
/* for each index, build a single index row, collation templage,
* and a sorter.
*/
for  int index   0  index < numindexes  index
// update the bit map of indexed columns
int keycolumns   constants irgs basecolumnpositions
for  int i2   0  i2 < keycolumns length  i2
// indexedcols is 1-based
indexedcols set keycolumns
// create a single index row template for each index
indexrows   constants irgs getindexrowtemplate
// get an index row based on the base row
// (this call is only necessary here because we need to
// pass a template to the sorter.)
constants irgs getindexrow sourcerow
rl
indexrows
formatablebitset  null
/* for non-unique indexes, we order by all columns + the rid.
* for unique indexes, we just order by the columns.
* we create a unique index observer for unique indexes
* so that we can catch duplicate key
*/
// get the conglomeratedescriptor for the index
conglomeratedescriptor cd
td getconglomeratedescriptor constants indexcids
int basecolumnpositions
constants irgs basecolumnpositions
boolean isascending       constants irgs isascending
int numcolumnorderings
sortobserver sortobserver   null
/* we can only reuse the wrappers when doing an
* external sort if there is only 1 index.  otherwise,
* we could get in a situation where 1 sort reuses a
* wrapper that is still in use in another sort.
*/
boolean reusewrappers    numindexes    1
if  cd getindexdescriptor   isunique
numcolumnorderings   basecolumnpositions length
string columnnames   getcolumnnames basecolumnpositions
string indexorconstraintname   cd getconglomeratename
if  cd isconstraint
// so, the index is backing up a constraint
constraintdescriptor condesc
dd getconstraintdescriptor td  cd getuuid
indexorconstraintname   condesc getconstraintname
sortobserver
new uniqueindexsortobserver
false     don't clone rows
cd isconstraint
indexorconstraintname
indexrows
reusewrappers
td getname
else
numcolumnorderings   basecolumnpositions length   1
sortobserver         new basicsortobserver false  false
indexrows
reusewrappers
ordering   new columnordering
for  int ii  0  ii < isascending length  ii
ordering   new indexcolumnorder ii  isascending
if  numcolumnorderings > isascending length
ordering
new indexcolumnorder isascending length
// set collation templates for later index creation
// call (createandloadconglomerate())
collation
constants irgs getcolumncollationids
td getcolumndescriptorlist
// create the sorters
sortids
tc createsort
properties null
indexrows getrowarrayclone
ordering
sortobserver
false 			                                not in order
int  sourceresultset getestimatedrowcount       est rows
1				   est row size   1 means no idea
needtodropsort   true
sorters   new sortcontroller
// open the sorts
for  int index   0  index < numindexes  index
sorters          tc opensort sortids
needtodropsort   true
/**
* update all of the indexes on a table when doing a bulk insert
* on an empty table.
*
* @exception standardexception					thrown on error
*/
private void updateallindexes long newheapconglom
insertconstantaction constants
tabledescriptor td
datadictionary dd
execrow fulltemplate
throws standardexception
int	numindexes   constants irgs length
/*
** if we didn't actually read in any rows, then
** we don't need to do anything, unless we were
** doing a replace.
*/
if  indexrows    null
if  bulkinsertreplace
emptyindexes newheapconglom  constants  td  dd  fulltemplate
return
dd dropstatisticsdescriptors td getuuid    null  tc
long newindexcongloms   new long
indexconversiontable   new hashtable numindexes
// populate each index
for  int index   0  index < numindexes  index
conglomeratecontroller indexcc
properties properties   new properties
conglomeratedescriptor cd
// get the conglomeratedescriptor for the index
cd   td getconglomeratedescriptor constants indexcids
// build the properties list for the new conglomerate
indexcc   tc opencompiledconglomerate
false
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
constants indexscocis
indexdcocis
// get the properties on the old index
indexcc getinternaltablepropertyset properties
/* create the properties that language supplies when creating the
* the index.  (the store doesn't preserve these.)
*/
int indexrowlength   indexrows ncolumns
properties put    long tostring newheapconglom
if  cd getindexdescriptor   isunique
properties put
integer tostring indexrowlength   1
else
properties put
integer tostring indexrowlength
properties put
integer tostring indexrowlength   1
properties put    integer tostring indexrowlength
indexcc close
// we can finally drain the sorter and rebuild the index
// resolve - all indexes are btrees right now
// populate the index.
sorters completedinserts
sorters   null
rowsources
new cardinalitycounter tc opensortrowsource sortids
newindexcongloms
tc createandloadconglomerate
indexrows getrowarray
ordering
collation
properties
transactioncontroller is_default
rowsources
long  null
cardinalitycounter ccount    cardinalitycounter rowsources
long numrows
if   numrows   ccount getrowcount    > 0
long c   ccount getcardinality
datadescriptorgenerator ddg   dd getdatadescriptorgenerator
for  int i  0  i < c length  i
statisticsdescriptor statdesc
new statisticsdescriptor dd  dd getuuidfactory   createuuid
cd getuuid    td getuuid
new
statisticsimpl numrows
c
i   1
dd adddescriptor statdesc  null
datadictionary sysstatistics_catalog_num
true  tc
/* update the datadictionary
* resolve - this will change in 1.4 because we will get
* back the same conglomerate number
*
* update sys.sysconglomerates with new conglomerate #, if the
* conglomerate is shared by duplicate indexes, all the descriptors
* for those indexes need to be updated with the new number.
*/
dd updateconglomeratedescriptor
td getconglomeratedescriptors constants indexcids
newindexcongloms  tc
// drop the old conglomerate
tc dropconglomerate constants indexcids
indexconversiontable put new long constants indexcids
new long newindexcongloms
/**
* @see resultset#cleanup
*
* @exception standardexception		thrown on error
*/
public void	cleanup   throws standardexception
if  tablescan    null
tablescan close
tablescan   null
if  triggeractivator    null
triggeractivator cleanup
// triggeractivator is reused across executions
/* close down the source resultset tree */
if  sourceresultset    null
sourceresultset close
// sourceresultset is reused across executions
numopens   0
if  rowchanger    null
rowchanger close
if  rowholder    null
rowholder close
if  fkchecker    null
fkchecker close
// fkchecker is reused across executions
if  bulkheapcc    null
bulkheapcc close
bulkheapcc   null
if  bulkheapsc    null
bulkheapsc close
bulkheapsc   null
// close each sorter
if  sorters    null
for  int index   0  index < constants irgs length  index
if  sorters    null
sorters completedinserts
sorters   null
if  needtodropsort    null
for  int index   0  index < needtodropsort length  index
if  needtodropsort
tc dropsort sortids
needtodropsort   false
if  rowsources    null
for  int index   0  index < rowsources length  index
if  rowsources    null
rowsources closerowsource
rowsources   null
super close
// class implementation
/**
* verify that bulkinsert is allowed on this table.
* the execution time check to see if bulkinsert is allowed
* simply consists of checking to see if this is not a deferred
* mode insert and that the table is empty if this is not replace.
*
* a side effect of calling this method is to get an exclusive
* table lock on the table.
*
* @return whether or not bulkinsert is allowed on this table.
*
* @exception standardexception		thrown on error
*/
protected boolean verifybulkinsert
throws standardexception
// bulk insert is disabled for deferred mode inserts
if  constants deferred
/* bulk insert replace should be disallowed for
* deferred mode inserts.
*/
if  sanitymanager debug
sanitymanager assert   bulkinsertreplace
return false
return getexclusivetablelock
/**
* get an exclusive table lock on the target table
* (and check to see if the table is populated if
* this is not a bulk insert replace).
*
* @return whether or not bulkinsert is allowed on this table.
*
* @exception standardexception		thrown on error
*/
private boolean getexclusivetablelock
throws standardexception
boolean rowfound   false
bulkheapsc   tc opencompiledscan
false
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
formatablebitset  null
datavaluedescriptor  null
0
qualifier  null
datavaluedescriptor  null
0
constants heapscoci
heapdcoci
/* no need to do next if bulk insert replace
* but we do need to get a row location for the
* case where the replace leaves an empty table.
*/
if    bulkinsertreplace
rowfound   bulkheapsc next
else
rl   bulkheapsc newrowlocationtemplate
bulkheapsc close
bulkheapsc   null
return   rowfound
/**
* set the estimated row count for this table.
*
* @param heapconglom	conglomerate number for the heap
*
* @exception standardexception		thrown on failure
*/
private void setestimatedrowcount long heapconglom
throws standardexception
bulkheapsc   tc opencompiledscan
false
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
formatablebitset  null
datavaluedescriptor  null
0
qualifier  null
datavaluedescriptor  null
0
constants heapscoci
heapdcoci
bulkheapsc setestimatedrowcount rowcount
bulkheapsc close
bulkheapsc   null
/**
* empty the indexes after doing a bulk insert replace
* where the table has 0 rows after the replace.
* resolve: this method is ugly!  prior to 2.0, we simply
* scanned back across the table to build the indexes.  we
* changed this in 2.0 to populate the sorters via a call back
* as we populated the table.  doing a 0 row replace into a
* table with indexes is a degenerate case, hence we allow
* ugly and unoptimized code.
*
* @exception standardexception		thrown on failure
*/
private void emptyindexes long newheapconglom
insertconstantaction constants
tabledescriptor td
datadictionary dd
execrow fulltemplate
throws standardexception
int					numindexes   constants irgs length
execindexrow		indexrows   new execindexrow
execrow				baserows   null
columnordering	ordering   new columnordering
int					numcolumns   td getnumberofcolumns
// create the bitset for mapping the partial row to the full row
formatablebitset bitset   new formatablebitset numcolumns   1
// need to check each index for referenced columns
int numreferencedcolumns   0
for  int index   0  index < numindexes  index
int basecolumnpositions   constants irgs basecolumnpositions
for  int bcp   0  bcp < basecolumnpositions length  bcp
if    bitset get basecolumnpositions
bitset set basecolumnpositions
numreferencedcolumns
// we can finally create the partial base row
baserows
activation getexecutionfactory   getvaluerow numreferencedcolumns
// fill in each base row with nulls of the correct data type
int colnumber   0
for  int index   0  index < numcolumns  index
if  bitset get index   1
colnumber
// note: 1-based column numbers
baserows setcolumn
colnumber
fulltemplate getcolumn index   1  getclone
needtodropsort   new boolean
sortids   new long
/* do the initial set up before scanning the heap.
* for each index, build a single index row and a sorter.
*/
for  int index   0  index < numindexes  index
// create a single index row template for each index
indexrows   constants irgs getindexrowtemplate
// get an index row based on the base row
// (this call is only necessary here because we need to pass a
// template to the sorter.)
constants irgs getindexrow baserows
rl
indexrows
bitset
/* for non-unique indexes, we order by all columns + the rid.
* for unique indexes, we just order by the columns.
* we create a unique index observer for unique indexes
* so that we can catch duplicate key
*/
conglomeratedescriptor cd
// get the conglomeratedescriptor for the index
cd   td getconglomeratedescriptor constants indexcids
int basecolumnpositions   constants irgs basecolumnpositions
boolean isascending   constants irgs isascending
int numcolumnorderings
sortobserver sortobserver   null
if  cd getindexdescriptor   isunique
numcolumnorderings   basecolumnpositions length
string columnnames   getcolumnnames basecolumnpositions
string indexorconstraintname   cd getconglomeratename
if  cd isconstraint
// so, the index is backing up a constraint
constraintdescriptor condesc
dd getconstraintdescriptor td  cd getuuid
indexorconstraintname   condesc getconstraintname
sortobserver
new uniqueindexsortobserver
false     don't clone rows
cd isconstraint
indexorconstraintname
indexrows
true
td getname
else
numcolumnorderings   basecolumnpositions length   1
sortobserver         new basicsortobserver false  false
indexrows
true
ordering   new columnordering
for  int ii  0  ii < isascending length  ii
ordering   new indexcolumnorder ii  isascending
if  numcolumnorderings > isascending length
ordering
new indexcolumnorder isascending length
// create the sorters
sortids
tc createsort
properties null
indexrows getrowarrayclone
ordering
sortobserver
false 			   not in order
rowcount 		   est rows
1				   est row size   1 means no idea
needtodropsort   true
// populate sorters and get the output of each sorter into a row
// source.  the sorters have the indexed columns only and the columns
// are in the correct order.
rowsources   new rowlocationretrowsource
// fill in the rowsources
sortcontroller	sorters   new sortcontroller
for  int index   0  index < numindexes  index
sorters   tc opensort sortids
sorters completedinserts
rowsources   tc opensortrowsource sortids
long newindexcongloms   new long
// populate each index
for  int index   0  index < numindexes  index
conglomeratecontroller indexcc
properties properties   new properties
conglomeratedescriptor cd
// get the conglomeratedescriptor for the index
cd   td getconglomeratedescriptor constants indexcids
// build the properties list for the new conglomerate
indexcc   tc opencompiledconglomerate
false
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
constants indexscocis
indexdcocis
// get the properties on the old index
indexcc getinternaltablepropertyset properties
/* create the properties that language supplies when creating the
* the index.  (the store doesn't preserve these.)
*/
int indexrowlength   indexrows ncolumns
properties put    long tostring newheapconglom
if  cd getindexdescriptor   isunique
properties put
integer tostring indexrowlength   1
else
properties put
integer tostring indexrowlength
properties put
integer tostring indexrowlength   1
properties put    integer tostring indexrowlength
indexcc close
// we can finally drain the sorter and rebuild the index
// populate the index.
newindexcongloms
tc createandloadconglomerate
indexrows getrowarray
null    default column sort order
collation
properties
transactioncontroller is_default
rowsources
long  null
/* update the datadictionary
*
* update sys.sysconglomerates with new conglomerate #, if the
* conglomerate is shared by duplicate indexes, all the descriptors
* for those indexes need to be updated with the new number.
*/
dd updateconglomeratedescriptor
td getconglomeratedescriptors constants indexcids
newindexcongloms  tc
// drop the old conglomerate
tc dropconglomerate constants indexcids
/**
* get me a table scan result set, preferably a bulk
* table scan, thank you.  if we already have one, reopen it.
*/
private bulktablescanresultset gettablescanresultset
long	conglomid
throws standardexception
if  tablescan    null
tablescan
new bulktablescanresultset
conglomid
tc getstaticcompiledconglominfo conglomid
activation
new myrowallocator fulltemplate  	   result row allocator
0 						   result set number
generatedmethod null  	   start key getter
0  						   start search operator
generatedmethod null 	   stop key getter
0  						   start search operator
false
qualifier null 	   qualifiers
string null
string null 			   index name
false 					   is constraint
false 					   for update
1 						   saved object for referenced bitimpl
1
tc mode_table
true 					   table locked
tc isolation_read_committed
languageproperties bulk_fetch_default_int 	   rows per read
false 					   not a 1 row per scan
0d 						   estimated rows
0d 					   estimated cost
tablescan opencore
else
tablescan reopencore
return tablescan
private string getcolumnnames int basecolumnpositions
int length   basecolumnpositions length
string columnnames   new string
for int i   0  i < length  i
columnnames   constants getcolumnname i
return columnnames
public void finish   throws standardexception
sourceresultset finish
super finish
// inner class to be our row template constructor
class myrowallocator implements generatedmethod
private execrow row
myrowallocator execrow row
this row   row
public object invoke object ref
return row getclone