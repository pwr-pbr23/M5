/*
file: concurrentreaderhashmap
written by doug lea. adapted and released, under explicit
permission, from jdk1.2 hashmap.java and hashtable.java which
carries the following copyright:
* copyright 1997 by sun microsystems, inc.,
* 901 san antonio road, palo alto, california, 94303, u.s.a.
* all rights reserved.
*
* this software is the confidential and proprietary information
* of sun microsystems, inc. ("confidential information").  you
* shall not disclose such confidential information and shall use
* it only in accordance with the terms of the license agreement
* you entered into with sun.
history:
date       who                what
28oct1999  dl               created
14dec1999  dl               jmm snapshot
19apr2000  dl               use barrierlock
12jan2001  dl               public release
17nov2001  dl               minor tunings
20may2002  dl               barrierlock can now be serialized.
09dec2002  dl               fix interference checks.
23jun2004  dl               avoid bad array sizings in view toarray methods
02jul2007  blackdrag        adaption of package name to groovy project
*/
package org codehaus groovy runtime metaclass
import java lang ref referencequeue
import java lang ref softreference
/**
* this map is astripped down version of concurrentreaderhashmap with
* small modifications here and there.
* it is no full map, it does have put/get/remove, but no iterators.
* this map is intended to hold values and keys as softreference. if
* one of value or key are removed, so will be complete entry. this map
* will not use the equals method to compare keys, think of it as a
* identityhashmap with features of concurrency and memory aware caching.
* as  concurrentreaderhashmap also does this implementation prefere read
* operations and tries not to lock if possible. softreferenced values
* are only removed from the map if the map goes into a synchronization
* block on this. this may affect reads, but only in rare cases.
**/
public class memoryawareconcurrentreadmap
/*
the basic strategy is an optimistic-style scheme based on
the guarantee that the hash table and its lists are always
kept in a consistent enough state to be read without locking:
* read operations first proceed without locking, by traversing the
apparently correct list of the apparently correct bin. if an
entry is found, but not invalidated (value field null), it is
returned. if not found, operations must recheck (after a memory
barrier) to make sure they are using both the right list and
the right table (which can change under resizes). if
invalidated, reads must acquire main update lock to wait out
the update, and then re-traverse.
* all list additions are at the front of each bin, making it easy
to check changes, and also fast to traverse.  entry next
pointers are never assigned. remove() builds new nodes when
necessary to preserve this.
* remove() (also clear()) invalidates removed nodes to alert read
operations that they must wait out the full modifications.
*/
/** a serializable class for barrier lock **/
protected static class barrierlock implements java io serializable
/**
* lock used only for its memory effects.
**/
protected final barrierlock barrierlock   new barrierlock
/**
* field written to only to guarantee lock ordering.
**/
protected transient object lastwrite
/**
* force a memory synchronization that will cause
* all readers to see table. call only when already
* holding main synch lock.
**/
protected final void recordmodification object x
synchronized barrierlock
lastwrite   x
/**
* get ref to table; the reference and the cells it
* accesses will be at least as fresh as from last
* use of barrierlock
**/
protected final entry gettableforreading
synchronized barrierlock
return table
/**
* the default initial number of table slots for this table (32).
* used when not otherwise specified in constructor.
**/
public static final int default_initial_capacity   32
/**
* the minimum capacity, used if a lower value is implicitly specified
* by either of the constructors with arguments.
* must be a power of two.
*/
private static final int minimum_capacity   4
/**
* the maximum capacity, used if a higher value is implicitly specified
* by either of the constructors with arguments.
* must be a power of two <= 1<<30.
*/
private static final int maximum_capacity   1 << 30
/**
* the default load factor for this table (1.0).
* used when not otherwise specified in constructor.
**/
public static final float default_load_factor   0 75f
/**
* the hash table data.
*/
protected transient entry table
/**
* the total number of mappings in the hash table.
*/
protected transient int count
/**
* the table is rehashed when its size exceeds this threshold.  (the
* value of this field is always (int)(capacity * loadfactor).)
*
* @serial
*/
protected int threshold
/**
* the load factor for the hash table.
*
* @serial
*/
protected float loadfactor
private referencequeue queue
/**
* returns the appropriate capacity (power of two) for the specified
* initial capacity argument.
*/
private int p2capacity int initialcapacity
int cap   initialcapacity
// compute the appropriate capacity
int result
if  cap > maximum_capacity    cap < 0
result   maximum_capacity
else
result   minimum_capacity
while  result < cap
result <<  1
return result
/**
* return hash code for object x. since we are using power-of-two
* tables, it is worth the effort to improve hashcode via
* the same multiplicative scheme as used in identityhashmap.
*/
private static int hash object x
int h   x hashcode
// multiply by 127 (quickly, via shifts), and mix in some high
// bits to help guard against bunching of codes that are
// consecutive or equally spaced.
return   h << 7    h    h >>> 9     h >>> 17
/**
* check for referential equality, null allowed
**/
protected boolean eq object x  object y
return x    y
/**
* constructs a new, empty map with the specified initial
* capacity and the specified load factor.
*
* @param initialcapacity the initial capacity
*  the actual initial capacity is rounded to the nearest power of two.
* @param loadfactor  the load factor of the concurrentreaderhashmap
* @throws illegalargumentexception  if the initial maximum number
*               of elements is less
*               than zero, or if the load factor is nonpositive.
*/
public memoryawareconcurrentreadmap int initialcapacity  float loadfactor
if  loadfactor <  0
throw new illegalargumentexception
loadfactor
this loadfactor   loadfactor
int cap   p2capacity initialcapacity
table   new entry
threshold    int  cap   loadfactor
queue   new referencequeue
/**
* constructs a new, empty map with the specified initial
* capacity and default load factor.
*
* @param   initialcapacity   the initial capacity of the
*                            concurrentreaderhashmap.
* @throws    illegalargumentexception if the initial maximum number
*              of elements is less
*              than zero.
*/
public memoryawareconcurrentreadmap int initialcapacity
this initialcapacity  default_load_factor
/**
* constructs a new, empty map with a default initial capacity
* and load factor.
*/
public memoryawareconcurrentreadmap
this default_initial_capacity  default_load_factor
/**
* returns the number of key-value mappings in this map.
*
* @return the number of key-value mappings in this map.
*/
public synchronized int size
return count
/**
* returns <tt>true</tt> if this map contains no key-value mappings.
*
* @return <tt>true</tt> if this map contains no key-value mappings.
*/
public synchronized boolean isempty
return count    0
/**
* returns the value to which the specified key is mapped in this table.
*
* @param   key   a key in the table.
* @return  the value to which the key is mapped in this table;
*          <code>null</code> if the key is not mapped to any value in
*          this table.
* @exception  nullpointerexception  if the key is
*               <code>null</code>.
* @see     #put(object, object)
*/
public object get object key
// throw null pointer exception if key null
int hash   hash key
/*
start off at the apparently correct bin.  if entry is found, we
need to check after a barrier anyway.  if not found, we need a
barrier to check if we are actually in right bin. so either
way, we encounter only one barrier unless we need to retry.
and we only need to fully synchronize if there have been
concurrent modifications.
*/
entry tab   table
int index   hash    tab length   1
entry first   tab
entry e   first
for
if  e    null
// if key apparently not there, check to
// make sure this was a valid read
entry reread   gettableforreading
if  tab    reread    first    tab
return null
else
// wrong list -- must restart traversal at new first
tab   reread
e   first   tab
continue
object ekey   e getkey
object evalue   e getvalue
if  e hash    hash    eq key  ekey
if  e value    dummy_ref  return evalue
// entry was invalidated during deletion. but it could
// have been re-inserted, so we must retraverse.
// to avoid useless contention, get lock to wait out modifications
// before retraversing.
synchronized this
if  ekey  null    evalue  null  expungestaleentries
tab   table
e   first   tab
else
e   e next
/**
* maps the specified <code>key</code> to the specified
* <code>value</code> in this table. neither the key nor the
* value can be <code>null</code>. <p>
*
* the value can be retrieved by calling the <code>get</code> method
* with a key that is equal to the original key.
*
* @param      key     the table key.
* @param      value   the value.
* @return     the previous value of the specified key in this table,
*             or <code>null</code> if it did not have one.
* @exception  nullpointerexception  if the key or value is
*               <code>null</code>.
* @see     #get(object)
*/
public object put object key  object value
if  value    null
throw new nullpointerexception
int hash   hash key
entry tab   table
int index   hash    tab length 1
entry first   tab
entry e
for  e   first  e    null  e   e next
if  e hash    hash    eq key  e getkey
break
synchronized this
if  tab    table
if  e    null
//  make sure we are adding to correct list
if  first    tab
//  add to front of list
entry newentry   new entry hash  key  value  first  queue
tab   newentry
if    count >  threshold  rehash
else recordmodification newentry
return null
else
object oldvalue   e getvalue
if  first    tab    oldvalue    null
e setvalue e value
return oldvalue
// retry if wrong list or lost race against concurrent remove
return sput key  value  hash
/**
* continuation of put(), called only when synch lock is
* held and interference has been detected.
**/
protected object sput object key  object value  int hash
expungestaleentries
entry tab   table
int index   hash    tab length 1
entry first   tab
entry e   first
for
if  e    null
entry newentry   new entry hash  key  value  first  queue
tab   newentry
if    count >  threshold  rehash
else recordmodification newentry
return null
else if  e hash    hash    eq key  e getkey
object oldvalue   e getvalue
e setvalue e value
return oldvalue
else
e   e next
/**
* rehashes the contents of this map into a new table
* with a larger capacity. this method is called automatically when the
* number of keys in this map exceeds its capacity and load factor.
*/
protected void rehash
entry oldtable   table
int oldcapacity   oldtable length
if  oldcapacity >  maximum_capacity
threshold   integer max_value     avoid retriggering
return
int newcapacity   oldcapacity << 1
int mask   newcapacity   1
threshold    int  newcapacity   loadfactor
entry newtable   new entry
/*
* reclassify nodes in each list to new map.  because we are
* using power-of-two expansion, the elements from each bin
* must either stay at same index, or move to
* oldcapacity+index. we also eliminate unnecessary node
* creation by catching cases where old nodes can be reused
* because their next fields won't change. statistically, at
* the default threshhold, only about one-sixth of them need
* cloning. (the nodes they replace will be garbage
* collectable as soon as they are no longer referenced by any
* reader thread that may be in the midst of traversing table
* right now.)
*/
for  int i   0  i < oldcapacity   i
// we need to guarantee that any existing reads of old map can
//  proceed. so we cannot yet null out each bin.
entry e   oldtable
if  e    null
int idx   e hash   mask
entry next   e next
//  single node on list
if  next    null
newtable   e
else
// reuse trailing consecutive sequence of all same bit
entry lastrun   e
int lastidx   idx
for  entry last   next  last    null  last   last next
int k   last hash   mask
if  k    lastidx
lastidx   k
lastrun   last
newtable   lastrun
// clone all remaining nodes
for  entry p   e  p    lastrun  p   p next
int k   p hash   mask
newtable   new entry p hash  p getkey
p getvalue    newtable  queue
table   newtable
recordmodification newtable
/**
* removes the key (and its corresponding value) from this
* table. this method does nothing if the key is not in the table.
*
* @param   key   the key that needs to be removed.
* @return  the value to which the key had been mapped in this table,
*          or <code>null</code> if the key did not have a mapping.
* @exception  nullpointerexception  if the key is
*               <code>null</code>.
*/
public object remove object key
/*
find the entry, then
1. set value field to null, to force get() to retry
2. rebuild the list without this entry.
all entries following removed node can stay in list, but
all preceeding ones need to be cloned.  traversals rely
on this strategy to ensure that elements will not be
repeated during iteration.
*/
int hash   hash key
entry tab   table
int index   hash    tab length 1
entry first   tab
entry e   first
for  e   first  e    null  e   e next
if  e hash    hash    eq key  e getkey
break
synchronized this
if  tab    table
if  e    null
if  first    tab
return null
else
object oldvalue   e getvalue
if  first    tab    oldvalue    null
e setvalue null
count
entry head   e next
for  entry p   first  p    e  p   p next
head   new entry p hash  p key  p value  head  queue
tab   head
recordmodification head
return oldvalue
// wrong list or interference
return sremove key  hash
/**
* continuation of remove(), called only when synch lock is
* held and interference has been detected.
**/
protected object sremove object key  int hash
expungestaleentries
entry tab   table
int index   hash    tab length 1
entry first   tab
for  entry e   first  e    null  e   e next
if  e hash    hash    eq key  e getkey
object oldvalue   e getvalue
e setvalue null
count
entry head   e next
for  entry p   first  p    e  p   p next
head   new entry p hash  p getkey    p getvalue    head  queue
tab   head
recordmodification head
return oldvalue
return null
/**
* removes all mappings from this map.
*/
public synchronized void clear
entry tab   table
for  int i   0  i < tab length     i
// must invalidate all to force concurrent get's to wait and then retry
for  entry e   tab  e    null  e   e next
e setvalue null
tab   null
count   0
recordmodification tab
/**
* removes entries from the referencequeue for keys and values
* of this map. this method is thought to be called only with
* an already existing lock on "this".
*
* the method expects softref instances in the queue. it uses
* the entry field to control if the entry is already removed
* map. if the entry is null the removal is skipped.
*/
private void expungestaleentries
softref ref
entry tab   table
while   ref  softref queue poll     null
entry entry   ref entry
// if entry== null, then it is already deleted
// form the map
if  entry    null  continue
ref entry   null
// if neither entry.key nor entry.value == ref then
// the entry was reused, but the value has become invalid
if  entry key  ref    entry value  ref  continue
int hash   entry hash
int index   hash    tab length 1
entry first   tab
for  entry e   first  e    null  e   e next
if  e  entry
entry key clear
entry setvalue null
count
entry head   e next
for  entry p   first  p    e  p   p next
head   new entry p hash  p key  p value  head
tab   head
recordmodification head
break
/**
* reference class used to support get()
*/
private static interface reference
object get
/**
* a dummy to replace the softreference if needed
*/
private static class dummyref implements reference
public object get
return null
// constant for dummyref, no need to keep more than one
// it is not critical if more than one is created here
private static final reference dummy_ref   new dummyref
/**
* a softreference representing a key or value of the map. the
* instance keeps a pointer to the entry it is sotring a
* key or value for. this is used to identify the entry we
* need to remove
* @see copyofmemoryawareconcurrentreadmap#expungestaleentries()
*/
private static class softref extends softreference implements reference
private volatile entry entry
public softref entry e  object v  referencequeue q
super v q
entry   e
public void clear
super clear
entry null
/**
* concurrentreaderhashmap collision list entry.
*/
private static class entry
/*
the use of volatile for value field ensures that
we can detect status changes without synchronization.
the other fields are never changed, and are
marked as final.
*/
private final int hash
private final softref key
private final entry next
private volatile reference value
entry int hash  object key  object value  entry next  referencequeue queue
this hash   hash
this key   new softref this key queue
this next   next
this value   new softref this value queue
entry int hash  softref key  reference value  entry next
this hash   hash
this key   key
key entry   this
this next   next
this value   dummy_ref
this setvalue value
// map.entry ops
public object getkey
return key get
public object getvalue
return value get
public object setvalue reference value
object oldvalue   this value get
if  value    null    value    dummy_ref
this value   dummy_ref
else
softref ref    softref  value
ref entry   this
this value   value
return oldvalue