/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*      http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache activemq store kahadb
import java io bytearrayinputstream
import java io bytearrayoutputstream
import java io datainput
import java io dataoutput
import java io eofexception
import java io file
import java io ioexception
import java io inputstream
import java io interruptedioexception
import java io objectinputstream
import java io objectoutputstream
import java io outputstream
import java util arraylist
import java util arrays
import java util collection
import java util collections
import java util date
import java util hashmap
import java util hashset
import java util iterator
import java util linkedhashmap
import java util linkedhashset
import java util list
import java util map
import java util map entry
import java util set
import java util sortedset
import java util stack
import java util treemap
import java util treeset
import java util concurrent atomic atomicboolean
import java util concurrent atomic atomiclong
import java util concurrent locks reentrantreadwritelock
import org apache activemq activemqmessageauditnosync
import org apache activemq broker brokerservice
import org apache activemq broker brokerserviceaware
import org apache activemq command messageack
import org apache activemq command subscriptioninfo
import org apache activemq command transactionid
import org apache activemq protobuf buffer
import org apache activemq store kahadb data kahaaddmessagecommand
import org apache activemq store kahadb data kahacommitcommand
import org apache activemq store kahadb data kahadestination
import org apache activemq store kahadb data kahaentrytype
import org apache activemq store kahadb data kahapreparecommand
import org apache activemq store kahadb data kahaproducerauditcommand
import org apache activemq store kahadb data kaharemovedestinationcommand
import org apache activemq store kahadb data kaharemovemessagecommand
import org apache activemq store kahadb data kaharollbackcommand
import org apache activemq store kahadb data kahasubscriptioncommand
import org apache activemq store kahadb data kahatracecommand
import org apache activemq store kahadb data kahatransactioninfo
import org apache activemq store kahadb disk index btreeindex
import org apache activemq store kahadb disk index btreevisitor
import org apache activemq store kahadb disk index listindex
import org apache activemq store kahadb disk journal datafile
import org apache activemq store kahadb disk journal journal
import org apache activemq store kahadb disk journal location
import org apache activemq store kahadb disk page page
import org apache activemq store kahadb disk page pagefile
import org apache activemq store kahadb disk page transaction
import org apache activemq store kahadb disk util locationmarshaller
import org apache activemq store kahadb disk util longmarshaller
import org apache activemq store kahadb disk util marshaller
import org apache activemq store kahadb disk util sequence
import org apache activemq store kahadb disk util sequenceset
import org apache activemq store kahadb disk util stringmarshaller
import org apache activemq store kahadb disk util variablemarshaller
import org apache activemq util bytesequence
import org apache activemq util callback
import org apache activemq util databytearrayinputstream
import org apache activemq util databytearrayoutputstream
import org apache activemq util iohelper
import org apache activemq util servicestopper
import org apache activemq util servicesupport
import org slf4j logger
import org slf4j loggerfactory
public abstract class messagedatabase extends servicesupport implements brokerserviceaware
protected brokerservice brokerservice
public static final string property_log_slow_access_time
public static final int log_slow_access_time   integer getinteger property_log_slow_access_time  0
public static final file default_directory   new file
protected static final buffer unmatched
static
unmatched   new buffer new byte
private static final logger log   loggerfactory getlogger messagedatabase class
private static final int default_database_locked_wait_delay   10   1000
static final int closed_state   1
static final int open_state   2
static final long not_acked    1
static final int version   4
protected class metadata
protected page<metadata> page
protected int state
protected btreeindex<string  storeddestination> destinations
protected location lastupdate
protected location firstinprogresstransactionlocation
protected location producersequenceidtrackerlocation   null
protected transient activemqmessageauditnosync producersequenceidtracker   new activemqmessageauditnosync
protected int version   version
public void read datainput is  throws ioexception
state   is readint
destinations   new btreeindex<string  storeddestination> pagefile  is readlong
if  is readboolean
lastupdate   locationmarshaller instance readpayload is
else
lastupdate   null
if  is readboolean
firstinprogresstransactionlocation   locationmarshaller instance readpayload is
else
firstinprogresstransactionlocation   null
try
if  is readboolean
producersequenceidtrackerlocation   locationmarshaller instance readpayload is
else
producersequenceidtrackerlocation   null
catch  eofexception expectedonupgrade
try
version   is readint
catch  eofexception expectedonupgrade
version 1
log info     version
public void write dataoutput os  throws ioexception
os writeint state
os writelong destinations getpageid
if  lastupdate    null
os writeboolean true
locationmarshaller instance writepayload lastupdate  os
else
os writeboolean false
if  firstinprogresstransactionlocation    null
os writeboolean true
locationmarshaller instance writepayload firstinprogresstransactionlocation  os
else
os writeboolean false
if  producersequenceidtrackerlocation    null
os writeboolean true
locationmarshaller instance writepayload producersequenceidtrackerlocation  os
else
os writeboolean false
os writeint version
class metadatamarshaller extends variablemarshaller<metadata>
@override
public metadata readpayload datainput datain  throws ioexception
metadata rc   new metadata
rc read datain
return rc
@override
public void writepayload metadata object  dataoutput dataout  throws ioexception
object write dataout
protected pagefile pagefile
protected journal journal
protected metadata metadata   new metadata
protected metadatamarshaller metadatamarshaller   new metadatamarshaller
protected boolean failifdatabaseislocked
protected boolean deleteallmessages
protected file directory   default_directory
protected thread checkpointthread
protected boolean enablejournaldisksyncs true
protected boolean archivedatalogs
protected file directoryarchive
protected atomiclong journalsize   new atomiclong 0
long checkpointinterval   5 1000
long cleanupinterval   30 1000
int journalmaxfilelength   journal default_max_file_length
int journalmaxwritebatchsize   journal default_max_write_batch_size
boolean enableindexwriteasync   false
int setindexwritebatchsize   pagefile default_write_batch_size
protected atomicboolean opened   new atomicboolean
private boolean ignoremissingjournalfiles   false
private int indexcachesize   10000
private boolean checkforcorruptjournalfiles   false
private boolean checksumjournalfiles   false
protected boolean forcerecoverindex   false
private final object checkpointthreadlock   new object
private boolean rewriteonredelivery   false
private boolean archivecorruptedindex   false
private boolean useindexlfrueviction   false
private float indexlfuevictionfactor   0 2f
private boolean enableindexdisksyncs   true
private boolean enableindexrecoveryfile   true
private boolean enableindexpagecaching   true
public messagedatabase
@override
public void dostart   throws exception
load
@override
public void dostop servicestopper stopper  throws exception
unload
private void loadpagefile   throws ioexception
this indexlock writelock   lock
try
final pagefile pagefile   getpagefile
pagefile load
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
if  pagefile getpagecount      0
// first time this is created.. initialize the metadata
page<metadata> page   tx allocate
assert page getpageid      0
page set metadata
metadata page   page
metadata state   closed_state
metadata destinations   new btreeindex<string  storeddestination> pagefile  tx allocate   getpageid
tx store metadata page  metadatamarshaller  true
else
page<metadata> page   tx load 0  metadatamarshaller
metadata   page get
metadata page   page
metadata destinations setkeymarshaller stringmarshaller instance
metadata destinations setvaluemarshaller new storeddestinationmarshaller
metadata destinations load tx
// load up all the destinations since we need to scan all the indexes to figure out which journal files can be deleted.
// perhaps we should just keep an index of file
storeddestinations clear
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
for  iterator<entry<string  storeddestination>> iterator   metadata destinations iterator tx   iterator hasnext
entry<string  storeddestination> entry   iterator next
storeddestination sd   loadstoreddestination tx  entry getkey    entry getvalue   subscriptions  null
storeddestinations put entry getkey    sd
pagefile flush
finally
this indexlock writelock   unlock
private void startcheckpoint
if  checkpointinterval    0     cleanupinterval    0
log info
return
synchronized  checkpointthreadlock
boolean start   false
if  checkpointthread    null
start   true
else if   checkpointthread isalive
start   true
log info
if  start
checkpointthread   new thread
@override
public void run
try
long lastcleanup   system currenttimemillis
long lastcheckpoint   system currenttimemillis
// sleep for a short time so we can periodically check
// to see if we need to exit this thread.
long sleeptime   math min checkpointinterval > 0 ? checkpointinterval   cleanupinterval  500
while  opened get
thread sleep sleeptime
long now   system currenttimemillis
if  cleanupinterval > 0     now   lastcleanup >  cleanupinterval
checkpointcleanup true
lastcleanup   now
lastcheckpoint   now
else if  checkpointinterval > 0     now   lastcheckpoint >  checkpointinterval
checkpointcleanup false
lastcheckpoint   now
catch  interruptedexception e
// looks like someone really wants us to exit this thread...
catch  ioexception ioe
log error    ioe
brokerservice handleioexception ioe
checkpointthread setdaemon true
checkpointthread start
public void open   throws ioexception
if  opened compareandset false  true
getjournal   start
try
loadpagefile
catch  throwable t
log warn     t
if  log isdebugenabled
log debug    t
// try to recover index
try
pagefile unload
catch  exception ignore
if  archivecorruptedindex
pagefile archive
else
pagefile delete
metadata   new metadata
pagefile   null
loadpagefile
startcheckpoint
recover
public void load   throws ioexception
this indexlock writelock   lock
iohelper mkdirs directory
try
if  deleteallmessages
getjournal   start
getjournal   delete
getjournal   close
journal   null
getpagefile   delete
log info
deleteallmessages   false
open
store new kahatracecommand   setmessage     new date
finally
this indexlock writelock   unlock
public void close   throws ioexception  interruptedexception
if  opened compareandset true  false
this indexlock writelock   lock
try
if  metadata page    null
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
checkpointupdate tx  true
pagefile unload
metadata   new metadata
finally
this indexlock writelock   unlock
journal close
synchronized  checkpointthreadlock
if  checkpointthread    null
checkpointthread join
public void unload   throws ioexception  interruptedexception
this indexlock writelock   lock
try
if  pagefile    null    pagefile isloaded
metadata state   closed_state
metadata firstinprogresstransactionlocation   getinprogresstxlocationrange
if  metadata page    null
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
tx store metadata page  metadatamarshaller  true
finally
this indexlock writelock   unlock
close
// public for testing
@suppresswarnings
public location getinprogresstxlocationrange
location range   new location null  null
synchronized  inflighttransactions
if   inflighttransactions isempty
for  list<operation> ops   inflighttransactions values
if   ops isempty
trackmaxandmin range  ops
if   preparedtransactions isempty
for  list<operation> ops   preparedtransactions values
if   ops isempty
trackmaxandmin range  ops
return range
private void trackmaxandmin location range  list<operation> ops
location t   ops get 0  getlocation
if  range  null    t compareto range  <  0
range   t
t   ops get ops size    1  getlocation
if  range  null    t compareto range  >  0
range   t
class traninfo
transactionid id
location location
class opcount
int add
int remove
hashmap<kahadestination  opcount> destinationopcount   new hashmap<kahadestination  opcount>
public void track operation operation
if  location    null
location   operation getlocation
kahadestination destination
boolean isadd   false
if  operation instanceof addopperation
addopperation add    addopperation  operation
destination   add getcommand   getdestination
isadd   true
else
removeopperation removeopperation    removeopperation  operation
destination   removeopperation getcommand   getdestination
opcount opcount   destinationopcount get destination
if  opcount    null
opcount   new opcount
destinationopcount put destination  opcount
if  isadd
opcount add
else
opcount remove
@override
public string tostring
stringbuffer buffer   new stringbuffer
buffer append location  append    append id  append
for  entry<kahadestination  opcount> op   destinationopcount entryset
buffer append op getkey    append    append op getvalue   add  append    append    append op getvalue   remove  append
return buffer tostring
@suppresswarnings
public string gettransactions
arraylist<traninfo> infos   new arraylist<traninfo>
synchronized  inflighttransactions
if   inflighttransactions isempty
for  entry<transactionid  list<operation>> entry   inflighttransactions entryset
traninfo info   new traninfo
info id   entry getkey
for  operation operation   entry getvalue
info track operation
infos add info
return infos tostring
/**
* move all the messages that were in the journal into long term storage. we
* just replay and do a checkpoint.
*
* @throws ioexception
* @throws ioexception
* @throws illegalstateexception
*/
private void recover   throws illegalstateexception  ioexception
this indexlock writelock   lock
try
long start   system currenttimemillis
location producerauditposition   recoverproduceraudit
location lastindoubtposition   getrecoveryposition
location recoveryposition   minimum producerauditposition  lastindoubtposition
if  recoveryposition    null
int redocounter   0
log info
while  recoveryposition    null
journalcommand<?> message   load recoveryposition
metadata lastupdate   recoveryposition
process message  recoveryposition  lastindoubtposition
redocounter
recoveryposition   journal getnextlocation recoveryposition
if  log isinfoenabled      redocounter % 100000    0
log info     recoveryposition         redocounter
if  log isinfoenabled
long end   system currenttimemillis
log info     redocounter         end   start    1000 0f
// we may have to undo some index updates.
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
recoverindex tx
// rollback any recovered inflight local transactions
set<transactionid> torollback   new hashset<transactionid>
synchronized  inflighttransactions
for  iterator<transactionid> it   inflighttransactions keyset   iterator    it hasnext
transactionid id   it next
if  id islocaltransaction
torollback add id
for  transactionid tx  torollback
if  log isdebugenabled
log debug     tx
store new kaharollbackcommand   settransactioninfo transactionidconversion converttolocal tx    false  null  null
finally
this indexlock writelock   unlock
@suppresswarnings
private kahatransactioninfo createlocaltransactioninfo transactionid tx
return transactionidconversion converttolocal tx
private location minimum location producerauditposition
location lastindoubtposition
location min   null
if  producerauditposition    null
min   producerauditposition
if  lastindoubtposition    null    lastindoubtposition compareto producerauditposition  < 0
min   lastindoubtposition
else
min   lastindoubtposition
return min
private location recoverproduceraudit   throws ioexception
if  metadata producersequenceidtrackerlocation    null
kahaproducerauditcommand audit    kahaproducerauditcommand  load metadata producersequenceidtrackerlocation
try
objectinputstream objectin   new objectinputstream audit getaudit   newinput
metadata producersequenceidtracker    activemqmessageauditnosync  objectin readobject
return journal getnextlocation metadata producersequenceidtrackerlocation
catch  exception e
log warn    e
return journal getnextlocation null
else
// got no audit stored so got to recreate via replay from start of the journal
return journal getnextlocation null
protected void recoverindex transaction tx  throws ioexception
long start   system currenttimemillis
// it is possible index updates got applied before the journal updates..
// in that case we need to removed references to messages that are not in the journal
final location lastappendlocation   journal getlastappendlocation
long undocounter 0
// go through all the destinations to see if they have messages past the lastappendlocation
for  storeddestination sd   storeddestinations values
final arraylist<long> matches   new arraylist<long>
// find all the locations that are >= than the last append location.
sd locationindex visit tx  new btreevisitor gtevisitor<location  long> lastappendlocation
@override
protected void matched location key  long value
matches add value
for  long sequenceid   matches
messagekeys keys   sd orderindex remove tx  sequenceid
sd locationindex remove tx  keys location
sd messageidindex remove tx  keys messageid
metadata producersequenceidtracker rollback keys messageid
undocounter
// todo: do we need to modify the ack positions for the pub sub case?
if  undocounter > 0
// the rolledback operations are basically in flight journal writes.  to avoid getting
// these the end user should do sync writes to the journal.
if  log isinfoenabled
long end   system currenttimemillis
log info     undocounter         end   start    1000 0f
undocounter   0
start   system currenttimemillis
// lets be extra paranoid here and verify that all the datafiles being referenced
// by the indexes still exists.
final sequenceset ss   new sequenceset
for  storeddestination sd   storeddestinations values
// use a visitor to cut down the number of pages that we load
sd locationindex visit tx  new btreevisitor<location  long>
int last  1
@override
public boolean isinterestedinkeysbetween location first  location second
if  first  null
return  ss contains 0  second getdatafileid
else if  second  null
return true
else
return  ss contains first getdatafileid    second getdatafileid
@override
public void visit list<location> keys  list<long> values
for  location l   keys
int fileid   l getdatafileid
if  last    fileid
ss add fileid
last   fileid
hashset<integer> missingjournalfiles   new hashset<integer>
while   ss isempty
missingjournalfiles add  int  ss removefirst
missingjournalfiles removeall journal getfilemap   keyset
if   missingjournalfiles isempty
if  log isinfoenabled
log info     missingjournalfiles
arraylist<btreevisitor predicate<location>> missingpredicates   new arraylist<btreevisitor predicate<location>>
for  integer missing   missingjournalfiles
missingpredicates add new btreevisitor betweenvisitor<location  long> new location missing  0   new location missing   1  0
if  checkforcorruptjournalfiles
collection<datafile> datafiles   journal getfilemap   values
for  datafile datafile   datafiles
int id   datafile getdatafileid
missingpredicates add new btreevisitor betweenvisitor<location  long> new location id  datafile getlength     new location id   1  0
sequence seq   datafile getcorruptedblocks   gethead
while  seq    null
missingpredicates add new btreevisitor betweenvisitor<location  long> new location id   int  seq getfirst     new location id   int  seq getlast     1
seq   seq getnext
if   missingpredicates isempty
for  storeddestination sd   storeddestinations values
final arraylist<long> matches   new arraylist<long>
sd locationindex visit tx  new btreevisitor orvisitor<location  long> missingpredicates
@override
protected void matched location key  long value
matches add value
// if somes message references are affected by the missing data files...
if   matches isempty
// we either 'gracefully' recover dropping the missing messages or
// we error out.
if  ignoremissingjournalfiles
// update the index to remove the references to the missing data
for  long sequenceid   matches
messagekeys keys   sd orderindex remove tx  sequenceid
sd locationindex remove tx  keys location
sd messageidindex remove tx  keys messageid
undocounter
// todo: do we need to modify the ack positions for the pub sub case?
else
throw new ioexception   matches size
if  undocounter > 0
// the rolledback operations are basically in flight journal writes.  to avoid getting these the end user
// should do sync writes to the journal.
if  log isinfoenabled
long end   system currenttimemillis
log info     undocounter         end   start    1000 0f
private location nextrecoveryposition
private location lastrecoveryposition
public void incrementalrecover   throws ioexception
this indexlock writelock   lock
try
if  nextrecoveryposition    null
if  lastrecoveryposition  null
nextrecoveryposition   getrecoveryposition
else
nextrecoveryposition   journal getnextlocation lastrecoveryposition
while  nextrecoveryposition    null
lastrecoveryposition   nextrecoveryposition
metadata lastupdate   lastrecoveryposition
journalcommand<?> message   load lastrecoveryposition
process message  lastrecoveryposition   runnable null
nextrecoveryposition   journal getnextlocation lastrecoveryposition
finally
this indexlock writelock   unlock
public location getlastupdateposition   throws ioexception
return metadata lastupdate
private location getrecoveryposition   throws ioexception
if   this forcerecoverindex
// if we need to recover the transactions..
if  metadata firstinprogresstransactionlocation    null
return metadata firstinprogresstransactionlocation
// perhaps there were no transactions...
if  metadata lastupdate  null
// start replay at the record after the last one recorded in the index file.
return journal getnextlocation metadata lastupdate
// this loads the first position.
return journal getnextlocation null
protected void checkpointcleanup final boolean cleanup  throws ioexception
long start
this indexlock writelock   lock
try
start   system currenttimemillis
if   opened get
return
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
checkpointupdate tx  cleanup
finally
this indexlock writelock   unlock
long end   system currenttimemillis
if  log_slow_access_time > 0    end   start > log_slow_access_time
if  log isinfoenabled
log info      end   start
public void checkpoint callback closure  throws exception
this indexlock writelock   lock
try
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
checkpointupdate tx  false
closure execute
finally
this indexlock writelock   unlock
public bytesequence tobytesequence journalcommand<?> data  throws ioexception
int size   data serializedsizeframed
databytearrayoutputstream os   new databytearrayoutputstream size   1
os writebyte data type   getnumber
data writeframed os
return os tobytesequence
// /////////////////////////////////////////////////////////////////
// methods call by the broker to update and query the store.
// /////////////////////////////////////////////////////////////////
public location store journalcommand<?> data  throws ioexception
return store data  false  null null
public location store journalcommand<?> data  runnable onjournalstorecomplete  throws ioexception
return store data  false  null null  onjournalstorecomplete
public location store journalcommand<?> data  boolean sync  runnable before runnable after  throws ioexception
return store data  sync  before  after  null
/**
* all updated are are funneled through this method. the updates are converted
* to a journalmessage which is logged to the journal and then the data from
* the journalmessage is used to update the index just like it would be done
* during a recovery process.
*/
public location store journalcommand<?> data  boolean sync  runnable before runnable after  runnable onjournalstorecomplete  throws ioexception
if  before    null
before run
try
bytesequence sequence   tobytesequence data
long start   system currenttimemillis
location location   onjournalstorecomplete    null ? journal write sequence  sync     journal write sequence  onjournalstorecomplete
long start2   system currenttimemillis
process data  location  after
long end   system currenttimemillis
if  log_slow_access_time>0    end start > log_slow_access_time
if  log isinfoenabled
log info    start2 start     end start2
if  after    null
runnable aftercompletion   null
synchronized  orderedtransactionafters
if   orderedtransactionafters empty
aftercompletion   orderedtransactionafters pop
if  aftercompletion    null
aftercompletion run
else
// non persistent message case
after run
if  checkpointthread    null     checkpointthread isalive
startcheckpoint
return location
catch  ioexception ioe
log error    ioe
brokerservice handleioexception ioe
throw ioe
/**
* loads a previously stored journalmessage
*
* @param location
* @return
* @throws ioexception
*/
public journalcommand<?> load location location  throws ioexception
long start   system currenttimemillis
bytesequence data   journal read location
long end   system currenttimemillis
if  log_slow_access_time>0    end start > log_slow_access_time
if  log isinfoenabled
log info    end start
databytearrayinputstream is   new databytearrayinputstream data
byte readbyte   is readbyte
kahaentrytype type   kahaentrytype valueof readbyte
if  type    null
throw new ioexception   location
journalcommand<?> message    journalcommand<?> type createmessage
message mergeframed is
return message
/**
* do minimal recovery till we reach the last indoubtlocation
* @param data
* @param location
* @param indoubtlocation
* @throws ioexception
*/
void process journalcommand<?> data  final location location  final location indoubtlocation  throws ioexception
if  indoubtlocation    null    location compareto indoubtlocation  >  0
process data  location   runnable  null
else
// just recover producer audit
data visit new visitor
@override
public void visit kahaaddmessagecommand command  throws ioexception
metadata producersequenceidtracker isduplicate command getmessageid
// /////////////////////////////////////////////////////////////////
// journaled record processing methods. once the record is journaled,
// these methods handle applying the index updates. these may be called
// from the recovery method too so they need to be idempotent
// /////////////////////////////////////////////////////////////////
void process journalcommand<?> data  final location location  final runnable after  throws ioexception
data visit new visitor
@override
public void visit kahaaddmessagecommand command  throws ioexception
process command  location
@override
public void visit kaharemovemessagecommand command  throws ioexception
process command  location
@override
public void visit kahapreparecommand command  throws ioexception
process command  location
@override
public void visit kahacommitcommand command  throws ioexception
process command  location  after
@override
public void visit kaharollbackcommand command  throws ioexception
process command  location
@override
public void visit kaharemovedestinationcommand command  throws ioexception
process command  location
@override
public void visit kahasubscriptioncommand command  throws ioexception
process command  location
@override
public void visit kahaproducerauditcommand command  throws ioexception
processlocation location
@override
public void visit kahatracecommand command
processlocation location
@suppresswarnings
protected void process final kahaaddmessagecommand command  final location location  throws ioexception
if  command hastransactioninfo
list<operation> inflighttx   getinflighttx command gettransactioninfo    location
inflighttx add new addopperation command  location
else
this indexlock writelock   lock
try
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
upadateindex tx  command  location
finally
this indexlock writelock   unlock
@suppresswarnings
protected void process final kaharemovemessagecommand command  final location location  throws ioexception
if  command hastransactioninfo
list<operation> inflighttx   getinflighttx command gettransactioninfo    location
inflighttx add new removeopperation command  location
else
this indexlock writelock   lock
try
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
updateindex tx  command  location
finally
this indexlock writelock   unlock
protected void process final kaharemovedestinationcommand command  final location location  throws ioexception
this indexlock writelock   lock
try
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
updateindex tx  command  location
finally
this indexlock writelock   unlock
protected void process final kahasubscriptioncommand command  final location location  throws ioexception
this indexlock writelock   lock
try
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
updateindex tx  command  location
finally
this indexlock writelock   unlock
protected void processlocation final location location
this indexlock writelock   lock
try
metadata lastupdate   location
finally
this indexlock writelock   unlock
private final stack<runnable> orderedtransactionafters   new stack<runnable>
private void push runnable after
if  after    null
synchronized  orderedtransactionafters
orderedtransactionafters push after
@suppresswarnings
protected void process kahacommitcommand command  location location  final runnable after  throws ioexception
transactionid key   transactionidconversion convert command gettransactioninfo
list<operation> inflighttx
synchronized  inflighttransactions
inflighttx   inflighttransactions remove key
if  inflighttx    null
inflighttx   preparedtransactions remove key
if  inflighttx    null
if  after    null
// since we don't push this after and we may find another, lets run it now
after run
return
final list<operation> messagingtx   inflighttx
this indexlock writelock   lock
try
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
for  operation op   messagingtx
op execute tx
metadata lastupdate   location
push after
finally
this indexlock writelock   unlock
@suppresswarnings
protected void process kahapreparecommand command  location location
transactionid key   transactionidconversion convert command gettransactioninfo
synchronized  inflighttransactions
list<operation> tx   inflighttransactions remove key
if  tx    null
preparedtransactions put key  tx
@suppresswarnings
protected void process kaharollbackcommand command  location location   throws ioexception
transactionid key   transactionidconversion convert command gettransactioninfo
list<operation> updates   null
synchronized  inflighttransactions
updates   inflighttransactions remove key
if  updates    null
updates   preparedtransactions remove key
if  isrewriteonredelivery
persistredeliverycount updates
@suppresswarnings
private void persistredeliverycount list<operation> updates   throws ioexception
if  updates    null
for  operation operation   updates
operation getcommand   visit new visitor
@override
public void visit kaharemovemessagecommand command  throws ioexception
incrementredeliveryandrewrite command getmessageid    command getdestination
abstract void incrementredeliveryandrewrite string key  kahadestination destination  throws ioexception
// /////////////////////////////////////////////////////////////////
// these methods do the actual index updates.
// /////////////////////////////////////////////////////////////////
protected final reentrantreadwritelock indexlock   new reentrantreadwritelock
private final hashset<integer> journalfilesbeingreplicated   new hashset<integer>
void upadateindex transaction tx  kahaaddmessagecommand command  location location  throws ioexception
storeddestination sd   getstoreddestination command getdestination    tx
// skip adding the message to the index if this is a topic and there are
// no subscriptions.
if  sd subscriptions    null    sd subscriptions isempty tx
return
// add the message.
int priority   command getprioritysupported   ? command getpriority     javax jms message default_priority
long id   sd orderindex getnextmessageid priority
long previous   sd locationindex put tx  location  id
if  previous    null
previous   sd messageidindex put tx  command getmessageid    id
if  previous    null
sd orderindex put tx  priority  id  new messagekeys command getmessageid    location
if  sd subscriptions    null     sd subscriptions isempty tx
addacklocationfornewmessage tx  sd  id
else
// if the message id as indexed, then the broker asked us to
// store a dup
// message. bad boy! don't do it, and log a warning.
log warn     command getdestination   getname         command getmessageid
sd messageidindex put tx  command getmessageid    previous
sd locationindex remove tx  location
rollbackstatsonduplicate command getdestination
else
// restore the previous value.. looks like this was a redo of a
// previously
// added message. we don't want to assign it a new id as the other
// indexes would
// be wrong..
//
sd locationindex put tx  location  previous
// record this id in any event, initial send or recovery
metadata producersequenceidtracker isduplicate command getmessageid
metadata lastupdate   location
abstract void rollbackstatsonduplicate kahadestination commanddestination
void updateindex transaction tx  kaharemovemessagecommand command  location acklocation  throws ioexception
storeddestination sd   getstoreddestination command getdestination    tx
if   command hassubscriptionkey
// in the queue case we just remove the message from the index..
long sequenceid   sd messageidindex remove tx  command getmessageid
if  sequenceid    null
messagekeys keys   sd orderindex remove tx  sequenceid
if  keys    null
sd locationindex remove tx  keys location
recordackmessagereferencelocation acklocation  keys location
else if  log isdebugenabled
log debug     sequenceid        command getmessageid
else if  log isdebugenabled
log debug     command getmessageid
else
// in the topic case we need remove the message once it's been acked
// by all the subs
long sequence   sd messageidindex get tx  command getmessageid
// make sure it's a valid message id...
if  sequence    null
string subscriptionkey   command getsubscriptionkey
if  command getack      unmatched
sd orderindex get tx  sequence
byte priority   sd orderindex lastgetpriority
sd subscriptionacks put tx  subscriptionkey  new lastack sequence  priority
// the following method handles deleting un-referenced messages.
removeacklocation tx  sd  subscriptionkey  sequence
else if  log isdebugenabled
log debug     command getmessageid         command getsubscriptionkey
metadata lastupdate   acklocation
map<integer  set<integer>> ackmessagefilemap   new hashmap<integer  set<integer>>
private void recordackmessagereferencelocation location acklocation  location messagelocation
set<integer> referencefileids   ackmessagefilemap get integer valueof acklocation getdatafileid
if  referencefileids    null
referencefileids   new hashset<integer>
referencefileids add messagelocation getdatafileid
ackmessagefilemap put acklocation getdatafileid    referencefileids
else
integer id   integer valueof messagelocation getdatafileid
if   referencefileids contains id
referencefileids add id
void updateindex transaction tx  kaharemovedestinationcommand command  location location  throws ioexception
storeddestination sd   getstoreddestination command getdestination    tx
sd orderindex remove tx
sd locationindex clear tx
sd locationindex unload tx
tx free sd locationindex getpageid
sd messageidindex clear tx
sd messageidindex unload tx
tx free sd messageidindex getpageid
if  sd subscriptions    null
sd subscriptions clear tx
sd subscriptions unload tx
tx free sd subscriptions getpageid
sd subscriptionacks clear tx
sd subscriptionacks unload tx
tx free sd subscriptionacks getpageid
sd ackpositions clear tx
sd ackpositions unload tx
tx free sd ackpositions getheadpageid
string key   key command getdestination
storeddestinations remove key
metadata destinations remove tx  key
void updateindex transaction tx  kahasubscriptioncommand command  location location  throws ioexception
storeddestination sd   getstoreddestination command getdestination    tx
final string subscriptionkey   command getsubscriptionkey
// if set then we are creating it.. otherwise we are destroying the sub
if  command hassubscriptioninfo
sd subscriptions put tx  subscriptionkey  command
long acklocation not_acked
if   command getretroactive
acklocation   sd orderindex nextmessageid 1
else
addacklocationforretroactivesub tx  sd  subscriptionkey
sd subscriptionacks put tx  subscriptionkey  new lastack acklocation
sd subscriptioncache add subscriptionkey
else
// delete the sub...
sd subscriptions remove tx  subscriptionkey
sd subscriptionacks remove tx  subscriptionkey
sd subscriptioncache remove subscriptionkey
removeacklocationsforsub tx  sd  subscriptionkey
if  sd subscriptions isempty tx
sd messageidindex clear tx
sd locationindex clear tx
sd orderindex clear tx
/**
* @param tx
* @throws ioexception
*/
void checkpointupdate transaction tx  boolean cleanup  throws ioexception
log debug
// reflect last update exclusive of current checkpoint
location lastupdate   metadata lastupdate
metadata state   open_state
metadata producersequenceidtrackerlocation   checkpointproduceraudit
location inprogresstxrange   getinprogresstxlocationrange
metadata firstinprogresstransactionlocation   inprogresstxrange
tx store metadata page  metadatamarshaller  true
pagefile flush
if  cleanup
final treeset<integer> completefileset   new treeset<integer> journal getfilemap   keyset
final treeset<integer> gccandidateset   new treeset<integer> completefileset
if  log istraceenabled
log trace     lastupdate       gccandidateset
if  lastupdate    null
gccandidateset remove lastupdate getdatafileid
// don't gc files under replication
if  journalfilesbeingreplicated  null
gccandidateset removeall journalfilesbeingreplicated
if  metadata producersequenceidtrackerlocation    null
gccandidateset remove metadata producersequenceidtrackerlocation getdatafileid
// don't gc files referenced by in-progress tx
if  inprogresstxrange    null
for  int pendingtx inprogresstxrange getdatafileid    pendingtx <  inprogresstxrange getdatafileid    pendingtx
gccandidateset remove pendingtx
if  log istraceenabled
log trace     arrays aslist inprogresstxrange        gccandidateset
// go through all the destinations to see if any of them can remove gc candidates.
for  entry<string  storeddestination> entry   storeddestinations entryset
if  gccandidateset isempty
break
// use a visitor to cut down the number of pages that we load
entry getvalue   locationindex visit tx  new btreevisitor<location  long>
int last  1
@override
public boolean isinterestedinkeysbetween location first  location second
if  first  null
sortedset<integer> subset   gccandidateset headset second getdatafileid   1
if   subset isempty      subset last      second getdatafileid
subset remove second getdatafileid
return  subset isempty
else if  second  null
sortedset<integer> subset   gccandidateset tailset first getdatafileid
if   subset isempty      subset first      first getdatafileid
subset remove first getdatafileid
return  subset isempty
else
sortedset<integer> subset   gccandidateset subset first getdatafileid    second getdatafileid   1
if   subset isempty      subset first      first getdatafileid
subset remove first getdatafileid
if   subset isempty      subset last      second getdatafileid
subset remove second getdatafileid
return  subset isempty
@override
public void visit list<location> keys  list<long> values
for  location l   keys
int fileid   l getdatafileid
if  last    fileid
gccandidateset remove fileid
last   fileid
if  log istraceenabled
log trace     entry getkey         gccandidateset
// check we are not deleting file with ack for in-use journal files
if  log istraceenabled
log trace     gccandidateset
final treeset<integer> gccandidates   new treeset<integer> gccandidateset
iterator<integer> candidates   gccandidateset iterator
while  candidates hasnext
integer candidate   candidates next
set<integer> referencedfileids   ackmessagefilemap get candidate
if  referencedfileids    null
for  integer referencedfileid   referencedfileids
if  completefileset contains referencedfileid      gccandidates contains referencedfileid
// active file that is not targeted for deletion is referenced so don't delete
candidates remove
break
if  gccandidateset contains candidate
ackmessagefilemap remove candidate
else
if  log istraceenabled
log trace     candidate
referencedfileids
if   gccandidateset isempty
if  log isdebugenabled
log debug     gccandidateset
journal removedatafiles gccandidateset
log debug
final runnable nullcompletioncallback   new runnable
@override
public void run
private location checkpointproduceraudit   throws ioexception
if  metadata producersequenceidtracker    null    metadata producersequenceidtracker modified
bytearrayoutputstream baos   new bytearrayoutputstream
objectoutputstream oout   new objectoutputstream baos
oout writeobject metadata producersequenceidtracker
oout flush
oout close
// using completion callback allows a disk sync to be avoided when enablejournaldisksyncs = false
location location   store new kahaproducerauditcommand   setaudit new buffer baos tobytearray      nullcompletioncallback
try
location getlatch   await
catch  interruptedexception e
throw new interruptedioexception e tostring
return location
return metadata producersequenceidtrackerlocation
public hashset<integer> getjournalfilesbeingreplicated
return journalfilesbeingreplicated
// /////////////////////////////////////////////////////////////////
// storeddestination related implementation methods.
// /////////////////////////////////////////////////////////////////
private final hashmap<string  storeddestination> storeddestinations   new hashmap<string  storeddestination>
class storedsubscription
subscriptioninfo subscriptioninfo
string lastackid
location lastacklocation
location cursor
static class messagekeys
final string messageid
final location location
public messagekeys string messageid  location location
this messageid messageid
this location location
@override
public string tostring
return   messageid   location
static protected class messagekeysmarshaller extends variablemarshaller<messagekeys>
static final messagekeysmarshaller instance   new messagekeysmarshaller
@override
public messagekeys readpayload datainput datain  throws ioexception
return new messagekeys datain readutf    locationmarshaller instance readpayload datain
@override
public void writepayload messagekeys object  dataoutput dataout  throws ioexception
dataout writeutf object messageid
locationmarshaller instance writepayload object location  dataout
class lastack
long lastackedsequence
byte priority
public lastack lastack source
this lastackedsequence   source lastackedsequence
this priority   source priority
public lastack
this priority   messageorderindex hi
public lastack long acklocation
this lastackedsequence   acklocation
this priority   messageorderindex lo
public lastack long acklocation  byte priority
this lastackedsequence   acklocation
this priority   priority
@override
public string tostring
return     lastackedsequence       priority
protected class lastackmarshaller implements marshaller<lastack>
@override
public void writepayload lastack object  dataoutput dataout  throws ioexception
dataout writelong object lastackedsequence
dataout writebyte object priority
@override
public lastack readpayload datainput datain  throws ioexception
lastack lastacked   new lastack
lastacked lastackedsequence   datain readlong
if  metadata version >  3
lastacked priority   datain readbyte
return lastacked
@override
public int getfixedsize
return 9
@override
public lastack deepcopy lastack source
return new lastack source
@override
public boolean isdeepcopysupported
return true
class storeddestination
messageorderindex orderindex   new messageorderindex
btreeindex<location  long> locationindex
btreeindex<string  long> messageidindex
// these bits are only set for topics
btreeindex<string  kahasubscriptioncommand> subscriptions
btreeindex<string  lastack> subscriptionacks
hashmap<string  messageordercursor> subscriptioncursors
listindex<string  sequenceset> ackpositions
// transient data used to track which messages are no longer needed.
final treemap<long  long> messagereferences   new treemap<long  long>
final hashset<string> subscriptioncache   new linkedhashset<string>
protected class storeddestinationmarshaller extends variablemarshaller<storeddestination>
@override
public storeddestination readpayload final datainput datain  throws ioexception
final storeddestination value   new storeddestination
value orderindex defaultpriorityindex   new btreeindex<long  messagekeys> pagefile  datain readlong
value locationindex   new btreeindex<location  long> pagefile  datain readlong
value messageidindex   new btreeindex<string  long> pagefile  datain readlong
if  datain readboolean
value subscriptions   new btreeindex<string  kahasubscriptioncommand> pagefile  datain readlong
value subscriptionacks   new btreeindex<string  lastack> pagefile  datain readlong
if  metadata version >  4
value ackpositions   new listindex<string  sequenceset> pagefile  datain readlong
else
// upgrade
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
btreeindex<long  hashset<string>> oldackpositions
new btreeindex<long  hashset<string>> pagefile  datain readlong
oldackpositions setkeymarshaller longmarshaller instance
oldackpositions setvaluemarshaller hashsetstringmarshaller instance
oldackpositions load tx
linkedhashmap<string  sequenceset> temp   new linkedhashmap<string  sequenceset>
// do the initial build of the data in memory before writing into the store
// based ack positions list to avoid a lot of disk thrashing.
iterator<entry<long  hashset<string>>> iterator   oldackpositions iterator tx
while  iterator hasnext
entry<long  hashset<string>> entry   iterator next
for string subkey   entry getvalue
sequenceset pendingacks   temp get subkey
if  pendingacks    null
pendingacks   new sequenceset
temp put subkey  pendingacks
pendingacks add entry getkey
// now move the pending messages to ack data into the store backed
// structure.
value ackpositions   new listindex<string  sequenceset> pagefile  tx allocate
for string subscriptionkey   temp keyset
value ackpositions put tx  subscriptionkey  temp get subscriptionkey
if  metadata version >  2
value orderindex lowpriorityindex   new btreeindex<long  messagekeys> pagefile  datain readlong
value orderindex highpriorityindex   new btreeindex<long  messagekeys> pagefile  datain readlong
else
// upgrade
pagefile tx   execute new transaction closure<ioexception>
@override
public void execute transaction tx  throws ioexception
value orderindex lowpriorityindex   new btreeindex<long  messagekeys> pagefile  tx allocate
value orderindex lowpriorityindex setkeymarshaller longmarshaller instance
value orderindex lowpriorityindex setvaluemarshaller messagekeysmarshaller instance
value orderindex lowpriorityindex load tx
value orderindex highpriorityindex   new btreeindex<long  messagekeys> pagefile  tx allocate
value orderindex highpriorityindex setkeymarshaller longmarshaller instance
value orderindex highpriorityindex setvaluemarshaller messagekeysmarshaller instance
value orderindex highpriorityindex load tx
return value
@override
public void writepayload storeddestination value  dataoutput dataout  throws ioexception
dataout writelong value orderindex defaultpriorityindex getpageid
dataout writelong value locationindex getpageid
dataout writelong value messageidindex getpageid
if  value subscriptions    null
dataout writeboolean true
dataout writelong value subscriptions getpageid
dataout writelong value subscriptionacks getpageid
dataout writelong value ackpositions getheadpageid
else
dataout writeboolean false
dataout writelong value orderindex lowpriorityindex getpageid
dataout writelong value orderindex highpriorityindex getpageid
static class kahasubscriptioncommandmarshaller extends variablemarshaller<kahasubscriptioncommand>
final static kahasubscriptioncommandmarshaller instance   new kahasubscriptioncommandmarshaller
@override
public kahasubscriptioncommand readpayload datainput datain  throws ioexception
kahasubscriptioncommand rc   new kahasubscriptioncommand
rc mergeframed  inputstream datain
return rc
@override
public void writepayload kahasubscriptioncommand object  dataoutput dataout  throws ioexception
object writeframed  outputstream dataout
protected storeddestination getstoreddestination kahadestination destination  transaction tx  throws ioexception
string key   key destination
storeddestination rc   storeddestinations get key
if  rc    null
boolean topic   destination gettype      kahadestination destinationtype topic    destination gettype      kahadestination destinationtype temp_topic
rc   loadstoreddestination tx  key  topic
// cache it. we may want to remove/unload destinations from the
// cache that are not used for a while
// to reduce memory usage.
storeddestinations put key  rc
return rc
protected storeddestination getexistingstoreddestination kahadestination destination  transaction tx  throws ioexception
string key   key destination
storeddestination rc   storeddestinations get key
if  rc    null    metadata destinations containskey tx  key
rc   getstoreddestination destination  tx
return rc
/**
* @param tx
* @param key
* @param topic
* @return
* @throws ioexception
*/
private storeddestination loadstoreddestination transaction tx  string key  boolean topic  throws ioexception
// try to load the existing indexes..
storeddestination rc   metadata destinations get tx  key
if  rc    null
// brand new destination.. allocate indexes for it.
rc   new storeddestination
rc orderindex allocate tx
rc locationindex   new btreeindex<location  long> pagefile  tx allocate
rc messageidindex   new btreeindex<string  long> pagefile  tx allocate
if  topic
rc subscriptions   new btreeindex<string  kahasubscriptioncommand> pagefile  tx allocate
rc subscriptionacks   new btreeindex<string  lastack> pagefile  tx allocate
rc ackpositions   new listindex<string  sequenceset> pagefile  tx allocate
metadata destinations put tx  key  rc
// configure the marshalers and load.
rc orderindex load tx
// figure out the next key using the last entry in the destination.
rc orderindex configurelast tx
rc locationindex setkeymarshaller org apache activemq store kahadb disk util locationmarshaller instance
rc locationindex setvaluemarshaller longmarshaller instance
rc locationindex load tx
rc messageidindex setkeymarshaller stringmarshaller instance
rc messageidindex setvaluemarshaller longmarshaller instance
rc messageidindex load tx
// if it was a topic...
if  topic
rc subscriptions setkeymarshaller stringmarshaller instance
rc subscriptions setvaluemarshaller kahasubscriptioncommandmarshaller instance
rc subscriptions load tx
rc subscriptionacks setkeymarshaller stringmarshaller instance
rc subscriptionacks setvaluemarshaller new lastackmarshaller
rc subscriptionacks load tx
rc ackpositions setkeymarshaller stringmarshaller instance
rc ackpositions setvaluemarshaller sequenceset marshaller instance
rc ackpositions load tx
rc subscriptioncursors   new hashmap<string  messageordercursor>
if  metadata version < 3
// on upgrade need to fill acklocation with available messages past last ack
for  iterator<entry<string  lastack>> iterator   rc subscriptionacks iterator tx   iterator hasnext
entry<string  lastack> entry   iterator next
for  iterator<entry<long  messagekeys>> orderiterator
rc orderindex iterator tx  new messageordercursor entry getvalue   lastackedsequence    orderiterator hasnext
long sequence   orderiterator next   getkey
addacklocation tx  rc  sequence  entry getkey
// modify so it is upgraded
rc subscriptionacks put tx  entry getkey    entry getvalue
// configure the message references index
iterator<entry<string  sequenceset>> subscriptions   rc ackpositions iterator tx
while  subscriptions hasnext
entry<string  sequenceset> subscription   subscriptions next
sequenceset pendingacks   subscription getvalue
if  pendingacks    null     pendingacks isempty
long lastpendingack   pendingacks gettail   getlast
for long sequenceid   pendingacks
long current   rc messagereferences get sequenceid
if  current    null
current   new long 0
// we always add a trailing empty entry for the next position to start from
// so we need to ensure we don't count that as a message reference on reload.
if   sequenceid equals lastpendingack
current   current longvalue     1
rc messagereferences put sequenceid  current
// configure the subscription cache
for  iterator<entry<string  lastack>> iterator   rc subscriptionacks iterator tx   iterator hasnext
entry<string  lastack> entry   iterator next
rc subscriptioncache add entry getkey
if  rc orderindex nextmessageid    0
// check for existing durable sub all acked out - pull next seq from acks as messages are gone
if   rc subscriptionacks isempty tx
for  iterator<entry<string  lastack>> iterator   rc subscriptionacks iterator tx   iterator hasnext
entry<string  lastack> entry   iterator next
rc orderindex nextmessageid
math max rc orderindex nextmessageid  entry getvalue   lastackedsequence  1
else
// update based on ackpositions for unmatched, last entry is always the next
if   rc messagereferences isempty
long nextmessageid    long  rc messagereferences keyset   toarray
rc orderindex nextmessageid
math max rc orderindex nextmessageid  nextmessageid
if  metadata version < version
// store again after upgrade
metadata destinations put tx  key  rc
return rc
private void addacklocation transaction tx  storeddestination sd  long messagesequence  string subscriptionkey  throws ioexception
sequenceset sequences   sd ackpositions get tx  subscriptionkey
if  sequences    null
sequences   new sequenceset
sequences add messagesequence
sd ackpositions add tx  subscriptionkey  sequences
else
sequences add messagesequence
sd ackpositions put tx  subscriptionkey  sequences
long count   sd messagereferences get messagesequence
if  count    null
count   long valueof 0l
count   count longvalue     1
sd messagereferences put messagesequence  count
// new sub is interested in potentially all existing messages
private void addacklocationforretroactivesub transaction tx  storeddestination sd  string subscriptionkey  throws ioexception
sequenceset alloutstanding   new sequenceset
iterator<map entry<string  sequenceset>> iterator   sd ackpositions iterator tx
while  iterator hasnext
sequenceset set   iterator next   getvalue
for  long entry   set
alloutstanding add entry
sd ackpositions put tx  subscriptionkey  alloutstanding
for  long ackposition   alloutstanding
long count   sd messagereferences get ackposition
count   count longvalue     1
sd messagereferences put ackposition  count
// on a new message add, all existing subs are interested in this message
private void addacklocationfornewmessage transaction tx  storeddestination sd  long messagesequence  throws ioexception
for string subscriptionkey   sd subscriptioncache
sequenceset sequences   sd ackpositions get tx  subscriptionkey
if  sequences    null
sequences   new sequenceset
sequences add new sequence messagesequence  messagesequence   1
sd ackpositions add tx  subscriptionkey  sequences
else
sequences add new sequence messagesequence  messagesequence   1
sd ackpositions put tx  subscriptionkey  sequences
long count   sd messagereferences get messagesequence
if  count    null
count   long valueof 0l
count   count longvalue     1
sd messagereferences put messagesequence  count
sd messagereferences put messagesequence 1  long valueof 0l
private void removeacklocationsforsub transaction tx  storeddestination sd  string subscriptionkey  throws ioexception
if   sd ackpositions isempty tx
sequenceset sequences   sd ackpositions remove tx  subscriptionkey
if  sequences    null    sequences isempty
return
arraylist<long> unreferenced   new arraylist<long>
for long sequenceid   sequences
long references   sd messagereferences get sequenceid
if  references    null
references   references longvalue     1
if  references longvalue   > 0
sd messagereferences put sequenceid  references
else
sd messagereferences remove sequenceid
unreferenced add sequenceid
for long sequenceid   unreferenced
// find all the entries that need to get deleted.
arraylist<entry<long  messagekeys>> deletes   new arraylist<entry<long  messagekeys>>
sd orderindex getdeletelist tx  deletes  sequenceid
// do the actual deletes.
for  entry<long  messagekeys> entry   deletes
sd locationindex remove tx  entry getvalue   location
sd messageidindex remove tx  entry getvalue   messageid
sd orderindex remove tx  entry getkey
/**
* @param tx
* @param sd
* @param subscriptionkey
* @param messagesequence
* @throws ioexception
*/
private void removeacklocation transaction tx  storeddestination sd  string subscriptionkey  long messagesequence  throws ioexception
// remove the sub from the previous location set..
if  messagesequence    null
sequenceset range   sd ackpositions get tx  subscriptionkey
if  range    null     range isempty
range remove messagesequence
if   range isempty
sd ackpositions put tx  subscriptionkey  range
else
sd ackpositions remove tx  subscriptionkey
// check if the message is reference by any other subscription.
long count   sd messagereferences get messagesequence
if  count    null
long references   count longvalue     1
if  references > 0
sd messagereferences put messagesequence  long valueof references
return
else
sd messagereferences remove messagesequence
// find all the entries that need to get deleted.
arraylist<entry<long  messagekeys>> deletes   new arraylist<entry<long  messagekeys>>
sd orderindex getdeletelist tx  deletes  messagesequence
// do the actual deletes.
for  entry<long  messagekeys> entry   deletes
sd locationindex remove tx  entry getvalue   location
sd messageidindex remove tx  entry getvalue   messageid
sd orderindex remove tx  entry getkey
public lastack getlastack transaction tx  storeddestination sd  string subscriptionkey  throws ioexception
return sd subscriptionacks get tx  subscriptionkey
public long getstoredmessagecount transaction tx  storeddestination sd  string subscriptionkey  throws ioexception
sequenceset messagesequences   sd ackpositions get tx  subscriptionkey
if  messagesequences    null
long result   messagesequences rangesize
// if there's anything in the range the last value is always the nextmessage marker, so remove 1.
return result > 0 ? result   1   0
return 0
private string key kahadestination destination
return destination gettype   getnumber         destination getname
// /////////////////////////////////////////////////////////////////
// transaction related implementation methods.
// /////////////////////////////////////////////////////////////////
@suppresswarnings
private final linkedhashmap<transactionid  list<operation>> inflighttransactions   new linkedhashmap<transactionid  list<operation>>
@suppresswarnings
protected final linkedhashmap<transactionid  list<operation>> preparedtransactions   new linkedhashmap<transactionid  list<operation>>
protected final set<string> ackedandprepared   new hashset<string>
// messages that have prepared (pending) acks cannot be re-dispatched unless the outcome is rollback,
// till then they are skipped by the store.
// 'at most once' xa guarantee
public void trackrecoveredacks arraylist<messageack> acks
this indexlock writelock   lock
try
for  messageack ack   acks
ackedandprepared add ack getlastmessageid   tostring
finally
this indexlock writelock   unlock
public void forgetrecoveredacks arraylist<messageack> acks  throws ioexception
if  acks    null
this indexlock writelock   lock
try
for  messageack ack   acks
ackedandprepared remove ack getlastmessageid   tostring
finally
this indexlock writelock   unlock
@suppresswarnings
private list<operation> getinflighttx kahatransactioninfo info  location location
transactionid key   transactionidconversion convert info
list<operation> tx
synchronized  inflighttransactions
tx   inflighttransactions get key
if  tx    null
tx   collections synchronizedlist new arraylist<operation>
inflighttransactions put key  tx
return tx
@suppresswarnings
private transactionid key kahatransactioninfo transactioninfo
return transactionidconversion convert transactioninfo
abstract class operation <t extends journalcommand<t>>
final t command
final location location
public operation t command  location location
this command   command
this location   location
public location getlocation
return location
public t getcommand
return command
abstract public void execute transaction tx  throws ioexception
class addopperation extends operation<kahaaddmessagecommand>
public addopperation kahaaddmessagecommand command  location location
super command  location
@override
public void execute transaction tx  throws ioexception
upadateindex tx  command  location
class removeopperation extends operation<kaharemovemessagecommand>
public removeopperation kaharemovemessagecommand command  location location
super command  location
@override
public void execute transaction tx  throws ioexception
updateindex tx  command  location
// /////////////////////////////////////////////////////////////////
// initialization related implementation methods.
// /////////////////////////////////////////////////////////////////
private pagefile createpagefile
pagefile index   new pagefile directory
index setenablewritethread isenableindexwriteasync
index setwritebatchsize getindexwritebatchsize
index setpagecachesize indexcachesize
index setuselfrueviction isuseindexlfrueviction
index setlfuevictionfactor getindexlfuevictionfactor
index setenabledisksyncs isenableindexdisksyncs
index setenablerecoveryfile isenableindexrecoveryfile
index setenablepagecaching isenableindexpagecaching
return index
private journal createjournal   throws ioexception
journal manager   new journal
manager setdirectory directory
manager setmaxfilelength getjournalmaxfilelength
manager setcheckforcorruptiononstartup checkforcorruptjournalfiles
manager setchecksum checksumjournalfiles    checkforcorruptjournalfiles
manager setwritebatchsize getjournalmaxwritebatchsize
manager setarchivedatalogs isarchivedatalogs
manager setsizeaccumulator journalsize
manager setenableasyncdisksync isenablejournaldisksyncs
if  getdirectoryarchive      null
iohelper mkdirs getdirectoryarchive
manager setdirectoryarchive getdirectoryarchive
return manager
public int getjournalmaxwritebatchsize
return journalmaxwritebatchsize
public void setjournalmaxwritebatchsize int journalmaxwritebatchsize
this journalmaxwritebatchsize   journalmaxwritebatchsize
public file getdirectory
return directory
public void setdirectory file directory
this directory   directory
public boolean isdeleteallmessages
return deleteallmessages
public void setdeleteallmessages boolean deleteallmessages
this deleteallmessages   deleteallmessages
public void setindexwritebatchsize int setindexwritebatchsize
this setindexwritebatchsize   setindexwritebatchsize
public int getindexwritebatchsize
return setindexwritebatchsize
public void setenableindexwriteasync boolean enableindexwriteasync
this enableindexwriteasync   enableindexwriteasync
boolean isenableindexwriteasync
return enableindexwriteasync
public boolean isenablejournaldisksyncs
return enablejournaldisksyncs
public void setenablejournaldisksyncs boolean syncwrites
this enablejournaldisksyncs   syncwrites
public long getcheckpointinterval
return checkpointinterval
public void setcheckpointinterval long checkpointinterval
this checkpointinterval   checkpointinterval
public long getcleanupinterval
return cleanupinterval
public void setcleanupinterval long cleanupinterval
this cleanupinterval   cleanupinterval
public void setjournalmaxfilelength int journalmaxfilelength
this journalmaxfilelength   journalmaxfilelength
public int getjournalmaxfilelength
return journalmaxfilelength
public void setmaxfailoverproducerstotrack int maxfailoverproducerstotrack
this metadata producersequenceidtracker setmaximumnumberofproducerstotrack maxfailoverproducerstotrack
public int getmaxfailoverproducerstotrack
return this metadata producersequenceidtracker getmaximumnumberofproducerstotrack
public void setfailoverproducersauditdepth int failoverproducersauditdepth
this metadata producersequenceidtracker setauditdepth failoverproducersauditdepth
public int getfailoverproducersauditdepth
return this metadata producersequenceidtracker getauditdepth
public pagefile getpagefile
if  pagefile    null
pagefile   createpagefile
return pagefile
public journal getjournal   throws ioexception
if  journal    null
journal   createjournal
return journal
public boolean isfailifdatabaseislocked
return failifdatabaseislocked
public void setfailifdatabaseislocked boolean failifdatabaseislocked
this failifdatabaseislocked   failifdatabaseislocked
public boolean isignoremissingjournalfiles
return ignoremissingjournalfiles
public void setignoremissingjournalfiles boolean ignoremissingjournalfiles
this ignoremissingjournalfiles   ignoremissingjournalfiles
public int getindexcachesize
return indexcachesize
public void setindexcachesize int indexcachesize
this indexcachesize   indexcachesize
public boolean ischeckforcorruptjournalfiles
return checkforcorruptjournalfiles
public void setcheckforcorruptjournalfiles boolean checkforcorruptjournalfiles
this checkforcorruptjournalfiles   checkforcorruptjournalfiles
public boolean ischecksumjournalfiles
return checksumjournalfiles
public void setchecksumjournalfiles boolean checksumjournalfiles
this checksumjournalfiles   checksumjournalfiles
@override
public void setbrokerservice brokerservice brokerservice
this brokerservice   brokerservice
/**
* @return the archivedatalogs
*/
public boolean isarchivedatalogs
return this archivedatalogs
/**
* @param archivedatalogs the archivedatalogs to set
*/
public void setarchivedatalogs boolean archivedatalogs
this archivedatalogs   archivedatalogs
/**
* @return the directoryarchive
*/
public file getdirectoryarchive
return this directoryarchive
/**
* @param directoryarchive the directoryarchive to set
*/
public void setdirectoryarchive file directoryarchive
this directoryarchive   directoryarchive
public boolean isrewriteonredelivery
return rewriteonredelivery
public void setrewriteonredelivery boolean rewriteonredelivery
this rewriteonredelivery   rewriteonredelivery
public boolean isarchivecorruptedindex
return archivecorruptedindex
public void setarchivecorruptedindex boolean archivecorruptedindex
this archivecorruptedindex   archivecorruptedindex
public float getindexlfuevictionfactor
return indexlfuevictionfactor
public void setindexlfuevictionfactor float indexlfuevictionfactor
this indexlfuevictionfactor   indexlfuevictionfactor
public boolean isuseindexlfrueviction
return useindexlfrueviction
public void setuseindexlfrueviction boolean useindexlfrueviction
this useindexlfrueviction   useindexlfrueviction
public void setenableindexdisksyncs boolean enableindexdisksyncs
this enableindexdisksyncs   enableindexdisksyncs
public void setenableindexrecoveryfile boolean enableindexrecoveryfile
this enableindexrecoveryfile   enableindexrecoveryfile
public void setenableindexpagecaching boolean enableindexpagecaching
this enableindexpagecaching   enableindexpagecaching
public boolean isenableindexdisksyncs
return enableindexdisksyncs
public boolean isenableindexrecoveryfile
return enableindexrecoveryfile
public boolean isenableindexpagecaching
return enableindexpagecaching
// /////////////////////////////////////////////////////////////////
// internal conversion methods.
// /////////////////////////////////////////////////////////////////
class messageordercursor
long defaultcursorposition
long lowprioritycursorposition
long highprioritycursorposition
messageordercursor
messageordercursor long position
this defaultcursorposition position
this lowprioritycursorposition position
this highprioritycursorposition position
messageordercursor messageordercursor other
this defaultcursorposition other defaultcursorposition
this lowprioritycursorposition other lowprioritycursorposition
this highprioritycursorposition other highprioritycursorposition
messageordercursor copy
return new messageordercursor this
void reset
this defaultcursorposition 0
this highprioritycursorposition 0
this lowprioritycursorposition 0
void increment
if  defaultcursorposition  0
defaultcursorposition
if  highprioritycursorposition  0
highprioritycursorposition
if  lowprioritycursorposition  0
lowprioritycursorposition
@override
public string tostring
return     defaultcursorposition
lowprioritycursorposition
highprioritycursorposition
public void sync messageordercursor other
this defaultcursorposition other defaultcursorposition
this lowprioritycursorposition other lowprioritycursorposition
this highprioritycursorposition other highprioritycursorposition
class messageorderindex
static final byte hi   9
static final byte lo   0
static final byte def   4
long nextmessageid
btreeindex<long  messagekeys> defaultpriorityindex
btreeindex<long  messagekeys> lowpriorityindex
btreeindex<long  messagekeys> highpriorityindex
messageordercursor cursor   new messageordercursor
long lastdefaultkey
long lasthighkey
long lastlowkey
byte lastgetpriority
messagekeys remove transaction tx  long key  throws ioexception
messagekeys result   defaultpriorityindex remove tx  key
if  result    null    highpriorityindex  null
result   highpriorityindex remove tx  key
if  result   null    lowpriorityindex  null
result   lowpriorityindex remove tx  key
return result
void load transaction tx  throws ioexception
defaultpriorityindex setkeymarshaller longmarshaller instance
defaultpriorityindex setvaluemarshaller messagekeysmarshaller instance
defaultpriorityindex load tx
lowpriorityindex setkeymarshaller longmarshaller instance
lowpriorityindex setvaluemarshaller messagekeysmarshaller instance
lowpriorityindex load tx
highpriorityindex setkeymarshaller longmarshaller instance
highpriorityindex setvaluemarshaller messagekeysmarshaller instance
highpriorityindex load tx
void allocate transaction tx  throws ioexception
defaultpriorityindex   new btreeindex<long  messagekeys> pagefile  tx allocate
if  metadata version >  2
lowpriorityindex   new btreeindex<long  messagekeys> pagefile  tx allocate
highpriorityindex   new btreeindex<long  messagekeys> pagefile  tx allocate
void configurelast transaction tx  throws ioexception
// figure out the next key using the last entry in the destination.
if  highpriorityindex    null
entry<long  messagekeys> lastentry   highpriorityindex getlast tx
if  lastentry    null
nextmessageid   lastentry getkey     1
else
lastentry   defaultpriorityindex getlast tx
if  lastentry    null
nextmessageid   lastentry getkey     1
else
lastentry   lowpriorityindex getlast tx
if  lastentry    null
nextmessageid   lastentry getkey     1
else
entry<long  messagekeys> lastentry   defaultpriorityindex getlast tx
if  lastentry    null
nextmessageid   lastentry getkey     1
void clear transaction tx  throws ioexception
this remove tx
this resetcursorposition
this allocate tx
this load tx
this configurelast tx
void remove transaction tx  throws ioexception
defaultpriorityindex clear tx
defaultpriorityindex unload tx
tx free defaultpriorityindex getpageid
if  lowpriorityindex    null
lowpriorityindex clear tx
lowpriorityindex unload tx
tx free lowpriorityindex getpageid
if  highpriorityindex    null
highpriorityindex clear tx
highpriorityindex unload tx
tx free highpriorityindex getpageid
void resetcursorposition
this cursor reset
lastdefaultkey   null
lasthighkey   null
lastlowkey   null
void setbatch transaction tx  long sequence  throws ioexception
if  sequence    null
long nextposition   new long sequence longvalue     1
if  defaultpriorityindex containskey tx  sequence
lastdefaultkey   sequence
cursor defaultcursorposition   nextposition longvalue
else if  highpriorityindex    null
if  highpriorityindex containskey tx  sequence
lasthighkey   sequence
cursor highprioritycursorposition   nextposition longvalue
else if  lowpriorityindex containskey tx  sequence
lastlowkey   sequence
cursor lowprioritycursorposition   nextposition longvalue
else
log warn     sequence       this
lastdefaultkey   sequence
cursor defaultcursorposition   nextposition longvalue
void setbatch transaction tx  lastack last  throws ioexception
setbatch tx  last lastackedsequence
if  cursor defaultcursorposition    0
cursor highprioritycursorposition    0
cursor lowprioritycursorposition    0
long next   last lastackedsequence   1
switch  last priority
case def
cursor defaultcursorposition   next
cursor highprioritycursorposition   next
break
case hi
cursor highprioritycursorposition   next
break
case lo
cursor lowprioritycursorposition   next
cursor defaultcursorposition   next
cursor highprioritycursorposition   next
break
void stoppediterating
if  lastdefaultkey  null
cursor defaultcursorposition lastdefaultkey longvalue   1
if  lasthighkey  null
cursor highprioritycursorposition lasthighkey longvalue   1
if  lastlowkey  null
cursor lowprioritycursorposition lastlowkey longvalue   1
lastdefaultkey   null
lasthighkey   null
lastlowkey   null
void getdeletelist transaction tx  arraylist<entry<long  messagekeys>> deletes  long sequenceid
throws ioexception
if  defaultpriorityindex containskey tx  sequenceid
getdeletelist tx  deletes  defaultpriorityindex  sequenceid
else if  highpriorityindex    null    highpriorityindex containskey tx  sequenceid
getdeletelist tx  deletes  highpriorityindex  sequenceid
else if  lowpriorityindex    null    lowpriorityindex containskey tx  sequenceid
getdeletelist tx  deletes  lowpriorityindex  sequenceid
void getdeletelist transaction tx  arraylist<entry<long  messagekeys>> deletes
btreeindex<long  messagekeys> index  long sequenceid  throws ioexception
iterator<entry<long  messagekeys>> iterator   index iterator tx  sequenceid
deletes add iterator next
long getnextmessageid int priority
return nextmessageid
messagekeys get transaction tx  long key  throws ioexception
messagekeys result   defaultpriorityindex get tx  key
if  result    null
result   highpriorityindex get tx  key
if  result    null
result   lowpriorityindex get tx  key
lastgetpriority   lo
else
lastgetpriority   hi
else
lastgetpriority   def
return result
messagekeys put transaction tx  int priority  long key  messagekeys value  throws ioexception
if  priority    javax jms message default_priority
return defaultpriorityindex put tx  key  value
else if  priority > javax jms message default_priority
return highpriorityindex put tx  key  value
else
return lowpriorityindex put tx  key  value
iterator<entry<long  messagekeys>> iterator transaction tx  throws ioexception
return new messageorderiterator tx cursor
iterator<entry<long  messagekeys>> iterator transaction tx  messageordercursor m  throws ioexception
return new messageorderiterator tx m
public byte lastgetpriority
return lastgetpriority
class messageorderiterator implements iterator<entry<long  messagekeys>>
iterator<entry<long  messagekeys>>currentiterator
final iterator<entry<long  messagekeys>>highiterator
final iterator<entry<long  messagekeys>>defaultiterator
final iterator<entry<long  messagekeys>>lowiterator
messageorderiterator transaction tx  messageordercursor m  throws ioexception
this defaultiterator   defaultpriorityindex iterator tx  m defaultcursorposition
if  highpriorityindex    null
this highiterator   highpriorityindex iterator tx  m highprioritycursorposition
else
this highiterator   null
if  lowpriorityindex    null
this lowiterator   lowpriorityindex iterator tx  m lowprioritycursorposition
else
this lowiterator   null
@override
public boolean hasnext
if  currentiterator    null
if  highiterator    null
if  highiterator hasnext
currentiterator   highiterator
return currentiterator hasnext
if  defaultiterator hasnext
currentiterator   defaultiterator
return currentiterator hasnext
if  lowiterator hasnext
currentiterator   lowiterator
return currentiterator hasnext
return false
else
currentiterator   defaultiterator
return currentiterator hasnext
if  highiterator    null
if  currentiterator hasnext
return true
if  currentiterator    highiterator
if  defaultiterator hasnext
currentiterator   defaultiterator
return currentiterator hasnext
if  lowiterator hasnext
currentiterator   lowiterator
return currentiterator hasnext
return false
if  currentiterator    defaultiterator
if  lowiterator hasnext
currentiterator   lowiterator
return currentiterator hasnext
return false
return currentiterator hasnext
@override
public entry<long  messagekeys> next
entry<long  messagekeys> result   currentiterator next
if  result    null
long key   result getkey
if  highiterator    null
if  currentiterator    defaultiterator
lastdefaultkey   key
else if  currentiterator    highiterator
lasthighkey   key
else
lastlowkey   key
else
lastdefaultkey   key
return result
@override
public void remove
throw new unsupportedoperationexception
private static class hashsetstringmarshaller extends variablemarshaller<hashset<string>>
final static hashsetstringmarshaller instance   new hashsetstringmarshaller
@override
public void writepayload hashset<string> object  dataoutput dataout  throws ioexception
bytearrayoutputstream baos   new bytearrayoutputstream
objectoutputstream oout   new objectoutputstream baos
oout writeobject object
oout flush
oout close
byte data   baos tobytearray
dataout writeint data length
dataout write data
@override
@suppresswarnings
public hashset<string> readpayload datainput datain  throws ioexception
int datalen   datain readint
byte data   new byte
datain readfully data
bytearrayinputstream bais   new bytearrayinputstream data
objectinputstream oin   new objectinputstream bais
try
return  hashset<string>  oin readobject
catch  classnotfoundexception cfe
ioexception ioe   new ioexception     cfe
ioe initcause cfe
throw ioe