/*
derby - class org.apache.derby.impl.sql.execute.altertableconstantaction
licensed to the apache software foundation (asf) under one or more
contributor license agreements.  see the notice file distributed with
this work for additional information regarding copyright ownership.
the asf licenses this file to you under the apache license, version 2.0
(the "license"); you may not use this file except in compliance with
the license.  you may obtain a copy of the license at
http://www.apache.org/licenses/license-2.0
unless required by applicable law or agreed to in writing, software
distributed under the license is distributed on an "as is" basis,
without warranties or conditions of any kind, either express or implied.
see the license for the specific language governing permissions and
limitations under the license.
*/
package org apache derby impl sql execute
import java sql sqlexception
import java util arraylist
import java util enumeration
import java util iterator
import java util list
import java util properties
import org apache derby catalog defaultinfo
import org apache derby catalog dependablefinder
import org apache derby catalog indexdescriptor
import org apache derby catalog uuid
import org apache derby catalog types referencedcolumnsdescriptorimpl
import org apache derby catalog types statisticsimpl
import org apache derby iapi error publicapi
import org apache derby iapi error standardexception
import org apache derby iapi reference sqlstate
import org apache derby iapi services io formatablebitset
import org apache derby iapi services io streamstorable
import org apache derby iapi services sanity sanitymanager
import org apache derby iapi sql activation
import org apache derby iapi sql preparedstatement
import org apache derby iapi sql resultset
import org apache derby iapi sql statementtype
import org apache derby iapi sql conn connectionutil
import org apache derby iapi sql conn languageconnectioncontext
import org apache derby iapi sql depend dependencymanager
import org apache derby iapi sql dictionary checkconstraintdescriptor
import org apache derby iapi sql dictionary columndescriptor
import org apache derby iapi sql dictionary columndescriptorlist
import org apache derby iapi sql dictionary conglomeratedescriptor
import org apache derby iapi sql dictionary constraintdescriptor
import org apache derby iapi sql dictionary constraintdescriptorlist
import org apache derby iapi sql dictionary datadescriptorgenerator
import org apache derby iapi sql dictionary datadictionary
import org apache derby iapi sql dictionary defaultdescriptor
import org apache derby iapi sql dictionary dependencydescriptor
import org apache derby iapi sql dictionary genericdescriptorlist
import org apache derby iapi sql dictionary indexlister
import org apache derby iapi sql dictionary indexrowgenerator
import org apache derby iapi sql dictionary referencedkeyconstraintdescriptor
import org apache derby iapi sql dictionary schemadescriptor
import org apache derby iapi sql dictionary statisticsdescriptor
import org apache derby iapi sql dictionary tabledescriptor
import org apache derby iapi sql dictionary triggerdescriptor
import org apache derby iapi sql execute constantaction
import org apache derby iapi sql execute execindexrow
import org apache derby iapi sql execute execrow
import org apache derby iapi store access columnordering
import org apache derby iapi store access conglomeratecontroller
import org apache derby iapi store access groupfetchscancontroller
import org apache derby iapi store access qualifier
import org apache derby iapi store access rowlocationretrowsource
import org apache derby iapi store access rowsource
import org apache derby iapi store access rowutil
import org apache derby iapi store access scancontroller
import org apache derby iapi store access sortcontroller
import org apache derby iapi store access sortobserver
import org apache derby iapi store access transactioncontroller
import org apache derby iapi types datatypedescriptor
import org apache derby iapi types datavaluedescriptor
import org apache derby iapi types rowlocation
import org apache derby iapi types stringdatavalue
import org apache derby iapi util idutil
import org apache derby impl sql catalog ddcolumndependablefinder
import org apache derby impl sql compile columndefinitionnode
/**
*	this class  describes actions that are always performed for an
*	alter table statement at execution time.
*
*/
class altertableconstantaction extends ddlsingletableconstantaction
implements rowlocationretrowsource
// copied from constructor args and stored locally.
private	    schemadescriptor			sd
private	    string						tablename
private	    uuid						schemaid
private	    int							tabletype
private	    columninfo				columninfo
private	    constraintconstantaction	constraintactions
private	    char						lockgranularity
private	    long						tableconglomerateid
private	    boolean					    compresstable
private     int						    behavior
private	    boolean					    sequential
private     boolean                     truncatetable
//the following three (purge, defragment and truncateendoftable) apply for
//inplace compress
private	    boolean					    purge
private	    boolean					    defragment
private	    boolean					    truncateendoftable
/**
* updatestatistics will indicate that we are here for updating the
* statistics. it could be statistics of just one index or all the
* indexes on a given table.
*/
private	    boolean					    updatestatistics
/**
* the flag updatestatisticsall will tell if we are going to update the
* statistics of all indexes or just one index on a table.
*/
private	    boolean					    updatestatisticsall
/**
* if statistic is getting updated for just one index, then
* indexnameforupdatestatistics will tell the name of the specific index
* whose statistics need to be updated.
*/
private	    string						indexnameforupdatestatistics
/**
* runtime state of the system is maintained in these objects.
* rowbufferone simply reuses the index row prepared by
* makeconstantaction. rowbuffertwo is a clone (an extra copy) of
* objects. rowbuffercurrent just switches between rowbufferone and
* rowbuffertwo.
*/
private datavaluedescriptor rowbufferarray
private datavaluedescriptor rowbuffer
private datavaluedescriptor lastuniquekey
private static final int group_fetch_size   16
// alter table compress and drop column
private     boolean					    donescan
private     boolean				    needtodropsort
private     boolean				    validrow
private	    int						    bulkfetchsize   16
private	    int						    currentcompressrow
private     int						    numindexes
private     int						    rowcount
private     long					    estimatedrowcount
private     long					    indexconglomeratenumbers
private	    long					    sortids
private     formatablebitset			indexedcols
private     conglomeratecontroller	    compressheapcc
private     execindexrow			    indexrows
private     execrow				    baserow
private     execrow					    currentrow
private	    groupfetchscancontroller    compressheapgsc
private     indexrowgenerator		    compressirgs
private	    datavaluedescriptor		baserowarray
private     rowlocation			    compressrl
private     sortcontroller		    sorters
private     int						    droppedcolumnposition
private     columnordering		    ordering
private     int		                collation
private	tabledescriptor 		        td
// constructors
private languageconnectioncontext lcc
private datadictionary dd
private dependencymanager dm
private transactioncontroller tc
private activation activation
/**
*	make the alteraction for an alter table statement.
*
*  @param sd			        descriptor for the table's schema.
*  @param tablename	        name of table.
*	@param tableid		        uuid of table
*	@param tableconglomerateid	heap conglomerate number of table
*  @param tabletype	        type of table (e.g., base).
*  @param columninfo	        information on all the columns in the table.
*  @param constraintactions	constraintconstantaction[] for constraints
*  @param lockgranularity	    the lock granularity.
*	@param compresstable	    whether or not this is a compress table
*	@param behavior		        drop behavior for dropping column
*	@param sequential	        if compress table/drop column,
*	                            whether or not sequential
*  @param truncatetable	    whether or not this is a truncate table
*  @param purge				purge during inplace compress?
*  @param defragment			defragment during inplace compress?
*  @param truncateendoftable	truncate end during inplace compress?
*  @param updatestatistics		true means we are here to update statistics
*  @param updatestatisticsall	true means we are here to update statistics
*  	of all the indexes. false means we are here to update statistics of
*  	only one index.
*  @param indexnameforupdatestatistics	will name the index whose statistics
*  	will be updated
*/
altertableconstantaction
schemadescriptor            sd
string			            tablename
uuid			            tableid
long			            tableconglomerateid
int				            tabletype
columninfo	            columninfo
constraintconstantaction  constraintactions
char			            lockgranularity
boolean			            compresstable
int				            behavior
boolean			            sequential
boolean                     truncatetable
boolean                     purge
boolean                     defragment
boolean                     truncateendoftable
boolean                     updatestatistics
boolean                     updatestatisticsall
string	                    indexnameforupdatestatistics
super tableid
this sd                       sd
this tablename                tablename
this tableconglomerateid      tableconglomerateid
this tabletype                tabletype
this columninfo               columninfo
this constraintactions        constraintactions
this lockgranularity          lockgranularity
this compresstable            compresstable
this behavior                 behavior
this sequential               sequential
this truncatetable            truncatetable
this purge          		  purge
this defragment          	  defragment
this truncateendoftable       truncateendoftable
this updatestatistics     	  updatestatistics
this updatestatisticsall      updatestatisticsall
this indexnameforupdatestatistics   indexnameforupdatestatistics
if  sanitymanager debug
sanitymanager assert sd    null
// object methods
public	string	tostring
// do not put this under sanitymanager.debug - it is needed for
// error reporting.
// we don't bother trying to print out the
// schema because we don't have it until execution
if truncatetable
return     tablename
else
return     tablename
// interface methods
/**
*	this is the guts of the execution-time logic for alter table.
*
*	@see constantaction#executeconstantaction
*
* @exception standardexception		thrown on failure
*/
public void	executeconstantaction
activation activation
throws standardexception
languageconnectioncontext   lcc
activation getlanguageconnectioncontext
datadictionary              dd   lcc getdatadictionary
dependencymanager           dm   dd getdependencymanager
transactioncontroller       tc   lcc gettransactionexecute
int							numrows   0
boolean						tablescanned   false
//following if is for inplace compress. compress using temporary
//tables to do the compression is done later in this method.
if  compresstable
if  purge    defragment    truncateendoftable
td   dd gettabledescriptor tableid
if  td    null
throw standardexception newexception
sqlstate lang_table_not_found_during_execution  tablename
// each of the following may give up locks allowing ddl on the
// table, so each phase needs to do the data dictionary lookup.
// the order is important as it makes sense to first purge
// deleted rows, then defragment existing non-deleted rows, and
// finally to truncate the end of the file which may have been
// made larger by the previous purge/defragment pass.
if  purge
purgerows tc
if  defragment
defragmentrows tc  lcc
if  truncateendoftable
truncateend tc
return
if  updatestatistics
updatestatistics activation
/*
** inform the data dictionary that we are about to write to it.
** there are several calls to data dictionary "get" methods here
** that might be done in "read" mode in the data dictionary, but
** it seemed safer to do this whole operation in "write" mode.
**
** we tell the data dictionary we're done writing at the end of
** the transaction.
*/
dd startwriting lcc
// now do the real work
// get an exclusive lock of the heap, to avoid deadlock on rows of
// syscolumns etc datadictionary tables and phantom table
// descriptor, in which case table shape could be changed by a
// concurrent thread doing add/drop column.
// older version (or at target) has to get td first, potential deadlock
if  tableconglomerateid    0
td   dd gettabledescriptor tableid
if  td    null
throw standardexception newexception
sqlstate lang_table_not_found_during_execution  tablename
tableconglomerateid   td getheapconglomerateid
locktableforddl tc  tableconglomerateid  true
td   dd gettabledescriptor tableid
if  td    null
throw standardexception newexception
sqlstate lang_table_not_found_during_execution  tablename
if  truncatetable
dm invalidatefor td  dependencymanager truncate_table  lcc
else
dm invalidatefor td  dependencymanager alter_table  lcc
// save the tabledescriptor off in the activation
activation setddltabledescriptor td
/*
** if the schema descriptor is null, then we must have just read
** ourselves in.  so we will get the corresponding schema descriptor
** from the data dictionary.
*/
if  sd    null
sd   getandcheckschemadescriptor dd  schemaid
/* prepare all dependents to invalidate.  (this is there chance
* to say that they can't be invalidated.  for example, an open
* cursor referencing a table/view that the user is attempting to
* alter.) if no one objects, then invalidate any dependent objects.
*/
if truncatetable
dm invalidatefor td  dependencymanager truncate_table  lcc
else
dm invalidatefor td  dependencymanager alter_table  lcc
// are we working on columns?
if  columninfo    null
boolean tableneedsscanning   false
/* note: we only allow a single column to be added within
* each alter table command at the language level.  however,
* this may change some day, so we will try to plan for it.
*/
/* for each new column, see if the user is adding a non-nullable
* column.  this is only allowed on an empty table.
*/
for  int ix   0  ix < columninfo length  ix
/* is this new column non-nullable?
* if so, it can only be added to an
* empty table if it does not have a default value.
* we need to scan the table to find out how many rows
* there are.
*/
if   columninfo action    columninfo create
columninfo datatype isnullable
columninfo defaultinfo    null
columninfo autoincinc    0
tableneedsscanning   true
// scan the table if necessary
if  tableneedsscanning
numrows   getsemirowcount tc
// don't allow add of non-nullable column to non-empty table
if  numrows > 0
throw standardexception newexception
sqlstate lang_adding_non_null_column_to_non_empty_table
td getqualifiedname
tablescanned   true
// for each related column, stuff system.column
for  int ix   0  ix < columninfo length  ix
columndescriptorlist cdl   new columndescriptorlist
/* if there is a default value, use it, otherwise use null */
// are we adding a new column or modifying a default?
if  columninfo action    columninfo create
addnewcolumntotable activation  lcc  dd  tc  ix
else if  columninfo action
columninfo modify_column_default_restart
columninfo action
columninfo modify_column_default_increment
columninfo action
columninfo modify_column_default_value
modifycolumndefault activation  ix
else if  columninfo action
columninfo modify_column_type
modifycolumntype activation  ix
else if  columninfo action
columninfo modify_column_constraint
modifycolumnconstraint
activation  columninfo name  true
else if  columninfo action
columninfo modify_column_constraint_not_null
if   tablescanned
tablescanned   true
numrows   getsemirowcount tc
// check that the data in the column is not null
string colnames    new string
colnames          columninfo name
boolean nullcols   new boolean
/* note validatenotnullconstraint returns true if the
* column is nullable
*/
if  validatenotnullconstraint
colnames  nullcols  numrows  lcc
sqlstate lang_null_data_in_non_null_column
/* nullable column - modify it to be not null
* this is o.k. at this point since we would have
* thrown an exception if any data was null
*/
modifycolumnconstraint
activation  columninfo name  false
else if  columninfo action    columninfo drop
dropcolumnfromtable activation  columninfo name
else if  sanitymanager debug
sanitymanager throwassert
/* create/drop any constraints */
if  constraintactions    null
for  int conindex   0
conindex < constraintactions length
conindex
constraintconstantaction cca   constraintactions
if  cca instanceof createconstraintconstantaction
int constrainttype   cca getconstrainttype
/* some constraint types require special checking:
*   check		 - table must be empty, for now
*   primary key - table cannot already have a primary key
*/
switch  constrainttype
case datadictionary primarykey_constraint
// check to see if a constraint of the same type
// already exists
constraintdescriptorlist cdl
dd getconstraintdescriptors td
if  cdl getprimarykey      null
throw standardexception newexception
sqlstate lang_add_primary_key_failed1
td getqualifiedname
if   tablescanned
tablescanned   true
numrows   getsemirowcount tc
break
case datadictionary check_constraint
if   tablescanned
tablescanned   true
numrows   getsemirowcount tc
if  numrows > 0
/*
** we are assuming that there will only be one
** check constraint that we are adding, so it
** is ok to do the check now rather than try
** to lump together several checks.
*/
constraintconstantaction validateconstraint
cca getconstraintname
createconstraintconstantaction cca  getconstrainttext
td
lcc  true
break
else
if  sanitymanager debug
if    cca instanceof dropconstraintconstantaction
sanitymanager throwassert
conindex
cca getclass   getname
constraintactions executeconstantaction activation
// are we changing the lock granularity?
if  lockgranularity
if  sanitymanager debug
if  lockgranularity
lockgranularity
sanitymanager throwassert
lockgranularity
// update the tabledescriptor
td setlockgranularity lockgranularity
// update the datadictionary
dd updatelockgranularity td  sd  lockgranularity  tc
// are we doing a compress table?
if  compresstable
compresstable activation
// are we doing a truncate table?
if  truncatetable
truncatetable activation
/**
* update statistics of either all the indexes on the table or only one
* specific index depending on what user has requested.
*
* @param   activation  the current activation
* @throws standardexception
*/
private void updatestatistics activation activation
throws standardexception
languageconnectioncontext lcc   activation getlanguageconnectioncontext
datadictionary dd   lcc getdatadictionary
transactioncontroller tc   lcc gettransactionexecute
conglomeratedescriptor cds
long conglomeratenumber
execindexrow indexrow
uuid objectuuid
groupfetchscancontroller gsc
dependencymanager dm   dd getdependencymanager
//initialize numrows to -1 so we can tell if we scanned an index.
long numrows    1
td   dd gettabledescriptor tableid
if  updatestatisticsall
cds   td getconglomeratedescriptors
else
cds   new conglomeratedescriptor
cds   dd getconglomeratedescriptor indexnameforupdatestatistics  sd  false
conglomeratenumber   new long
indexrow   new execindexrow
objectuuid   new uuid
conglomeratecontroller heapcc
tc openconglomerate td getheapconglomerateid    false  0
transactioncontroller mode_record
transactioncontroller isolation_repeatable_read
try
for  int i   0  i < cds length  i
if   cds isindex
conglomeratenumber    1
continue
conglomeratenumber   cds getconglomeratenumber
objectuuid   cds getuuid
indexrow
cds getindexdescriptor   getnullindexrow
td getcolumndescriptorlist
heapcc newrowlocationtemplate
finally
heapcc close
dd startwriting lcc
dm invalidatefor td  dependencymanager update_statistics  lcc
for  int indexnumber   0  indexnumber < conglomeratenumber length
indexnumber
if  conglomeratenumber     1
continue
int numcols   indexrow ncolumns     1
long cardinality   new long
numrows   0
initializerowbuffers indexrow
/* read uncommited, with record locking. actually cs store may
not hold record locks */
gsc
tc opengroupfetchscan
conglomeratenumber
false      hold
0          openmode  for read
transactioncontroller mode_record     locking
transactioncontroller isolation_read_uncommitted    isolation level
null       scancolumnlist   want everything
null       startkeyvalue   start from the beginning
0
null       qualifiers  none
null       stopkeyvalue
0
try
boolean firstrow   true
int rowsfetched   0
while   rowsfetched   gsc fetchnextgroup rowbufferarray  null   > 0
for  int i   0  i < rowsfetched  i
int whichpositionchanged   comparewithprevkey i  firstrow
firstrow   false
if  whichpositionchanged >  0
for  int j   whichpositionchanged  j < cardinality length  j
cardinality
numrows
datavaluedescriptor tmp
tmp   rowbufferarray
rowbufferarray   lastuniquekey
lastuniquekey   tmp
while
gsc setestimatedrowcount numrows
try
finally
gsc close
gsc   null
if  numrows    0
/* if there is no data in the table: no need to write anything
* to sys.sysstatstics
*/
break
statisticsdescriptor statdesc
dd dropstatisticsdescriptors tableid  objectuuid
tc
for  int i   0  i < indexrow ncolumns     1  i
statdesc   new statisticsdescriptor dd  dd getuuidfactory   createuuid
objectuuid
tableid
new statisticsimpl numrows
cardinality
i   1
dd adddescriptor statdesc  null
datadictionary sysstatistics_catalog_num
true  tc
for each leading column  c1   c1 c2
for each index
// derby-4116 if there were indexes we scanned, we now know the row count.
// update statistics should update the store estimated row count for the table.
// if we didn't scan an index and don't know, numrows will still be -1 and
// we skip the estimatedrowcount update.
if  numrows     1
return
scancontroller heapsc   tc openscan td getheapconglomerateid
false      hold
0          openmode  for read
transactioncontroller mode_record     locking
transactioncontroller isolation_read_uncommitted    isolation level
null       scancolumnlist   want everything
null       startkeyvalue   start from the beginning
0
null       qualifiers  none
null       stopkeyvalue
0
try
heapsc setestimatedrowcount numrows
finally
heapsc close
private void initializerowbuffers execindexrow ir
rowbufferarray   new datavaluedescriptor
lastuniquekey   ir getrowarrayclone
rowbufferarray   ir getrowarray       1 gets old objects
private int comparewithprevkey int index  boolean firstrow
throws standardexception
if  firstrow
return 0
datavaluedescriptor prev    index    0  ? lastuniquekey   rowbufferarray
datavaluedescriptor curr   rowbufferarray
// no point trying to do rowlocation; hence - 1
for  int i   0  i <  prev length   1   i
datavaluedescriptor dvd    datavaluedescriptor prev
if  dvd isnull
return i    nulls are counted as unique values
if  prev compare curr     0
return i
return  1
/**
* truncate end of conglomerate.
* <p>
* returns the contiguous free space at the end of the table back to
* the operating system.  takes care of space allocation bit maps, and
* os call to return the actual space.
* <p>
*
* @param tc                transaction controller to use to do updates.
*
**/
private void truncateend
transactioncontroller   tc
throws standardexception
switch  td gettabletype
/* skip views and vti tables */
case tabledescriptor view_type
case tabledescriptor vti_type
break
// other types give various errors here
// derby-719,derby-720
default
conglomeratedescriptor conglom_descriptors
td getconglomeratedescriptors
for  int cd_idx   0  cd_idx < conglom_descriptors length  cd_idx
conglomeratedescriptor cd   conglom_descriptors
tc compressconglomerate cd getconglomeratenumber
return
/**
* defragment rows in the given table.
* <p>
* scans the rows at the end of a table and moves them to free spots
* towards the beginning of the table.  in the same transaction all
* associated indexes are updated to reflect the new location of the
* base table row.
* <p>
* after a defragment pass, if was possible, there will be a set of
* empty pages at the end of the table which can be returned to the
* operating system by calling truncateend().  the allocation bit
* maps will be set so that new inserts will tend to go to empty and
* half filled pages starting from the front of the conglomerate.
*
* @param tc                transaction controller to use to do updates.
* @param lcc				the language connection context
*
**/
private void defragmentrows
transactioncontroller tc
languageconnectioncontext lcc
throws standardexception
groupfetchscancontroller base_group_fetch_cc   null
int                      num_indexes           0
int                  index_col_map          null
scancontroller         index_scan             null
conglomeratecontroller index_cc               null
datavaluedescriptor  index_row              null
transactioncontroller     nested_tc   null
try
nested_tc
tc startnestedusertransaction false
switch  td gettabletype
/* skip views and vti tables */
case tabledescriptor view_type
case tabledescriptor vti_type
return
// other types give various errors here
// derby-719,derby-720
default
break
conglomeratedescriptor heapcd
td getconglomeratedescriptor td getheapconglomerateid
/* get a row template for the base table */
execrow baserow
lcc getlanguageconnectionfactory   getexecutionfactory   getvaluerow
td getnumberofcolumns
/* fill the row with nulls of the correct type */
columndescriptorlist cdl   td getcolumndescriptorlist
int					 cdlsize   cdl size
for  int index   0  index < cdlsize  index
columndescriptor cd    columndescriptor  cdl elementat index
baserow setcolumn cd getposition    cd gettype   getnull
datavaluedescriptor row_array   new datavaluedescriptor
row_array   baserow getrowarray
rowlocation old_row_location_array   new rowlocation
rowlocation new_row_location_array   new rowlocation
// create the following 3 arrays which will be used to update
// each index as the scan moves rows about the heap as part of
// the compress:
//     index_col_map - map location of index cols in the base row,
//                     ie. index_col_map[0] is column offset of 1st
//                     key column in base row.  all offsets are 0
//                     based.
//     index_scan - open scancontroller used to delete old index row
//     index_cc   - open conglomeratecontroller used to insert new
//                  row
conglomeratedescriptor conglom_descriptors
td getconglomeratedescriptors
// conglom_descriptors has an entry for the conglomerate and each
// one of it's indexes.
num_indexes   conglom_descriptors length   1
// if indexes exist, set up data structures to update them
if  num_indexes > 0
// allocate arrays
index_col_map     new int
index_scan        new scancontroller
index_cc          new conglomeratecontroller
index_row         new datavaluedescriptor
setup_indexes
nested_tc
td
index_col_map
index_scan
index_cc
index_row
/* open the heap for reading */
base_group_fetch_cc
nested_tc defragmentconglomerate
td getheapconglomerateid
false
true
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
int num_rows_fetched   0
while   num_rows_fetched
base_group_fetch_cc fetchnextgroup
row_array
old_row_location_array
new_row_location_array      0
if  num_indexes > 0
for  int row   0  row < num_rows_fetched  row
for  int index   0  index < num_indexes  index
fixindex
row_array
index_row
old_row_location_array
new_row_location_array
index_cc
index_scan
index_col_map
// todo - it would be better if commits happened more frequently
// in the nested transaction, but to do that there has to be more
// logic to catch a ddl that might jump in the middle of the
// above loop and invalidate the various table control structures
// which are needed to properly update the indexes.  for example
// the above loop would corrupt an index added midway through
// the loop if not properly handled.  see derby-1188.
nested_tc commit
finally
/* clean up before we leave */
if  base_group_fetch_cc    null
base_group_fetch_cc close
base_group_fetch_cc   null
if  num_indexes > 0
for  int i   0  i < num_indexes  i
if  index_scan    null    index_scan    null
index_scan close
index_scan   null
if  index_cc    null    index_cc    null
index_cc close
index_cc   null
if  nested_tc    null
nested_tc destroy
return
private static void setup_indexes
transactioncontroller       tc
tabledescriptor             td
int                     index_col_map
scancontroller            index_scan
conglomeratecontroller    index_cc
datavaluedescriptor     index_row
throws standardexception
// initialize the following 3 arrays which will be used to update
// each index as the scan moves rows about the heap as part of
// the compress:
//     index_col_map - map location of index cols in the base row, ie.
//                     index_col_map[0] is column offset of 1st key
//                     column in base row.  all offsets are 0 based.
//     index_scan - open scancontroller used to delete old index row
//     index_cc   - open conglomeratecontroller used to insert new row
conglomeratedescriptor conglom_descriptors
td getconglomeratedescriptors
int index_idx   0
for  int cd_idx   0  cd_idx < conglom_descriptors length  cd_idx
conglomeratedescriptor index_cd   conglom_descriptors
if   index_cd isindex
// skip the heap descriptor entry
continue
// scancontrollers are used to delete old index row
index_scan
tc openscan
index_cd getconglomeratenumber
true 	   hold
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
null       full row is retrieved
// so that full row can be used for start/stop keys
null 	   startkeyvalue   will be reset with reopenscan
0
null 	   qualifier
null 	   stopkeyvalue    will be reset with reopenscan
0
// conglomeratecontrollers are used to insert new index row
index_cc
tc openconglomerate
index_cd getconglomeratenumber
true      hold
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
// build column map to allow index row to be built from base row
int basecolumnpositions
index_cd getindexdescriptor   basecolumnpositions
int zero_based_map
new int
for  int i   0  i < basecolumnpositions length  i
zero_based_map   basecolumnpositions   1
index_col_map   zero_based_map
// build row array to delete from index and insert into index
//     length is length of column map + 1 for rowlocation.
index_row
new datavaluedescriptor
index_idx
return
/**
* delete old index row and insert new index row in input index.
* <p>
*
* @param base_row      all columns of base row
* @param index_row     an index row template, filled in by this routine
* @param old_row_loc   old location of base row, used to delete index
* @param new_row_loc   new location of base row, used to update index
* @param index_cc      index conglomerate to insert new row
* @param index_scan    index scan to delete old entry
* @param index_col_map description of mapping of index row to base row,
*
*
* @exception  standardexception  standard exception policy.
**/
private static void fixindex
datavaluedescriptor   base_row
datavaluedescriptor   index_row
rowlocation             old_row_loc
rowlocation             new_row_loc
conglomeratecontroller  index_cc
scancontroller          index_scan
int					index_col_map
throws standardexception
if  sanitymanager debug
// basecolumnpositions should describe all columns in index row
// except for the final column, which is the rowlocation.
sanitymanager assert index_col_map    null
sanitymanager assert index_row    null
sanitymanager assert
index_col_map length     index_row length   1
// create the index row to delete from from the base row, using map
for  int index   0  index < index_col_map length  index
index_row   base_row]
// last column in index in the rowlocation
index_row   old_row_loc
// position the scan for the delete, the scan should already be open.
// this is done by setting start scan to full key, ge and stop scan
// to full key, gt.
index_scan reopenscan
index_row
scancontroller ge
qualifier  null
index_row
scancontroller gt
// position the scan, serious problem if scan does not find the row.
if  index_scan next
index_scan delete
else
// didn't find the row we wanted to delete.
if  sanitymanager debug
sanitymanager throwassert
rowutil tostring base_row
rowutil tostring index_row
// insert the new index row into the conglomerate
index_row   new_row_loc
index_cc insert index_row
return
/**
* purge committed deleted rows from conglomerate.
* <p>
* scans the table and purges any committed deleted rows from the
* table.  if all rows on a page are purged then page is also
* reclaimed.
* <p>
*
* @param tc                transaction controller to use to do updates.
*
**/
private void purgerows transactioncontroller   tc
throws standardexception
switch  td gettabletype
/* skip views and vti tables */
case tabledescriptor view_type
case tabledescriptor vti_type
break
// other types give various errors here
// derby-719,derby-720
default
conglomeratedescriptor conglom_descriptors
td getconglomeratedescriptors
for  int cd_idx   0  cd_idx < conglom_descriptors length  cd_idx
conglomeratedescriptor cd   conglom_descriptors
tc purgeconglomerate cd getconglomeratenumber
return
/**
* workhorse for adding a new column to a table.
*
* @param   ix 			the index of the column specfication in the alter
*						statement-- currently we allow only one.
* @exception standardexception 	thrown on failure.
*/
private void addnewcolumntotable
activation                  activation
languageconnectioncontext   lcc
datadictionary              dd
transactioncontroller       tc
int                         ix
throws standardexception
columndescriptor columndescriptor
td getcolumndescriptor columninfo name
datavaluedescriptor storabledv
int                     colnumber     td getmaxcolumnid     ix
datadescriptorgenerator ddg           dd getdatadescriptorgenerator
/* we need to verify that the table does not have an existing
* column with the same name before we try to add the new
* one as addcolumndescriptor() is a void method.
*/
if  columndescriptor    null
throw
standardexception newexception
sqlstate lang_object_already_exists_in_object
columndescriptor getdescriptortype
columninfo name
td getdescriptortype
td getqualifiedname
if  columninfo defaultvalue    null
storabledv   columninfo defaultvalue
else
storabledv   columninfo datatype getnull
// add the column to the conglomerate.(column ids in store are 0-based)
tc addcolumntoconglomerate
td getheapconglomerateid
colnumber
storabledv
columninfo datatype getcollationtype
uuid defaultuuid   columninfo newdefaultuuid
/* generate a uuid for the default, if one exists
* and there is no default id yet.
*/
if  columninfo defaultinfo    null
defaultuuid    null
defaultuuid   dd getuuidfactory   createuuid
// add the column to syscolumns.
// column ids in system tables are 1-based
columndescriptor
new columndescriptor
columninfo name
colnumber   1
columninfo datatype
columninfo defaultvalue
columninfo defaultinfo
td
defaultuuid
columninfo autoincstart
columninfo autoincinc
dd adddescriptor columndescriptor  td
datadictionary syscolumns_catalog_num  false  tc
// now add the column to the tables column descriptor list.
td getcolumndescriptorlist   add columndescriptor
if  columndescriptor isautoincrement
updatenewautoincrementcolumn activation  columninfo name
columninfo autoincstart
columninfo autoincinc
// update the new column to its default, if it has a non-null default
if  columndescriptor hasnonnulldefault
updatenewcolumntodefault activation  columndescriptor  lcc
//
// add dependencies. these can arise if a generated column depends
// on a user created function.
//
addcolumndependencies  lcc  dd  td  columninfo
// update syscolperms table which tracks the permissions granted
// at columns level. the sytem table has a bit map of all the columns
// in the user table to help determine which columns have the
// permission granted on them. since we are adding a new column,
// that bit map needs to be expanded and initialize the bit for it
// to 0 since at the time of add column, no permissions have been
// granted on that new column.
//
dd updatesyscolpermsforaddcolumntousertable td getuuid    tc
/**
* workhorse for dropping a column from a table.
*
* this routine drops a column from a table, taking care
* to properly handle the various related schema objects.
*
* the syntax which gets you here is:
*
*   alter table tbl drop [column] col [cascade|restrict]
*
* the keyword column is optional, and if you don't
* specify cascade or restrict, the default is cascade
* (the default is chosen in the parser, not here).
*
* if you specify restrict, then the column drop should be
* rejected if it would cause a dependent schema object
* to become invalid.
*
* if you specify cascade, then the column drop should
* additionally drop other schema objects which have
* become invalid.
*
* you may not drop the last (only) column in a table.
*
* schema objects of interest include:
*  - views
*  - triggers
*  - constraints
*    - check constraints
*    - primary key constraints
*    - foreign key constraints
*    - unique key constraints
*    - not null constraints
*  - privileges
*  - indexes
*  - default values
*
* dropping a column may also change the column position
* numbers of other columns in the table, which may require
* fixup of schema objects (such as triggers and column
* privileges) which refer to columns by column position number.
*
* indexes are a bit interesting. the official sql spec
* doesn't talk about indexes; they are considered to be
* an imlementation-specific performance optimization.
* the current derby behavior is that:
*  - cascade/restrict doesn't matter for indexes
*  - when a column is dropped, it is removed from any indexes
*    which contain it.
*  - if that column was the only column in the index, the
*    entire index is dropped.
*
* @param   activation  the current activation
* @param   columnname the name of the column specfication in the alter
*						statement-- currently we allow only one.
* @exception standardexception 	thrown on failure.
*/
private void dropcolumnfromtable activation activation  string columnname
throws standardexception
languageconnectioncontext lcc   activation getlanguageconnectioncontext
datadictionary dd   lcc getdatadictionary
dependencymanager dm   dd getdependencymanager
transactioncontroller tc   lcc gettransactionexecute
boolean cascade    behavior    statementtype drop_cascade
// drop any generated columns which reference this column
columndescriptorlist    generatedcolumnlist   td getgeneratedcolumns
int                                 generatedcolumncount   generatedcolumnlist size
arraylist                   cascadeddroppedcolumns   new arraylist
for   int i   0  i < generatedcolumncount  i
columndescriptor    generatedcolumn   generatedcolumnlist elementat  i
string                       referencedcolumnnames   generatedcolumn getdefaultinfo   getreferencedcolumnnames
int                         referencedcolumncount   referencedcolumnnames length
for   int j   0  j < referencedcolumncount  j
if   columnname equals  referencedcolumnnames
string      generatedcolumnname   generatedcolumn getcolumnname
// ok, the current generated column references the column
// we're trying to drop
if    cascade
// reject the drop column, because there exists a
// generated column which references this column.
//
throw standardexception newexception
sqlstate lang_provider_has_dependent_object
dm getactionstring dependencymanager drop_column
columnname
generatedcolumnname
else
cascadeddroppedcolumns add  generatedcolumnname
datadescriptorgenerator ddg   dd getdatadescriptorgenerator
int                             cascadeddrops   cascadeddroppedcolumns size
int sizeaftercascadeddrops   td getcolumndescriptorlist   size     cascadeddrops
// can not drop a column if it is the only one in the table
if  sizeaftercascadeddrops    1
throw standardexception newexception
sqlstate lang_provider_has_dependent_object
dm getactionstring dependencymanager drop_column
columnname
td getqualifiedname
// now drop dependent generated columns
for   int i   0  i < cascadeddrops  i
string      generatedcolumnname    string  cascadeddroppedcolumns get  i
activation addwarning
standardexception newwarning  sqlstate lang_gen_col_dropped  generatedcolumnname  td getname
//
// we can only recurse 2 levels since a generation clause cannot
// refer to other generated columns.
//
dropcolumnfromtable  activation  generatedcolumnname
/*
* cascaded drops of dependent generated columns may require us to
* rebuild the table descriptor.
*/
td   dd gettabledescriptor tableid
columndescriptor columndescriptor   td getcolumndescriptor  columnname
// we already verified this in bind, but do it again
if  columndescriptor    null
throw
standardexception newexception
sqlstate lang_column_not_found_in_table
columnname
td getqualifiedname
int size   td getcolumndescriptorlist   size
droppedcolumnposition   columndescriptor getposition
formatablebitset todrop   new formatablebitset size   1
todrop set droppedcolumnposition
td setreferencedcolumnmap todrop
dm invalidatefor td
cascade ? dependencymanager drop_column
dependencymanager drop_column_restrict
lcc
// if column has a default we drop the default and any dependencies
if  columndescriptor getdefaultinfo      null
dm cleardependencies
lcc  columndescriptor getdefaultdescriptor dd
// need to deal with triggers if has referencedcolumns
genericdescriptorlist tdl   dd gettriggerdescriptors td
enumeration descs   tdl elements
while  descs hasmoreelements
triggerdescriptor trd    triggerdescriptor  descs nextelement
int referencedcols   trd getreferencedcols
if  referencedcols    null
continue
int refcollen   referencedcols length  j
boolean changed   false
for  j   0  j < refcollen  j
if  referencedcols > droppedcolumnposition
changed   true
else if  referencedcols    droppedcolumnposition
if  cascade
trd drop lcc
activation addwarning
standardexception newwarning
sqlstate lang_trigger_dropped
trd getname    td getname
else
we t drop it
// otherwsie there would be unexpected behaviors
throw standardexception newexception
sqlstate lang_provider_has_dependent_object
dm getactionstring dependencymanager drop_column
columnname
trd getname
break
// change triggers to refer to columns in new positions
if  j    refcollen    changed
dd droptriggerdescriptor trd  tc
for  j   0  j < refcollen  j
if  referencedcols > droppedcolumnposition
referencedcols
dd adddescriptor trd  sd
datadictionary systriggers_catalog_num
false  tc
constraintdescriptorlist csdl   dd getconstraintdescriptors td
int csdl_size   csdl size
arraylist newcongloms   new arraylist
// we want to remove referenced primary/unique keys in the second
// round.  this will ensure that self-referential constraints will
// work ok.
int tbr_size   0
constraintdescriptor toberemoved
new constraintdescriptor
// let's go downwards, don't want to get messed up while removing
for  int i   csdl_size   1  i >  0  i
constraintdescriptor cd   csdl elementat i
int referencedcolumns   cd getreferencedcolumns
int numrefcols   referencedcolumns length  j
boolean changed   false
for  j   0  j < numrefcols  j
if  referencedcolumns > droppedcolumnposition
changed   true
if  referencedcolumns    droppedcolumnposition
break
if  j    numrefcols 			   column not referenced
if   cd instanceof checkconstraintdescriptor     changed
dd dropconstraintdescriptor cd  tc
for  j   0  j < numrefcols  j
if  referencedcolumns > droppedcolumnposition
referencedcolumns
checkconstraintdescriptor  cd  setreferencedcolumnsdescriptor new referencedcolumnsdescriptorimpl referencedcolumns
dd addconstraintdescriptor cd  tc
continue
if    cascade
// reject the drop column, because there exists a constraint
// which references this column.
//
throw standardexception newexception
sqlstate lang_provider_has_dependent_object
dm getactionstring dependencymanager drop_column
columnname
cd getconstraintname
if  cd instanceof referencedkeyconstraintdescriptor
// restrict will raise an error in invalidate if referenced
toberemoved   cd
continue
// drop now in all other cases
dm invalidatefor cd  dependencymanager drop_constraint
lcc
dropconstraint cd  td  newcongloms  activation  lcc  true
activation addwarning
standardexception newwarning sqlstate lang_constraint_dropped
cd getconstraintname    td getname
for  int i   tbr_size   1  i >  0  i
constraintdescriptor cd   toberemoved
dropconstraint cd  td  newcongloms  activation  lcc  false
activation addwarning
standardexception newwarning sqlstate lang_constraint_dropped
cd getconstraintname    td getname
if  cascade
constraintdescriptorlist fkcdl   dd getforeignkeys cd getuuid
for  int j   0  j < fkcdl size    j
constraintdescriptor fkcd
constraintdescriptor  fkcdl elementat j
dm invalidatefor fkcd
dependencymanager drop_constraint
lcc
dropconstraint fkcd  td
newcongloms  activation  lcc  true
activation addwarning
standardexception newwarning
sqlstate lang_constraint_dropped
fkcd getconstraintname
fkcd gettabledescriptor   getname
dm invalidatefor cd  dependencymanager drop_constraint  lcc
dm cleardependencies lcc  cd
/* if there are new backing conglomerates which must be
* created to replace a dropped shared conglomerate
* (where the shared conglomerate was dropped as part
* of a "drop constraint" call above), then create them
* now.  we do this *after* dropping all dependent
* constraints because we don't want to waste time
* creating a new conglomerate if it's just going to be
* dropped again as part of another "drop constraint".
*/
createnewbackingcongloms
newcongloms   long null  activation  dd
/*
* the work we've done above, specifically the possible
* dropping of primary key, foreign key, and unique constraints
* and their underlying indexes, may have affected the table
* descriptor. by re-reading the table descriptor here, we
* ensure that the compresstable code is working with an
* accurate table descriptor. without this line, we may get
* conglomerate-not-found errors and the like due to our
* stale table descriptor.
*/
td   dd gettabledescriptor tableid
compresstable activation
columndescriptorlist tab_cdl   td getcolumndescriptorlist
// drop the column from syscolumns
dd dropcolumndescriptor td getuuid    columnname  tc
columndescriptor cdlarray
new columndescriptor
// for each column in this table with a higher column position,
// drop the entry from syscolumns, but hold on to the column
// descriptor and reset its position to adjust for the dropped
// column. then, re-add all those adjusted column descriptors
// back to syscolumns
//
for  int i   columndescriptor getposition    j   0  i < size  i    j
columndescriptor cd    columndescriptor  tab_cdl elementat i
dd dropcolumndescriptor td getuuid    cd getcolumnname    tc
cd setposition i
if  cd isautoincrement
cd setautoinc_create_or_modify_start_increment
columndefinitionnode create_autoincrement
cdlarray   cd
dd adddescriptorarray cdlarray  td
datadictionary syscolumns_catalog_num  false  tc
list deps   dd getprovidersdescriptorlist td getobjectid   tostring
for  iterator depsiterator   deps listiterator
depsiterator hasnext
dependencydescriptor depdesc
dependencydescriptor  depsiterator next
dependablefinder finder   depdesc getproviderfinder
if  finder instanceof ddcolumndependablefinder
ddcolumndependablefinder colfinder
ddcolumndependablefinder  finder
formatablebitset oldcolumnbitmap
new formatablebitset colfinder getcolumnbitmap
formatablebitset newcolumnbitmap
new formatablebitset oldcolumnbitmap
newcolumnbitmap clear
int bitlen   oldcolumnbitmap getlength
for  int i   0  i < bitlen  i
if  i < droppedcolumnposition    oldcolumnbitmap isset i
newcolumnbitmap set i
if  i > droppedcolumnposition    oldcolumnbitmap isset i
newcolumnbitmap set i   1
if  newcolumnbitmap equals oldcolumnbitmap
continue
dd dropstoreddependency depdesc  tc
colfinder setcolumnbitmap newcolumnbitmap getbytearray
dd adddescriptor depdesc  null
datadictionary sysdepends_catalog_num
true  tc
// adjust the column permissions rows in syscolperms to reflect the
// changed column positions due to the dropped column:
dd updatesyscolpermsfordropcolumn td getuuid    tc  columndescriptor
// remove column descriptor from table descriptor. this fixes up the
// list in case we were called recursively in order to cascade-drop a
// dependent generated column.
tab_cdl remove  td getcolumndescriptor  columnname
private void modifycolumntype activation activation
int ix
throws standardexception
languageconnectioncontext lcc   activation getlanguageconnectioncontext
datadictionary dd   lcc getdatadictionary
transactioncontroller tc   lcc gettransactionexecute
columndescriptor columndescriptor
td getcolumndescriptor columninfo name
newcolumndescriptor   null
newcolumndescriptor
new columndescriptor columninfo name
columndescriptor getposition
columninfo datatype
columndescriptor getdefaultvalue
columndescriptor getdefaultinfo
td
columndescriptor getdefaultuuid
columninfo autoincstart
columninfo autoincinc
// update the columndescriptor with new default info
dd dropcolumndescriptor td getuuid    columninfo name  tc
dd adddescriptor newcolumndescriptor  td
datadictionary syscolumns_catalog_num  false  tc
/**
* workhorse for modifying column level constraints.
* right now it is restricted to modifying a null constraint to a not null
* constraint.
*/
private void modifycolumnconstraint activation activation
string colname
boolean nullability
throws standardexception
languageconnectioncontext lcc
activation getlanguageconnectioncontext
datadictionary dd   lcc getdatadictionary
transactioncontroller tc   lcc gettransactionexecute
columndescriptor columndescriptor
td getcolumndescriptor colname
newcolumndescriptor   null
// get the type and change the nullability
datatypedescriptor datatype
columndescriptor gettype   getnullabilitytype nullability
//check if there are any unique constraints to update
constraintdescriptorlist cdl   dd getconstraintdescriptors td
int columnpostion   columndescriptor getposition
for  int i   0  i < cdl size    i
constraintdescriptor cd   cdl elementat i
if  cd getconstrainttype      datadictionary unique_constraint
columndescriptorlist columns   cd getcolumndescriptors
for  int count   0  count < columns size    count
if  columns elementat count  getposition      columnpostion
break
//get backing index
conglomeratedescriptor desc
td getconglomeratedescriptor cd getconglomerateid
//check if the backing index was created when the column
//not null ie is backed by unique index
if   desc getindexdescriptor   isunique
break
// replace backing index with a unique when not null index.
recreateuniqueconstraintbackingindexasuniquewhennotnull
desc  td  activation  lcc
newcolumndescriptor
new columndescriptor colname
columndescriptor getposition
datatype
columndescriptor getdefaultvalue
columndescriptor getdefaultinfo
td
columndescriptor getdefaultuuid
columndescriptor getautoincstart
columndescriptor getautoincinc
// update the columndescriptor with new default info
dd dropcolumndescriptor td getuuid    colname  tc
dd adddescriptor newcolumndescriptor  td
datadictionary syscolumns_catalog_num  false  tc
/**
* workhorse for modifying the default value of a column.
*
* @param 		activation 		activation
* @param       ix 		the index of the column specfication in the alter
*						statement-- currently we allow only one.
* @exception	standardexception, thrown on error.
*/
private void modifycolumndefault activation activation
int ix
throws standardexception
languageconnectioncontext lcc   activation getlanguageconnectioncontext
datadictionary dd   lcc getdatadictionary
dependencymanager dm   dd getdependencymanager
transactioncontroller tc   lcc gettransactionexecute
columndescriptor columndescriptor
td getcolumndescriptor columninfo name
datadescriptorgenerator ddg   dd getdatadescriptorgenerator
int columnposition   columndescriptor getposition
// clean up after the old default, if non-null
if  columndescriptor hasnonnulldefault
// invalidate off of the old default
defaultdescriptor defaultdescriptor   new defaultdescriptor dd  columninfo olddefaultuuid
td getuuid    columnposition
dm invalidatefor defaultdescriptor  dependencymanager modify_column_default  lcc
// drop any dependencies
dm cleardependencies lcc  defaultdescriptor
uuid defaultuuid   columninfo newdefaultuuid
/* generate a uuid for the default, if one exists
* and there is no default id yet.
*/
if  columninfo defaultinfo    null
defaultuuid    null
defaultuuid   dd getuuidfactory   createuuid
/* get a columndescriptor reflecting the new default */
columndescriptor   new columndescriptor
columninfo name
columnposition
columninfo datatype
columninfo defaultvalue
columninfo defaultinfo
td
defaultuuid
columninfo autoincstart
columninfo autoincinc
columninfo autoinc_create_or_modify_start_increment
// update the columndescriptor with new default info
dd dropcolumndescriptor td getuuid    columninfo name  tc
dd adddescriptor columndescriptor  td
datadictionary syscolumns_catalog_num  false  tc
if  columninfo action    columninfo modify_column_default_increment
// adding an autoincrement default-- calculate the maximum value
// of the autoincrement column.
long maxvalue   getcolumnmax activation  td  columninfo name
columninfo autoincinc
columninfo autoincstart
dd setautoincrementvalue tc  td getuuid    columninfo name
maxvalue  true
else if  columninfo action    columninfo modify_column_default_restart
dd setautoincrementvalue tc  td getuuid    columninfo name
columninfo autoincstart  false
// else we are simply changing the default value
/**
* routine to process compress table or alter table <t> drop column <c>;
* <p>
* uses class level variable "compresstable" to determine if processing
* compress table or drop column:
*     if (!compresstable)
*         must be drop column.
* <p>
* handles rebuilding of base conglomerate and all necessary indexes.
**/
private void compresstable
activation activation
throws standardexception
long					newheapconglom
properties				properties   new properties
rowlocation				rl
this lcc          activation getlanguageconnectioncontext
this dd           lcc getdatadictionary
this dm           dd getdependencymanager
this tc           lcc gettransactionexecute
this activation   activation
if  sanitymanager debug
if  lockgranularity
sanitymanager throwassert
lockgranularity
sanitymanager assert   compresstable    columninfo    null
sanitymanager assert constraintactions    null
execrow emptyheaprow    td getemptyexecrow
int   collation_ids   td getcolumncollationids
compressheapcc
tc openconglomerate
td getheapconglomerateid
false
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
// invalidate any prepared statements that depended on this table
// (including this one), this fixes problem with threads that start up
// and block on our lock, but do not see they have to recompile their
// plan.  we now invalidate earlier however they still might recompile
// using the old conglomerate id before we commit our dd changes.
//
dm invalidatefor td  dependencymanager compress_table  lcc
rl   compressheapcc newrowlocationtemplate
// get the properties on the old heap
compressheapcc getinternaltablepropertyset properties
compressheapcc close
compressheapcc   null
// create an array to put base row template
baserow   new execrow
baserowarray   new datavaluedescriptor
validrow   new boolean
/* set up index info */
getaffectedindexes activation
// get an array of rowlocation template
compressrl   new rowlocation
indexrows    new execindexrow
if   compresstable
// must be a drop column, thus the number of columns in the
// new template row and the collation template is one less.
execrow newrow
activation getexecutionfactory   getvaluerow
emptyheaprow ncolumns     1
int   new_collation_ids   new int
for  int i   0  i < newrow ncolumns    i
newrow setcolumn
i   1
i < droppedcolumnposition   1 ?
emptyheaprow getcolumn i   1
emptyheaprow getcolumn i   1   1
new_collation_ids
collation_ids[
i < droppedcolumnposition   1  ? i    i   1 ]
emptyheaprow   newrow
collation_ids   new_collation_ids
setupallsorts emptyheaprow  rl
// start by opening a full scan on the base table.
openbulkfetchscan td getheapconglomerateid
// get the estimated row count for the sorters
estimatedrowcount   compressheapgsc getestimatedrowcount
// create the array of base row template
for  int i   0  i < bulkfetchsize  i
// create a base row template
baserow   td getemptyexecrow
baserowarray   baserow getrowarray
compressrl   compressheapgsc newrowlocationtemplate
newheapconglom
tc createandloadconglomerate
emptyheaprow getrowarray
null    column sort order   not required for heap
collation_ids
properties
transactioncontroller is_default
this
long  null
closebulkfetchscan
// set the "estimated" row count
scancontroller compressheapsc   tc openscan
newheapconglom
false
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
formatablebitset  null
datavaluedescriptor  null
0
qualifier  null
datavaluedescriptor  null
0
compressheapsc setestimatedrowcount rowcount
compressheapsc close
compressheapsc   null     resolve djd cleanup
/*
** inform the data dictionary that we are about to write to it.
** there are several calls to data dictionary "get" methods here
** that might be done in "read" mode in the data dictionary, but
** it seemed safer to do this whole operation in "write" mode.
**
** we tell the data dictionary we're done writing at the end of
** the transaction.
*/
dd startwriting lcc
// update all indexes
if  compressirgs length > 0
updateallindexes newheapconglom  dd
/* update the datadictionary
* resolve - this will change in 1.4 because we will get
* back the same conglomerate number
*/
// get the conglomeratedescriptor for the heap
long oldheapconglom         td getheapconglomerateid
conglomeratedescriptor cd
td getconglomeratedescriptor oldheapconglom
// update sys.sysconglomerates with new conglomerate #
dd updateconglomeratedescriptor cd  newheapconglom  tc
// drop the old conglomerate
tc dropconglomerate oldheapconglom
cleanup
/*
* truncate table  tablename; (quickly removes all the rows from table and
* it's correctponding indexes).
* truncate is implemented by dropping the existing conglomerates(heap,indexes) and recreating a
* new ones  with the properties of dropped conglomerates. currently store
* does not have support to truncate existing conglomerated until store
* supports it , this is the only way to do it.
* error cases: truncate error cases same as other ddl's statements except
* 1)truncate is not allowed when the table is references by another table.
* 2)truncate is not allowed when there are enabled delete triggers on the table.
* note: because conglomerate number is changed during recreate process all the statements will be
* marked as invalide and they will get recompiled internally on their next
* execution. this is okay because truncate makes the number of rows to zero
* it may be good idea to recompile them becuase plans are likely to be
* incorrect. recompile is done internally by derby, user does not have
* any effect.
*/
private void truncatetable activation activation
throws standardexception
execrow					emptyheaprow
long					newheapconglom
properties				properties   new properties
rowlocation				rl
this lcc   activation getlanguageconnectioncontext
this dd   lcc getdatadictionary
this dm   dd getdependencymanager
this tc   lcc gettransactionexecute
this activation   activation
if  sanitymanager debug
if  lockgranularity
sanitymanager throwassert
lockgranularity
sanitymanager assert columninfo    null
sanitymanager assert constraintactions    null
//truncate table is not allowed if there are any tables referencing it.
//except if it is self referencing.
constraintdescriptorlist cdl   dd getconstraintdescriptors td
for int index   0  index < cdl size    index
constraintdescriptor cd   cdl elementat index
if  cd instanceof referencedkeyconstraintdescriptor
referencedkeyconstraintdescriptor rfcd    referencedkeyconstraintdescriptor  cd
if rfcd hasnonselfreferencingfk constraintdescriptor enabled
throw standardexception newexception sqlstate lang_no_truncate_on_fk_reference_table td getname
//truncate is not allowed when there are enabled delete triggers
genericdescriptorlist tdl   dd gettriggerdescriptors td
enumeration descs   tdl elements
while  descs hasmoreelements
triggerdescriptor trd    triggerdescriptor  descs nextelement
if  trd listensforevent triggerdescriptor trigger_event_delete
trd isenabled
throw
standardexception newexception sqlstate lang_no_truncate_on_enabled_delete_triggers
td getname   trd getname
//gather information from the existing conglomerate to create new one.
emptyheaprow   td getemptyexecrow
compressheapcc   tc openconglomerate
td getheapconglomerateid
false
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
// invalidate any prepared statements that
// depended on this table (including this one)
// bug 3653 has threads that start up and block on our lock, but do
// not see they have to recompile their plan.    we now invalidate earlier
// however they still might recompile using the old conglomerate id before we
// commit our dd changes.
//
dm invalidatefor td  dependencymanager truncate_table  lcc
rl   compressheapcc newrowlocationtemplate
// get the properties on the old heap
compressheapcc getinternaltablepropertyset properties
compressheapcc close
compressheapcc   null
//create new conglomerate
newheapconglom
tc createconglomerate
emptyheaprow getrowarray
null    column sort order   not required for heap
td getcolumncollationids
properties
transactioncontroller is_default
/* set up index info to perform truncate on them*/
getaffectedindexes activation
if numindexes > 0
indexrows   new execindexrow
ordering    new columnordering
collation   new int
for  int index   0  index < numindexes  index
// create a single index row template for each index
indexrows   compressirgs getindexrowtemplate
compressirgs getindexrow emptyheaprow
rl
indexrows
formatablebitset  null
/* for non-unique indexes, we order by all columns + the rid.
* for unique indexes, we just order by the columns.
* no need to try to enforce uniqueness here as
* index should be valid.
*/
int basecolumnpositions
compressirgs basecolumnpositions
boolean isascending   compressirgs isascending
int numcolumnorderings
numcolumnorderings   basecolumnpositions length   1
ordering      new columnordering
collation     new int
for  int ii  0  ii < numcolumnorderings   1  ii
ordering
new indexcolumnorder ii  isascending
ordering
new indexcolumnorder numcolumnorderings   1
/*
** inform the data dictionary that we are about to write to it.
** there are several calls to data dictionary "get" methods here
** that might be done in "read" mode in the data dictionary, but
** it seemed safer to do this whole operation in "write" mode.
**
** we tell the data dictionary we're done writing at the end of
** the transaction.
*/
dd startwriting lcc
// truncate  all indexes
if numindexes > 0
long newindexcongloms   new long
for  int index   0  index < numindexes  index
updateindex newheapconglom  dd  index  newindexcongloms
// update the datadictionary
// get the conglomeratedescriptor for the heap
long oldheapconglom   td getheapconglomerateid
conglomeratedescriptor cd   td getconglomeratedescriptor oldheapconglom
// update sys.sysconglomerates with new conglomerate #
dd updateconglomeratedescriptor cd  newheapconglom  tc
// drop the old conglomerate
tc dropconglomerate oldheapconglom
cleanup
/**
* update all of the indexes on a table when doing a bulk insert
* on an empty table.
*
* @exception standardexception					thrown on error
*/
private void updateallindexes long newheapconglom
datadictionary dd
throws standardexception
long newindexcongloms   new long
/* populate each index (one at a time or all at once). */
if  sequential
// first sorter populated during heap compression
if  numindexes >  1
updateindex newheapconglom  dd  0  newindexcongloms
for  int index   1  index < numindexes  index
// scan heap and populate next sorter
openbulkfetchscan newheapconglom
while  getnextrowfromrowsource      null
objectifystreamingcolumns
insertintosorter index  compressrl
updateindex newheapconglom  dd  index  newindexcongloms
closebulkfetchscan
else
for  int index   0  index < numindexes  index
updateindex newheapconglom  dd  index  newindexcongloms
private void updateindex
long            newheapconglom
datadictionary  dd
int             index
long          newindexcongloms
throws standardexception
properties properties   new properties
// get the conglomeratedescriptor for the index
conglomeratedescriptor cd
td getconglomeratedescriptor indexconglomeratenumbers
// build the properties list for the new conglomerate
conglomeratecontroller indexcc
tc openconglomerate
indexconglomeratenumbers
false
transactioncontroller openmode_forupdate
transactioncontroller mode_table
transactioncontroller isolation_serializable
// get the properties on the old index
indexcc getinternaltablepropertyset properties
/* create the properties that language supplies when creating the
* the index.  (the store doesn't preserve these.)
*/
int indexrowlength   indexrows ncolumns
properties put    long tostring newheapconglom
if  cd getindexdescriptor   isunique
properties put
integer tostring indexrowlength   1
else
properties put
integer tostring indexrowlength
properties put
integer tostring indexrowlength   1
properties put
integer tostring indexrowlength
indexcc close
// we can finally drain the sorter and rebuild the index
// populate the index.
rowlocationretrowsource ccount             null
boolean                 statisticsexist    false
if   truncatetable
sorters completedinserts
sorters   null
if  td statisticsexist cd
ccount
new cardinalitycounter
tc opensortrowsource sortids
statisticsexist   true
else
ccount
new cardinalitycounter
tc opensortrowsource sortids
newindexcongloms
tc createandloadconglomerate
indexrows getrowarray
ordering
collation
properties
transactioncontroller is_default
ccount
long  null
//for an index, if the statistics already exist, then drop them.
//the statistics might not exist for an index if the index was
//created when the table was empty.
//
//for all alter table actions, including alter table compress,
//for both kinds of indexes (ie. one with preexisting statistics
//and with no statistics), create statistics for them if the table
//is not empty.
if  statisticsexist
dd dropstatisticsdescriptors td getuuid    cd getuuid    tc
long numrows
if   numrows     cardinalitycounter ccount  getrowcount    > 0
long c     cardinalitycounter ccount  getcardinality
for  int i   0  i < c length  i
statisticsdescriptor statdesc
new statisticsdescriptor
dd
dd getuuidfactory   createuuid
cd getuuid
td getuuid
new statisticsimpl numrows  c
i   1
dd adddescriptor
statdesc
null       no parent descriptor
datadictionary sysstatistics_catalog_num
true       no error on duplicate
tc
else
newindexcongloms
tc createconglomerate
indexrows getrowarray
ordering
collation
properties
transactioncontroller is_default
//on truncate drop the statistics because we know for sure
//rowscount is zero and existing statistic will be invalid.
if  td statisticsexist cd
dd dropstatisticsdescriptors td getuuid    cd getuuid    tc
/* update the datadictionary
*
* update sys.sysconglomerates with new conglomerate #, we need to
* update all (if any) duplicate index entries sharing this same
* conglomerate.
*/
dd updateconglomeratedescriptor
td getconglomeratedescriptors indexconglomeratenumbers
newindexcongloms
tc
// drop the old conglomerate
tc dropconglomerate indexconglomeratenumbers
/**
* get info on the indexes on the table being compressed.
*
* @exception standardexception		thrown on error
*/
private void getaffectedindexes activation activation
throws standardexception
indexlister	indexlister   td getindexlister
/* we have to get non-distinct index row generaters and conglom numbers
* here and then compress it to distinct later because drop column
* will need to change the index descriptor directly on each index
* entry in sysconglomerates, on duplicate indexes too.
*/
compressirgs   indexlister getindexrowgenerators
numindexes   compressirgs length
indexconglomeratenumbers   indexlister getindexconglomeratenumbers
arraylist newcongloms   new arraylist
if     compresstable    truncatetable  		   then it's drop column
for  int i   0  i < compressirgs length  i
int basecolumnpositions   compressirgs basecolumnpositions
int j
for  j   0  j < basecolumnpositions length  j
if  basecolumnpositions    droppedcolumnposition  break
if  j    basecolumnpositions length 	   not related
continue
if  basecolumnpositions length    1
behavior    statementtype drop_cascade    compressirgs isunique
numindexes
/* get first conglomerate with this conglom number each time
* and each duplicate one will be eventually all dropped
*/
conglomeratedescriptor cd   td getconglomeratedescriptor
indexconglomeratenumbers
dropconglomerate cd  td  true  newcongloms  activation
activation getlanguageconnectioncontext
compressirgs   null 		   mark it
continue
// give an error for unique index on multiple columns including
// the column we are to drop (restrict), such index is not for
// a constraint, because constraints have already been handled
if  compressirgs isunique
conglomeratedescriptor cd   td getconglomeratedescriptor
indexconglomeratenumbers
throw standardexception newexception sqlstate lang_provider_has_dependent_object
dm getactionstring dependencymanager drop_column
columninfo name
cd getconglomeratename
/* if there are new backing conglomerates which must be
* created to replace a dropped shared conglomerate
* (where the shared conglomerate was dropped as part
* of a "drop conglomerate" call above), then create
* them now.  we do this *after* dropping all dependent
* conglomerates because we don't want to waste time
* creating a new conglomerate if it's just going to be
* dropped again as part of another "drop conglomerate"
* call.
*/
createnewbackingcongloms newcongloms
indexconglomeratenumbers  activation  dd
indexrowgenerator newirgs   new indexrowgenerator
long newindexconglomnumbers   new long
for  int i   0  j   0  i < numindexes  i    j
while  compressirgs    null
j
int basecolumnpositions   compressirgs basecolumnpositions
newirgs   compressirgs
newindexconglomnumbers   indexconglomeratenumbers
boolean isascending   compressirgs isascending
boolean remakearrays   false
int size   basecolumnpositions length
for  int k   0  k < size  k
if  basecolumnpositions > droppedcolumnposition
basecolumnpositions
else if  basecolumnpositions    droppedcolumnposition
basecolumnpositions   0 		   mark it
remakearrays   true
if  remakearrays
size
int newbcp   new int
boolean newisascending   new boolean
for  int k   0  step   0  k < size  k
if  step    0    basecolumnpositions    0
step
newbcp   basecolumnpositions
newisascending   isascending
indexdescriptor id   compressirgs getindexdescriptor
id setbasecolumnpositions newbcp
id setisascending newisascending
id setnumberoforderedcolumns id numberoforderedcolumns     1
compressirgs   newirgs
indexconglomeratenumbers   newindexconglomnumbers
/* now we are done with updating each index descriptor entry directly
* in sysconglomerates (for duplicate index as well), from now on, our
* work should apply only once for each real conglomerate, so we
* compress any duplicate indexes now.
*/
object compressindexresult
compressindexarrays indexconglomeratenumbers  compressirgs
if  compressindexresult    null
indexconglomeratenumbers    long  compressindexresult
compressirgs    indexrowgenerator  compressindexresult
numindexes   indexconglomeratenumbers length
indexedcols   new formatablebitset compresstable    truncatetable ? td getnumberofcolumns     1
td getnumberofcolumns
for  int index   0  index < numindexes  index
int colids   compressirgs getindexdescriptor   basecolumnpositions
for  int index2   0  index2 < colids length  index2
indexedcols set colids
/**
* iterate through the received list of createindexconstantactions and
* execute each one, it's possible that one or more of the constant
* actions in the list has been rendered "unneeded" by the time we get
* here (because the index that the constant action was going to create
* is no longer needed), so we have to check for that.
*
* @param newconglomactions potentially empty list of constant actions
*   to execute, if still needed
* @param ixcongnums optional array of conglomerate numbers; if non-null
*   then any entries in the array which correspond to a dropped physical
*   conglomerate (as determined from the list of constant actions) will
*   be updated to have the conglomerate number of the newly-created
*   physical conglomerate.
*/
private void createnewbackingcongloms arraylist newconglomactions
long  ixcongnums  activation activation  datadictionary dd
throws standardexception
int sz   newconglomactions size
for  int i   0  i < sz  i
createindexconstantaction ca
createindexconstantaction newconglomactions get i
if  dd getconglomeratedescriptor ca getcreateduuid       null
/* conglomerate descriptor was dropped after
* being selected as the source for a new
* conglomerate, so don't create the new
* conglomerate after all.  either we found
* another conglomerate descriptor that can
* serve as the source for the new conglom,
* or else we don't need a new conglomerate
* at all because all constraints/indexes
* which shared it had a dependency on the
* dropped column and no longer exist.
*/
continue
executeconglomreplacement ca  activation
long oldcongnum   ca getreplacedconglomnumber
long newcongnum   ca getcreatedconglomnumber
/* the preceding call to executeconglomreplacement updated all
* relevant conglomeratedescriptors with the new conglomerate
* number *within the data dictionary*.  but the table
* descriptor that we have will not have been updated.
* there are two approaches to syncing the table descriptor
* with the dictionary: 1) refetch the table descriptor from
* the dictionary, or 2) update the table descriptor directly.
* we choose option #2 because the caller of this method (esp.
* getaffectedindexes()) has pointers to objects from the
* table descriptor as it was before we entered this method.
* it then changes data within those objects, with the
* expectation that, later, those objects can be used to
* persist the changes to disk.  if we change the table
* descriptor here the objects that will get persisted to
* disk (from the table descriptor) will *not* be the same
* as the objects that were updated--so we'll lose the updates
* and that will in turn cause other problems.  so we go with
* option #2 and just change the existing tabledescriptor to
* reflect the fact that the conglomerate number has changed.
*/
conglomeratedescriptor  tdcds
td getconglomeratedescriptors oldcongnum
for  int j   0  j < tdcds length  j
tdcds setconglomeratenumber newcongnum
/* if we received a list of index conglomerate numbers
* then they are the "old" numbers; see if any of those
* numbers should now be updated to reflect the new
* conglomerate, and if so, update them.
*/
if  ixcongnums    null
for  int j   0  j < ixcongnums length  j
if  ixcongnums    oldcongnum
ixcongnums   newcongnum
/**
* set up to update all of the indexes on a table when doing a bulk insert
* on an empty table.
*
* @exception standardexception					thrown on error
*/
private void setupallsorts execrow sourcerow
rowlocation rl
throws standardexception
ordering          new columnordering
collation         new int
needtodropsort    new boolean
sortids           new long
int base_table_collation_ids   td getcolumncollationids
/* for each index, build a single index row and a sorter. */
for  int index   0  index < numindexes  index
// create a single index row template for each index
indexrows   compressirgs getindexrowtemplate
// get an index row based on the base row
// (this call is only necessary here because we need to pass a
// template to the sorter.)
compressirgs getindexrow
sourcerow  rl  indexrows   formatablebitset  null
// setup collation id array to be passed in on call to create index.
collation
compressirgs getcolumncollationids
td getcolumndescriptorlist
/* for non-unique indexes, we order by all columns + the rid.
* for unique indexes, we just order by the columns.
* no need to try to enforce uniqueness here as
* index should be valid.
*/
int       basecolumnpositions
compressirgs basecolumnpositions
boolean   isascending
compressirgs isascending
int         numcolumnorderings
basecolumnpositions length   1
/* we can only reuse the wrappers when doing an
* external sort if there is only 1 index.  otherwise,
* we could get in a situation where 1 sort reuses a
* wrapper that is still in use in another sort.
*/
boolean reusewrappers    numindexes    1
sortobserver    sortobserver
new basicsortobserver
false  false  indexrows  reusewrappers
ordering   new columnordering
for  int ii  0  ii < numcolumnorderings   1  ii
ordering   new indexcolumnorder ii  isascending
ordering
new indexcolumnorder numcolumnorderings   1
// create the sorters
sortids
tc createsort
properties null
indexrows getrowarrayclone
ordering
sortobserver
false 			           not in order
estimatedrowcount 		   est rows
1				           est row size   1 means no idea
sorters   new sortcontroller
// open the sorts
for  int index   0  index < numindexes  index
sorters   tc opensort sortids
needtodropsort   true
// rowsource interface
/**
* @see rowsource#getvalidcolumns
*/
public formatablebitset getvalidcolumns
// all columns are valid
return null
/**
* @see rowsource#getnextrowfromrowsource
* @exception standardexception on error
*/
public datavaluedescriptor getnextrowfromrowsource
throws standardexception
currentrow   null
// time for a new bulk fetch?
if     donescan
currentcompressrow    bulkfetchsize     validrow
int bulkfetched   0
bulkfetched   compressheapgsc fetchnextgroup baserowarray  compressrl
donescan    bulkfetched    bulkfetchsize
currentcompressrow   0
rowcount    bulkfetched
for  int index   0  index < bulkfetched  index
validrow   true
for  int index   bulkfetched  index < bulkfetchsize  index
validrow   false
if  validrow
if  compresstable
currentrow   baserow
else
if  currentrow    null
currentrow
activation getexecutionfactory   getvaluerow
baserowarray length   1
for  int i   0  i < currentrow ncolumns    i
currentrow setcolumn
i   1
i < droppedcolumnposition   1 ?
baserow getcolumn i 1
baserow getcolumn i 1 1
currentcompressrow
if  currentrow    null
/* let the target preprocess the row.  for now, this
* means doing an in place clone on any indexed columns
* to optimize cloning and so that we don't try to drain
* a stream multiple times.
*/
if  compressirgs length > 0
/* do in-place cloning of all of the key columns */
currentrow    currentrow getclone indexedcols
return currentrow getrowarray
return null
/**
* @see rowsource#needstoclone
*/
public boolean needstoclone
return true
/**
* @see rowsource#closerowsource
*/
public void closerowsource
// do nothing here - actual work will be done in close()
// rowlocationretrowsource interface
/**
* @see rowlocationretrowsource#needsrowlocation
*/
public boolean needsrowlocation
// only true if table has indexes
return  numindexes > 0
/**
* @see rowlocationretrowsource#rowlocation
* @exception standardexception on error
*/
public void rowlocation rowlocation rl
throws standardexception
/* set up sorters, etc. if 1st row and there are indexes */
if  compressirgs length > 0
objectifystreamingcolumns
/* put the row into the indexes.  if sequential,
* then we only populate the 1st sorter when compressing
* the heap.
*/
int maxindex   compressirgs length
if  maxindex > 1    sequential
maxindex   1
for  int index   0  index < maxindex  index
insertintosorter index  rl
private void objectifystreamingcolumns
throws standardexception
// objectify any the streaming columns that are indexed.
for  int i   0  i < currentrow getrowarray   length  i
/* object array is 0-based,
* indexedcols is 1-based.
*/
if    indexedcols get i   1
continue
if  currentrow getrowarray   instanceof streamstorable
datavaluedescriptor  currentrow getrowarray    getobject
private void insertintosorter int index  rowlocation rl
throws standardexception
// get a new object array for the index
indexrows getnewobjectarray
// associate the index row with the source row
compressirgs getindexrow currentrow
rowlocation  rl cloneobject
indexrows
formatablebitset  null
// insert the index row into the matching sorter
sorters insert indexrows getrowarray
/**
*
* @exception standardexception		thrown on error
*/
private void	cleanup   throws standardexception
if  compressheapcc    null
compressheapcc close
compressheapcc   null
if  compressheapgsc    null
closebulkfetchscan
// close each sorter
if  sorters    null
for  int index   0  index < compressirgs length  index
if  sorters    null
sorters completedinserts
sorters   null
if  needtodropsort    null
for  int index   0  index < needtodropsort length  index
if  needtodropsort
tc dropsort sortids
needtodropsort   false
// class implementation
/**
* return the "semi" row count of a table.  we are only interested in
* whether the table has 0, 1 or > 1 rows.
*
*
* @return number of rows (0, 1 or > 1) in table.
*
* @exception standardexception		thrown on failure
*/
private int getsemirowcount transactioncontroller tc
throws standardexception
int			   numrows   0
scancontroller sc   tc openscan td getheapconglomerateid
false 	   hold
0 	       open read only
transactioncontroller mode_table
transactioncontroller isolation_serializable
rowutil empty_row_bitset     scancolumnlist
null 	   start position
scancontroller ge          startsearchoperation
null     scanqualifier
null    stop position   through last row
scancontroller gt          stopsearchoperation
while  sc next
numrows
// we're only interested in whether the table has 0, 1 or > 1 rows
if  numrows    2
break
sc close
return numrows
/**
* update a new column with its default.
* we could do the scan ourself here, but
* instead we get a nested connection and
* issue the appropriate update statement.
*
* @param columndescriptor  catalog descriptor for the column
* @param lcc				the language connection context
*
* @exception standardexception if update to default fails
*/
private void updatenewcolumntodefault
activation activation
columndescriptor    columndescriptor
languageconnectioncontext		lcc
throws standardexception
defaultinfo defaultinfo   columndescriptor getdefaultinfo
string  columnname   columndescriptor getcolumnname
string  defaulttext
if   defaultinfo isgeneratedcolumn       defaulttext
else   defaulttext   columndescriptor getdefaultinfo   getdefaulttext
/* need to use delimited identifiers for all object names
* to ensure correctness.
*/
string updatestmt       "
td getname       set
columnname       "   defaulttext
altertableconstantaction executeupdate lcc  updatestmt
private static void executeupdate languageconnectioncontext lcc  string updatestmt  throws standardexception
preparedstatement ps   lcc prepareinternalstatement updatestmt
// this is a substatement; for now, we do not set any timeout
// for it. we might change this behaviour later, by linking
// timeout to its parent statement's timeout settings.
resultset rs   ps executesubstatement lcc  true  0l
rs close
/**
* computes the minimum/maximum value in a column of a table.
*/
private long getcolumnmax activation activation  tabledescriptor td  string columnname
long increment  long initial
throws standardexception
string maxstr    increment > 0  ?
string maxstmt       maxstr
languageconnectioncontext lcc   activation getlanguageconnectioncontext
preparedstatement ps   lcc prepareinternalstatement maxstmt
// this is a substatement, for now we do not set any timeout for it
// we might change this later by linking timeout to parent statement
resultset rs   ps executesubstatement lcc  false  0l
datavaluedescriptor rowarray   rs getnextrow   getrowarray
rs close
rs finish
return rowarray getlong
private void dropallcolumndefaults uuid tableid  datadictionary dd
throws standardexception
columndescriptorlist cdl   td getcolumndescriptorlist
int					 cdlsize   cdl size
for int index   0  index < cdlsize  index
columndescriptor cd    columndescriptor  cdl elementat index
// if column has a default we drop the default and
// any dependencies
if  cd getdefaultinfo      null
defaultdescriptor defaultdesc   cd getdefaultdescriptor dd
dm cleardependencies lcc  defaultdesc
private void openbulkfetchscan long heapconglomnumber
throws standardexception
donescan   false
compressheapgsc   tc opengroupfetchscan
heapconglomnumber
false 	   hold
0 	   open base table read only
transactioncontroller mode_table
transactioncontroller isolation_serializable
null        all fields as objects
datavaluedescriptor  null 	   startkeyvalue
0 		   not used when giving null start posn
null 	   qualifier
datavaluedescriptor  null 	   stopkeyvalue
0  		   not used when giving null stop posn
private void closebulkfetchscan
throws standardexception
compressheapgsc close
compressheapgsc   null
/**
* update values in a new autoincrement column being added to a table.
* this is similar to updatenewcolumntodefault whereby we issue an
* update statement using a nested connection. the update statement
* uses a static method in connectioninfo (which is not documented)
* which returns the next value to be inserted into the autoincrement
* column.
*
* @param columnname autoincrement column name that is being added.
* @param initial    initial value of the autoincrement column.
* @param increment  increment value of the autoincrement column.
*
* @see #updatenewcolumntodefault
*/
private void updatenewautoincrementcolumn activation activation  string columnname  long initial
long increment
throws standardexception
languageconnectioncontext lcc   activation getlanguageconnectioncontext
// don't throw an error in bind when we try to update the
// autoincrement column.
lcc setautoincrementupdate true
lcc autoincrementcreatecounter td getschemaname
td getname
columnname  new long initial
increment  0
// the sql query is.
// update table
//  set ai_column = connectioninfo.nextautoincrementvalue(
//							schemaname, tablename,
//							columnname)
string updatestmt       "
td getname       set      columnname       "
td getschemaname
td getname
columnname
try
altertableconstantaction executeupdate lcc  updatestmt
catch  standardexception se
if  se getmessageid   equals sqlstate lang_outside_range_for_datatype
// if overflow, override with more meaningful message.
throw standardexception newexception sqlstate lang_ai_overflow
se
td getname
columnname
throw se
finally
// and now update the autoincrement value.
lcc autoincrementflushcache td getuuid
lcc setautoincrementupdate false
/**
* make sure that the columns are non null
* if any column is nullable, check that the data is null.
*
* @param	columnnames	names of columns to be checked
* @param	nullcols	true if corresponding column is nullable
* @param	numrows		number of rows in the table
* @param	lcc		language context
* @param	errormsg	error message to use for exception
*
* @return true if any nullable columns found (nullable columns must have
*		all non null data or exception is thrown
* @exception standardexception on error
*/
private boolean validatenotnullconstraint
string							columnnames
boolean							nullcols
int								numrows
languageconnectioncontext		lcc
string							errormsg
throws standardexception
boolean foundnullable   false
stringbuffer constrainttext   new stringbuffer
/*
* check for nullable columns and create a constraint string which can
* be used in validateconstraint to check whether any of the
* data is null.
*/
for  int colctr   0  colctr < columnnames length  colctr
columndescriptor cd   td getcolumndescriptor columnnames
if  cd    null
throw standardexception newexception sqlstate lang_column_not_found_in_table
columnnames
td getname
if  cd gettype   isnullable
if  numrows > 0
// already found a nullable column so add "and"
if  foundnullable
constrainttext append
// delimiting the column name is important in case the
// column name uses lower case characters, spaces, or
// other unusual characters.
constrainttext append
idutil normaltodelimited columnnames
foundnullable   true
nullcols   true
/* if the table has nullable columns and isn't empty
* we need to validate the data
*/
if  foundnullable    numrows > 0
if   constraintconstantaction validateconstraint
string  null
constrainttext tostring
td
lcc
false
if  errormsg equals sqlstate lang_null_data_in_primary_key_or_unique_constraint
alter table add primary key
//soft upgrade mode
throw standardexception newexception
sqlstate lang_null_data_in_primary_key_or_unique_constraint
td getqualifiedname
else if  errormsg equals sqlstate lang_null_data_in_primary_key
alter table add primary key
throw standardexception newexception
sqlstate lang_null_data_in_primary_key
td getqualifiedname
else
alter table modify column not null
throw standardexception newexception
sqlstate lang_null_data_in_non_null_column
td getqualifiedname    columnnames
return foundnullable
/**
* get rid of duplicates from a set of index conglomerate numbers and
* index descriptors.
*
* @param	indexcids	array of index conglomerate numbers
* @param	irgs		array of index row generaters
*
* @return value:		if no duplicates, returns null; otherwise,
*						a size-3 array of objects, first element is an
*						array of duplicates' indexes in the input arrays;
*						second element is the compact indexcids; third
*						element is the compact irgs.
*/
private object compressindexarrays
long indexcids
indexrowgenerator irgs
/* an efficient way to compress indexes.  from one end of workspace,
* we save unique conglom ids; and from the other end we save
* duplicate indexes' indexes.  we save unique conglom ids so that
* we can do less amount of comparisons.  this is efficient in
* space as well.  no need to use hash table.
*/
long workspace   new long
int j   0  k   indexcids length   1
for  int i   0  i < indexcids length  i
int m
for  m   0  m < j  m   		   look up our unique set
if  indexcids    workspace 	   it's a duplicate
workspace   i 		   save dup index's index
break
if  m    j
workspace   indexcids 	   save unique conglom id
if  j < indexcids length 		   duplicate exists
long newindexcids   new long
indexrowgenerator newirgs   new indexrowgenerator
int duplicateindexes   new int
k   0
// do everything in one loop
for  int m   0  n   indexcids length   1  m < indexcids length  m
// we already gathered our indexcids and duplicateindexes
if  m < j
newindexcids   workspace
else
duplicateindexes    int  workspace
// stack up our irgs, indexscocis, indexdcocis
if   n >  j      m     int  workspace
n
else
newirgs   irgs
k
// construct return value
object returnvalue   new object
returnvalue   duplicateindexes
returnvalue   newindexcids
returnvalue   newirgs
return returnvalue
else		   no duplicates
return null