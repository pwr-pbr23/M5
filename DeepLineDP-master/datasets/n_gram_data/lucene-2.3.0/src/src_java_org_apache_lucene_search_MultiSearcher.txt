package org apache lucene search
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import org apache lucene document document
import org apache lucene document fieldselector
import org apache lucene index corruptindexexception
import org apache lucene index term
import java io ioexception
import java util hashmap
import java util hashset
import java util map
import java util set
/** implements search over a set of <code>searchables</code>.
*
* <p>applications usually need only call the inherited {@link #search(query)}
* or {@link #search(query,filter)} methods.
*/
public class multisearcher extends searcher
/**
* document frequency cache acting as a dummy-searcher.
* this class is no full-fledged searcher, but only supports
* the methods necessary to initialize weights.
*/
private static class cacheddfsource extends searcher
private map dfmap     map from terms to corresponding doc freqs
private int maxdoc     document count
public cacheddfsource map dfmap  int maxdoc  similarity similarity
this dfmap   dfmap
this maxdoc   maxdoc
setsimilarity similarity
public int docfreq term term
int df
try
df     integer  dfmap get term   intvalue
catch  nullpointerexception e
throw new illegalargumentexception     term text
return df
public int docfreqs term terms
int result   new int
for  int i   0  i < terms length  i
result   docfreq terms
return result
public int maxdoc
return maxdoc
public query rewrite query query
// this is a bit of a hack. we know that a query which
// creates a weight based on this dummy-searcher is
// always already rewritten (see preparedweight()).
// therefore we just return the unmodified query here
return query
public void close
throw new unsupportedoperationexception
public document doc int i
throw new unsupportedoperationexception
public document doc int i  fieldselector fieldselector
throw new unsupportedoperationexception
public explanation explain weight weight int doc
throw new unsupportedoperationexception
public void search weight weight  filter filter  hitcollector results
throw new unsupportedoperationexception
public topdocs search weight weight filter filter int n
throw new unsupportedoperationexception
public topfielddocs search weight weight filter filter int n sort sort
throw new unsupportedoperationexception
private searchable searchables
private int starts
private int maxdoc   0
/** creates a searcher which searches <i>searchables</i>. */
public multisearcher searchable searchables  throws ioexception
this searchables   searchables
starts   new int 	     build starts array
for  int i   0  i < searchables length  i
starts   maxdoc
maxdoc    searchables maxdoc                compute maxdocs
starts   maxdoc
/** return the array of {@link searchable}s this searches. */
public searchable getsearchables
return searchables
protected int getstarts
return starts
// inherit javadoc
public void close   throws ioexception
for  int i   0  i < searchables length  i
searchables close
public int docfreq term term  throws ioexception
int docfreq   0
for  int i   0  i < searchables length  i
docfreq    searchables docfreq term
return docfreq
// inherit javadoc
public document doc int n  throws corruptindexexception  ioexception
int i   subsearcher n  			     find searcher index
return searchables doc n   starts  	     dispatch to searcher
// inherit javadoc
public document doc int n  fieldselector fieldselector  throws corruptindexexception  ioexception
int i   subsearcher n  			     find searcher index
return searchables doc n   starts  fieldselector  	     dispatch to searcher
/** returns index of the searcher for document <code>n</code> in the array
* used to construct this searcher. */
public int subsearcher int n                       find searcher for doc n
// replace w/ call to arrays.binarysearch in java 1.2
int lo   0 					     search starts array
int hi   searchables length   1 		     for first element less
// than n, return its index
while  hi >  lo
int mid    lo   hi  >> 1
int midvalue   starts
if  n < midvalue
hi   mid   1
else if  n > midvalue
lo   mid   1
else                                           found a match
while  mid 1 < searchables length    starts    midvalue
mid                                        scan to last match
return mid
return hi
/** returns the document number of document <code>n</code> within its
* sub-index. */
public int subdoc int n
return n   starts
public int maxdoc   throws ioexception
return maxdoc
public topdocs search weight weight  filter filter  int ndocs
throws ioexception
hitqueue hq   new hitqueue ndocs
int totalhits   0
for  int i   0  i < searchables length  i         search each searcher
topdocs docs   searchables search weight  filter  ndocs
totalhits    docs totalhits 		     update totalhits
scoredoc scoredocs   docs scoredocs
for  int j   0  j < scoredocs length  j         merge scoredocs into hq
scoredoc scoredoc   scoredocs
scoredoc doc    starts                    convert doc
if  hq insert scoredoc
break                                    no more scores > minscore
scoredoc scoredocs   new scoredoc
for  int i   hq size   1  i >  0  i   	     put docs in array
scoredocs    scoredoc hq pop
float maxscore    totalhits  0  ? float negative_infinity   scoredocs score
return new topdocs totalhits  scoredocs  maxscore
public topfielddocs search  weight weight  filter filter  int n  sort sort
throws ioexception
fielddocsortedhitqueue hq   null
int totalhits   0
float maxscore float negative_infinity
for  int i   0  i < searchables length  i         search each searcher
topfielddocs docs   searchables search  weight  filter  n  sort
if  hq    null  hq   new fielddocsortedhitqueue  docs fields  n
totalhits    docs totalhits 		     update totalhits
maxscore   math max maxscore  docs getmaxscore
scoredoc scoredocs   docs scoredocs
for  int j   0  j < scoredocs length  j         merge scoredocs into hq
scoredoc scoredoc   scoredocs
scoredoc doc    starts                    convert doc
if   hq insert  scoredoc
break                                      no more scores > minscore
scoredoc scoredocs   new scoredoc
for  int i   hq size     1  i >  0  i   	     put docs in array
scoredocs    scoredoc  hq pop
return new topfielddocs  totalhits  scoredocs  hq getfields    maxscore
// inherit javadoc
public void search weight weight  filter filter  final hitcollector results
throws ioexception
for  int i   0  i < searchables length  i
final int start   starts
searchables search weight  filter  new hitcollector
public void collect int doc  float score
results collect doc   start  score
public query rewrite query original  throws ioexception
query queries   new query
for  int i   0  i < searchables length  i
queries   searchables rewrite original
return queries combine queries
public explanation explain weight weight  int doc  throws ioexception
int i   subsearcher doc  			     find searcher index
return searchables explain weight doc starts      dispatch to searcher
/**
* create weight in multiple index scenario.
*
* distributed query processing is done in the following steps:
* 1. rewrite query
* 2. extract necessary terms
* 3. collect dfs for these terms from the searchables
* 4. create query weight using aggregate dfs.
* 5. distribute that weight to searchables
* 6. merge results
*
* steps 1-4 are done here, 5+6 in the search() methods
*
* @return rewritten queries
*/
protected weight createweight query original  throws ioexception
// step 1
query rewrittenquery   rewrite original
// step 2
set terms   new hashset
rewrittenquery extractterms terms
// step3
term alltermsarray   new term
terms toarray alltermsarray
int aggregateddfs   new int
for  int i   0  i < searchables length  i
int dfs   searchables docfreqs alltermsarray
for int j 0  j<aggregateddfs length  j
aggregateddfs    dfs
hashmap dfmap   new hashmap
for int i 0  i<alltermsarray length  i
dfmap put alltermsarray  new integer aggregateddfs
// step4
int numdocs   maxdoc
cacheddfsource cachesim   new cacheddfsource dfmap  numdocs  getsimilarity
return rewrittenquery weight cachesim