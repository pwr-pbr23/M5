/*
* created on 25-jan-2006
*/
package org apache lucene xmlparser builders
import java util map entry
import org apache lucene search cachingwrapperfilter
import org apache lucene search filter
import org apache lucene search query
import org apache lucene search queryfilter
import org apache lucene xmlparser domutils
import org apache lucene xmlparser filterbuilder
import org apache lucene xmlparser filterbuilderfactory
import org apache lucene xmlparser parserexception
import org apache lucene xmlparser querybuilder
import org apache lucene xmlparser querybuilderfactory
import org w3c dom element
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
/**
* filters are cached in an lru cache keyed on the contained query or filter object. using this will
* speed up overall performance for repeated uses of the same expensive query/filter. the sorts of
* queries/filters likely to benefit from caching need not necessarily be complex - e.g. simple
* termquerys with a large df (document frequency) can be expensive	on large indexes.
* a good example of this might be a term query on a field with only 2 possible	values -
* "true" or "false". in a large index, querying or filtering on this field requires reading
* millions	of document ids from disk which can more usefully be cached as a filter bitset.
*
* for queries/filters to be cached and reused the object must implement hashcode and
* equals methods correctly so that duplicate queries/filters can be detected in the cache.
*
* the coreparser.maxnumcachedfilters property can be used to control the size of the lru
* cache established during the construction of coreparser instances.
*
* @author maharwood
*/
public class cachedfilterbuilder implements filterbuilder
private querybuilderfactory queryfactory
private filterbuilderfactory filterfactory
private  lrucache filtercache   null
private int cachesize
public cachedfilterbuilder querybuilderfactory queryfactory
filterbuilderfactory filterfactory int cachesize
this queryfactory queryfactory
this filterfactory filterfactory
this cachesize cachesize
public filter getfilter element e  throws parserexception
element childelement   domutils getfirstchildorfail e
if  filtercache    null
filtercache   new lrucache cachesize
// test to see if child element is a query or filter that needs to be
// cached
querybuilder qb   queryfactory getquerybuilder childelement
getnodename
object cachekey   null
query q   null
filter f   null
if  qb    null
q   qb getquery childelement
cachekey   q
else
f   filterfactory getfilter childelement
cachekey   f
filter cachedfilter   null
synchronized  filtercache
check cache
cachedfilter    filter  filtercache get cachekey
if  cachedfilter    null
return cachedfilter     cache hit
//cache miss
if  qb    null
cachedfilter   new queryfilter q
else
cachedfilter   new cachingwrapperfilter f
synchronized  filtercache
update cache
filtercache put cachekey  cachedfilter
return cachedfilter
static class lrucache extends java util linkedhashmap
public lrucache int maxsize
super maxsize   4   3   1  0 75f  true
this maxsize   maxsize
protected int maxsize
protected boolean removeeldestentry entry eldest
return size   > maxsize