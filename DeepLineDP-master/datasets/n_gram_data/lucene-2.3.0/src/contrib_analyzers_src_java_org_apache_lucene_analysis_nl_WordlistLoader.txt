package org apache lucene analysis nl
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io file
import java io filereader
import java io ioexception
import java io linenumberreader
import java util hashmap
/**
*         <p/>
*         loads a text file and adds every line as an entry to a hashtable. every line
*         should contain only one word. if the file is not found or on any error, an
*         empty table is returned.
*
* @author gerhard schwarz
* @deprecated use {@link org.apache.lucene.analysis.wordlistloader} instead
*/
public class wordlistloader
/**
* @param path     path to the wordlist
* @param wordfile name of the wordlist
* @deprecated use {@link org.apache.lucene.analysis.wordlistloader#getwordset(file)} instead
*/
public static hashmap getwordtable string path  string wordfile
if  path    null    wordfile    null
return new hashmap
return getwordtable new file path  wordfile
/**
* @param wordfile complete path to the wordlist
* @deprecated use {@link org.apache.lucene.analysis.wordlistloader#getwordset(file)} instead
*/
public static hashmap getwordtable string wordfile
if  wordfile    null
return new hashmap
return getwordtable new file wordfile
/**
* reads a stemsdictionary. each line contains:
* word \t stem
* i.e. tab seperated)
*
* @return stem dictionary that overrules, the stemming algorithm
* @deprecated use {@link org.apache.lucene.analysis.wordlistloader#getstemdict(file)} instead
*/
public static hashmap getstemdict file wordstemfile
if  wordstemfile    null
return new hashmap
hashmap result   new hashmap
try
linenumberreader lnr   new linenumberreader new filereader wordstemfile
string line
string wordstem
while   line   lnr readline       null
wordstem   line split    2
result put wordstem  wordstem
catch  ioexception e
return result
/**
* @param wordfile file containing the wordlist
* @deprecated use {@link org.apache.lucene.analysis.wordlistloader#getwordset(file)} instead
*/
public static hashmap getwordtable file wordfile
if  wordfile    null
return new hashmap
hashmap result   null
try
linenumberreader lnr   new linenumberreader new filereader wordfile
string word   null
string stopwords   new string
int wordcount   0
while   word   lnr readline       null
wordcount
if  wordcount    stopwords length
string tmp   new string
system arraycopy stopwords  0  tmp  0  wordcount
stopwords   tmp
stopwords   word
result   makewordtable stopwords  wordcount
// on error, use an empty table
catch  ioexception e
result   new hashmap
return result
/**
* builds the wordlist table.
*
* @param words  word that where read
* @param length amount of words that where read into <tt>words</tt>
*/
private static hashmap makewordtable string words  int length
hashmap table   new hashmap length
for  int i   0  i < length  i
table put words  words
return table