package org apache lucene analysis cn
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java util hashtable
import org apache lucene analysis
/**
* title: chinesefilter
* description: filter with a stop word table
*              rule: no digital is allowed.
*                    english word/token should larger than 1 character.
*                    one chinese character as one chinese word.
* to do:
*   1. add chinese stop words, such as \ue400
*   2. dictionary based chinese word extraction
*   3. intelligent chinese word extraction
*
* copyright:    copyright (c) 2001
* company:
* @author yiyi sun
* @version 1.0
*
*/
public final class chinesefilter extends tokenfilter
// only english now, chinese to be added later.
public static final string stop_words
private hashtable stoptable
public chinesefilter tokenstream in
super in
stoptable   new hashtable stop_words length
for  int i   0  i < stop_words length  i
stoptable put stop_words  stop_words
public final token next   throws java io ioexception
for  token token   input next    token    null  token   input next
string text   token termtext
// why not key off token type here assuming chinesetokenizer comes first?
if  stoptable get text     null
switch  character gettype text charat 0
case character lowercase_letter
case character uppercase_letter
// english word/token should larger than 1 character.
if  text length  >1
return token
break
case character other_letter
// one chinese character as one chinese word.
// chinese word extraction to be added later here.
return token
return null