package org apache lucene benchmark stats
/**
* copyright 2005 the apache software foundation
*
* licensed under the apache license, version 2.0 (the "license");
* you may not use this file except in compliance with the license.
* you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io file
import java text numberformat
import java util arraylist
import java util collection
import java util date
import java util hashmap
import java util iterator
import java util linkedhashmap
import java util list
import java util vector
import org apache lucene analysis analyzer
import org apache lucene benchmark constants
import org apache lucene store directory
/**
* this class holds together all parameters related to a test. single test is
* performed several times, and all results are averaged.
*
* @author andrzej bialecki &lt;ab@getopt.org&gt;
*/
public class testdata
public static int max_buffered_docs_counts   new int 10  20  50  100  200  500
public static int mergefactor_counts   new int 10  20  50  100  200  500
/**
* id of this test data.
*/
private string id
/**
* heap size.
*/
private long heap
/**
* list of results for each test run with these parameters.
*/
private vector rundata   new vector
private int maxbuffereddocs  mergefactor
/**
* directory containing source files.
*/
private file source
/**
* lucene directory implementation for creating an index.
*/
private directory directory
/**
* analyzer to use when adding documents.
*/
private analyzer analyzer
/**
* if true, use compound file format.
*/
private boolean compound
/**
* if true, optimize index when finished adding documents.
*/
private boolean optimize
/**
* data for search benchmarks.
*/
private querydata queries
public testdata
heap   runtime getruntime   maxmemory
private static class dcounter
double total
int count  recordcount
private static class lcounter
long total
int count
private static class ldcounter
double dtotal
int dcount  drecordcount
long ltotal0
int lcount0
long ltotal1
int lcount1
/**
* get a textual summary of the benchmark results, average from all test runs.
*/
static final string id
static final string op
static final string runcnt
static final string reccnt
static final string recsec
static final string freemem
static final string totmem
static final string cols
id
op
runcnt
reccnt
recsec
freemem
totmem
public string showrundata string prefix
if  rundata size      0
return
hashmap resbytask   new hashmap
stringbuffer sb   new stringbuffer
string linesep   system getproperty
sb append    append linesep  append    append linesep  append    append linesep  append linesep
for  int i   0  i < cols length  i
sb append cols
sb append
linkedhashmap mapmem   new linkedhashmap
linkedhashmap mapspeed   new linkedhashmap
for  int i   0  i < rundata size    i
testrundata trd    testrundata  rundata get i
collection labels   trd getlabels
iterator it   labels iterator
while  it hasnext
string label    string  it next
memusage mem   trd getmemusage label
if  mem    null
testdata lcounter tm    testdata lcounter  mapmem get label
if  tm    null
tm   new testdata lcounter
tm   new testdata lcounter
tm   new testdata lcounter
mapmem put label  tm
tm total    mem avgfree
tm count
tm total    mem avgtotal
tm count
timedata td   trd gettotals label
if  td    null
testdata dcounter dc    testdata dcounter  mapspeed get label
if  dc    null
dc   new testdata dcounter
mapspeed put label  dc
dc count
//dc.total += td.getrate();
dc total     td count>0    td elapsed< 0 ? 1   td elapsed      assume atleast 1ms for any countable op
dc recordcount    td count
linkedhashmap res   new linkedhashmap
iterator it   mapspeed keyset   iterator
while  it hasnext
string label    string  it next
testdata dcounter dc    testdata dcounter  mapspeed get label
res put label
format dc count  runcnt
format dc recordcount   dc count  reccnt
format 1  float   dc recordcount   1000 0    dc total>0 ? dc total   1 0    recsec
//format((float) (dc.total / (double) dc.count), recsec)
// also sum by task
string task   label substring label lastindexof    1
ldcounter ldc    ldcounter  resbytask get task
if  ldc  null
ldc   new ldcounter
resbytask put task ldc
ldc dcount    dc count
ldc drecordcount    dc recordcount
ldc dtotal     dc count>0    dc total< 0 ? 1   dc total      assume atleast 1ms for any countable op
it   mapmem keyset   iterator
while  it hasnext
string label    string  it next
testdata lcounter lc    testdata lcounter  mapmem get label
string speed    string  res get label
boolean makespeed   false
if  speed    null
makespeed   true
speed
format lc count  runcnt
format 0  reccnt
format 0  float 0 0  recsec
res put label  speed
format 0  lc total   lc count  freemem
format 0  lc total   lc count  totmem
// also sum by task
string task   label substring label lastindexof    1
ldcounter ldc    ldcounter  resbytask get task
if  ldc  null
ldc   new ldcounter
resbytask put task ldc
makespeed   true
if  makespeed
ldc dcount    lc count
ldc lcount0    lc count
ldc lcount1    lc count
ldc ltotal0    lc total
ldc ltotal1    lc total
it   res keyset   iterator
while  it hasnext
string label    string  it next
sb append format prefix  id
sb append format label  op
sb append res get label   append
// show results by task (srch, optimize, etc.)
sb append
for  int i   0  i < cols length  i
sb append cols
sb append
it   resbytask keyset   iterator
while  it hasnext
string task    string  it next
ldcounter ldc    ldcounter  resbytask get task
sb append format    id
sb append format task  op
sb append format ldc dcount  runcnt
sb append format ldc drecordcount   ldc dcount  reccnt
sb append format 1  float   ldc drecordcount   1000 0    ldc dtotal>0 ? ldc dtotal   1 0    recsec
sb append format 0  ldc ltotal0   ldc lcount0  freemem
sb append format 0  ldc ltotal1   ldc lcount1  totmem
sb append
return sb tostring
private static numberformat numformat      numberformat getinstance    numberformat getinstance
private static final string padd
static
numformat setmaximumfractiondigits 0
numformat setminimumfractiondigits 0
numformat setmaximumfractiondigits 1
numformat setminimumfractiondigits 1
// padd number from left
// numfracdigits must be 0 or 1.
static string format int numfracdigits  float f  string col
string res   padd   numformat format f
return res substring res length     col length
// padd number from left
static string format int n  string col
string res   padd   n
return res substring res length     col length
// padd string from right
static string format string s  string col
return  s   padd  substring 0 col length
/**
* prepare a list of benchmark data, using all possible combinations of
* benchmark parameters.
*
* @param sources   list of directories containing different source document
*                  collections
* @param analyzers of analyzers to use.
*/
public static testdata getall file sources  analyzer analyzers
list res   new arraylist 50
testdata ref   new testdata
for  int q   0  q < analyzers length  q
for  int m   0  m < sources length  m
for  int i   0  i < max_buffered_docs_counts length  i
for  int k   0  k < mergefactor_counts length  k
for  int n   0  n < constants booleans length  n
for  int p   0  p < constants booleans length  p
ref id       q   m   i   k   n   p
ref source   sources
ref analyzer   analyzers
ref maxbuffereddocs   max_buffered_docs_counts
ref mergefactor   mergefactor_counts
ref compound   constants booleans booleanvalue
ref optimize   constants booleans booleanvalue
try
res add ref clone
catch  exception e
e printstacktrace
return  testdata  res toarray new testdata
/**
* similar to {@link #getall(java.io.file[], org.apache.lucene.analysis.analyzer[])} but only uses
* maxbuffereddocs of 10 and 100 and same for mergefactor, thus reducing the number of permutations significantly.
* it also only uses compund file and optimize is always true.
*
* @param sources
* @param analyzers
* @return an array of {@link testdata}
*/
public static testdata gettestdataminmaxmergeandmaxbuffered file sources  analyzer analyzers
list res   new arraylist 50
testdata ref   new testdata
for  int q   0  q < analyzers length  q
for  int m   0  m < sources length  m
ref id       q   m       10       10
ref source   sources
ref analyzer   analyzers
ref maxbuffereddocs   10
ref mergefactor   10   mergefactor_counts
ref compound   true
ref optimize   true
try
res add ref clone
catch  exception e
e printstacktrace
ref id       q   m        10       100
ref source   sources
ref analyzer   analyzers
ref maxbuffereddocs   10
ref mergefactor   100   mergefactor_counts
ref compound   true
ref optimize   true
try
res add ref clone
catch  exception e
e printstacktrace
ref id       q   m       100       10
ref source   sources
ref analyzer   analyzers
ref maxbuffereddocs   100
ref mergefactor   10   mergefactor_counts
ref compound   true
ref optimize   true
try
res add ref clone
catch  exception e
e printstacktrace
ref id       q   m       100       100
ref source   sources
ref analyzer   analyzers
ref maxbuffereddocs   100
ref mergefactor   100   mergefactor_counts
ref compound   true
ref optimize   true
try
res add ref clone
catch  exception e
e printstacktrace
return  testdata  res toarray new testdata
protected object clone
testdata cl   new testdata
cl id   id
cl compound   compound
cl heap   heap
cl mergefactor   mergefactor
cl maxbuffereddocs   maxbuffereddocs
cl optimize   optimize
cl source   source
cl directory   directory
cl analyzer   analyzer
// don't clone rundata
return cl
public string tostring
stringbuffer res   new stringbuffer
res append    append id  append    append new date    append    append heap  append
res append    append source  append    append directory  append
res append    append maxbuffereddocs  append    append mergefactor
res append    append compound  append    append optimize  append
if  queries    null
res append querydata getlabels    append
for  int i   0  i < queries length  i
res append    append queries tostring    append
return res tostring
public analyzer getanalyzer
return analyzer
public void setanalyzer analyzer analyzer
this analyzer   analyzer
public boolean iscompound
return compound
public void setcompound boolean compound
this compound   compound
public directory getdirectory
return directory
public void setdirectory directory directory
this directory   directory
public long getheap
return heap
public void setheap long heap
this heap   heap
public string getid
return id
public void setid string id
this id   id
public int getmaxbuffereddocs
return maxbuffereddocs
public void setmaxbuffereddocs int maxbuffereddocs
this maxbuffereddocs   maxbuffereddocs
public int getmergefactor
return mergefactor
public void setmergefactor int mergefactor
this mergefactor   mergefactor
public boolean isoptimize
return optimize
public void setoptimize boolean optimize
this optimize   optimize
public querydata getqueries
return queries
public void setqueries querydata queries
this queries   queries
public vector getrundata
return rundata
public void setrundata vector rundata
this rundata   rundata
public file getsource
return source
public void setsource file source
this source   source