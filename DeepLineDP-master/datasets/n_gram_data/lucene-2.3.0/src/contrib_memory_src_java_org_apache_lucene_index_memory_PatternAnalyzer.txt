package org apache lucene index memory
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io ioexception
import java io reader
import java io stringreader
import java util arrays
import java util hashset
import java util locale
import java util set
import java util regex matcher
import java util regex pattern
import org apache lucene analysis analyzer
import org apache lucene analysis stopanalyzer
import org apache lucene analysis stopfilter
import org apache lucene analysis token
import org apache lucene analysis tokenstream
/**
* efficient lucene analyzer/tokenizer that preferably operates on a string rather than a
* {@link java.io.reader}, that can flexibly separate text into terms via a regular expression {@link pattern}
* (with behaviour identical to {@link string#split(string)}),
* and that combines the functionality of
* {@link org.apache.lucene.analysis.lettertokenizer},
* {@link org.apache.lucene.analysis.lowercasetokenizer},
* {@link org.apache.lucene.analysis.whitespacetokenizer},
* {@link org.apache.lucene.analysis.stopfilter} into a single efficient
* multi-purpose class.
* <p>
* if you are unsure how exactly a regular expression should look like, consider
* prototyping by simply trying various expressions on some test texts via
* {@link string#split(string)}. once you are satisfied, give that regex to
* patternanalyzer. also see <a target="_blank"
* href="http://java.sun.com/docs/books/tutorial/extra/regex/">java regular expression tutorial</a>.
* <p>
* this class can be considerably faster than the "normal" lucene tokenizers.
* it can also serve as a building block in a compound lucene
* {@link org.apache.lucene.analysis.tokenfilter} chain. for example as in this
* stemming example:
* <pre>
* patternanalyzer pat = ...
* tokenstream tokenstream = new snowballfilter(
*     pat.tokenstream("content", "james is running round in the woods"),
*     "english"));
* </pre>
*
* @author whoschek.at.lbl.dot.gov
*/
public class patternanalyzer extends analyzer
/** <code>"\\w+"</code>; divides text at non-letters (not character.isletter(c)) */
public static final pattern non_word_pattern   pattern compile
/** <code>"\\s+"</code>; divides text at whitespaces (character.iswhitespace(c)) */
public static final pattern whitespace_pattern   pattern compile
private static final set extended_english_stop_words   makestopset new string
/**
* a lower-casing word analyzer with english stop words (can be shared
* freely across threads without harm); global per class loader.
*/
public static final patternanalyzer default_analyzer   new patternanalyzer
non_word_pattern  true  makestopset stopanalyzer english_stop_words
/**
* a lower-casing word analyzer with <b>extended </b> english stop words
* (can be shared freely across threads without harm); global per class
* loader. the stop words are borrowed from
* http://thomas.loc.gov/home/stopwords.html, see
* http://thomas.loc.gov/home/all.about.inquery.html
*/
public static final patternanalyzer extended_analyzer   new patternanalyzer
non_word_pattern  true  extended_english_stop_words
private final pattern pattern
private final boolean tolowercase
private final set stopwords
/**
* constructs a new instance with the given parameters.
*
* @param pattern
*            a regular expression delimiting tokens
* @param tolowercase
*            if <code>true</code> returns tokens after applying
*            string.tolowercase()
* @param stopwords
*            if non-null, ignores all tokens that are contained in the
*            given stop set (after previously having applied tolowercase()
*            if applicable). for example, created via
*            {@link stopfilter#makestopset(string[])}and/or
*            {@link org.apache.lucene.analysis.wordlistloader}as in
*            <code>wordlistloader.getwordset(new file("samples/fulltext/stopwords.txt")</code>
*            or <a href="http://www.unine.ch/info/clef/">other stop words
*            lists </a>.
*/
public patternanalyzer pattern pattern  boolean tolowercase  set stopwords
if  pattern    null
throw new illegalargumentexception
if  eqpattern non_word_pattern  pattern   pattern   non_word_pattern
else if  eqpattern whitespace_pattern  pattern   pattern   whitespace_pattern
if  stopwords    null    stopwords size      0  stopwords   null
this pattern   pattern
this tolowercase   tolowercase
this stopwords   stopwords
/**
* creates a token stream that tokenizes the given string into token terms
* (aka words).
*
* @param fieldname
*            the name of the field to tokenize (currently ignored).
* @param text
*            the string to tokenize
* @return a new token stream
*/
public tokenstream tokenstream string fieldname  string text
// ideally the analyzer superclass should have a method with the same signature,
// with a default impl that simply delegates to the stringreader flavour.
if  text    null
throw new illegalargumentexception
tokenstream stream
if  pattern    non_word_pattern       fast path
stream   new faststringtokenizer text  true  tolowercase  stopwords
else if  pattern    whitespace_pattern       fast path
stream   new faststringtokenizer text  false  tolowercase  stopwords
else
stream   new patterntokenizer text  pattern  tolowercase
if  stopwords    null  stream   new stopfilter stream  stopwords
return stream
/**
* creates a token stream that tokenizes all the text in the given reader;
* this implementation forwards to <code>tokenstream(string, string)</code> and is
* less efficient than <code>tokenstream(string, string)</code>.
*
* @param fieldname
*            the name of the field to tokenize (currently ignored).
* @param reader
*            the reader delivering the text
* @return a new token stream
*/
public tokenstream tokenstream string fieldname  reader reader
if  reader instanceof faststringreader       fast path
return tokenstream fieldname    faststringreader reader  getstring
try
string text   tostring reader
return tokenstream fieldname  text
catch  ioexception e
throw new runtimeexception e
/**
* indicates whether some other object is "equal to" this one.
*
* @param other
*            the reference object with which to compare.
* @return true if equal, false otherwise
*/
public boolean equals object other
if  this     other  return true
if  this     default_analyzer    other    extended_analyzer  return false
if  other    default_analyzer    this     extended_analyzer  return false
if  other instanceof patternanalyzer
patternanalyzer p2    patternanalyzer  other
return
tolowercase    p2 tolowercase
eqpattern pattern  p2 pattern
eq stopwords  p2 stopwords
return false
/**
* returns a hash code value for the object.
*
* @return the hash code.
*/
public int hashcode
if  this    default_analyzer  return  1218418418     fast path
if  this    extended_analyzer  return 1303507063     fast path
int h   1
h   31 h   pattern pattern   hashcode
h   31 h   pattern flags
h   31 h    tolowercase ? 1231   1237
h   31 h    stopwords    null ? stopwords hashcode     0
return h
/** equality where o1 and/or o2 can be null */
private static boolean eq object o1  object o2
return  o1    o2      o1    null ? o1 equals o2    false
/** assumes p1 and p2 are not null */
private static boolean eqpattern pattern p1  pattern p2
return p1    p2     p1 flags      p2 flags      p1 pattern   equals p2 pattern
/**
* reads until end-of-stream and returns all read chars, finally closes the stream.
*
* @param input the input stream
* @throws ioexception if an i/o error occurs while reading the stream
*/
private static string tostring reader input  throws ioexception
try
int len   256
char buffer   new char
char output   new char
len   0
int n
while   n   input read buffer   >  0
if  len   n > output length       grow capacity
char tmp   new char
system arraycopy output  0  tmp  0  len
system arraycopy buffer  0  tmp  len  n
buffer   output     use larger buffer for future larger bulk reads
output   tmp
else
system arraycopy buffer  0  output  len  n
len    n
return new string output  0  len
finally
if  input    null  input close
/** somewhat oversized to minimize hash collisions */
private static set makestopset string stopwords
set stops   new hashset stopwords length   2  0 3f
stops addall arrays aslist stopwords
return stops
//    return collections.unmodifiableset(stops);
///////////////////////////////////////////////////////////////////////////////
// nested classes:
///////////////////////////////////////////////////////////////////////////////
/**
* the work horse; performance isn't fantastic, but it's not nearly as bad
* as one might think - kudos to the sun regex developers.
*/
private static final class patterntokenizer extends tokenstream
private final string str
private final boolean tolowercase
private matcher matcher
private int pos   0
private static final locale locale   locale getdefault
public patterntokenizer string str  pattern pattern  boolean tolowercase
this str   str
this matcher   pattern matcher str
this tolowercase   tolowercase
public token next
if  matcher    null  return null
while  true       loop takes care of leading and trailing boundary cases
int start   pos
int end
boolean ismatch   matcher find
if  ismatch
end   matcher start
pos   matcher end
else
end   str length
matcher   null     we're finished
if  start    end       non empty match  header trailer
string text   str substring start  end
if  tolowercase  text   text tolowercase locale
return new token text  start  end
if   ismatch  return null
///////////////////////////////////////////////////////////////////////////////
// nested classes:
///////////////////////////////////////////////////////////////////////////////
/**
* special-case class for best performance in common cases; this class is
* otherwise unnecessary.
*/
private static final class faststringtokenizer extends tokenstream
private final string str
private int pos
private final boolean isletter
private final boolean tolowercase
private final set stopwords
private static final locale locale   locale getdefault
public faststringtokenizer string str  boolean isletter  boolean tolowercase  set stopwords
this str   str
this isletter   isletter
this tolowercase   tolowercase
this stopwords   stopwords
public token next
// cache loop instance vars (performance)
string s   str
int len   s length
int i   pos
boolean letter   isletter
int start   0
string text
do
// find beginning of token
text   null
while  i < len     istokenchar s charat i   letter
i
if  i < len       found beginning  now find end of token
start   i
while  i < len    istokenchar s charat i   letter
i
text   s substring start  i
if  tolowercase  text   text tolowercase locale
//          if (tolowercase) {
////            use next line once jdk 1.5 string.tolowercase() performance regression is fixed
////            see http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6265809
//            text = s.substring(start, i).tolowercase();
////            char[] chars = new char[i-start];
////            for (int j=start; j < i; j++) chars[j-start] = character.tolowercase(s.charat(j));
////            text = new string(chars);
//          } else {
//            text = s.substring(start, i);
//          }
while  text    null    isstopword text
pos   i
return text    null ? new token text  start  i    null
private boolean istokenchar char c  boolean isletter
return isletter ? character isletter c     character iswhitespace c
private boolean isstopword string text
return stopwords    null    stopwords contains text
///////////////////////////////////////////////////////////////////////////////
// nested classes:
///////////////////////////////////////////////////////////////////////////////
/**
* a stringreader that exposes it's contained string for fast direct access.
* might make sense to generalize this to charsequence and make it public?
*/
static final class faststringreader extends stringreader
private final string s
faststringreader string s
super s
this s   s
string getstring
return s