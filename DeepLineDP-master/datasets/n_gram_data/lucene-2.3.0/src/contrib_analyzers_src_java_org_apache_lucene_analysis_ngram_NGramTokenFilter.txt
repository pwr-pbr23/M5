package org apache lucene analysis ngram
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import org apache lucene analysis token
import org apache lucene analysis tokenfilter
import org apache lucene analysis tokenstream
import java io ioexception
import java util linkedlist
/**
* tokenizes the input into n-grams of the given size(s).
* @author otis gospodnetic
*/
public class ngramtokenfilter extends tokenfilter
public static final int default_min_ngram_size   1
public static final int default_max_ngram_size   2
private int mingram  maxgram
private linkedlist ngrams
/**
* creates ngramtokenfilter with given min and max n-grams.
* @param input tokenstream holding the input to be tokenized
* @param mingram the smallest n-gram to generate
* @param maxgram the largest n-gram to generate
*/
public ngramtokenfilter tokenstream input  int mingram  int maxgram
super input
if  mingram < 1
throw new illegalargumentexception
if  mingram > maxgram
throw new illegalargumentexception
this mingram   mingram
this maxgram   maxgram
this ngrams   new linkedlist
/**
* creates ngramtokenfilter with default min and max n-grams.
* @param input tokenstream holding the input to be tokenized
*/
public ngramtokenfilter tokenstream input
this input  default_min_ngram_size  default_max_ngram_size
/** returns the next token in the stream, or null at eos. */
public final token next   throws ioexception
if  ngrams size   > 0
return  token  ngrams removefirst
token token   input next
if  token    null
return null
ngram token
if  ngrams size   > 0
return  token  ngrams removefirst
else
return null
private void ngram token token
string instr   token termtext
int inlen   instr length
int gramsize   mingram
while  gramsize <  maxgram
int pos   0                            reset to beginning of string
while  pos gramsize <  inlen           while there is input
string gram   instr substring pos  pos gramsize
token tok   new token gram  pos  pos gramsize
//        tok.setpositionincrement(pos);
ngrams add tok
pos
gramsize                               increase n gram size