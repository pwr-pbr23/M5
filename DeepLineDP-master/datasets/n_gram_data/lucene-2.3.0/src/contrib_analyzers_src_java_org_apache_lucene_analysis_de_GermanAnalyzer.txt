package org apache lucene analysis de
// this file is encoded in utf-8
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io file
import java io ioexception
import java io reader
import java util hashset
import java util hashtable
import java util set
import org apache lucene analysis analyzer
import org apache lucene analysis lowercasefilter
import org apache lucene analysis stopfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis wordlistloader
import org apache lucene analysis standard standardfilter
import org apache lucene analysis standard standardtokenizer
/**
* analyzer for german language. supports an external list of stopwords (words that
* will not be indexed at all) and an external list of exclusions (word that will
* not be stemmed, but indexed).
* a default set of stopwords is used unless an alternative list is specified, the
* exclusion list is empty by default.
*
*
* @version $id$
*/
public class germananalyzer extends analyzer
/**
* list of typical german stopwords.
*/
public final static string german_stop_words
/**
* contains the stopwords used with the stopfilter.
*/
private set stopset   new hashset
/**
* contains words that should be indexed but not stemmed.
*/
private set exclusionset   new hashset
/**
* builds an analyzer with the default stop words
* (<code>german_stop_words</code>).
*/
public germananalyzer
stopset   stopfilter makestopset german_stop_words
/**
* builds an analyzer with the given stop words.
*/
public germananalyzer string stopwords
stopset   stopfilter makestopset stopwords
/**
* builds an analyzer with the given stop words.
*/
public germananalyzer hashtable stopwords
stopset   new hashset stopwords keyset
/**
* builds an analyzer with the given stop words.
*/
public germananalyzer file stopwords  throws ioexception
stopset   wordlistloader getwordset stopwords
/**
* builds an exclusionlist from an array of strings.
*/
public void setstemexclusiontable string exclusionlist
exclusionset   stopfilter makestopset exclusionlist
/**
* builds an exclusionlist from a hashtable.
*/
public void setstemexclusiontable hashtable exclusionlist
exclusionset   new hashset exclusionlist keyset
/**
* builds an exclusionlist from the words contained in the given file.
*/
public void setstemexclusiontable file exclusionlist  throws ioexception
exclusionset   wordlistloader getwordset exclusionlist
/**
* creates a tokenstream which tokenizes all the text in the provided reader.
*
* @return a tokenstream build from a standardtokenizer filtered with
*         standardfilter, lowercasefilter, stopfilter, germanstemfilter
*/
public tokenstream tokenstream string fieldname  reader reader
tokenstream result   new standardtokenizer reader
result   new standardfilter result
result   new lowercasefilter result
result   new stopfilter result  stopset
result   new germanstemfilter result  exclusionset
return result