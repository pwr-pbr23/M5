package org apache lucene analysis
import java io ioexception
import java util arraylist
import java util iterator
import java util list
/**
* a sinktokenizer can be used to cache tokens for use in an analyzer
*
* @see teetokenfilter
*
**/
public class sinktokenizer extends tokenizer
protected list  <token>   lst   new arraylist  <token>
protected iterator  <token>   iter
public sinktokenizer list  <token>   input
this lst   input
if  this lst    null  this lst   new arraylist  <token>
public sinktokenizer
this lst   new arraylist
public sinktokenizer int initcap
this lst   new arraylist initcap
/**
* get the tokens in the internal list.
* <p/>
* warning: adding tokens to this list requires the {@link #reset()} method to be called in order for them
* to be made available.  also, this tokenizer does nothing to protect against {@link java.util.concurrentmodificationexception}s
* in the case of adds happening while {@link #next(org.apache.lucene.analysis.token)} is being called.
*
* @return a list of {@link org.apache.lucene.analysis.token}s
*/
public list  <token>   gettokens
return lst
/**
* returns the next token out of the list of cached tokens
* @return the next {@link org.apache.lucene.analysis.token} in the sink.
* @throws ioexception
*/
public token next   throws ioexception
if  iter    null  iter   lst iterator
return iter hasnext   ?  token  iter next     null
/**
* override this method to cache only certain tokens, or new tokens based
* on the old tokens.
*
* @param t the {@link org.apache.lucene.analysis.token} to add to the sink
*/
public void add token t
if  t    null  return
lst add  token  t clone
public void close   throws ioexception
//nothing to close
input   null
lst   null
/**
* reset the internal data structures to the start at the front of the list of tokens.  should be called
* if tokens were added to the list after an invocation of {@link #next(token)}
* @throws ioexception
*/
public void reset   throws ioexception
iter   lst iterator