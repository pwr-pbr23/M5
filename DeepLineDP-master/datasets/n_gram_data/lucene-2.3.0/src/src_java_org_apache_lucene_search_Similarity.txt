package org apache lucene search
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import org apache lucene index term
import org apache lucene util smallfloat
import java io ioexception
import java io serializable
import java util collection
import java util iterator
/** expert: scoring api.
* <p>subclasses implement search scoring.
*
* <p>the score of query <code>q</code> for document <code>d</code> correlates to the
* cosine-distance or dot-product between document and query vectors in a
* <a href="http://en.wikipedia.org/wiki/vector_space_model">
* vector space model (vsm) of information retrieval</a>.
* a document whose vector is closer to the query vector in that model is scored higher.
*
* the score is computed as follows:
*
* <p>
* <table cellpadding="1" cellspacing="0" border="1" align="center">
* <tr><td>
* <table cellpadding="1" cellspacing="0" border="0" align="center">
*  <tr>
*    <td valign="middle" align="right" rowspan="1">
*      score(q,d) &nbsp; = &nbsp;
*      <a href="#formula_coord">coord(q,d)</a> &nbsp;&middot;&nbsp;
*      <a href="#formula_querynorm">querynorm(q)</a> &nbsp;&middot;&nbsp;
*    </td>
*    <td valign="bottom" align="center" rowspan="1">
*      <big><big><big>&sum;</big></big></big>
*    </td>
*    <td valign="middle" align="right" rowspan="1">
*      <big><big>(</big></big>
*      <a href="#formula_tf">tf(t in d)</a> &nbsp;&middot;&nbsp;
*      <a href="#formula_idf">idf(t)</a><sup>2</sup> &nbsp;&middot;&nbsp;
*      <a href="#formula_termboost">t.getboost()</a>&nbsp;&middot;&nbsp;
*      <a href="#formula_norm">norm(t,d)</a>
*      <big><big>)</big></big>
*    </td>
*  </tr>
*  <tr valigh="top">
*   <td></td>
*   <td align="center"><small>t in q</small></td>
*   <td></td>
*  </tr>
* </table>
* </td></tr>
* </table>
*
* <p> where
* <ol>
*    <li>
*      <a name="formula_tf"></a>
*      <b>tf(t in d)</b>
*      correlates to the term's <i>frequency</i>,
*      defined as the number of times term <i>t</i> appears in the currently scored document <i>d</i>.
*      documents that have more occurrences of a given term receive a higher score.
*      the default computation for <i>tf(t in d)</i> in
*      {@link org.apache.lucene.search.defaultsimilarity#tf(float) defaultsimilarity} is:
*
*      <br>&nbsp;<br>
*      <table cellpadding="2" cellspacing="2" border="0" align="center">
*        <tr>
*          <td valign="middle" align="right" rowspan="1">
*            {@link org.apache.lucene.search.defaultsimilarity#tf(float) tf(t in d)} &nbsp; = &nbsp;
*          </td>
*          <td valign="top" align="center" rowspan="1">
*               frequency<sup><big>&frac12;</big></sup>
*          </td>
*        </tr>
*      </table>
*      <br>&nbsp;<br>
*    </li>
*
*    <li>
*      <a name="formula_idf"></a>
*      <b>idf(t)</b> stands for inverse document frequency. this value
*      correlates to the inverse of <i>docfreq</i>
*      (the number of documents in which the term <i>t</i> appears).
*      this means rarer terms give higher contribution to the total score.
*      the default computation for <i>idf(t)</i> in
*      {@link org.apache.lucene.search.defaultsimilarity#idf(int, int) defaultsimilarity} is:
*
*      <br>&nbsp;<br>
*      <table cellpadding="2" cellspacing="2" border="0" align="center">
*        <tr>
*          <td valign="middle" align="right">
*            {@link org.apache.lucene.search.defaultsimilarity#idf(int, int) idf(t)}&nbsp; = &nbsp;
*          </td>
*          <td valign="middle" align="center">
*            1 + log <big>(</big>
*          </td>
*          <td valign="middle" align="center">
*            <table>
*               <tr><td align="center"><small>numdocs</small></td></tr>
*               <tr><td align="center">&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;</td></tr>
*               <tr><td align="center"><small>docfreq+1</small></td></tr>
*            </table>
*          </td>
*          <td valign="middle" align="center">
*            <big>)</big>
*          </td>
*        </tr>
*      </table>
*      <br>&nbsp;<br>
*    </li>
*
*    <li>
*      <a name="formula_coord"></a>
*      <b>coord(q,d)</b>
*      is a score factor based on how many of the query terms are found in the specified document.
*      typically, a document that contains more of the query's terms will receive a higher score
*      than another document with fewer query terms.
*      this is a search time factor computed in
*      {@link #coord(int, int) coord(q,d)}
*      by the similarity in effect at search time.
*      <br>&nbsp;<br>
*    </li>
*
*    <li><b>
*      <a name="formula_querynorm"></a>
*      querynorm(q)
*      </b>
*      is a normalizing factor used to make scores between queries comparable.
*      this factor does not affect document ranking (since all ranked documents are multiplied by the same factor),
*      but rather just attempts to make scores from different queries (or even different indexes) comparable.
*      this is a search time factor computed by the similarity in effect at search time.
*
*      the default computation in
*      {@link org.apache.lucene.search.defaultsimilarity#querynorm(float) defaultsimilarity}
*      is:
*      <br>&nbsp;<br>
*      <table cellpadding="1" cellspacing="0" border="0" align="center">
*        <tr>
*          <td valign="middle" align="right" rowspan="1">
*            querynorm(q)  &nbsp; = &nbsp;
*            {@link org.apache.lucene.search.defaultsimilarity#querynorm(float) querynorm(sumofsquaredweights)}
*            &nbsp; = &nbsp;
*          </td>
*          <td valign="middle" align="center" rowspan="1">
*            <table>
*               <tr><td align="center"><big>1</big></td></tr>
*               <tr><td align="center"><big>
*                  &ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;
*               </big></td></tr>
*               <tr><td align="center">sumofsquaredweights<sup><big>&frac12;</big></sup></td></tr>
*            </table>
*          </td>
*        </tr>
*      </table>
*      <br>&nbsp;<br>
*
*      the sum of squared weights (of the query terms) is
*      computed by the query {@link org.apache.lucene.search.weight} object.
*      for example, a {@link org.apache.lucene.search.booleanquery boolean query}
*      computes this value as:
*
*      <br>&nbsp;<br>
*      <table cellpadding="1" cellspacing="0" border="0"n align="center">
*        <tr>
*          <td valign="middle" align="right" rowspan="1">
*            {@link org.apache.lucene.search.weight#sumofsquaredweights() sumofsquaredweights} &nbsp; = &nbsp;
*            {@link org.apache.lucene.search.query#getboost() q.getboost()} <sup><big>2</big></sup>
*            &nbsp;&middot;&nbsp;
*          </td>
*          <td valign="bottom" align="center" rowspan="1">
*            <big><big><big>&sum;</big></big></big>
*          </td>
*          <td valign="middle" align="right" rowspan="1">
*            <big><big>(</big></big>
*            <a href="#formula_idf">idf(t)</a> &nbsp;&middot;&nbsp;
*            <a href="#formula_termboost">t.getboost()</a>
*            <big><big>) <sup>2</sup> </big></big>
*          </td>
*        </tr>
*        <tr valigh="top">
*          <td></td>
*          <td align="center"><small>t in q</small></td>
*          <td></td>
*        </tr>
*      </table>
*      <br>&nbsp;<br>
*
*    </li>
*
*    <li>
*      <a name="formula_termboost"></a>
*      <b>t.getboost()</b>
*      is a search time boost of term <i>t</i> in the query <i>q</i> as
*      specified in the query text
*      (see <a href="../../../../../queryparsersyntax.html#boosting a term">query syntax</a>),
*      or as set by application calls to
*      {@link org.apache.lucene.search.query#setboost(float) setboost()}.
*      notice that there is really no direct api for accessing a boost of one term in a multi term query,
*      but rather multi terms are represented in a query as multi
*      {@link org.apache.lucene.search.termquery termquery} objects,
*      and so the boost of a term in the query is accessible by calling the sub-query
*      {@link org.apache.lucene.search.query#getboost() getboost()}.
*      <br>&nbsp;<br>
*    </li>
*
*    <li>
*      <a name="formula_norm"></a>
*      <b>norm(t,d)</b> encapsulates a few (indexing time) boost and length factors:
*
*      <ul>
*        <li><b>document boost</b> - set by calling
*        {@link org.apache.lucene.document.document#setboost(float) doc.setboost()}
*        before adding the document to the index.
*        </li>
*        <li><b>field boost</b> - set by calling
*        {@link org.apache.lucene.document.fieldable#setboost(float) field.setboost()}
*        before adding the field to a document.
*        </li>
*        <li>{@link #lengthnorm(string, int) <b>lengthnorm</b>(field)} - computed
*        when the document is added to the index in accordance with the number of tokens
*        of this field in the document, so that shorter fields contribute more to the score.
*        lengthnorm is computed by the similarity class in effect at indexing.
*        </li>
*      </ul>
*
*      <p>
*      when a document is added to the index, all the above factors are multiplied.
*      if the document has multiple fields with the same name, all their boosts are multiplied together:
*
*      <br>&nbsp;<br>
*      <table cellpadding="1" cellspacing="0" border="0"n align="center">
*        <tr>
*          <td valign="middle" align="right" rowspan="1">
*            norm(t,d) &nbsp; = &nbsp;
*            {@link org.apache.lucene.document.document#getboost() doc.getboost()}
*            &nbsp;&middot;&nbsp;
*            {@link #lengthnorm(string, int) lengthnorm(field)}
*            &nbsp;&middot;&nbsp;
*          </td>
*          <td valign="bottom" align="center" rowspan="1">
*            <big><big><big>&prod;</big></big></big>
*          </td>
*          <td valign="middle" align="right" rowspan="1">
*            {@link org.apache.lucene.document.fieldable#getboost() f.getboost}()
*          </td>
*        </tr>
*        <tr valigh="top">
*          <td></td>
*          <td align="center"><small>field <i><b>f</b></i> in <i>d</i> named as <i><b>t</b></i></small></td>
*          <td></td>
*        </tr>
*      </table>
*      <br>&nbsp;<br>
*      however the resulted <i>norm</i> value is {@link #encodenorm(float) encoded} as a single byte
*      before being stored.
*      at search time, the norm byte value is read from the index
*      {@link org.apache.lucene.store.directory directory} and
*      {@link #decodenorm(byte) decoded} back to a float <i>norm</i> value.
*      this encoding/decoding, while reducing index size, comes with the price of
*      precision loss - it is not guaranteed that decode(encode(x)) = x.
*      for instance, decode(encode(0.89)) = 0.75.
*      also notice that search time is too late to modify this <i>norm</i> part of scoring, e.g. by
*      using a different {@link similarity} for search.
*      <br>&nbsp;<br>
*    </li>
* </ol>
*
* @see #setdefault(similarity)
* @see org.apache.lucene.index.indexwriter#setsimilarity(similarity)
* @see searcher#setsimilarity(similarity)
*/
public abstract class similarity implements serializable
/** the similarity implementation used by default. */
private static similarity defaultimpl   new defaultsimilarity
/** set the default similarity implementation used by indexing and search
* code.
*
* @see searcher#setsimilarity(similarity)
* @see org.apache.lucene.index.indexwriter#setsimilarity(similarity)
*/
public static void setdefault similarity similarity
similarity defaultimpl   similarity
/** return the default similarity implementation used by indexing and search
* code.
*
* <p>this is initially an instance of {@link defaultsimilarity}.
*
* @see searcher#setsimilarity(similarity)
* @see org.apache.lucene.index.indexwriter#setsimilarity(similarity)
*/
public static similarity getdefault
return similarity defaultimpl
/** cache of decoded bytes. */
private static final float norm_table   new float
static
for  int i   0  i < 256  i
norm_table   smallfloat byte315tofloat  byte i
/** decodes a normalization factor stored in an index.
* @see #encodenorm(float)
*/
public static float decodenorm byte b
return norm_table        0xff maps negative bytes to positive above 127
/** returns a table for decoding normalization bytes.
* @see #encodenorm(float)
*/
public static float getnormdecoder
return norm_table
/** computes the normalization value for a field given the total number of
* terms contained in a field.  these values, together with field boosts, are
* stored in an index and multipled into scores for hits on each field by the
* search code.
*
* <p>matches in longer fields are less precise, so implementations of this
* method usually return smaller values when <code>numtokens</code> is large,
* and larger values when <code>numtokens</code> is small.
*
* <p>that these values are computed under
* {@link org.apache.lucene.index.indexwriter#adddocument(org.apache.lucene.document.document)}
* and stored then using
* {@link #encodenorm(float)}.
* thus they have limited precision, and documents
* must be re-indexed if this method is altered.
*
* @param fieldname the name of the field
* @param numtokens the total number of tokens contained in fields named
* <i>fieldname</i> of <i>doc</i>.
* @return a normalization factor for hits on this field of this document
*
* @see org.apache.lucene.document.field#setboost(float)
*/
public abstract float lengthnorm string fieldname  int numtokens
/** computes the normalization value for a query given the sum of the squared
* weights of each of the query terms.  this value is then multipled into the
* weight of each query term.
*
* <p>this does not affect ranking, but rather just attempts to make scores
* from different queries comparable.
*
* @param sumofsquaredweights the sum of the squares of query term weights
* @return a normalization factor for query weights
*/
public abstract float querynorm float sumofsquaredweights
/** encodes a normalization factor for storage in an index.
*
* <p>the encoding uses a three-bit mantissa, a five-bit exponent, and
* the zero-exponent point at 15, thus
* representing values from around 7x10^9 to 2x10^-9 with about one
* significant decimal digit of accuracy.  zero is also represented.
* negative numbers are rounded up to zero.  values too large to represent
* are rounded down to the largest representable value.  positive values too
* small to represent are rounded up to the smallest positive representable
* value.
*
* @see org.apache.lucene.document.field#setboost(float)
* @see org.apache.lucene.util.smallfloat
*/
public static byte encodenorm float f
return smallfloat floattobyte315 f
/** computes a score factor based on a term or phrase's frequency in a
* document.  this value is multiplied by the {@link #idf(term, searcher)}
* factor for each term in the query and these products are then summed to
* form the initial score for a document.
*
* <p>terms and phrases repeated in a document indicate the topic of the
* document, so implementations of this method usually return larger values
* when <code>freq</code> is large, and smaller values when <code>freq</code>
* is small.
*
* <p>the default implementation calls {@link #tf(float)}.
*
* @param freq the frequency of a term within a document
* @return a score factor based on a term's within-document frequency
*/
public float tf int freq
return tf  float freq
/** computes the amount of a sloppy phrase match, based on an edit distance.
* this value is summed for each sloppy phrase match in a document to form
* the frequency that is passed to {@link #tf(float)}.
*
* <p>a phrase match with a small edit distance to a document passage more
* closely matches the document, so implementations of this method usually
* return larger values when the edit distance is small and smaller values
* when it is large.
*
* @see phrasequery#setslop(int)
* @param distance the edit distance of this sloppy phrase match
* @return the frequency increment for this match
*/
public abstract float sloppyfreq int distance
/** computes a score factor based on a term or phrase's frequency in a
* document.  this value is multiplied by the {@link #idf(term, searcher)}
* factor for each term in the query and these products are then summed to
* form the initial score for a document.
*
* <p>terms and phrases repeated in a document indicate the topic of the
* document, so implementations of this method usually return larger values
* when <code>freq</code> is large, and smaller values when <code>freq</code>
* is small.
*
* @param freq the frequency of a term within a document
* @return a score factor based on a term's within-document frequency
*/
public abstract float tf float freq
/** computes a score factor for a simple term.
*
* <p>the default implementation is:<pre>
*   return idf(searcher.docfreq(term), searcher.maxdoc());
* </pre>
*
* note that {@link searcher#maxdoc()} is used instead of
* {@link org.apache.lucene.index.indexreader#numdocs()} because it is proportional to
* {@link searcher#docfreq(term)} , i.e., when one is inaccurate,
* so is the other, and in the same direction.
*
* @param term the term in question
* @param searcher the document collection being searched
* @return a score factor for the term
*/
public float idf term term  searcher searcher  throws ioexception
return idf searcher docfreq term   searcher maxdoc
/** computes a score factor for a phrase.
*
* <p>the default implementation sums the {@link #idf(term,searcher)} factor
* for each term in the phrase.
*
* @param terms the terms in the phrase
* @param searcher the document collection being searched
* @return a score factor for the phrase
*/
public float idf collection terms  searcher searcher  throws ioexception
float idf   0 0f
iterator i   terms iterator
while  i hasnext
idf    idf  term i next    searcher
return idf
/** computes a score factor based on a term's document frequency (the number
* of documents which contain the term).  this value is multiplied by the
* {@link #tf(int)} factor for each term in the query and these products are
* then summed to form the initial score for a document.
*
* <p>terms that occur in fewer documents are better indicators of topic, so
* implementations of this method usually return larger values for rare terms,
* and smaller values for common terms.
*
* @param docfreq the number of documents which contain the term
* @param numdocs the total number of documents in the collection
* @return a score factor based on the term's document frequency
*/
public abstract float idf int docfreq  int numdocs
/** computes a score factor based on the fraction of all query terms that a
* document contains.  this value is multiplied into scores.
*
* <p>the presence of a large portion of the query terms indicates a better
* match with the query, so implementations of this method usually return
* larger values when the ratio between these parameters is large and smaller
* values when the ratio between them is small.
*
* @param overlap the number of query terms matched in the document
* @param maxoverlap the total number of terms in the query
* @return a score factor based on term overlap with the query
*/
public abstract float coord int overlap  int maxoverlap
/**
* calculate a scoring factor based on the data in the payload.  overriding implementations
* are responsible for interpreting what is in the payload.  lucene makes no assumptions about
* what is in the byte array.
* <p>
* the default implementation returns 1.
*
* @param fieldname the fieldname of the term this payload belongs to
* @param payload the payload byte array to be scored
* @param offset the offset into the payload array
* @param length the length in the array
* @return an implementation dependent float to be used as a scoring factor
*/
public float scorepayload string fieldname  byte  payload  int offset  int length
//do nothing
return 1