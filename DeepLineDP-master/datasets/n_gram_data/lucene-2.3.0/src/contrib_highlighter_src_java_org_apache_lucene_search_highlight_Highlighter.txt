package org apache lucene search highlight
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io ioexception
import java io stringreader
import java util arraylist
import java util iterator
import org apache lucene analysis analyzer
import org apache lucene analysis token
import org apache lucene analysis tokenstream
import org apache lucene util priorityqueue
/**
* class used to markup highlighted terms found in the best sections of a
* text, using configurable {@link fragmenter}, {@link scorer}, {@link formatter},
* {@link encoder} and tokenizers.
* @author mark@searcharea.co.uk
*/
public class highlighter
{
public static final  int default_max_doc_bytes_to_analyze 50 1024
private int maxdocbytestoanalyze default_max_doc_bytes_to_analyze
private formatter formatter
private encoder encoder
private fragmenter textfragmenter new simplefragmenter
private scorer fragmentscorer null
public highlighter scorer fragmentscorer
{
this new simplehtmlformatter   fragmentscorer
}
public highlighter formatter formatter  scorer fragmentscorer
{
this formatter new defaultencoder   fragmentscorer
}
public highlighter formatter formatter  encoder encoder  scorer fragmentscorer
{
this formatter   formatter
this encoder   encoder
this fragmentscorer   fragmentscorer
}
/**
* highlights chosen terms in a text, extracting the most relevant section.
* this is a convenience method that calls
* {@link #getbestfragment(tokenstream, string)}
*
* @param analyzer   the analyzer that will be used to split <code>text</code>
* into chunks
* @param text text to highlight terms in
* @param fieldname name of field used to influence analyzer's tokenization policy
*
* @return highlighted text fragment or null if no terms found
*/
public final string getbestfragment analyzer analyzer  string fieldname string text
throws ioexception
{
tokenstream tokenstream   analyzer tokenstream fieldname  new stringreader text
return getbestfragment tokenstream  text
}
/**
* highlights chosen terms in a text, extracting the most relevant section.
* the document text is analysed in chunks to record hit statistics
* across the document. after accumulating stats, the fragment with the highest score
* is returned
*
* @param tokenstream   a stream of tokens identified in the text parameter, including offset information.
* this is typically produced by an analyzer re-parsing a document's
* text. some work may be done on retrieving tokenstreams more efficently
* by adding support for storing original text position data in the lucene
* index but this support is not currently available (as of lucene 1.4 rc2).
* @param text text to highlight terms in
*
* @return highlighted text fragment or null if no terms found
*/
public final string getbestfragment tokenstream tokenstream  string text
throws ioexception
{
string results   getbestfragments tokenstream text  1
if  results length > 0
{
return results
}
return null
}
/**
* highlights chosen terms in a text, extracting the most relevant sections.
* this is a convenience method that calls
* {@link #getbestfragments(tokenstream, string, int)}
*
* @param analyzer   the analyzer that will be used to split <code>text</code>
* into chunks
* @param text        	text to highlight terms in
* @param maxnumfragments  the maximum number of fragments.
* @deprecated this method incorrectly hardcodes the choice of fieldname. use the
* method of the same name that takes a fieldname.
* @return highlighted text fragments (between 0 and maxnumfragments number of fragments)
*/
public final string getbestfragments
analyzer analyzer
string text
int maxnumfragments
throws ioexception
{
tokenstream tokenstream   analyzer tokenstream    new stringreader text
return getbestfragments tokenstream  text  maxnumfragments
}
/**
* highlights chosen terms in a text, extracting the most relevant sections.
* this is a convenience method that calls
* {@link #getbestfragments(tokenstream, string, int)}
*
* @param analyzer   the analyzer that will be used to split <code>text</code>
* into chunks
* @param fieldname     the name of the field being highlighted (used by analyzer)
* @param text        	text to highlight terms in
* @param maxnumfragments  the maximum number of fragments.
*
* @return highlighted text fragments (between 0 and maxnumfragments number of fragments)
*/
public final string getbestfragments
analyzer analyzer
string fieldname
string text
int maxnumfragments
throws ioexception
{
tokenstream tokenstream   analyzer tokenstream fieldname  new stringreader text
return getbestfragments tokenstream  text  maxnumfragments
}
/**
* highlights chosen terms in a text, extracting the most relevant sections.
* the document text is analysed in chunks to record hit statistics
* across the document. after accumulating stats, the fragments with the highest scores
* are returned as an array of strings in order of score (contiguous fragments are merged into
* one in their original order to improve readability)
*
* @param text        	text to highlight terms in
* @param maxnumfragments  the maximum number of fragments.
*
* @return highlighted text fragments (between 0 and maxnumfragments number of fragments)
*/
public final string getbestfragments
tokenstream tokenstream
string text
int maxnumfragments
throws ioexception
{
maxnumfragments   math max 1  maxnumfragments     sanity check
textfragment frag  getbesttextfragments tokenstream text  true maxnumfragments
//get text
arraylist fragtexts   new arraylist
for  int i   0  i < frag length  i
{
if   frag    null      frag getscore   > 0
{
fragtexts add frag tostring
}
}
return  string  fragtexts toarray new string
}
/**
* low level api to get the most relevant (formatted) sections of the document.
* this method has been made public to allow visibility of score information held in textfragment objects.
* thanks to jason calabrese for help in redefining the interface.
* @param tokenstream
* @param text
* @param maxnumfragments
* @param mergecontiguousfragments
* @throws ioexception
*/
public final textfragment getbesttextfragments
tokenstream tokenstream
string text
boolean mergecontiguousfragments
int maxnumfragments
throws ioexception
{
arraylist docfrags   new arraylist
stringbuffer newtext new stringbuffer
textfragment currentfrag  	new textfragment newtext newtext length    docfrags size
fragmentscorer startfragment currentfrag
docfrags add currentfrag
fragmentqueue fragqueue   new fragmentqueue maxnumfragments
try
{
org apache lucene analysis token token
string tokentext
int startoffset
int endoffset
int lastendoffset   0
textfragmenter start text
tokengroup tokengroup new tokengroup
token   tokenstream next
while   token   null    token startoffset  <maxdocbytestoanalyze
{
if  tokengroup numtokens>0    tokengroup isdistinct token
{
//the current token is distinct from previous tokens -
// markup the cached token group info
startoffset   tokengroup matchstartoffset
endoffset   tokengroup matchendoffset
tokentext   text substring startoffset  endoffset
string markeduptext formatter highlightterm encoder encodetext tokentext   tokengroup
//store any whitespace etc from between this and last group
if  startoffset > lastendoffset
newtext append encoder encodetext text substring lastendoffset  startoffset
newtext append markeduptext
lastendoffset math max endoffset  lastendoffset
tokengroup clear
//check if current token marks the start of a new fragment
if textfragmenter isnewfragment token
{
currentfrag setscore fragmentscorer getfragmentscore
//record stats for a new fragment
currentfrag textendpos   newtext length
currentfrag  new textfragment newtext  newtext length    docfrags size
fragmentscorer startfragment currentfrag
docfrags add currentfrag
}
}
tokengroup addtoken token fragmentscorer gettokenscore token
//				if(lastendoffset>maxdocbytestoanalyze)
//				{
//					break;
//				}
token   tokenstream next
}
currentfrag setscore fragmentscorer getfragmentscore
if tokengroup numtokens>0
{
//flush the accumulated text (same code as in above loop)
startoffset   tokengroup matchstartoffset
endoffset   tokengroup matchendoffset
tokentext   text substring startoffset  endoffset
string markeduptext formatter highlightterm encoder encodetext tokentext   tokengroup
//store any whitespace etc from between this and last group
if  startoffset > lastendoffset
newtext append encoder encodetext text substring lastendoffset  startoffset
newtext append markeduptext
lastendoffset math max lastendoffset endoffset
}
//test what remains of the original text beyond the point where we stopped analyzing
if
//					if there is text beyond the last token considered..
lastendoffset < text length
//					and that text is not too large...
text length  <maxdocbytestoanalyze
{
//append it to the last fragment
newtext append encoder encodetext text substring lastendoffset
}
currentfrag textendpos   newtext length
//sort the most relevant sections of the text
for  iterator i   docfrags iterator    i hasnext
{
currentfrag    textfragment  i next
//if you are running with a version of lucene before 11th sept 03
// you do not have priorityqueue.insert() - so uncomment the code below
/*
if (currentfrag.getscore() >= minscore)
{
fragqueue.put(currentfrag);
if (fragqueue.size() > maxnumfragments)
{ // if hit queue overfull
fragqueue.pop(); // remove lowest in hit queue
minscore = ((textfragment) fragqueue.top()).getscore(); // reset minscore
}
}
*/
//the above code caused a problem as a result of christoph goller's 11th sept 03
//fix to priorityqueue. the correct method to use here is the new "insert" method
// use above code if this does not compile!
fragqueue insert currentfrag
}
//return the most relevant fragments
textfragment frag   new textfragment
for  int i   frag length   1  i >  0  i
{
frag    textfragment  fragqueue pop
}
//merge any contiguous fragments to improve readability
if mergecontiguousfragments
{
mergecontiguousfragments frag
arraylist fragtexts   new arraylist
for  int i   0  i < frag length  i
{
if   frag    null      frag getscore   > 0
{
fragtexts add frag
}
}
frag   textfragment  fragtexts toarray new textfragment
}
return frag
}
finally
{
if  tokenstream    null
{
try
{
tokenstream close
}
catch  exception e
{
}
}
}
}
/** improves readability of a score-sorted list of textfragments by merging any fragments
* that were contiguous in the original text into one larger fragment with the correct order.
* this will leave a "null" in the array entry for the lesser scored fragment.
*
* @param frag an array of document fragments in descending score
*/
private void mergecontiguousfragments textfragment frag
{
boolean mergingstillbeingdone
if  frag length > 1
do
{
mergingstillbeingdone   false    initialise loop control flag
//for each fragment, scan other frags looking for contiguous blocks
for  int i   0  i < frag length  i
{
if  frag    null
{
continue
}
//merge any contiguous blocks
for  int x   0  x < frag length  x
{
if  frag    null
{
continue
}
if  frag    null
{
break
}
textfragment frag1   null
textfragment frag2   null
int frag1num   0
int frag2num   0
int bestscoringfragnum
int worstscoringfragnum
//if blocks are contiguous....
if  frag follows frag
{
frag1   frag
frag1num   x
frag2   frag
frag2num   i
}
else
if  frag follows frag
{
frag1   frag
frag1num   i
frag2   frag
frag2num   x
}
//merging required..
if  frag1    null
{
if  frag1 getscore   > frag2 getscore
{
bestscoringfragnum   frag1num
worstscoringfragnum   frag2num
}
else
{
bestscoringfragnum   frag2num
worstscoringfragnum   frag1num
}
frag1 merge frag2
frag   null
mergingstillbeingdone   true
frag   frag1
}
}
}
}
while  mergingstillbeingdone
}
/**
* highlights terms in the  text , extracting the most relevant sections
* and concatenating the chosen fragments with a separator (typically "...").
* the document text is analysed in chunks to record hit statistics
* across the document. after accumulating stats, the fragments with the highest scores
* are returned in order as "separator" delimited strings.
*
* @param text        text to highlight terms in
* @param maxnumfragments  the maximum number of fragments.
* @param separator  the separator used to intersperse the document fragments (typically "...")
*
* @return highlighted text
*/
public final string getbestfragments
tokenstream tokenstream
string text
int maxnumfragments
string separator
throws ioexception
{
string sections  	getbestfragments tokenstream text  maxnumfragments
stringbuffer result   new stringbuffer
for  int i   0  i < sections length  i
{
if  i > 0
{
result append separator
}
result append sections
}
return result tostring
}
/**
* @return the maximum number of bytes to be tokenized per doc
*/
public int getmaxdocbytestoanalyze
{
return maxdocbytestoanalyze
}
/**
* @param bytecount the maximum number of bytes to be tokenized per doc
* (this can improve performance with large documents)
*/
public void setmaxdocbytestoanalyze int bytecount
{
maxdocbytestoanalyze   bytecount
}
/**
*/
public fragmenter gettextfragmenter
{
return textfragmenter
}
/**
* @param fragmenter
*/
public void settextfragmenter fragmenter fragmenter
{
textfragmenter   fragmenter
}
/**
* @return object used to score each text fragment
*/
public scorer getfragmentscorer
{
return fragmentscorer
}
/**
* @param scorer
*/
public void setfragmentscorer scorer scorer
{
fragmentscorer   scorer
}
public encoder getencoder
{
return encoder
}
public void setencoder encoder encoder
{
this encoder   encoder
}
}
class fragmentqueue extends priorityqueue
{
public fragmentqueue int size
{
initialize size
}
public final boolean lessthan object a  object b
{
textfragment fraga    textfragment  a
textfragment fragb    textfragment  b
if  fraga getscore      fragb getscore
return fraga fragnum > fragb fragnum
else
return fraga getscore   < fragb getscore
}
}