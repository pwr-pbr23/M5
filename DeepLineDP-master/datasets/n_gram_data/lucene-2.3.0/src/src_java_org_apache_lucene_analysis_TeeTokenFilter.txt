package org apache lucene analysis
import java io ioexception
/**
* works in conjunction with the sinktokenizer to provide the ability to set aside tokens
* that have already been analyzed.  this is useful in situations where multiple fields share
* many common analysis steps and then go their separate ways.
* <p/>
* it is also useful for doing things like entity extraction or proper noun analysis as
* part of the analysis workflow and saving off those tokens for use in another field.
*
* <pre>
sinktokenizer sink1 = new sinktokenizer(null);
sinktokenizer sink2 = new sinktokenizer(null);
tokenstream source1 = new teetokenfilter(new teetokenfilter(new whitespacetokenizer(reader1), sink1), sink2);
tokenstream source2 = new teetokenfilter(new teetokenfilter(new whitespacetokenizer(reader2), sink1), sink2);
tokenstream final1 = new lowercasefilter(source1);
tokenstream final2 = source2;
tokenstream final3 = new entitydetect(sink1);
tokenstream final4 = new urldetect(sink2);
d.add(new field("f1", final1));
d.add(new field("f2", final2));
d.add(new field("f3", final3));
d.add(new field("f4", final4));
* </pre>
* in this example, sink1 and sink2 will both get tokens from both reader1 and reader2 after whitespace tokenizer
and now we can further wrap any of these in extra analysis, and more "sources" can be inserted if desired.
note, the entitydetect and urldetect tokenstreams are for the example and do not currently exist in lucene
<p/>
*
* see http://issues.apache.org/jira/browse/lucene-1058
* @see sinktokenizer
*
**/
public class teetokenfilter extends tokenfilter
sinktokenizer sink
public teetokenfilter tokenstream input  sinktokenizer sink
super input
this sink   sink
public token next token result  throws ioexception
token t   input next result
sink add t
return t