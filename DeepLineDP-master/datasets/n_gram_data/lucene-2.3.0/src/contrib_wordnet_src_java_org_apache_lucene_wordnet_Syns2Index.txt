package org apache lucene wordnet
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io bufferedreader
import java io file
import java io fileinputstream
import java io inputstreamreader
import java io printstream
import java util iterator
import java util linkedlist
import java util list
import java util map
import java util set
import java util treemap
import java util treeset
import org apache lucene analysis analyzer
import org apache lucene analysis standard standardanalyzer
import org apache lucene document document
import org apache lucene document field
import org apache lucene index indexwriter
/**
* convert the prolog file wn_s.pl from the <a href="http://www.cogsci.princeton.edu/2.0/wnprolog-2.0.tar.gz">wordnet prolog download</a>
* into a lucene index suitable for looking up synonyms and performing query expansion ({@link synexpand#expand synexpand.expand(...)}).
*
* this has been tested with wordnet 2.0.
*
* the index has fields named "word" ({@link #f_word})
* and "syn" ({@link #f_syn}).
* <p>
* the source word (such as 'big') can be looked up in the
* "word" field, and if present there will be fields named "syn"
* for every synonym. what's tricky here is that there could be <b>multiple</b>
* fields with the same name, in the general case for words that have multiple synonyms.
* that's not a problem with lucene, you just use {@link org.apache.lucene.document.document#getvalues}
* </p>
* <p>
* while the wordnet file distinguishes groups of synonyms with
* related meanings we don't do that here.
* </p>
*
* this can take 4 minutes to execute and build an index on a "fast" system and the index takes up almost 3 mb.
*
* @author dave spencer, dave&#064;searchmorph.com
* @see <a href="http://www.cogsci.princeton.edu/~wn/">wordnet home page</a>
* @see <a href="http://www.cogsci.princeton.edu/~wn/man/prologdb.5wn.html">prologdb man page</a>
* @see <a href="http://www.hostmon.com/rfc/advanced.jsp">sample site that uses it</a>
*/
public class syns2index
/**
*
*/
private static final printstream o   system out
/**
*
*/
private static final printstream err   system err
/**
*
*/
public static final string f_syn
/**
*
*/
public static final string f_word
/**
*
*/
private static final analyzer ana   new standardanalyzer
/**
* takes arg of prolog file name and index directory.
*/
public static void main string args
throws throwable
// get command line arguments
string prologfilename   null     name of file
string indexdir   null
if  args length    2
prologfilename   args
indexdir   args
else
usage
system exit 1
// ensure that the prolog file is readable
if     new file prologfilename   canread
err println     prologfilename
system exit 1
// exit if the target index directory already exists
if   new file indexdir   isdirectory
err println     indexdir
err println
system exit 1
o println     prologfilename
final fileinputstream fis   new fileinputstream prologfilename
final bufferedreader br   new bufferedreader new inputstreamreader fis
string line
// maps a word to all the "groups" it's in
final map word2nums   new treemap
// maps a group to all the words in it
final map num2words   new treemap
// number of rejected words
int ndecent   0
// status output
int mod   1
int row   1
// parse prolog file
o println      prologfilename
while   line   br readline       null
// occasional progress
if     row  % mod    0     periodically print out line we read in
mod    2
o println     row       line       word2nums size
num2words size         ndecent
// syntax check
if    line startswith
err println     line
system exit 1
// parse line
line   line substring 2
int comma   line indexof
string num   line substring 0  comma
int q1   line indexof
line   line substring q1   1
int q2   line indexof
string word   line substring 0  q2  tolowercase
// make sure is a normal word
if    isdecent word
ndecent
continue     don't store words w  spaces
// 1/2: word2nums map
// append to entry or add new one
list lis   list  word2nums get word
if  lis    null
lis   new linkedlist
lis add num
word2nums put word  lis
else
lis add num
// 2/2: num2words map
lis    list  num2words get num
if  lis    null
lis   new linkedlist
lis add word
num2words put num  lis
else
lis add word
// close the streams
fis close
br close
// create the index
o println
word2nums size         num2words size
index indexdir  word2nums  num2words
/**
* checks to see if a word contains only alphabetic characters by
* checking it one character at a time.
*
* @param s string to check
* @return <code>true</code> if the string is decent
*/
private static boolean isdecent string s
int len   s length
for  int i   0  i < len  i
if   character isletter s charat i
return false
return true
/**
* forms a lucene index based on the 2 maps.
*
* @param indexdir the direcotry where the index should be created
* @param word2nums
* @param num2words
*/
private static void index string indexdir  map word2nums  map num2words
throws throwable
int row   0
int mod   1
// override the specific index if it already exists
indexwriter writer   new indexwriter indexdir  ana  true
writer setusecompoundfile true      why?
// blindly up these parameters for speed
writer setmergefactor  writer getmergefactor     2
writer setmaxbuffereddocs  writer getmaxbuffereddocs     2
iterator i1   word2nums keyset   iterator
while  i1 hasnext       for each word
string g    string  i1 next
document doc   new document
int n   index word2nums  num2words  g  doc
if  n > 0
doc add  new field  f_word  g  field store yes  field index un_tokenized
if     row % mod     0
o println     row       word2nums size         doc
mod    2
writer adddocument doc
else degenerate
o println
writer optimize
writer close
/**
* given the 2 maps fills a document for 1 word.
*/
private static int index map word2nums  map num2words  string g  document doc
throws throwable
list keys    list  word2nums get g      get list of key#'s
iterator i2   keys iterator
set already   new treeset       keep them sorted
// pass 1: fill up 'already' with all words
while  i2 hasnext       for each key#
already addall  list  num2words get i2 next         get list of words
int num   0
already remove g      of course a word is it's own syn
iterator it   already iterator
while  it hasnext
string cur    string  it next
// don't store things like 'pit bull' -> 'american pit bull'
if   isdecent cur
continue
num
doc add  new field  f_syn  cur  field store yes  field index no
return num
/**
*
*/
private static void usage
o println