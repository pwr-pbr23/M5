/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql index
import java io ioexception
import java util arraylist
import java util list
import java util iterator
import java util set
import java util map
import java util arrays
import java util hashmap
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop fs path
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop hive conf hiveconf
import org apache hadoop hive conf hiveconf confvars
import org apache hadoop hive ql exec utilities
import org apache hadoop hive ql io hivefileformatutils
import org apache hadoop hive ql io hiveinputformat
import org apache hadoop hive ql io iopreparecache
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql plan partitiondesc
import org apache hadoop io sequencefile
import org apache hadoop mapred fileinputformat
import org apache hadoop mapred filesplit
import org apache hadoop mapred inputformat
import org apache hadoop mapred inputsplit
import org apache hadoop mapred jobconf
/**
* input format for doing queries that use indexes.
* uses a blockfilter file to specify the blocks to query.
*/
public class hiveindexedinputformat extends hiveinputformat
public static final log l4j   logfactory getlog
private final string indexfile
public hiveindexedinputformat
super
indexfile
public hiveindexedinputformat string indexfilename
indexfile   indexfilename
public inputsplit dogetsplits jobconf job  int numsplits  throws ioexception
super init job
path dirs   fileinputformat getinputpaths job
if  dirs length    0
throw new ioexception
jobconf newjob   new jobconf job
arraylist<inputsplit> result   new arraylist<inputsplit>
// for each dir, get the inputformat, and do getsplits.
partitiondesc part
for  path dir   dirs
part   hivefileformatutils
getpartitiondescfrompathrecursively pathtopartitioninfo  dir
iopreparecache get   allocatepartitiondescmap    true
// create a new inputformat instance if this is the first time to see this
// class
class inputformatclass   part getinputfileformatclass
inputformat inputformat   getinputformatfromcache inputformatclass  job
utilities copytablejobpropertiestoconf part gettabledesc    newjob
fileinputformat setinputpaths newjob  dir
newjob setinputformat inputformat getclass
inputsplit iss   inputformat getsplits newjob  numsplits   dirs length
for  inputsplit is   iss
result add new hiveinputsplit is  inputformatclass getname
return result toarray new hiveinputsplit
public static list<string> getindexfiles string indexfilestr
// tokenize and store string of form (path,)+
if  indexfilestr    null
return null
string chunks   indexfilestr split
return arrays aslist chunks
@override
public inputsplit getsplits jobconf job  int numsplits  throws ioexception
string indexfilestr   job get indexfile
l4j info     indexfilestr
list<string> indexfiles   getindexfiles indexfilestr
hiveindexresult hiveindexresult   null
if  indexfiles    null
boolean first   true
stringbuilder newinputpaths   new stringbuilder
try
hiveindexresult   new hiveindexresult indexfiles  job
catch  hiveexception e
l4j error
throw new ioexception e
set<string> inputfiles   hiveindexresult buckets keyset
if  inputfiles    null    inputfiles size   <  0
// return empty splits if index results were empty
return new inputsplit
iterator<string> iter   inputfiles iterator
while iter hasnext
string path   iter next
if  path trim   equalsignorecase
continue
if   first
newinputpaths append
else
first   false
newinputpaths append path
fileinputformat setinputpaths job  newinputpaths tostring
else
return super getsplits job  numsplits
hiveinputsplit splits    hiveinputsplit  this dogetsplits job  numsplits
arraylist<hiveinputsplit> newsplits   new arraylist<hiveinputsplit>
numsplits
long maxinputsize   hiveconf getlongvar job  confvars hive_index_compact_query_max_size
if  maxinputsize < 0
maxinputsize long max_value
long sumsplitlengths   0
for  hiveinputsplit split   splits
l4j info     split getstart
l4j info      split getstart     split getlength
try
if  hiveindexresult contains split
// we may miss a sync here
hiveinputsplit newsplit   split
if  split inputformatclassname   contains
split inputformatclassname   contains
if  split getstart   > sequencefile sync_interval
newsplit   new hiveinputsplit new filesplit split getpath
split getstart     sequencefile sync_interval
split getlength     sequencefile sync_interval
split getlocations
split inputformatclassname
sumsplitlengths    newsplit getlength
if  sumsplitlengths > maxinputsize
throw new ioexception
maxinputsize       confvars hive_index_compact_query_max_size varname
newsplits add newsplit
catch  hiveexception e
throw new runtimeexception
split getpath
inputsplit reta   newsplits toarray  new filesplit
l4j info     splits length
reta length       sumsplitlengths
return reta