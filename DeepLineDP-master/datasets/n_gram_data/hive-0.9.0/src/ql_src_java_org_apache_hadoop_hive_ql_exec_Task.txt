/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql exec
import java io ioexception
import java io serializable
import java util arraylist
import java util collection
import java util hashmap
import java util linkedlist
import java util list
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop hive conf hiveconf
import org apache hadoop hive metastore api fieldschema
import org apache hadoop hive ql commandneedretryexception
import org apache hadoop hive ql context
import org apache hadoop hive ql drivercontext
import org apache hadoop hive ql queryplan
import org apache hadoop hive ql lib node
import org apache hadoop hive ql metadata hive
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql plan api stagetype
import org apache hadoop hive ql session sessionstate
import org apache hadoop hive ql session sessionstate loghelper
import org apache hadoop util stringutils
/**
* task implementation.
**/
public abstract class task<t extends serializable> implements serializable  node
private static final long serialversionuid   1l
protected transient boolean started
protected transient boolean initialized
protected transient boolean isdone
protected transient boolean queued
protected transient hiveconf conf
protected transient hive db
protected transient loghelper console
protected transient queryplan queryplan
protected transient taskhandle taskhandle
protected transient hashmap<string  long> taskcounters
protected transient drivercontext drivercontext
protected transient boolean clonedconf   false
protected transient string jobid
protected task<? extends serializable> backuptask
protected list<task<? extends serializable>> backupchildrentasks   new arraylist<task<? extends serializable>>
protected static transient log log   logfactory getlog task class
protected int tasktag
private boolean islocalmode  false
private boolean retrycmdwhenfail   false
public static final int no_tag   0
public static final int common_join   1
public static final int converted_mapjoin   2
public static final int converted_local_mapjoin   3
public static final int backup_common_join   4
public static final int local_mapjoin 5
// descendants tasks who subscribe feeds from this task
protected transient list<task<? extends serializable>> feedsubscribers
public static enum feedtype
dynamic_partitions     list of dynamic partitions
// bean methods
protected list<task<? extends serializable>> childtasks
protected list<task<? extends serializable>> parenttasks
public task
isdone   false
started   false
initialized   false
queued   false
this taskcounters   new hashmap<string  long>
tasktag   task no_tag
public void initialize hiveconf conf  queryplan queryplan  drivercontext drivercontext
this queryplan   queryplan
isdone   false
started   false
setinitialized
this conf   conf
try
db   hive get conf
catch  hiveexception e
// bail out ungracefully - we should never hit
// this here - but would have hit it in semanticanalyzer
log error stringutils stringifyexception e
throw new runtimeexception e
this drivercontext   drivercontext
console   new loghelper log
/**
* this method is called in the driver on every task. it updates counters and calls execute(),
* which is overridden in each task
*
* @return return value of execute()
*/
public int executetask
try
sessionstate ss   sessionstate get
this setstarted
if  ss    null
ss gethivehistory   logplanprogress queryplan
int retval   execute drivercontext
this setdone
if  ss    null
ss gethivehistory   logplanprogress queryplan
return retval
catch  ioexception e
throw new runtimeexception e getmessage
/**
* this method is overridden in each task. todo execute should return a taskhandle.
*
* @return status of executing the task
*/
protected abstract int execute drivercontext drivercontext
// dummy method - fetchtask overwrites this
public boolean fetch arraylist<string> res  throws ioexception  commandneedretryexception
assert false
return false
public void setchildtasks list<task<? extends serializable>> childtasks
this childtasks   childtasks
public list<? extends node> getchildren
return getchildtasks
public list<task<? extends serializable>> getchildtasks
return childtasks
public void setparenttasks list<task<? extends serializable>> parenttasks
this parenttasks   parenttasks
public list<task<? extends serializable>> getparenttasks
return parenttasks
public task<? extends serializable> getbackuptask
return backuptask
public void setbackuptask task<? extends serializable> backuptask
this backuptask   backuptask
public list<task<? extends serializable>> getbackupchildrentasks
return backupchildrentasks
public void setbackupchildrentasks list<task<? extends serializable>> backupchildrentasks
this backupchildrentasks   backupchildrentasks
public task<? extends serializable> getandinitbackuptask
if  backuptask    null
// first set back the backup task with its children task.
if  backupchildrentasks   null
for  task<? extends serializable> backupchild   backupchildrentasks
backupchild getparenttasks   add backuptask
// recursively remove task from its children tasks if this task doesn't have any parent task
this removefromchildrentasks
return backuptask
public void removefromchildrentasks
list<task<? extends serializable>> childrentasks   this getchildtasks
if  childrentasks    null
return
for  task<? extends serializable> childtsk   childrentasks
// remove this task from its children tasks
childtsk getparenttasks   remove this
// recursively remove non-parent task from its children
list<task<? extends serializable>> siblingtasks   childtsk getparenttasks
if  siblingtasks    null    siblingtasks size      0
childtsk removefromchildrentasks
return
/**
* the default dependent tasks are just child tasks, but different types could implement their own
* (e.g. conditionaltask will use the listtasks as dependents).
*
* @return a list of tasks that are dependent on this task.
*/
public list<task<? extends serializable>> getdependenttasks
return getchildtasks
/**
* add a dependent task on the current task. return if the dependency already existed or is this a
* new one
*
* @return true if the task got added false if it already existed
*/
public boolean adddependenttask task<? extends serializable> dependent
boolean ret   false
if  getchildtasks      null
setchildtasks new arraylist<task<? extends serializable>>
if   getchildtasks   contains dependent
ret   true
getchildtasks   add dependent
if  dependent getparenttasks      null
dependent setparenttasks new arraylist<task<? extends serializable>>
if   dependent getparenttasks   contains this
dependent getparenttasks   add this
return ret
/**
* remove the dependent task.
*
* @param dependent
*          the task to remove
*/
public void removedependenttask task<? extends serializable> dependent
if   getchildtasks      null      getchildtasks   contains dependent
getchildtasks   remove dependent
if   dependent getparenttasks      null      dependent getparenttasks   contains this
dependent getparenttasks   remove this
public void setstarted
this started   true
public boolean started
return started
public boolean done
return isdone
public void setdone
isdone   true
public void setqueued
queued   true
public boolean getqueued
return queued
public void setinitialized
initialized   true
public boolean getinitialized
return initialized
public boolean isrunnable
boolean isrunnable   true
if  parenttasks    null
for  task<? extends serializable> parent   parenttasks
if   parent done
isrunnable   false
break
return isrunnable
protected string id
protected t work
public void setwork t work
this work   work
public t getwork
return work
public void setid string id
this id   id
public string getid
return id
public boolean ismapredtask
return false
public boolean ismapredlocaltask
return false
public collection<operator<? extends serializable>> gettopoperators
return new linkedlist<operator<? extends serializable>>
public boolean hasreduce
return false
public operator<? extends serializable> getreducer
return null
public hashmap<string  long> getcounters
return taskcounters
/**
* should be overridden to return the type of the specific task among the types in stagetype.
*
* @return stagetype.* or null if not overridden
*/
public abstract stagetype gettype
/**
* if this task uses any map-reduce intermediate data (either for reading or for writing),
* localize them (using the supplied context). map-reduce intermediate directories are allocated
* using context.getmrtmpfileuri() and can be localized using localizemrtmpfileuri().
*
* this method is declared abstract to force any task code to explicitly deal with this aspect of
* execution.
*
* @param ctx
*          context object with which to localize
*/
abstract protected void localizemrtmpfilesimpl context ctx
/**
* localize a task tree
*
* @param ctx
*          context object with which to localize
*/
public final void localizemrtmpfiles context ctx
localizemrtmpfilesimpl ctx
if  childtasks    null
return
for  task<? extends serializable> t   childtasks
t localizemrtmpfiles ctx
/**
* subscribe the feed of publisher. to prevent cycles, a task can only subscribe to its ancestor.
* feed is a generic form of execution-time feedback (type, value) pair from one task to another
* task. examples include dynamic partitions (which are only available at execution time). the
* movetask may pass the list of dynamic partitions to the statstask since after the movetask the
* list of dynamic partitions are lost (movetask moves them to the table's destination directory
* which is mixed with old partitions).
*
* @param publisher
*          this feed provider.
*/
public void subscribefeed task<? extends serializable> publisher
if  publisher    this    publisher ancestororself this
if  publisher getfeedsubscribers      null
publisher setfeedsubscribers new linkedlist<task<? extends serializable>>
publisher getfeedsubscribers   add this
// return true if this task is an ancestor of itself of parameter desc
private boolean ancestororself task<? extends serializable> desc
if  this    desc
return true
list<task<? extends serializable>> deps   getdependenttasks
if  deps    null
for  task<? extends serializable> d   deps
if  d ancestororself desc
return true
return false
public list<task<? extends serializable>> getfeedsubscribers
return feedsubscribers
public void setfeedsubscribers list<task<? extends serializable>> s
feedsubscribers   s
// push the feed to its subscribers
protected void pushfeed feedtype feedtype  object feedvalue
if  feedsubscribers    null
for  task<? extends serializable> s   feedsubscribers
s receivefeed feedtype  feedvalue
// a subscriber accept the feed and do something depending on the task type
protected void receivefeed feedtype feedtype  object feedvalue
protected void cloneconf
if   clonedconf
clonedconf   true
conf   new hiveconf conf
public int gettasktag
return tasktag
public void settasktag int tasktag
this tasktag   tasktag
public boolean islocalmode
return islocalmode
public void setlocalmode boolean islocalmode
this islocalmode   islocalmode
public boolean requirelock
return false
public boolean ifretrycmdwhenfail
return retrycmdwhenfail
public void setretrycmdwhenfail boolean retrycmdwhenfail
this retrycmdwhenfail   retrycmdwhenfail
public queryplan getqueryplan
return queryplan
public void setqueryplan queryplan queryplan
this queryplan   queryplan
public string getjobid
return jobid
public list<fieldschema> getresultschema
return null