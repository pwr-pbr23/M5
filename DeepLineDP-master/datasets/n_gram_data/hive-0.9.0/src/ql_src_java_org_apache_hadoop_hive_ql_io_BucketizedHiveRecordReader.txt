/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql io
import java io ioexception
import org apache hadoop hive io hiveioexceptionhandlerutil
import org apache hadoop io writable
import org apache hadoop io writablecomparable
import org apache hadoop mapred filesplit
import org apache hadoop mapred inputformat
import org apache hadoop mapred jobconf
import org apache hadoop mapred reporter
/**
* bucketizedhiverecordreader is a wrapper on a list of recordreader. it behaves
* similar as hiverecordreader while it wraps a list of recordreader from one
* file.
*/
public class bucketizedhiverecordreader<k extends writablecomparable  v extends writable>
extends hivecontextawarerecordreader<k  v>
protected final bucketizedhiveinputsplit split
protected final inputformat inputformat
protected final reporter reporter
protected long progress
protected int idx
public bucketizedhiverecordreader inputformat inputformat
bucketizedhiveinputsplit bucketizedsplit  jobconf jobconf
reporter reporter  throws ioexception
super jobconf
this split   bucketizedsplit
this inputformat   inputformat
this reporter   reporter
initnextrecordreader
@override
public void doclose   throws ioexception
if  recordreader    null
recordreader close
recordreader   null
idx   0
public k createkey
return  k  recordreader createkey
public v createvalue
return  v  recordreader createvalue
public long getpos   throws ioexception
if  recordreader    null
return recordreader getpos
else
return 0
@override
public float getprogress   throws ioexception
// the calculation is strongly dependent on the assumption that all splits
// came from the same file
return math min 1 0f    recordreader    null    this getiocontext   isbinarysearching    ?
progress   recordreader getpos       float   split getlength
@override
public boolean donext k key  v value  throws ioexception
while   recordreader    null      donextwithexceptionhandler key  value
if   initnextrecordreader
return false
return true
private boolean donextwithexceptionhandler k key  v value  throws ioexception
return super donext key  value
/**
* get the record reader for the next chunk in this
* bucketizedhiverecordreader.
*/
protected boolean initnextrecordreader   throws ioexception
if  recordreader    null
recordreader close
recordreader   null
if  idx > 0
progress    split getlength idx   1      done processing so far
// if all chunks have been processed, nothing more to do.
if  idx    split getnumsplits
return false
// get a record reader for the idx-th chunk
try
recordreader   inputformat getrecordreader split getsplit idx   jobconf
reporter
catch  exception e
recordreader   hiveioexceptionhandlerutil handlerecordreadercreationexception e  jobconf
// if we're performing a binary search, we need to restart it
if  issorted
initiocontextsortedprops  filesplit  split getsplit idx   recordreader  jobconf
idx
return true