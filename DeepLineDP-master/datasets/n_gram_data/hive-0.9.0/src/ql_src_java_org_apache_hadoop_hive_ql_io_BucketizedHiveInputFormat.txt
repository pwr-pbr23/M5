/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql io
import java io ioexception
import java util arraylist
import java util list
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop hive common fileutils
import org apache hadoop hive ql plan partitiondesc
import org apache hadoop io writable
import org apache hadoop io writablecomparable
import org apache hadoop mapred fileinputformat
import org apache hadoop mapred inputformat
import org apache hadoop mapred inputsplit
import org apache hadoop mapred invalidinputexception
import org apache hadoop mapred jobconf
import org apache hadoop mapred recordreader
import org apache hadoop mapred reporter
/**
* bucketizedhiveinputformat serves the similar function as hiveinputformat but
* its getsplits() always group splits from one input file into one wrapper
* split. it is useful for the applications that requires input files to fit in
* one mapper.
*/
public class bucketizedhiveinputformat<k extends writablecomparable  v extends writable>
extends hiveinputformat<k  v>
public static final log log   logfactory
getlog
@override
public recordreader getrecordreader inputsplit split  jobconf job
reporter reporter  throws ioexception
bucketizedhiveinputsplit hsplit    bucketizedhiveinputsplit  split
string inputformatclassname   null
class inputformatclass   null
try
inputformatclassname   hsplit inputformatclassname
inputformatclass   job getclassbyname inputformatclassname
catch  exception e
throw new ioexception     inputformatclassname
// clone a jobconf for setting needed columns for reading
jobconf clonejobconf   new jobconf job
pushprojectionsandfilters clonejobconf  inputformatclass  hsplit getpath
tostring    hsplit getpath   touri   getpath
inputformat inputformat   getinputformatfromcache inputformatclass
clonejobconf
bucketizedhiverecordreader<k  v> rr  new bucketizedhiverecordreader inputformat  hsplit  clonejobconf
reporter
rr initiocontext hsplit  clonejobconf  inputformatclass
return rr
protected filestatus liststatus jobconf job  path path  throws ioexception
arraylist<filestatus> result   new arraylist<filestatus>
list<ioexception> errors   new arraylist<ioexception>
filesystem fs   path getfilesystem job
filestatus matches   fs globstatus path
if  matches    null
errors add new ioexception     path
else if  matches length    0
errors add new ioexception     path
else
for  filestatus globstat   matches
fileutils liststatusrecursively fs  globstat  result
if   errors isempty
throw new invalidinputexception errors
log info     result size
return result toarray new filestatus
@override
public inputsplit getsplits jobconf job  int numsplits  throws ioexception
init job
path dirs   fileinputformat getinputpaths job
if  dirs length    0
throw new ioexception
jobconf newjob   new jobconf job
arraylist<inputsplit> result   new arraylist<inputsplit>
int numorigsplits   0
// for each dir, get all files under the dir, do getsplits to each
// individual file,
// and then create a bucketizedhiveinputsplit on it
for  path dir   dirs
partitiondesc part   getpartitiondescfrompath pathtopartitioninfo  dir
// create a new inputformat instance if this is the first time to see this
// class
class inputformatclass   part getinputfileformatclass
inputformat inputformat   getinputformatfromcache inputformatclass  job
newjob setinputformat inputformat getclass
filestatus liststatus   liststatus newjob  dir
for  filestatus status   liststatus
log info     status getblocksize
log info     status getlen
fileinputformat setinputpaths newjob  status getpath
inputsplit iss   inputformat getsplits newjob  0
if  iss    null    iss length > 0
numorigsplits    iss length
result add new bucketizedhiveinputsplit iss  inputformatclass
getname
log info result size
numorigsplits
return result toarray new bucketizedhiveinputsplit