/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql exec
import java io ioexception
import java util arraylist
import java util hashmap
import java util hashset
import java util list
import java util map
import java util set
import org apache hadoop hive conf hiveconf
import org apache hadoop hive ql exec errors errorandsolution
import org apache hadoop hive ql exec errors tasklogprocessor
import org apache hadoop hive ql session sessionstate loghelper
import org apache hadoop hive shims shimloader
import org apache hadoop mapred jobconf
import org apache hadoop mapred runningjob
import org apache hadoop mapred taskcompletionevent
/**
* jobdebugger takes a runningjob that has failed and grabs the top 4 failing
* tasks and outputs this information to the hive cli.
*/
public class jobdebugger implements runnable
private final jobconf conf
private final runningjob rj
private final loghelper console
private final map<string  list<list<string>>> stacktraces
// mapping from task id to the number of failures
private final map<string  integer> failures   new hashmap<string  integer>
private final set<string> successes   new hashset<string>       successful task id's
private final map<string  taskinfo> taskidtoinfo   new hashmap<string  taskinfo>
// used for showjobfaildebuginfo
private static class taskinfo
string jobid
set<string> logurls
public taskinfo string jobid
this jobid   jobid
logurls   new hashset<string>
public void addlogurl string logurl
logurls add logurl
public set<string> getlogurls
return logurls
public string getjobid
return jobid
public jobdebugger jobconf conf  runningjob rj  loghelper console
this conf   conf
this rj   rj
this console   console
this stacktraces   null
public jobdebugger jobconf conf  runningjob rj  loghelper console
map<string  list<list<string>>> stacktraces
this conf   conf
this rj   rj
this console   console
this stacktraces   stacktraces
public void run
try
showjobfaildebuginfo
catch  ioexception e
console printerror e getmessage
private string gettaskattemptlogurl string tasktrackerhttpaddress  string taskattemptid
return tasktrackerhttpaddress       taskattemptid
class taskloggrabber implements runnable
public void run
try
gettasklogs
catch  ioexception e
console printerror e getmessage
private void gettasklogs   throws ioexception
int startindex   0
while  true
taskcompletionevent taskcompletions   rj gettaskcompletionevents startindex
if  taskcompletions    null    taskcompletions length    0
break
boolean more   true
boolean firsterror   true
for  taskcompletionevent t   taskcompletions
// gettaskjobids returns strings for compatibility with hadoop versions
// without taskid or taskattemptid
string taskjobids   shimloader gethadoopshims   gettaskjobids t
if  taskjobids    null
console printerror
more   false
break
// for each task completion event, get the associated task id, job id
// and the logs
string taskid   taskjobids
string jobid   taskjobids
if  firsterror
console printerror     taskid       jobid
firsterror   false
taskinfo ti   taskidtoinfo get taskid
if  ti    null
ti   new taskinfo jobid
taskidtoinfo put taskid  ti
// these tasks should have come from the same job.
assert  ti getjobid      null     ti getjobid   equals jobid
ti getlogurls   add gettaskattemptlogurl t gettasktrackerhttp    t gettaskid
// if a task failed, then keep track of the total number of failures
// for that task (typically, a task gets re-run up to 4 times if it
// fails
if  t gettaskstatus      taskcompletionevent status succeeded
integer failattempts   failures get taskid
if  failattempts    null
failattempts   integer valueof 0
failattempts   integer valueof failattempts intvalue     1
failures put taskid  failattempts
else
successes add taskid
if   more
break
startindex    taskcompletions length
@suppresswarnings
private void showjobfaildebuginfo   throws ioexception
console printerror
// loop to get all task completion events because gettaskcompletionevents
// only returns a subset per call
taskloggrabber tlg   new taskloggrabber
thread t   new thread tlg
try
t start
t join hiveconf getintvar conf  hiveconf confvars tasklog_debug_timeout
catch  interruptedexception e
console printerror
// remove failures for tasks that succeeded
for  string task   successes
failures remove task
if  failures keyset   size      0
return
// find the highest failure count
int maxfailures   0
for  integer failcount   failures values
if  maxfailures < failcount intvalue
maxfailures   failcount intvalue
// display error message for tasks with the highest failure count
string jturl   jobtrackerurlresolver geturl conf
for  string task   failures keyset
if  failures get task  intvalue      maxfailures
taskinfo ti   taskidtoinfo get task
string jobid   ti getjobid
string taskurl   jturl       jobid       task tostring
tasklogprocessor tlp   new tasklogprocessor conf
for  string logurl   ti getlogurls
tlp addtaskattemptlogurl logurl
if  hiveconf getboolvar conf  hiveconf confvars job_debug_capture_stacktraces
stacktraces    null
if   stacktraces containskey jobid
stacktraces put jobid  new arraylist<list<string>>
stacktraces get jobid  addall tlp getstacktraces
if  hiveconf getboolvar conf  hiveconf confvars show_job_fail_debug_info
list<errorandsolution> errors   tlp geterrors
stringbuilder sb   new stringbuilder
// we use a stringbuilder and then call printerror only once as
// printerror will write to both stderr and the error log file. in
// situations where both the stderr and the log file output is
// simultaneously output to a single stream, this will look cleaner.
sb append
sb append     maxfailures
sb append
sb append     task
sb append     taskurl
for  errorandsolution e   errors
sb append
sb append     e geterror
sb append     e getsolution
sb append
console printerror sb tostring
// only print out one task because that's good enough for debugging.
break
return