/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql optimizer
import java io serializable
import java util hashset
import java util set
import org apache hadoop hive ql exec joinoperator
import org apache hadoop hive ql exec operator
import org apache hadoop hive ql exec reducesinkoperator
import org apache hadoop hive ql exec tablescanoperator
import org apache hadoop hive ql parse parsecontext
import org apache hadoop hive ql parse qbjointree
import org apache hadoop hive ql parse semanticexception
/**
* implementation of rule-based join table reordering optimization. user passes
* hints to specify which tables are to be streamed and they are moved to have
* largest tag so that they are processed last. in future, once statistics are
* implemented, this transformation can also be done based on costs.
*/
public class joinreorder implements transform
/**
* estimate the size of the output based on the streamtable hints. to do so
* the whole tree is traversed. possible sizes: 0: the operator and its
* subtree don't contain any big tables 1: the subtree of the operator
* contains a big table 2: the operator is a big table
*
* @param operator
*          the operator which output size is to be estimated
* @param bigtables
*          set of tables that should be streamed
* @return the estimated size - 0 (no streamed tables), 1 (streamed tables in
*         subtree) or 2 (a streamed table)
*/
private int getoutputsize operator<? extends serializable> operator
set<string> bigtables
// if a join operator contains a big subtree, there is a chance that its
// output is also big, so the output size is 1 (medium)
if  operator instanceof joinoperator
for  operator<? extends serializable> o   operator getparentoperators
if  getoutputsize o  bigtables     0
return 1
// if a table is in bigtables then its output is big (2)
if  operator instanceof tablescanoperator
string alias     tablescanoperator  operator  getconf   getalias
if  bigtables contains alias
return 2
// for all other kinds of operators, assume the output is as big as the
// the biggest output from a parent
int maxsize   0
if  operator getparentoperators      null
for  operator<? extends serializable> o   operator getparentoperators
int current   getoutputsize o  bigtables
if  current > maxsize
maxsize   current
return maxsize
/**
* find all big tables from streamtable hints.
*
* @param joinctx
*          the join context
* @return set of all big tables
*/
private set<string> getbigtables parsecontext joinctx
set<string> bigtables   new hashset<string>
for  qbjointree qbjoin   joinctx getjoincontext   values
if  qbjoin getstreamaliases      null
bigtables addall qbjoin getstreamaliases
return bigtables
/**
* reorder the tables in a join operator appropriately (by reordering the tags
* of the reduces sinks).
*
* @param joinop
*          the join operator to be processed
* @param bigtables
*          set of all big tables
*/
private void reorder joinoperator joinop  set<string> bigtables
int count   joinop getparentoperators   size
// find the biggest reduce sink
int biggestpos   count   1
int biggestsize   getoutputsize
joinop getparentoperators   get biggestpos   bigtables
for  int i   0  i < count   1  i
int currsize   getoutputsize joinop getparentoperators   get i
bigtables
if  currsize > biggestsize
biggestsize   currsize
biggestpos   i
// reorder tags if need be
if  biggestpos     count   1
byte tagorder   joinop getconf   gettagorder
byte temp   tagorder
tagorder   tagorder
tagorder   temp
// update tags of reduce sinks
reducesinkoperator  joinop getparentoperators   get biggestpos
getconf   settag count   1
reducesinkoperator  joinop getparentoperators   get count   1
getconf   settag biggestpos
/**
* transform the query tree. for each join, check which reduce sink will
* output the biggest result (based on streamtable hints) and give it the
* biggest tag so that it gets streamed.
*
* @param pactx
*          current parse context
*/
public parsecontext transform parsecontext pactx  throws semanticexception
set<string> bigtables   getbigtables pactx
for  joinoperator joinop   pactx getjoincontext   keyset
reorder joinop  bigtables
return pactx