/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql optimizer
import java io ioexception
import java util arraylist
import java util arrays
import java util collection
import java util hashmap
import java util linkedhashmap
import java util map
import java util stack
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop hive ql exec filteroperator
import org apache hadoop hive ql exec tablescanoperator
import org apache hadoop hive ql lib defaultgraphwalker
import org apache hadoop hive ql lib defaultruledispatcher
import org apache hadoop hive ql lib dispatcher
import org apache hadoop hive ql lib graphwalker
import org apache hadoop hive ql lib node
import org apache hadoop hive ql lib nodeprocessor
import org apache hadoop hive ql lib nodeprocessorctx
import org apache hadoop hive ql lib rule
import org apache hadoop hive ql lib ruleregexp
import org apache hadoop hive ql metadata hive
import org apache hadoop hive ql metadata partition
import org apache hadoop hive ql parse parsecontext
import org apache hadoop hive ql parse semanticexception
import org apache hadoop hive ql plan filterdesc
import org apache hadoop hive ql plan filterdesc sampledesc
/**
* the transformation step that does sample pruning.
*
*/
public class samplepruner implements transform
/**
* sampleprunerctx.
*
*/
public static class sampleprunerctx implements nodeprocessorctx
hashmap<tablescanoperator  sampledesc> optosamplepruner
public sampleprunerctx
hashmap<tablescanoperator  sampledesc> optosamplepruner
this optosamplepruner   optosamplepruner
}
/**
* @return the optosamplepruner
*/
public hashmap<tablescanoperator  sampledesc> getoptosamplepruner
return optosamplepruner
}
/**
* @param optosamplepruner
*          the optosamplepruner to set
*/
public void setoptosamplepruner
hashmap<tablescanoperator  sampledesc> optosamplepruner
this optosamplepruner   optosamplepruner
}
}
// the log
private static final log log   logfactory
getlog
/*
* (non-javadoc)
*
* @see
* org.apache.hadoop.hive.ql.optimizer.transform#transform(org.apache.hadoop
* .hive.ql.parse.parsecontext)
*/
@override
public parsecontext transform parsecontext pctx  throws semanticexception
// create a the context for walking operators
sampleprunerctx sampleprunerctx   new sampleprunerctx pctx
getoptosamplepruner
map<rule  nodeprocessor> oprules   new linkedhashmap<rule  nodeprocessor>
oprules put new ruleregexp        getfilterproc
// the dispatcher fires the processor corresponding to the closest matching
// rule and passes the context along
dispatcher disp   new defaultruledispatcher getdefaultproc    oprules
sampleprunerctx
graphwalker ogw   new defaultgraphwalker disp
// create a list of topop nodes
arraylist<node> topnodes   new arraylist<node>
topnodes addall pctx gettopops   values
ogw startwalking topnodes  null
return pctx
}
/**
* filterppr filter processor.
*
*/
public static class filterppr implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
filteroperator filop    filteroperator  nd
filterdesc filopdesc   filop getconf
sampledesc sampledescr   filopdesc getsampledescr
if   sampledescr    null      sampledescr getinputpruning
return null;
}
assert  stack size      3    stack get 1  instanceof filteroperator
stack size      2
tablescanoperator tsop    tablescanoperator  stack get 0
sampleprunerctx  procctx  getoptosamplepruner   put tsop  sampledescr
return null;
}
}
public static nodeprocessor getfilterproc
return new filterppr
}
/**
* defaultppr default processor which does nothing.
*
*/
public static class defaultppr implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
// nothing needs to be done.
return null;
}
}
public static nodeprocessor getdefaultproc
return new defaultppr
}
/**
* prunes to get all the files in the partition that satisfy the tablesample
* clause.
*
* @param part
*          the partition to prune
* @return path[]
* @throws semanticexception
*/
@suppresswarnings
public static path prune partition part  sampledesc sampledescr
throws semanticexception
int num   sampledescr getnumerator
int den   sampledescr getdenominator
int bucketcount   part getbucketcount
string fullscanmsg
// check if input pruning is possible
if  sampledescr getinputpruning
log trace     num
log trace     den
log trace     bucketcount
if  bucketcount    den
path ret   new path
ret   part getbucketpath num   1
return  ret
else if  bucketcount > den    bucketcount % den    0
int numpathsinsample   bucketcount   den
path ret   new path
for  int i   0  i < numpathsinsample  i
ret   part getbucketpath i   den   num   1
}
return ret
else if  bucketcount < den    den % bucketcount    0
path ret   new path
ret   part getbucketpath  num   1  % bucketcount
return ret
} else {
// need to do full scan
fullscanmsg       den
bucketcount
part gettable   gettablename
}
} else {
// need to do full scan
fullscanmsg
}
log warn fullscanmsg
path ret   part getpath
return ret
}
/**
* class used for return value of addpath()
*
*/
public static class addpathreturnstatus
public addpathreturnstatus boolean hasfile  boolean allfile  long sizeleft
this hasfile   hasfile
this allfile   allfile
this sizeleft   sizeleft
}
// whether the sub-directory has any file
public boolean hasfile
// whether all files are not sufficient to reach sizeleft
public boolean allfile
// remaining size needed after putting files in the return path list
public long sizeleft
}
/**
* try to recursively add files in sub-directories into retpathlist until
* reaching the sizeleft.
* @param fs
* @param pathpattern
* @param sizeleft
* @param filelimit
* @param retpathlist
* @return status of the recursive call
* @throws ioexception
*/
public static addpathreturnstatus addpath filesystem fs  string pathpattern  long sizeleft  int filelimit
collection<path> retpathlist
throws ioexception
log info     pathpattern
filestatus srcs   fs globstatus new path pathpattern
arrays sort srcs
boolean hasfile   false  allfile   true
for  filestatus src   srcs
if  sizeleft <  0
allfile   false
break
}
if  src isdir
log info     src getpath
addpathreturnstatus ret   addpath fs  src getpath   tostring        sizeleft
filelimit, retpathlist);
if (ret == null) {
// not qualify this optimization
return null;
}
sizeleft = ret.sizeleft;
hasfile |= ret.hasfile;
allfile &= ret.allfile;
} else {
log.info("got file: " + src.getpath());
hasfile = true;
retpathlist.add(src.getpath());
sizeleft -= src.getlen();
if (retpathlist.size() >= filelimit && sizeleft > 0) {
return null;
}
}
}
return new addpathreturnstatus(hasfile, allfile, sizeleft);
}
public enum limitpruneretstatus {
// no files in the partition
nofile,
// sum size of all files in the partition is smaller than size required
needallfiles,
// a susbset of files for the partition are sufficient for the optimization
needsomefiles,
// the partition doesn't qualify the global limit optimization for some reason
notqualify
}
/**
* try to generate a list of subset of files in the partition to reach a size
* limit with number of files less than filelimit
* @param part
* @param sizelimit
* @param filelimit
* @param retpathlist list of paths returned
* @return the result of the attempt
* @throws semanticexception
*/
public static limitpruneretstatus limitprune partition part  long sizelimit  int filelimit
collection<path> retpathlist
throws semanticexception
try
filesystem fs   filesystem get part getpartitionpath   touri    hive get
getconf
string pathpattern   part getpartitionpath   tostring
addpathreturnstatus ret   addpath fs  pathpattern  sizelimit  filelimit  retpathlist
if (ret == null) {
return limitpruneretstatus notqualify
else if   ret hasfile
return limitpruneretstatus nofile
else if  ret sizeleft > 0
return limitpruneretstatus notqualify
else if  ret allfile
return limitpruneretstatus needallfiles
} else {
return limitpruneretstatus needsomefiles
}
catch  exception e
throw new runtimeexception    e
}
}
}