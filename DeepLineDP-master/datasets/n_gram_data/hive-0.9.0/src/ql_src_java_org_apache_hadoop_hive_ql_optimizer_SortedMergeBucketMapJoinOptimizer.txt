/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.see the notice file
* distributed with this work for additional information
* regarding copyright ownership.the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.you may obtain a copy of the license at
*
* http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql optimizer
import java io serializable
import java util arraylist
import java util hashmap
import java util linkedhashmap
import java util list
import java util map
import java util stack
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop hive metastore api order
import org apache hadoop hive ql exec functionregistry
import org apache hadoop hive ql exec mapjoinoperator
import org apache hadoop hive ql exec operator
import org apache hadoop hive ql exec smbmapjoinoperator
import org apache hadoop hive ql exec tablescanoperator
import org apache hadoop hive ql lib defaultgraphwalker
import org apache hadoop hive ql lib defaultruledispatcher
import org apache hadoop hive ql lib dispatcher
import org apache hadoop hive ql lib graphwalker
import org apache hadoop hive ql lib node
import org apache hadoop hive ql lib nodeprocessor
import org apache hadoop hive ql lib nodeprocessorctx
import org apache hadoop hive ql lib rule
import org apache hadoop hive ql lib ruleregexp
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata partition
import org apache hadoop hive ql metadata table
import org apache hadoop hive ql optimizer ppr partitionpruner
import org apache hadoop hive ql parse basesemanticanalyzer
import org apache hadoop hive ql parse parsecontext
import org apache hadoop hive ql parse prunedpartitionlist
import org apache hadoop hive ql parse qbjointree
import org apache hadoop hive ql parse semanticexception
import org apache hadoop hive ql plan exprnodecolumndesc
import org apache hadoop hive ql plan exprnodedesc
import org apache hadoop hive ql plan exprnodegenericfuncdesc
import org apache hadoop hive ql plan smbjoindesc
import org apache hadoop hive ql udf generic genericudf
//try to replace a bucket map join with a sorted merge map join
public class sortedmergebucketmapjoinoptimizer implements transform
private static final log log   logfactory
getlog sortedmergebucketmapjoinoptimizer class getname
public sortedmergebucketmapjoinoptimizer
@override
public parsecontext transform parsecontext pctx  throws semanticexception
map<rule  nodeprocessor> oprules   new linkedhashmap<rule  nodeprocessor>
// go through all map joins and find out all which have enabled bucket map
// join.
oprules put new ruleregexp
getsortedmergebucketmapjoinproc pctx
// the dispatcher fires the processor corresponding to the closest matching
// rule and passes the context along
dispatcher disp   new defaultruledispatcher getdefaultproc    oprules  null
graphwalker ogw   new defaultgraphwalker disp
// create a list of topop nodes
arraylist<node> topnodes   new arraylist<node>
topnodes addall pctx gettopops   values
ogw startwalking topnodes  null
return pctx
private nodeprocessor getsortedmergebucketmapjoinproc parsecontext pctx
return new sortedmergebucketmapjoinproc pctx
private nodeprocessor getdefaultproc
return new nodeprocessor
@override
public object process node nd  stack<node> stack
nodeprocessorctx procctx  object    nodeoutputs
throws semanticexception
return null
class sortedmergebucketmapjoinproc implements nodeprocessor
parsecontext pgraphcontext
public sortedmergebucketmapjoinproc parsecontext pctx
this pgraphcontext   pctx
public sortedmergebucketmapjoinproc
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
if  nd instanceof smbmapjoinoperator
return null
mapjoinoperator mapjoinop    mapjoinoperator  nd
if  mapjoinop getconf   getaliasbucketfilenamemapping      null
mapjoinop getconf   getaliasbucketfilenamemapping   size      0
return null
boolean tablesorted   true
qbjointree joincxt   this pgraphcontext getmapjoincontext
get mapjoinop
if  joincxt    null
return null
string srcs   joincxt getbasesrc
int pos   0
for  string src   srcs
tablesorted   tablesorted
istablesorted this pgraphcontext  mapjoinop  joincxt  src  pos
pos
if   tablesorted
//this is a mapjoin but not suit for a sort merge bucket map join. check outer joins
mapjoinprocessor checkmapjoin   mapjoinoperator  nd  getconf   getposbigtable
mapjoinoperator  nd  getconf   getconds
return null
// convert a bucket map join operator to a sorted merge bucket map join
// operator
converttosmbjoin mapjoinop  srcs
return null
private smbmapjoinoperator converttosmbjoin mapjoinoperator mapjoinop
string srcs
smbmapjoinoperator smbjop   new smbmapjoinoperator mapjoinop
smbjoindesc smbjoindesc   new smbjoindesc mapjoinop getconf
smbjop setconf smbjoindesc
hashmap<byte  string> tagtoalias   new hashmap<byte  string>
for  int i   0  i < srcs length  i
tagtoalias put  byte  i  srcs
smbjoindesc settagtoalias tagtoalias
int indexinlistmapjoinnoreducer   this pgraphcontext getlistmapjoinopsnoreducer   indexof mapjoinop
if indexinlistmapjoinnoreducer >  0
this pgraphcontext getlistmapjoinopsnoreducer   remove indexinlistmapjoinnoreducer
this pgraphcontext getlistmapjoinopsnoreducer   add indexinlistmapjoinnoreducer  smbjop
list<? extends operator> parentoperators   mapjoinop getparentoperators
for  int i   0  i < parentoperators size    i
operator par   parentoperators get i
int index   par getchildoperators   indexof mapjoinop
par getchildoperators   remove index
par getchildoperators   add index  smbjop
list<? extends operator> childops   mapjoinop getchildoperators
for  int i   0  i < childops size    i
operator child   childops get i
int index   child getparentoperators   indexof mapjoinop
child getparentoperators   remove index
child getparentoperators   add index  smbjop
return smbjop
private boolean istablesorted parsecontext pctx  mapjoinoperator op
qbjointree jointree  string alias  int pos  throws semanticexception
map<string  operator<? extends serializable>> topops   this pgraphcontext
gettopops
map<tablescanoperator  table> toptotable   this pgraphcontext
gettoptotable
tablescanoperator tso    tablescanoperator  topops get alias
if  tso    null
return false
list<exprnodedesc> keys   op getconf   getkeys   get  byte  pos
// get all join columns from join keys stored in mapjoindesc
list<string> joincols   new arraylist<string>
list<exprnodedesc> joinkeys   new arraylist<exprnodedesc>
joinkeys addall keys
while  joinkeys size   > 0
exprnodedesc node   joinkeys remove 0
if  node instanceof exprnodecolumndesc
joincols addall node getcols
else if  node instanceof exprnodegenericfuncdesc
exprnodegenericfuncdesc udfnode     exprnodegenericfuncdesc  node
genericudf udf   udfnode getgenericudf
if   functionregistry isdeterministic udf
return false
joinkeys addall 0  udfnode getchildexprs
table tbl   toptotable get tso
if  tbl ispartitioned
prunedpartitionlist prunedparts   null
try
prunedparts   pgraphcontext getoptopartlist   get tso
if  prunedparts    null
prunedparts   partitionpruner prune tbl  pgraphcontext
getoptopartpruner   get tso   pgraphcontext getconf    alias
pgraphcontext getprunedpartitions
pgraphcontext getoptopartlist   put tso  prunedparts
catch  hiveexception e
log error org apache hadoop util stringutils stringifyexception e
throw new semanticexception e getmessage    e
boolean ret   true
for  partition p   prunedparts getconfirmedpartns
ret   ret    checksortcolsandjoincols p getsortcols    joincols
if   ret
return false
for  partition p   prunedparts getunknownpartns
ret   ret    checksortcolsandjoincols p getsortcols    joincols
if   ret
return false
else
return checksortcolsandjoincols tbl getsortcols    joincols
return true
private boolean checksortcolsandjoincols list<order> sortcols
list<string> joincols
// require all sort columns are asc, right now only support asc
list<string> sortcolnames   new arraylist<string>
for  order o   sortcols
if  o getorder      basesemanticanalyzer hive_column_order_asc
return false
sortcolnames add o getcol
return sortcolnames containsall joincols
sortcolnames size      joincols size