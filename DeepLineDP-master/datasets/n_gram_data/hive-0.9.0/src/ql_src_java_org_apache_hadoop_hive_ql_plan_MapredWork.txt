/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql plan
import java io bytearrayoutputstream
import java io serializable
import java util arraylist
import java util hashmap
import java util linkedhashmap
import java util list
import java util map
import org apache hadoop fs path
import org apache hadoop hive conf hiveconf
import org apache hadoop hive ql exec operator
import org apache hadoop hive ql exec utilities
import org apache hadoop hive ql parse opparsecontext
import org apache hadoop hive ql parse qbjointree
import org apache hadoop hive ql parse splitsample
/**
* mapredwork.
*
*/
@explain displayname
public class mapredwork implements serializable
private static final long serialversionuid   1l
private string command
// map side work
// use linkedhashmap to make sure the iteration order is
// deterministic, to ease testing
private linkedhashmap<string  arraylist<string>> pathtoaliases
private linkedhashmap<string  partitiondesc> pathtopartitioninfo
private linkedhashmap<string  operator<? extends serializable>> aliastowork
private linkedhashmap<string  partitiondesc> aliastopartninfo
private hashmap<string  splitsample> nametosplitsample
// map<->reduce interface
// schema of the map-reduce 'key' object - this is homogeneous
private tabledesc keydesc
// schema of the map-reduce 'val' object - this is heterogeneous
private list<tabledesc> tagtovaluedesc
private operator<?> reducer
private integer numreducetasks
private integer nummaptasks
private long maxsplitsize
private long minsplitsize
private long minsplitsizepernode
private long minsplitsizeperrack
private boolean needstagging
private boolean hadoopsupportssplittable
private mapredlocalwork maplocalwork
private string inputformat
private string indexintermediatefile
private boolean gatheringstats
private string tmphdfsfileuri
private linkedhashmap<operator<? extends serializable>  opparsecontext> opparsectxmap
private qbjointree jointree
private boolean mappercannotspanpartns
// used to indicate the input is sorted, and so a binarysearchrecordreader shoudl be used
private boolean inputformatsorted   false
public mapredwork
aliastopartninfo   new linkedhashmap<string  partitiondesc>
public mapredwork
final string command
final linkedhashmap<string  arraylist<string>> pathtoaliases
final linkedhashmap<string  partitiondesc> pathtopartitioninfo
final linkedhashmap<string  operator<? extends serializable>> aliastowork
final tabledesc keydesc  list<tabledesc> tagtovaluedesc
final operator<?> reducer  final integer numreducetasks
final mapredlocalwork maplocalwork
final boolean hadoopsupportssplittable
this command   command
this pathtoaliases   pathtoaliases
this pathtopartitioninfo   pathtopartitioninfo
this aliastowork   aliastowork
this keydesc   keydesc
this tagtovaluedesc   tagtovaluedesc
this reducer   reducer
this numreducetasks   numreducetasks
this maplocalwork   maplocalwork
aliastopartninfo   new linkedhashmap<string  partitiondesc>
this hadoopsupportssplittable   hadoopsupportssplittable
maxsplitsize   null
minsplitsize   null
minsplitsizepernode   null
minsplitsizeperrack   null
public string getcommand
return command
public void setcommand final string command
this command   command
@explain displayname      normalexplain   false
public linkedhashmap<string  arraylist<string>> getpathtoaliases
return pathtoaliases
public void setpathtoaliases
final linkedhashmap<string  arraylist<string>> pathtoaliases
this pathtoaliases   pathtoaliases
@explain displayname      normalexplain   false
public linkedhashmap<string  partitiondesc> getpathtopartitioninfo
return pathtopartitioninfo
public void setpathtopartitioninfo
final linkedhashmap<string  partitiondesc> pathtopartitioninfo
this pathtopartitioninfo   pathtopartitioninfo
/**
* @return the aliastopartninfo
*/
public linkedhashmap<string  partitiondesc> getaliastopartninfo
return aliastopartninfo
/**
* @param aliastopartninfo
*          the aliastopartninfo to set
*/
public void setaliastopartninfo
linkedhashmap<string  partitiondesc> aliastopartninfo
this aliastopartninfo   aliastopartninfo
@explain displayname
public linkedhashmap<string  operator<? extends serializable>> getaliastowork
return aliastowork
public void setaliastowork
final linkedhashmap<string  operator<? extends serializable>> aliastowork
this aliastowork   aliastowork
/**
* @return the mapredlocalwork
*/
@explain displayname
public mapredlocalwork getmaplocalwork
return maplocalwork
/**
* @param maplocalwork
*          the mapredlocalwork to set
*/
public void setmaplocalwork final mapredlocalwork maplocalwork
this maplocalwork   maplocalwork
public tabledesc getkeydesc
return keydesc
public void setkeydesc final tabledesc keydesc
this keydesc   keydesc
public list<tabledesc> gettagtovaluedesc
return tagtovaluedesc
public void settagtovaluedesc final list<tabledesc> tagtovaluedesc
this tagtovaluedesc   tagtovaluedesc
@explain displayname
public operator<?> getreducer
return reducer
@explain displayname
public hashmap<string  splitsample> getnametosplitsample
return nametosplitsample
public void setnametosplitsample hashmap<string  splitsample> nametosplitsample
this nametosplitsample   nametosplitsample
public void setreducer final operator<?> reducer
this reducer   reducer
public integer getnummaptasks
return nummaptasks
public void setnummaptasks integer nummaptasks
this nummaptasks   nummaptasks
/**
* if the number of reducers is -1, the runtime will automatically figure it
* out by input data size.
*
* the number of reducers will be a positive number only in case the target
* table is bucketed into n buckets (through create table). this feature is
* not supported yet, so the number of reducers will always be -1 for now.
*/
public integer getnumreducetasks
return numreducetasks
public void setnumreducetasks final integer numreducetasks
this numreducetasks   numreducetasks
@suppresswarnings
public void addmapwork string path  string alias  operator<?> work
partitiondesc pd
arraylist<string> curaliases   pathtoaliases get path
if  curaliases    null
assert  pathtopartitioninfo get path     null
curaliases   new arraylist<string>
pathtoaliases put path  curaliases
pathtopartitioninfo put path  pd
else
assert  pathtopartitioninfo get path     null
for  string onealias   curaliases
if  onealias equals alias
throw new runtimeexception     alias
path
curaliases add alias
if  aliastowork get alias     null
throw new runtimeexception     alias
aliastowork put alias  work
@suppresswarnings
public string isinvalid
if   getnumreducetasks   >  1      getreducer      null
return
if   getnumreducetasks      0      getreducer      null
return
return null
public string toxml
bytearrayoutputstream baos   new bytearrayoutputstream
utilities serializemapredwork this  baos
return  baos tostring
// non bean
/**
* for each map side operator - stores the alias the operator is working on
* behalf of in the operator runtime state. this is used by reducesink
* operator - but could be useful for debugging as well.
*/
private void setaliases
if aliastowork    null
return
for  string onealias   aliastowork keyset
aliastowork get onealias  setalias onealias
/**
* derive additional attributes to be rendered by explain.
*/
public void deriveexplainattributes
if  pathtopartitioninfo    null
for  map entry<string  partitiondesc> entry   pathtopartitioninfo
entryset
entry getvalue   derivebasefilename entry getkey
if  maplocalwork    null
maplocalwork deriveexplainattributes
public void initialize
setaliases
@explain displayname      normalexplain   false
public boolean getneedstagging
return needstagging
public void setneedstagging boolean needstagging
this needstagging   needstagging
public boolean gethadoopsupportssplittable
return hadoopsupportssplittable
public void sethadoopsupportssplittable boolean hadoopsupportssplittable
this hadoopsupportssplittable   hadoopsupportssplittable
public long getmaxsplitsize
return maxsplitsize
public void setmaxsplitsize long maxsplitsize
this maxsplitsize   maxsplitsize
public long getminsplitsize
return minsplitsize
public void setminsplitsize long minsplitsize
this minsplitsize   minsplitsize
public long getminsplitsizepernode
return minsplitsizepernode
public void setminsplitsizepernode long minsplitsizepernode
this minsplitsizepernode   minsplitsizepernode
public long getminsplitsizeperrack
return minsplitsizeperrack
public void setminsplitsizeperrack long minsplitsizeperrack
this minsplitsizeperrack   minsplitsizeperrack
public string getinputformat
return inputformat
public void setinputformat string inputformat
this inputformat   inputformat
public string getindexintermediatefile
return indexintermediatefile
public void addindexintermediatefile string filename
if  this indexintermediatefile    null
this indexintermediatefile   filename
else
this indexintermediatefile        filename
public void setgatheringstats boolean gatherstats
this gatheringstats   gatherstats
public boolean isgatheringstats
return this gatheringstats
public void setmappercannotspanpartns boolean mappercannotspanpartns
this mappercannotspanpartns   mappercannotspanpartns
public boolean ismappercannotspanpartns
return this mappercannotspanpartns
public string gettmphdfsfileuri
return tmphdfsfileuri
public void settmphdfsfileuri string tmphdfsfileuri
this tmphdfsfileuri   tmphdfsfileuri
public qbjointree getjointree
return jointree
public void setjointree qbjointree jointree
this jointree   jointree
public linkedhashmap<operator<? extends serializable>  opparsecontext> getopparsectxmap
return opparsectxmap
public void setopparsectxmap
linkedhashmap<operator<? extends serializable>  opparsecontext> opparsectxmap
this opparsectxmap   opparsectxmap
public boolean isinputformatsorted
return inputformatsorted
public void setinputformatsorted boolean inputformatsorted
this inputformatsorted   inputformatsorted
public void resolvedynamicpartitionmerge hiveconf conf  path path
tabledesc tbldesc  arraylist<string> aliases  partitiondesc partdesc
pathtoaliases put path tostring    aliases
pathtopartitioninfo put path tostring    partdesc
public list<operator<?>> getalloperators
arraylist<operator<?>> oplist   new arraylist<operator<?>>
arraylist<operator<?>> returnlist   new arraylist<operator<?>>
if  getreducer      null
oplist add getreducer
map<string  arraylist<string>> pa   getpathtoaliases
if  pa    null
for  list<string> ls   pa values
for  string a   ls
operator<?> op   getaliastowork   get a
if  op    null
oplist add op
//recursively add all children
while   oplist isempty
operator<?> op   oplist remove 0
if  op getchildoperators      null
oplist addall op getchildoperators
returnlist add op
return returnlist