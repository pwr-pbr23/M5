/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql exec
import java io serializable
import org apache hadoop conf configuration
import org apache hadoop hive conf hiveconf
import org apache hadoop hive ql io iocontext
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql plan filterdesc
import org apache hadoop hive ql plan api operatortype
import org apache hadoop hive serde2 objectinspector objectinspector
import org apache hadoop hive serde2 objectinspector primitiveobjectinspector
import org apache hadoop io longwritable
/**
* filter operator implementation.
**/
public class filteroperator extends operator<filterdesc> implements
serializable
private static final long serialversionuid   1l
/**
* counter.
*
*/
public static enum counter
filtered  passed
private final transient longwritable filtered_count  passed_count
private transient exprnodeevaluator conditionevaluator
private transient primitiveobjectinspector conditioninspector
private transient int consecutivefails
private transient int consecutivesearches
private transient iocontext iocontext
transient int heartbeatinterval
public filteroperator
super
filtered_count   new longwritable
passed_count   new longwritable
consecutivefails   0
consecutivesearches   0
@override
protected void initializeop configuration hconf  throws hiveexception
try
heartbeatinterval   hiveconf getintvar hconf
hiveconf confvars hivesendheartbeat
conditionevaluator   exprnodeevaluatorfactory get conf getpredicate
statsmap put counter filtered  filtered_count
statsmap put counter passed  passed_count
conditioninspector   null
iocontext   iocontext get
catch  throwable e
throw new hiveexception e
initializechildren hconf
@override
public void processop object row  int tag  throws hiveexception
objectinspector rowinspector   inputobjinspectors
if  conditioninspector    null
conditioninspector    primitiveobjectinspector  conditionevaluator
initialize rowinspector
// if the input is sorted, and we are executing a search based on the arguments to this filter,
// set the comparison in the iocontext and the type of the udf
if  conf issortedfilter      iocontext usesorted
if    conditionevaluator instanceof exprnodegenericfuncevaluator
log error
iocontext setusesorted false
return
else
iocontext setcomparison   exprnodegenericfuncevaluator conditionevaluator  compare row
if  iocontext getgenericudfclassname      null
iocontext setgenericudfclassname
exprnodegenericfuncevaluator conditionevaluator  genericudf getclass   getname
// if we are currently searching the data for a place to begin, do not return data yet
if  iocontext isbinarysearching
consecutivesearches
// in case we're searching through an especially large set of data, send a heartbeat in
// order to avoid timeout
if    consecutivesearches % heartbeatinterval     0      reporter    null
reporter progress
return
object condition   conditionevaluator evaluate row
// if we are currently performing a binary search on the input, don't forward the results
// currently this value is set when a query is optimized using a compact index.  the map reduce
// job responsible for scanning and filtering the index sets this value.  it remains set
// throughout the binary search executed by the hivebinarysearchrecordresder until a starting
// point for a linear scan has been identified, at which point this value is unset.
if  iocontext isbinarysearching
return
boolean ret    boolean  conditioninspector
getprimitivejavaobject condition
if  boolean true equals ret
forward row  rowinspector
passed_count set passed_count get     1
consecutivefails   0
else
filtered_count set filtered_count get     1
consecutivefails
// in case of a lot of consecutive failures, send a heartbeat in order to
// avoid timeout
if    consecutivefails % heartbeatinterval     0      reporter    null
reporter progress
/**
* @return the name of the operator
*/
@override
public string getname
return
@override
public operatortype gettype
return operatortype filter