/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql exec
import java io ioexception
import java lang management managementfactory
import java lang management memorymxbean
import java net urlclassloader
import java util arraylist
import java util arrays
import java util iterator
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop hive ql exec execmapper reportstats
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql plan mapredwork
import org apache hadoop hive ql plan tabledesc
import org apache hadoop hive serde2 deserializer
import org apache hadoop hive serde2 serde
import org apache hadoop hive serde2 serdeexception
import org apache hadoop hive serde2 serdeutils
import org apache hadoop hive serde2 io bytewritable
import org apache hadoop hive serde2 objectinspector objectinspector
import org apache hadoop hive serde2 objectinspector objectinspectorfactory
import org apache hadoop hive serde2 objectinspector primitive primitiveobjectinspectorfactory
import org apache hadoop io byteswritable
import org apache hadoop mapred jobconf
import org apache hadoop mapred mapreducebase
import org apache hadoop mapred outputcollector
import org apache hadoop mapred reducer
import org apache hadoop mapred reporter
import org apache hadoop util reflectionutils
import org apache hadoop util stringutils
/**
* execreducer.
*
*/
public class execreducer extends mapreducebase implements reducer
private jobconf jc
private outputcollector<?  ?> oc
private operator<?> reducer
private reporter rp
private boolean abort   false
private boolean istagged   false
private long cntr   0
private long nextcntr   1
private static string fieldnames
public static final log l4j   logfactory getlog
private boolean isloginfoenabled   false
// used to log memory usage periodically
private memorymxbean memorymxbean
// todo: move to dynamicserde when it's ready
private deserializer inputkeydeserializer
// input value serde needs to be an array to support different serde
// for different tags
private final serde inputvaluedeserializer   new serde
static
arraylist<string> fieldnamearray   new arraylist<string>
for  utilities reducefield r   utilities reducefield values
fieldnamearray add r tostring
fieldnames   fieldnamearray toarray new string
tabledesc keytabledesc
tabledesc valuetabledesc
objectinspector rowobjectinspector
@override
public void configure jobconf job
rowobjectinspector   new objectinspector
objectinspector valueobjectinspector   new objectinspector
objectinspector keyobjectinspector
// allocate the bean at the beginning -
memorymxbean   managementfactory getmemorymxbean
l4j info     memorymxbean getheapmemoryusage   getmax
isloginfoenabled   l4j isinfoenabled
try
l4j info
arrays aslist   urlclassloader  job getclassloader    geturls
l4j info
arrays aslist   urlclassloader  thread currentthread
getcontextclassloader    geturls
catch  exception e
l4j info     e getmessage
jc   job
mapredwork gwork   utilities getmapredwork job
reducer   gwork getreducer
reducer setparentoperators null      clear out any parents as reducer is the
// root
istagged   gwork getneedstagging
try
keytabledesc   gwork getkeydesc
inputkeydeserializer    serde  reflectionutils newinstance keytabledesc
getdeserializerclass    null
inputkeydeserializer initialize null  keytabledesc getproperties
keyobjectinspector   inputkeydeserializer getobjectinspector
valuetabledesc   new tabledesc
for  int tag   0  tag < gwork gettagtovaluedesc   size    tag
// we should initialize the serde with the typeinfo when available.
valuetabledesc   gwork gettagtovaluedesc   get tag
inputvaluedeserializer    serde  reflectionutils newinstance
valuetabledesc getdeserializerclass    null
inputvaluedeserializer initialize null  valuetabledesc
getproperties
valueobjectinspector   inputvaluedeserializer
getobjectinspector
arraylist<objectinspector> ois   new arraylist<objectinspector>
ois add keyobjectinspector
ois add valueobjectinspector
ois add primitiveobjectinspectorfactory writablebyteobjectinspector
rowobjectinspector   objectinspectorfactory
getstandardstructobjectinspector arrays aslist fieldnames   ois
catch  exception e
throw new runtimeexception e
// initialize reduce operator tree
try
l4j info reducer dump 0
reducer initialize jc  rowobjectinspector
catch  throwable e
abort   true
if  e instanceof outofmemoryerror
// don't create a new object if we are already out of memory
throw  outofmemoryerror  e
else
throw new runtimeexception    e
private object keyobject
private final object valueobject   new object
private byteswritable groupkey
arraylist<object> row   new arraylist<object> 3
bytewritable tag   new bytewritable
public void reduce object key  iterator values  outputcollector output
reporter reporter  throws ioexception
if  oc    null
// propagete reporter and output collector to all operators
oc   output
rp   reporter
reducer setoutputcollector oc
reducer setreporter rp
try
byteswritable keywritable    byteswritable  key
tag set  byte  0
if  istagged
// remove the tag
int size   keywritable getsize     1
tag set keywritable get
keywritable setsize size
if   keywritable equals groupkey
// if a operator wants to do some work at the beginning of a group
if  groupkey    null       the first group
groupkey   new byteswritable
else
// if a operator wants to do some work at the end of a group
l4j trace
reducer endgroup
try
keyobject   inputkeydeserializer deserialize keywritable
catch  exception e
throw new hiveexception
utilities formatbinarystring keywritable get    0
keywritable getsize
keytabledesc getproperties    e
groupkey set keywritable get    0  keywritable getsize
l4j trace
reducer startgroup
reducer setgroupkeyobject keyobject
// system.err.print(keyobject.tostring());
while  values hasnext
byteswritable valuewritable    byteswritable  values next
// system.err.print(who.getho().tostring());
try
valueobject   inputvaluedeserializer
deserialize valuewritable
catch  serdeexception e
throw new hiveexception
tag get
utilities formatbinarystring valuewritable get    0
valuewritable getsize
valuetabledesc getproperties    e
row clear
row add keyobject
row add valueobject
// the tag is not used any more, we should remove it.
row add tag
if  isloginfoenabled
cntr
if  cntr    nextcntr
long used_memory   memorymxbean getheapmemoryusage   getused
l4j info     cntr
used_memory
nextcntr   getnextcntr cntr
try
reducer process row  tag get
catch  exception e
string rowstring   null
try
rowstring   serdeutils getjsonstring row  rowobjectinspector
catch  exception e2
rowstring
stringutils stringifyexception e2
throw new hiveexception
tag get         rowstring  e
catch  throwable e
abort   true
if  e instanceof outofmemoryerror
// don't create a new object if we are already out of memory
throw  outofmemoryerror  e
else
l4j fatal stringutils stringifyexception e
throw new runtimeexception e
private long getnextcntr long cntr
// a very simple counter to keep track of number of rows processed by the
// reducer. it dumps
// every 1 million times, and quickly before that
if  cntr >  1000000
return cntr   1000000
return 10   cntr
@override
public void close
// no row was processed
if  oc    null
l4j trace
try
if  groupkey    null
// if a operator wants to do some work at the end of a group
l4j trace
reducer endgroup
if  isloginfoenabled
l4j info     cntr
memorymxbean getheapmemoryusage   getused
reducer close abort
reportstats rps   new reportstats rp
reducer preordermap rps
catch  exception e
if   abort
// signal new failure to map-reduce
l4j error
throw new runtimeexception
e getmessage    e