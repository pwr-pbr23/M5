/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql index
import java io ioexception
import java util arraylist
import java util hashmap
import java util list
import java util map
import java util sortedset
import java util treeset
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop fs fsdatainputstream
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop hive conf hiveconf
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive serde2 columnar bytesrefwritable
import org apache hadoop hive serde2 lazy lazysimpleserde
import org apache hadoop io text
import org apache hadoop mapred filesplit
import org apache hadoop mapred jobconf
import org apache hadoop mapred linerecordreader linereader
/**
* hiveindexresult parses the input stream from an index query
* to generate a list of file splits to query.
*/
public class hiveindexresult
public static final log l4j
logfactory getlog hiveindexresult class getsimplename
// indexbucket
static class ibucket
private string name   null
private final sortedset<long> offsets   new treeset<long>
public ibucket string n
name   n
public void add long offset
offsets add offset
public string getname
return name
public sortedset<long> getoffsets
return offsets
@override
public boolean equals object obj
if  obj getclass      this getclass
return false
return    ibucket  obj  name comparetoignorecase this name     0
jobconf job   null
bytesrefwritable bytesref   new bytesrefwritable
boolean ignorehdfsloc   false
public hiveindexresult list<string> indexfiles  jobconf conf  throws ioexception
hiveexception
job   conf
bytesref   new bytesrefwritable
bytesref   new bytesrefwritable
ignorehdfsloc   hiveconf getboolvar conf  hiveconf confvars hive_index_ignore_hdfs_loc
if  indexfiles    null    indexfiles size   > 0
list<path> paths   new arraylist<path>
for  string indexfile   indexfiles
path indexfilepath   new path indexfile
filesystem fs   indexfilepath getfilesystem conf
filestatus indexstat   fs getfilestatus indexfilepath
if  indexstat isdir
filestatus fss   fs liststatus indexfilepath
for  filestatus f   fss
paths add f getpath
else
paths add indexfilepath
long maxentriestoload   hiveconf getlongvar conf  hiveconf confvars hive_index_compact_query_max_entries
if  maxentriestoload < 0
maxentriestoload long max_value
long linecounter   0
for  path indexfinalpath   paths
filesystem fs   indexfinalpath getfilesystem conf
fsdatainputstream ifile   fs open indexfinalpath
linereader lr   new linereader ifile  conf
try
text line   new text
while  lr readline line  > 0
if    linecounter > maxentriestoload
throw new hiveexception     maxentriestoload
hiveconf confvars hive_index_compact_query_max_entries varname
add line
finally
// this will close the input stream
lr close
map<string  ibucket> buckets   new hashmap<string  ibucket>
private void add text line  throws hiveexception
string l   line tostring
byte bytes   l getbytes
int firstend   0
int i   0
for  int index   0  index < bytes length  index
if  bytes    lazysimpleserde defaultseparators
i
firstend   index
if  i > 1
throw new hiveexception
line tostring
string bucketfilename   new string bytes  0  firstend
if  ignorehdfsloc
path tmppath   new path bucketfilename
bucketfilename   tmppath touri   getpath
ibucket bucket   buckets get bucketfilename
if  bucket    null
bucket   new ibucket bucketfilename
buckets put bucketfilename  bucket
int currentstart   firstend   1
int currentend   firstend   1
for    currentend < bytes length  currentend
if  bytes    lazysimpleserde defaultseparators
string one_offset   new string bytes  currentstart  currentend
currentstart
long offset   long parselong one_offset
bucket getoffsets   add offset
currentstart   currentend   1
string one_offset   new string bytes  currentstart  currentend
currentstart
bucket getoffsets   add long parselong one_offset
public boolean contains filesplit split  throws hiveexception
if  buckets    null
return false
string bucketname   split getpath   tostring
ibucket bucket   buckets get bucketname
if  bucket    null
bucketname   split getpath   touri   getpath
bucket   buckets get bucketname
if  bucket    null
return false
for  long offset   bucket getoffsets
if   offset >  split getstart
offset <  split getstart     split getlength
return true
return false