/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql index compact
import java io serializable
import java util arraylist
import java util collection
import java util hashset
import java util linkedhashmap
import java util list
import java util set
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop conf configuration
import org apache hadoop hive conf hiveconf
import org apache hadoop hive conf hiveconf confvars
import org apache hadoop hive metastore api fieldschema
import org apache hadoop hive metastore api index
import org apache hadoop hive metastore api storagedescriptor
import org apache hadoop hive metastore api table
import org apache hadoop hive ql driver
import org apache hadoop hive ql exec filteroperator
import org apache hadoop hive ql exec operator
import org apache hadoop hive ql exec task
import org apache hadoop hive ql hooks readentity
import org apache hadoop hive ql hooks writeentity
import org apache hadoop hive ql index hiveindexquerycontext
import org apache hadoop hive ql index indexpredicateanalyzer
import org apache hadoop hive ql index indexsearchcondition
import org apache hadoop hive ql index tablebasedindexhandler
import org apache hadoop hive ql io hiveinputformat
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata hivestoragepredicatehandler decomposedpredicate
import org apache hadoop hive ql metadata hiveutils
import org apache hadoop hive ql metadata partition
import org apache hadoop hive ql metadata virtualcolumn
import org apache hadoop hive ql optimizer indexutils
import org apache hadoop hive ql parse parsecontext
import org apache hadoop hive ql plan exprnodecolumndesc
import org apache hadoop hive ql plan exprnodedesc
import org apache hadoop hive ql plan exprnodegenericfuncdesc
import org apache hadoop hive ql plan mapredwork
import org apache hadoop hive ql plan partitiondesc
import org apache hadoop hive ql udf generic genericudfopequal
import org apache hadoop hive ql udf generic genericudfopequalorgreaterthan
import org apache hadoop hive ql udf generic genericudfopequalorlessthan
import org apache hadoop hive ql udf generic genericudfopgreaterthan
import org apache hadoop hive ql udf generic genericudfoplessthan
import org apache hadoop hive ql udf generic genericudfopnotnull
import org apache hadoop hive ql udf generic genericudfopnull
public class compactindexhandler extends tablebasedindexhandler
private configuration configuration
// the names of the partition columns
private set<string> partitioncols
// whether or not the conditions have been met to use the fact the index is sorted
private boolean usesorted
private static final log log   logfactory getlog compactindexhandler class getname
@override
public void analyzeindexdefinition table basetable  index index
table indextable  throws hiveexception
storagedescriptor storagedesc   index getsd
if  this usesindextable      indextable    null
storagedescriptor indextablesd   storagedesc deepcopy
list<fieldschema> indextblcols   indextablesd getcols
fieldschema bucketfilename   new fieldschema
indextblcols add bucketfilename
fieldschema offsets   new fieldschema
indextblcols add offsets
indextable setsd indextablesd
@override
protected task<?> getindexbuildermapredtask set<readentity> inputs  set<writeentity> outputs
list<fieldschema> indexfield  boolean partitioned
partitiondesc indextblpartdesc  string indextablename
partitiondesc basetablepartdesc  string basetablename  string dbname  throws hiveexception
string indexcols   hiveutils getunparsedcolumnnamesfromfieldschema indexfield
//form a new insert overwrite query.
stringbuilder command  new stringbuilder
linkedhashmap<string  string> partspec   indextblpartdesc getpartspec
command append     hiveutils unparseidentifier indextablename
if  partitioned    indextblpartdesc    null
command append
list<string> ret   getpartkvpairstringarray partspec
for  int i   0  i < ret size    i
string partkv   ret get i
command append partkv
if  i < ret size     1
command append
command append
command append
command append indexcols
command append
command append virtualcolumn filename getname
command append
command append
command append virtualcolumn blockoffset getname
command append
command append     hiveutils unparseidentifier basetablename
linkedhashmap<string  string> basepartspec   basetablepartdesc getpartspec
if basepartspec    null
command append
list<string> pkv   getpartkvpairstringarray basepartspec
for  int i   0  i < pkv size    i
string partkv   pkv get i
command append partkv
if  i < pkv size     1
command append
command append
command append indexcols       virtualcolumn filename getname
hiveconf builderconf   new hiveconf getconf    compactindexhandler class
builderconf setboolvar hiveconf confvars hivemergemapfiles  false
builderconf setboolvar hiveconf confvars hivemergemapredfiles  false
task<?> roottask   indexutils createroottask builderconf  inputs  outputs
command  partspec  indextablename  dbname
return roottask
@override
public void generateindexquery list<index> indexes  exprnodedesc predicate
parsecontext pctx  hiveindexquerycontext querycontext
index index   indexes get 0
decomposedpredicate decomposedpredicate   decomposepredicate predicate  index
querycontext getquerypartitions
if  decomposedpredicate    null
querycontext setquerytasks null
return     abort if we couldn't pull out anything from the predicate
// pass residual predicate back out for further processing
querycontext setresidualpredicate decomposedpredicate residualpredicate
// setup tablescanoperator to change input format for original query
querycontext setindexinputformat hivecompactindexinputformat class getname
// build reentrant ql for index query
stringbuilder qlcommand   new stringbuilder
string tmpfile   pctx getcontext   getmrtmpfileuri
querycontext setindexintermediatefile tmpfile
qlcommand append                       ql includes " around file name
qlcommand append
qlcommand append hiveutils unparseidentifier index getindextablename
qlcommand append
string predicatestring   decomposedpredicate pushedpredicate getexprstring
qlcommand append predicatestring
// generate tasks from index query string
log info     qlcommand tostring
hiveconf queryconf   new hiveconf pctx getconf    compactindexhandler class
hiveconf setboolvar queryconf  hiveconf confvars compressresult  false
driver driver   new driver queryconf
driver compile qlcommand tostring    false
if  pctx getconf   getboolvar confvars hive_index_compact_binary_search     usesorted
// for now, only works if the predicate is a single condition
mapredwork work   null
string originalinputformat   null
for  task task   driver getplan   getroottasks
// the index query should have one and only one map reduce task in the root tasks
// otherwise something is wrong, log the problem and continue using the default format
if  task getwork   instanceof mapredwork
if  work    null
log error
work setinputformat null
work setinputformatsorted false
break
work    mapredwork task getwork
string inputformat   work getinputformat
originalinputformat   inputformat
if  inputformat    null
inputformat   hiveconf getvar pctx getconf    hiveconf confvars hiveinputformat
// we can only perform a binary search with hiveinputformat and combinehiveinputformat
// and bucketizedhiveinputformat
try
if   hiveinputformat class isassignablefrom class forname inputformat
work   null
break
catch  classnotfoundexception e
log error     inputformat
work   null
break
work setinputformatsorted true
if  work    null
// find the filter operator and expr node which act on the index column and mark them
if   findindexcolumnfilter work getaliastowork   values
log error
work setinputformat originalinputformat
work setinputformatsorted false
querycontext addadditionalsemanticinputs driver getplan   getinputs
querycontext setquerytasks driver getplan   getroottasks
return
/**
* does a depth first search on the operator tree looking for a filter operator whose predicate
* has one child which is a column which is not in the partition
* @param operators
* @return whether or not it has found its target
*/
private boolean findindexcolumnfilter collection<operator<? extends serializable>> operators
for  operator<? extends serializable> op   operators
if  op instanceof filteroperator      filteroperator op  getconf   getpredicate   getchildren      null
// is this the target
if  findindexcolumnexprnodedesc   filteroperator op  getconf   getpredicate
filteroperator op  getconf   setsortedfilter true
return true
// if the target has been found, no need to continue
if  findindexcolumnfilter op getchildoperators
return true
return false
private boolean findindexcolumnexprnodedesc exprnodedesc expression
if  expression getchildren      null
return false
if  expression getchildren   size      2
exprnodecolumndesc columndesc   null
if  expression getchildren   get 0  instanceof exprnodecolumndesc
columndesc    exprnodecolumndesc expression getchildren   get 0
else if  expression getchildren   get 1  instanceof exprnodecolumndesc
columndesc    exprnodecolumndesc expression getchildren   get 1
// is this the target
if  columndesc    null     partitioncols contains columndesc getcolumn
assert expression instanceof exprnodegenericfuncdesc
exprnodegenericfuncdesc expression  setsortedexpr true
return true
for  exprnodedesc child   expression getchildren
// if the target has been found, no need to continue
if  findindexcolumnexprnodedesc child
return true
return false
/**
* split the predicate into the piece we can deal with (pushed), and the one we can't (residual)
* @param predicate
* @param index
* @return
*/
private decomposedpredicate decomposepredicate exprnodedesc predicate  index index
set<partition> querypartitions
indexpredicateanalyzer analyzer   getindexpredicateanalyzer index  querypartitions
list<indexsearchcondition> searchconditions   new arraylist<indexsearchcondition>
// split predicate into pushed (what we can handle), and residual (what we can't handle)
exprnodedesc residualpredicate   analyzer analyzepredicate predicate  searchconditions
if  searchconditions size      0
return null
int numindexcols   0
for  indexsearchcondition searchcondition   searchconditions
if   partitioncols contains searchcondition getcolumndesc   getcolumn
numindexcols
// for now, only works if the predicate has a single condition on an index column
if  numindexcols    1
usesorted   true
else
usesorted   false
decomposedpredicate decomposedpredicate   new decomposedpredicate
decomposedpredicate pushedpredicate   analyzer translatesearchconditions searchconditions
decomposedpredicate residualpredicate   residualpredicate
return decomposedpredicate
/**
* instantiate a new predicate analyzer suitable for determining
* whether we can use an index, based on rules for indexes in
* where clauses that we support
*
* @return preconfigured predicate analyzer for where queries
*/
private indexpredicateanalyzer getindexpredicateanalyzer index index  set<partition> querypartitions
indexpredicateanalyzer analyzer   new indexpredicateanalyzer
analyzer addcomparisonop genericudfopequal class getname
analyzer addcomparisonop genericudfoplessthan class getname
analyzer addcomparisonop genericudfopequalorlessthan class getname
analyzer addcomparisonop genericudfopgreaterthan class getname
analyzer addcomparisonop genericudfopequalorgreaterthan class getname
// only return results for columns in this index
list<fieldschema> columnschemas   index getsd   getcols
for  fieldschema column   columnschemas
analyzer allowcolumnname column getname
// partitioned columns are treated as if they have indexes so that the partitions
// are used during the index query generation
partitioncols   new hashset<string>
for  partition part   querypartitions
if  part getspec   isempty
continue     empty partitions are from whole tables  so we don't want to add them in
for  string column   part getspec   keyset
analyzer allowcolumnname column
partitioncols add column
return analyzer
@override
public boolean checkquerysize long querysize  hiveconf hiveconf
long minsize   hiveconf getlongvar hiveconf confvars hiveoptindexfilter_compact_minsize
long maxsize   hiveconf getlongvar hiveconf confvars hiveoptindexfilter_compact_maxsize
if  maxsize < 0
maxsize   long max_value
return  querysize > minsize   querysize < maxsize
@override
public boolean usesindextable
return true