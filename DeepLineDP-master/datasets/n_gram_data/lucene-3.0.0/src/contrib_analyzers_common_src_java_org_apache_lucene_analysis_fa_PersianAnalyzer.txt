package org apache lucene analysis fa
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io file
import java io ioexception
import java io inputstream
import java io inputstreamreader
import java io reader
import java util collections
import java util hashtable
import java util set
import org apache lucene analysis analyzer
import org apache lucene analysis chararrayset
import org apache lucene analysis lowercasefilter
import org apache lucene analysis stopfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenizer
import org apache lucene analysis wordlistloader
import org apache lucene analysis ar arabiclettertokenizer
import org apache lucene analysis ar arabicnormalizationfilter
import org apache lucene util version
/**
* {@link analyzer} for persian.
* <p>
* this analyzer uses {@link arabiclettertokenizer} which implies tokenizing around
* zero-width non-joiner in addition to whitespace. some persian-specific variant forms (such as farsi
* yeh and keheh) are standardized. "stemming" is accomplished via stopwords.
* </p>
*/
public final class persiananalyzer extends analyzer
/**
* file containing default persian stopwords.
*
* default stopword list is from
* http://members.unine.ch/jacques.savoy/clef/index.html the stopword list is
* bsd-licensed.
*
*/
public final static string default_stopword_file
/**
* contains the stopwords used with the stopfilter.
*/
private final set<?> stoptable
/**
* the comment character in the stopwords file. all lines prefixed with this
* will be ignored
*/
public static final string stopwords_comment
/**
* returns an unmodifiable instance of the default stop-words set.
* @return an unmodifiable instance of the default stop-words set.
*/
public static set<?> getdefaultstopset
return defaultsetholder default_stop_set
/**
* atomically loads the default_stop_set in a lazy fashion once the outer class
* accesses the static final set the first time.;
*/
private static class defaultsetholder
static final set<?> default_stop_set
static
try
default_stop_set   loaddefaultstopwordset
catch  ioexception ex
// default set should always be present as it is part of the
// distribution (jar)
throw new runtimeexception
static set<string> loaddefaultstopwordset   throws ioexception
inputstream stream   persiananalyzer class
getresourceasstream default_stopword_file
try
inputstreamreader reader   new inputstreamreader stream
// make sure it is unmodifiable as we expose it in the outer class
return collections unmodifiableset wordlistloader getwordset reader
stopwords_comment
finally
stream close
private final version matchversion
/**
* builds an analyzer with the default stop words:
* {@link #default_stopword_file}.
*/
public persiananalyzer version matchversion
this matchversion  defaultsetholder default_stop_set
/**
* builds an analyzer with the given stop words
*
* @param matchversion
*          lucene compatibility version
* @param stopwords
*          a stopword set
*/
public persiananalyzer version matchversion  set<?> stopwords
stoptable   chararrayset unmodifiableset chararrayset copy stopwords
this matchversion   matchversion
/**
* builds an analyzer with the given stop words.
* @deprecated use {@link #persiananalyzer(version, set)} instead
*/
public persiananalyzer version matchversion  string    stopwords
this matchversion  stopfilter makestopset stopwords
/**
* builds an analyzer with the given stop words.
* @deprecated use {@link #persiananalyzer(version, set)} instead
*/
public persiananalyzer version matchversion  hashtable<?  ?> stopwords
this matchversion  stopwords keyset
/**
* builds an analyzer with the given stop words. lines can be commented out
* using {@link #stopwords_comment}
* @deprecated use {@link #persiananalyzer(version, set)} instead
*/
public persiananalyzer version matchversion  file stopwords  throws ioexception
this matchversion  wordlistloader getwordset stopwords  stopwords_comment
/**
* creates a {@link tokenstream} which tokenizes all the text in the provided
* {@link reader}.
*
* @return a {@link tokenstream} built from a {@link arabiclettertokenizer}
*         filtered with {@link lowercasefilter},
*         {@link arabicnormalizationfilter},
*         {@link persiannormalizationfilter} and persian stop words
*/
@override
public tokenstream tokenstream string fieldname  reader reader
tokenstream result   new arabiclettertokenizer reader
result   new lowercasefilter result
result   new arabicnormalizationfilter result
/* additional persian-specific normalization */
result   new persiannormalizationfilter result
/*
* the order here is important: the stopword list is normalized with the
* above!
*/
result   new stopfilter stopfilter getenablepositionincrementsversiondefault matchversion
result  stoptable
return result
private class savedstreams
tokenizer source
tokenstream result
/**
* returns a (possibly reused) {@link tokenstream} which tokenizes all the text
* in the provided {@link reader}.
*
* @return a {@link tokenstream} built from a {@link arabiclettertokenizer}
*         filtered with {@link lowercasefilter},
*         {@link arabicnormalizationfilter},
*         {@link persiannormalizationfilter} and persian stop words
*/
@override
public tokenstream reusabletokenstream string fieldname  reader reader
throws ioexception
savedstreams streams    savedstreams  getprevioustokenstream
if  streams    null
streams   new savedstreams
streams source   new arabiclettertokenizer reader
streams result   new lowercasefilter streams source
streams result   new arabicnormalizationfilter streams result
/* additional persian-specific normalization */
streams result   new persiannormalizationfilter streams result
/*
* the order here is important: the stopword list is normalized with the
* above!
*/
streams result   new stopfilter stopfilter getenablepositionincrementsversiondefault matchversion
streams result  stoptable
setprevioustokenstream streams
else
streams source reset reader
return streams result