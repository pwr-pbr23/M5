package org apache lucene analysis standard
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import org apache lucene analysis
import org apache lucene util version
import java io file
import java io ioexception
import java io reader
import java util set
/**
* filters {@link standardtokenizer} with {@link standardfilter}, {@link
* lowercasefilter} and {@link stopfilter}, using a list of
* english stop words.
*
* <a name="version"/>
* <p>you must specify the required {@link version}
* compatibility when creating standardanalyzer:
* <ul>
*   <li> as of 2.9, stopfilter preserves position
*        increments
*   <li> as of 2.4, tokens incorrectly identified as acronyms
*        are corrected (see <a href="https://issues.apache.org/jira/browse/lucene-1068">lucene-1608</a>
* </ul>
*/
public class standardanalyzer extends analyzer
private set<?> stopset
/**
* specifies whether deprecated acronyms should be replaced with host type.
* see {@linkplain https://issues.apache.org/jira/browse/lucene-1068}
*/
private final boolean replaceinvalidacronym enablestoppositionincrements
/** an unmodifiable set containing some common english words that are usually not
useful for searching. */
public static final set<?> stop_words_set   stopanalyzer english_stop_words_set
private final version matchversion
/** builds an analyzer with the default stop words ({@link
* #stop_words_set}).
* @param matchversion lucene version to match see {@link
* <a href="#version">above</a>}
*/
public standardanalyzer version matchversion
this matchversion  stop_words_set
/** builds an analyzer with the given stop words.
* @param matchversion lucene version to match see {@link
* <a href="#version">above</a>}
* @param stopwords stop words */
public standardanalyzer version matchversion  set<?> stopwords
stopset   stopwords
setoverridestokenstreammethod standardanalyzer class
enablestoppositionincrements   stopfilter getenablepositionincrementsversiondefault matchversion
replaceinvalidacronym   matchversion onorafter version lucene_24
this matchversion   matchversion
/** builds an analyzer with the stop words from the given file.
* @see wordlistloader#getwordset(file)
* @param matchversion lucene version to match see {@link
* <a href="#version">above</a>}
* @param stopwords file to read stop words from */
public standardanalyzer version matchversion  file stopwords  throws ioexception
this matchversion  wordlistloader getwordset stopwords
/** builds an analyzer with the stop words from the given reader.
* @see wordlistloader#getwordset(reader)
* @param matchversion lucene version to match see {@link
* <a href="#version">above</a>}
* @param stopwords reader to read stop words from */
public standardanalyzer version matchversion  reader stopwords  throws ioexception
this matchversion  wordlistloader getwordset stopwords
/** constructs a {@link standardtokenizer} filtered by a {@link
standardfilter}, a {@link lowercasefilter} and a {@link stopfilter}. */
@override
public tokenstream tokenstream string fieldname  reader reader
standardtokenizer tokenstream   new standardtokenizer matchversion  reader
tokenstream setmaxtokenlength maxtokenlength
tokenstream result   new standardfilter tokenstream
result   new lowercasefilter result
result   new stopfilter enablestoppositionincrements  result  stopset
return result
private static final class savedstreams
standardtokenizer tokenstream
tokenstream filteredtokenstream
/** default maximum allowed token length */
public static final int default_max_token_length   255
private int maxtokenlength   default_max_token_length
/**
* set maximum allowed token length.  if a token is seen
* that exceeds this length then it is discarded.  this
* setting only takes effect the next time tokenstream or
* reusabletokenstream is called.
*/
public void setmaxtokenlength int length
maxtokenlength   length
/**
* @see #setmaxtokenlength
*/
public int getmaxtokenlength
return maxtokenlength
@override
public tokenstream reusabletokenstream string fieldname  reader reader  throws ioexception
if  overridestokenstreammethod
// lucene-1678: force fallback to tokenstream() if we
// have been subclassed and that subclass overrides
// tokenstream but not reusabletokenstream
return tokenstream fieldname  reader
savedstreams streams    savedstreams  getprevioustokenstream
if  streams    null
streams   new savedstreams
setprevioustokenstream streams
streams tokenstream   new standardtokenizer matchversion  reader
streams filteredtokenstream   new standardfilter streams tokenstream
streams filteredtokenstream   new lowercasefilter streams filteredtokenstream
streams filteredtokenstream   new stopfilter enablestoppositionincrements
streams filteredtokenstream  stopset
else
streams tokenstream reset reader
streams tokenstream setmaxtokenlength maxtokenlength
streams tokenstream setreplaceinvalidacronym replaceinvalidacronym
return streams filteredtokenstream