package org apache lucene analysis compound
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java util set
import org apache lucene analysis token
import org apache lucene analysis tokenfilter     for javadocs
import org apache lucene analysis tokenstream
/**
* a {@link tokenfilter} that decomposes compound words found in many germanic languages.
* <p>
* "donaudampfschiff" becomes donau, dampf, schiff so that you can find
* "donaudampfschiff" even when you only enter "schiff".
*  it uses a brute-force algorithm to achieve this.
* </p>
*/
public class dictionarycompoundwordtokenfilter extends compoundwordtokenfilterbase
/**
*
* @param input the {@link tokenstream} to process
* @param dictionary the word dictionary to match against
* @param minwordsize only words longer than this get processed
* @param minsubwordsize only subwords longer than this get to the output stream
* @param maxsubwordsize only subwords shorter than this get to the output stream
* @param onlylongestmatch add only the longest matching subword to the stream
*/
public dictionarycompoundwordtokenfilter tokenstream input  string dictionary
int minwordsize  int minsubwordsize  int maxsubwordsize  boolean onlylongestmatch
super input  dictionary  minwordsize  minsubwordsize  maxsubwordsize  onlylongestmatch
/**
*
* @param input the {@link tokenstream} to process
* @param dictionary the word dictionary to match against
*/
public dictionarycompoundwordtokenfilter tokenstream input  string dictionary
super input  dictionary
/**
*
* @param input the {@link tokenstream} to process
* @param dictionary the word dictionary to match against. if this is a {@link org.apache.lucene.analysis.chararrayset chararrayset} it must have set ignorecase=false and only contain
*        lower case strings.
*/
public dictionarycompoundwordtokenfilter tokenstream input  set dictionary
super input  dictionary
/**
*
* @param input the {@link tokenstream} to process
* @param dictionary the word dictionary to match against. if this is a {@link org.apache.lucene.analysis.chararrayset chararrayset} it must have set ignorecase=false and only contain
*        lower case strings.
* @param minwordsize only words longer than this get processed
* @param minsubwordsize only subwords longer than this get to the output stream
* @param maxsubwordsize only subwords shorter than this get to the output stream
* @param onlylongestmatch add only the longest matching subword to the stream
*/
public dictionarycompoundwordtokenfilter tokenstream input  set dictionary
int minwordsize  int minsubwordsize  int maxsubwordsize  boolean onlylongestmatch
super input  dictionary  minwordsize  minsubwordsize  maxsubwordsize  onlylongestmatch
@override
protected void decomposeinternal final token token
// only words longer than minwordsize get processed
if  token termlength   < this minwordsize
return
char lowercasetermbuffer makelowercasecopy token termbuffer
for  int i 0 i<token termlength   this minsubwordsize   i
token longestmatchtoken null
for  int j this minsubwordsize 1 j<this maxsubwordsize   j
if i j>token termlength
break
if dictionary contains lowercasetermbuffer  i  j
if  this onlylongestmatch
if  longestmatchtoken  null
if  longestmatchtoken termlength  <j
longestmatchtoken createtoken i j token
else
longestmatchtoken createtoken i j token
else
tokens add createtoken i j token
if  this onlylongestmatch    longestmatchtoken  null
tokens add longestmatchtoken