package org apache lucene analysis ar
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io file
import java io ioexception
import java io inputstream
import java io inputstreamreader
import java io reader
import java util collections
import java util hashtable
import java util set
import org apache lucene analysis analyzer
import org apache lucene analysis chararrayset
import org apache lucene analysis lowercasefilter
import org apache lucene analysis stopfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenizer
import org apache lucene analysis wordlistloader
import org apache lucene util version
/**
* {@link analyzer} for arabic.
* <p>
* this analyzer implements light-stemming as specified by:
* <i>
* light stemming for arabic information retrieval
* </i>
* http://www.mtholyoke.edu/~lballest/pubs/arab_stem05.pdf
* <p>
* the analysis package contains three primary components:
* <ul>
*  <li>{@link arabicnormalizationfilter}: arabic orthographic normalization.
*  <li>{@link arabicstemfilter}: arabic light stemming
*  <li>arabic stop words file: a set of default arabic stop words.
* </ul>
*
*/
public final class arabicanalyzer extends analyzer
/**
* file containing default arabic stopwords.
*
* default stopword list is from http://members.unine.ch/jacques.savoy/clef/index.html
* the stopword list is bsd-licensed.
*/
public final static string default_stopword_file
/**
* contains the stopwords used with the stopfilter.
*/
private final set<?> stoptable
/**
* the comment character in the stopwords file.  all lines prefixed with this will be ignored
* @deprecated use {@link wordlistloader#getwordset(file, string)} directly
*/
public static final string stopwords_comment
/**
* returns an unmodifiable instance of the default stop-words set.
* @return an unmodifiable instance of the default stop-words set.
*/
public static set<string> getdefaultstopset
return defaultsetholder default_stop_set
/**
* atomically loads the default_stop_set in a lazy fashion once the outer class
* accesses the static final set the first time.;
*/
private static class defaultsetholder
static final set<string> default_stop_set
static
try
default_stop_set   loaddefaultstopwordset
catch  ioexception ex
// default set should always be present as it is part of the
// distribution (jar)
throw new runtimeexception
static set<string> loaddefaultstopwordset   throws ioexception
inputstream stream   arabicanalyzer class
getresourceasstream default_stopword_file
try
inputstreamreader reader   new inputstreamreader stream
// make sure it is unmodifiable as we expose it in the outer class
return collections unmodifiableset wordlistloader getwordset reader
stopwords_comment
finally
stream close
private final version matchversion
/**
* builds an analyzer with the default stop words: {@link #default_stopword_file}.
*/
public arabicanalyzer version matchversion
this matchversion  defaultsetholder default_stop_set
/**
* builds an analyzer with the given stop words
*
* @param matchversion
*          lucene compatibility version
* @param stopwords
*          a stopword set
*/
public arabicanalyzer version matchversion  set<?> stopwords
stoptable   chararrayset unmodifiableset chararrayset copy stopwords
this matchversion   matchversion
/**
* builds an analyzer with the given stop words.
* @deprecated use {@link #arabicanalyzer(version, set)} instead
*/
public arabicanalyzer  version matchversion  string    stopwords
this matchversion  stopfilter makestopset  stopwords
/**
* builds an analyzer with the given stop words.
* @deprecated use {@link #arabicanalyzer(version, set)} instead
*/
public arabicanalyzer  version matchversion  hashtable<? ?> stopwords
this matchversion  stopwords keyset
/**
* builds an analyzer with the given stop words.  lines can be commented out using {@link #stopwords_comment}
* @deprecated use {@link #arabicanalyzer(version, set)} instead
*/
public arabicanalyzer  version matchversion  file stopwords   throws ioexception
this matchversion  wordlistloader getwordset  stopwords  stopwords_comment
/**
* creates a {@link tokenstream} which tokenizes all the text in the provided {@link reader}.
*
* @return  a {@link tokenstream} built from an {@link arabiclettertokenizer} filtered with
* 			{@link lowercasefilter}, {@link stopfilter}, {@link arabicnormalizationfilter}
*            and {@link arabicstemfilter}.
*/
@override
public final tokenstream tokenstream string fieldname  reader reader
tokenstream result   new arabiclettertokenizer  reader
result   new lowercasefilter result
// the order here is important: the stopword list is not normalized!
result   new stopfilter  stopfilter getenablepositionincrementsversiondefault matchversion
result  stoptable
result   new arabicnormalizationfilter  result
result   new arabicstemfilter  result
return result
private class savedstreams
tokenizer source
tokenstream result
/**
* returns a (possibly reused) {@link tokenstream} which tokenizes all the text
* in the provided {@link reader}.
*
* @return  a {@link tokenstream} built from an {@link arabiclettertokenizer} filtered with
*            {@link lowercasefilter}, {@link stopfilter}, {@link arabicnormalizationfilter}
*            and {@link arabicstemfilter}.
*/
@override
public tokenstream reusabletokenstream string fieldname  reader reader
throws ioexception
savedstreams streams    savedstreams  getprevioustokenstream
if  streams    null
streams   new savedstreams
streams source   new arabiclettertokenizer reader
streams result   new lowercasefilter streams source
// the order here is important: the stopword list is not normalized!
streams result   new stopfilter stopfilter getenablepositionincrementsversiondefault matchversion
streams result  stoptable
streams result   new arabicnormalizationfilter streams result
streams result   new arabicstemfilter streams result
setprevioustokenstream streams
else
streams source reset reader
return streams result