/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache lucene analysis standard
import java io ioexception
import java io reader
import org apache lucene analysis token
import org apache lucene analysis tokenizer
import org apache lucene analysis tokenattributes offsetattribute
import org apache lucene analysis tokenattributes positionincrementattribute
import org apache lucene analysis tokenattributes termattribute
import org apache lucene analysis tokenattributes typeattribute
import org apache lucene util attributesource
import org apache lucene util version
/** a grammar-based tokenizer constructed with jflex
*
* <p> this should be a good tokenizer for most european-language documents:
*
* <ul>
*   <li>splits words at punctuation characters, removing punctuation. however, a
*     dot that's not followed by whitespace is considered part of a token.
*   <li>splits words at hyphens, unless there's a number in the token, in which case
*     the whole token is interpreted as a product number and is not split.
*   <li>recognizes email addresses and internet hostnames as one token.
* </ul>
*
* <p>many applications have specific tokenizer needs.  if this tokenizer does
* not suit your application, please consider copying this source code
* directory to your project and maintaining your own grammar-based tokenizer.
*
* <a name="version"/>
* <p>you must specify the required {@link version}
* compatibility when creating standardanalyzer:
* <ul>
*   <li> as of 2.4, tokens incorrectly identified as acronyms
*        are corrected (see <a href="https://issues.apache.org/jira/browse/lucene-1068">lucene-1608</a>
* </ul>
*/
public final class standardtokenizer extends tokenizer
/** a private instance of the jflex-constructed scanner */
private final standardtokenizerimpl scanner
public static final int alphanum            0
public static final int apostrophe          1
public static final int acronym             2
public static final int company             3
public static final int email               4
public static final int host                5
public static final int num                 6
public static final int cj                  7
/**
* @deprecated this solves a bug where hosts that end with '.' are identified
*             as acronyms.
*/
public static final int acronym_dep         8
/** string token types that correspond to token type int constants */
public static final string  token_types   new string
private boolean replaceinvalidacronym
private int maxtokenlength   standardanalyzer default_max_token_length
/** set the max allowed token length.  any token longer
*  than this is skipped. */
public void setmaxtokenlength int length
this maxtokenlength   length
/** @see #setmaxtokenlength */
public int getmaxtokenlength
return maxtokenlength
/**
* creates a new instance of the {@link org.apache.lucene.analysis.standard.standardtokenizer}.  attaches
* the <code>input</code> to the newly created jflex scanner.
*
* @param input the input reader
*
* see http://issues.apache.org/jira/browse/lucene-1068
*/
public standardtokenizer version matchversion  reader input
super
this scanner   new standardtokenizerimpl input
init input  matchversion
/**
* creates a new standardtokenizer with a given {@link attributesource}.
*/
public standardtokenizer version matchversion  attributesource source  reader input
super source
this scanner   new standardtokenizerimpl input
init input  matchversion
/**
* creates a new standardtokenizer with a given {@link org.apache.lucene.util.attributesource.attributefactory}
*/
public standardtokenizer version matchversion  attributefactory factory  reader input
super factory
this scanner   new standardtokenizerimpl input
init input  matchversion
private void init reader input  version matchversion
if  matchversion onorafter version lucene_24
replaceinvalidacronym   true
else
replaceinvalidacronym   false
this input   input
termatt   addattribute termattribute class
offsetatt   addattribute offsetattribute class
posincratt   addattribute positionincrementattribute class
typeatt   addattribute typeattribute class
// this tokenizer generates three attributes:
// offset, positionincrement and type
private termattribute termatt
private offsetattribute offsetatt
private positionincrementattribute posincratt
private typeattribute typeatt
/*
* (non-javadoc)
*
* @see org.apache.lucene.analysis.tokenstream#next()
*/
@override
public final boolean incrementtoken   throws ioexception
clearattributes
int posincr   1
while true
int tokentype   scanner getnexttoken
if  tokentype    standardtokenizerimpl yyeof
return false
if  scanner yylength   <  maxtokenlength
posincratt setpositionincrement posincr
scanner gettext termatt
final int start   scanner yychar
offsetatt setoffset correctoffset start   correctoffset start termatt termlength
// this 'if' should be removed in the next release. for now, it converts
// invalid acronyms to host. when removed, only the 'else' part should
// remain.
if  tokentype    standardtokenizerimpl acronym_dep
if  replaceinvalidacronym
typeatt settype standardtokenizerimpl token_types
termatt settermlength termatt termlength     1      remove extra
else
typeatt settype standardtokenizerimpl token_types
else
typeatt settype standardtokenizerimpl token_types
return true
else
// when we skip a too-long term, we still increment the
// position increment
posincr
@override
public final void end
// set final offset
int finaloffset   correctoffset scanner yychar     scanner yylength
offsetatt setoffset finaloffset  finaloffset
/*
* (non-javadoc)
*
* @see org.apache.lucene.analysis.tokenstream#reset()
*/
@override
public void reset   throws ioexception
super reset
scanner yyreset input
@override
public void reset reader reader  throws ioexception
super reset reader
reset
/**
* prior to https://issues.apache.org/jira/browse/lucene-1068, standardtokenizer mischaracterized as acronyms tokens like www.abc.com
* when they should have been labeled as hosts instead.
* @return true if standardtokenizer now returns these tokens as hosts, otherwise false
*
* @deprecated remove in 3.x and make true the only valid value
*/
public boolean isreplaceinvalidacronym
return replaceinvalidacronym
/**
*
* @param replaceinvalidacronym set to true to replace mischaracterized acronyms as host.
* @deprecated remove in 3.x and make true the only valid value
*
* see https://issues.apache.org/jira/browse/lucene-1068
*/
public void setreplaceinvalidacronym boolean replaceinvalidacronym
this replaceinvalidacronym   replaceinvalidacronym