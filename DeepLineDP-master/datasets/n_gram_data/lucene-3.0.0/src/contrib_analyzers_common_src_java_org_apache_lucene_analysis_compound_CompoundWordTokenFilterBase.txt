package org apache lucene analysis compound
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io ioexception
import java util arrays
import java util collection
import java util iterator
import java util linkedlist
import java util set
import org apache lucene analysis chararrayset
import org apache lucene analysis token
import org apache lucene analysis tokenfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenattributes flagsattribute
import org apache lucene analysis tokenattributes offsetattribute
import org apache lucene analysis tokenattributes payloadattribute
import org apache lucene analysis tokenattributes positionincrementattribute
import org apache lucene analysis tokenattributes termattribute
import org apache lucene analysis tokenattributes typeattribute
/**
* base class for decomposition token filters.
*/
public abstract class compoundwordtokenfilterbase extends tokenfilter
/**
* the default for minimal word length that gets decomposed
*/
public static final int default_min_word_size   5
/**
* the default for minimal length of subwords that get propagated to the output of this filter
*/
public static final int default_min_subword_size   2
/**
* the default for maximal length of subwords that get propagated to the output of this filter
*/
public static final int default_max_subword_size   15
protected final chararrayset dictionary
protected final linkedlist tokens
protected final int minwordsize
protected final int minsubwordsize
protected final int maxsubwordsize
protected final boolean onlylongestmatch
private termattribute termatt
private offsetattribute offsetatt
private flagsattribute flagsatt
private positionincrementattribute posincatt
private typeattribute typeatt
private payloadattribute payloadatt
private final token wrapper   new token
protected compoundwordtokenfilterbase tokenstream input  string dictionary  int minwordsize  int minsubwordsize  int maxsubwordsize  boolean onlylongestmatch
this input makedictionary dictionary  minwordsize minsubwordsize maxsubwordsize  onlylongestmatch
protected compoundwordtokenfilterbase tokenstream input  string dictionary  boolean onlylongestmatch
this input makedictionary dictionary  default_min_word_size default_min_subword_size default_max_subword_size  onlylongestmatch
protected compoundwordtokenfilterbase tokenstream input  set dictionary  boolean onlylongestmatch
this input dictionary default_min_word_size default_min_subword_size default_max_subword_size  onlylongestmatch
protected compoundwordtokenfilterbase tokenstream input  string dictionary
this input makedictionary dictionary  default_min_word_size default_min_subword_size default_max_subword_size  false
protected compoundwordtokenfilterbase tokenstream input  set dictionary
this input dictionary default_min_word_size default_min_subword_size default_max_subword_size  false
protected compoundwordtokenfilterbase tokenstream input  set dictionary  int minwordsize  int minsubwordsize  int maxsubwordsize  boolean onlylongestmatch
super input
this tokens new linkedlist
this minwordsize minwordsize
this minsubwordsize minsubwordsize
this maxsubwordsize maxsubwordsize
this onlylongestmatch onlylongestmatch
if  dictionary instanceof chararrayset
this dictionary    chararrayset  dictionary
else
this dictionary   new chararrayset dictionary size    false
addalllowercase this dictionary  dictionary
termatt   addattribute termattribute class
offsetatt   addattribute offsetattribute class
flagsatt   addattribute flagsattribute class
posincatt   addattribute positionincrementattribute class
typeatt   addattribute typeattribute class
payloadatt   addattribute payloadattribute class
/**
* create a set of words from an array
* the resulting set does case insensitive matching
* todo we should look for a faster dictionary lookup approach.
* @param dictionary
* @return {@link set} of lowercased terms
*/
public static final set makedictionary final string dictionary
// is the below really case insensitive?
chararrayset dict   new chararrayset dictionary length  false
addalllowercase dict  arrays aslist dictionary
return dict
private final void settoken final token token  throws ioexception
termatt settermbuffer token termbuffer    0  token termlength
flagsatt setflags token getflags
typeatt settype token type
offsetatt setoffset token startoffset    token endoffset
posincatt setpositionincrement token getpositionincrement
payloadatt setpayload token getpayload
@override
public final boolean incrementtoken   throws ioexception
if  tokens size   > 0
settoken  token tokens removefirst
return true
if  input incrementtoken      false
return false
wrapper settermbuffer termatt termbuffer    0  termatt termlength
wrapper setstartoffset offsetatt startoffset
wrapper setendoffset offsetatt endoffset
wrapper setflags flagsatt getflags
wrapper settype typeatt type
wrapper setpositionincrement posincatt getpositionincrement
wrapper setpayload payloadatt getpayload
decompose wrapper
if  tokens size   > 0
settoken  token tokens removefirst
return true
else
return false
protected static final void addalllowercase set target  collection col
iterator iter col iterator
while  iter hasnext
target add   string iter next    tolowercase
protected static char makelowercasecopy final char buffer
char result new char
system arraycopy buffer  0  result  0  buffer length
for  int i 0 i<buffer length   i
result character tolowercase buffer
return result
protected final token createtoken final int offset  final int length
final token prototype
int newstart   prototype startoffset     offset
token t   prototype clone prototype termbuffer    offset  length  newstart  newstart length
t setpositionincrement 0
return t
protected void decompose final token token
// in any case we give the original token back
tokens add  token  token clone
// only words longer than minwordsize get processed
if  token termlength   < this minwordsize
return
decomposeinternal token
protected abstract void decomposeinternal final token token
@override
public void reset   throws ioexception
super reset
tokens clear