package org apache lucene analysis cn
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io ioexception
import java io reader
import org apache lucene analysis tokenizer
import org apache lucene analysis tokenattributes offsetattribute
import org apache lucene analysis tokenattributes termattribute
import org apache lucene util attributesource
/**
* tokenize chinese text as individual chinese characters.
*
* <p>
* the difference between chinesetokenizer and
* cjktokenizer is that they have different
* token parsing logic.
* </p>
* <p>
* for example, if the chinese text
* "c1c2c3c4" is to be indexed:
* <ul>
* <li>the tokens returned from chinesetokenizer are c1, c2, c3, c4.
* <li>the tokens returned from the cjktokenizer are c1c2, c2c3, c3c4.
* </ul>
* </p>
* <p>
* therefore the index created by cjktokenizer is much larger.
* </p>
* <p>
* the problem is that when searching for c1, c1c2, c1c3,
* c4c2, c1c2c3 ... the chinesetokenizer works, but the
* cjktokenizer will not work.
* </p>
* @version 1.0
*
*/
public final class chinesetokenizer extends tokenizer
public chinesetokenizer reader in
super in
init
public chinesetokenizer attributesource source  reader in
super source  in
init
public chinesetokenizer attributefactory factory  reader in
super factory  in
init
private void init
termatt   addattribute termattribute class
offsetatt   addattribute offsetattribute class
private int offset   0  bufferindex 0  datalen 0
private final static int max_word_len   255
private final static int io_buffer_size   1024
private final char buffer   new char
private final char iobuffer   new char
private int length
private int start
private termattribute termatt
private offsetattribute offsetatt
private final void push char c
if  length    0  start   offset 1                start of token
buffer   character tolowercase c       buffer it
private final boolean flush
if  length>0
//system.out.println(new string(buffer, 0,
//length));
termatt settermbuffer buffer  0  length
offsetatt setoffset correctoffset start   correctoffset start length
return true
else
return false
@override
public boolean incrementtoken   throws ioexception
clearattributes
length   0
start   offset
while  true
final char c
offset
if  bufferindex >  datalen
datalen   input read iobuffer
bufferindex   0
if  datalen     1  return flush
else
c   iobuffer
switch character gettype c
case character decimal_digit_number
case character lowercase_letter
case character uppercase_letter
push c
if  length    max_word_len  return flush
break
case character other_letter
if  length>0
bufferindex
offset
return flush
push c
return flush
default
if  length>0  return flush
break
@override
public final void end
// set final offset
final int finaloffset   offset
this offsetatt setoffset finaloffset  finaloffset
@override
public void reset   throws ioexception
super reset
offset   bufferindex   datalen   0
@override
public void reset reader input  throws ioexception
super reset input
reset