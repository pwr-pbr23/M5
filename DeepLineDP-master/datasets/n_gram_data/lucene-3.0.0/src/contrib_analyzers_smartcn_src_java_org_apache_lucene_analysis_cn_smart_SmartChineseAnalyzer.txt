/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache lucene analysis cn smart
import java io ioexception
import java io inputstream
import java io inputstreamreader
import java io reader
import java util collections
import java util set
import org apache lucene analysis analyzer
import org apache lucene analysis porterstemfilter
import org apache lucene analysis stopfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenizer
import org apache lucene analysis wordlistloader
import org apache lucene analysis cn smart sentencetokenizer
import org apache lucene analysis cn smart wordtokenfilter
import org apache lucene util version
/**
* <p>
* smartchineseanalyzer is an analyzer for chinese or mixed chinese-english text.
* the analyzer uses probabilistic knowledge to find the optimal word segmentation for simplified chinese text.
* the text is first broken into sentences, then each sentence is segmented into words.
* </p>
* <p>
* segmentation is based upon the <a href="http://en.wikipedia.org/wiki/hidden_markov_model">hidden markov model</a>.
* a large training corpus was used to calculate chinese word frequency probability.
* </p>
* <p>
* this analyzer requires a dictionary to provide statistical data.
* smartchineseanalyzer has an included dictionary out-of-box.
* </p>
* <p>
* the included dictionary data is from <a href="http://www.ictclas.org">ictclas1.0</a>.
* thanks to ictclas for their hard work, and for contributing the data under the apache 2 license!
* </p>
* <p><font color="#ff0000">
* warning: the status of the analyzers/smartcn <b>analysis.cn.smart</b> package is experimental.
* the apis and file formats introduced here might change in the future and will not be
* supported anymore in such a case.</font>
* </p>
*/
public class smartchineseanalyzer extends analyzer
private final set<?> stopwords
private static final string default_stopword_file
private static final string stopword_file_comment
/**
* returns an unmodifiable instance of the default stop-words set.
* @return an unmodifiable instance of the default stop-words set.
*/
public static set<string> getdefaultstopset
return defaultsetholder default_stop_set
/**
* atomically loads the default_stop_set in a lazy fashion once the outer class
* accesses the static final set the first time.;
*/
private static class defaultsetholder
static final set<string> default_stop_set
static
try
default_stop_set   loaddefaultstopwordset
catch  ioexception ex
// default set should always be present as it is part of the
// distribution (jar)
throw new runtimeexception
static set<string> loaddefaultstopwordset   throws ioexception
inputstream stream   smartchineseanalyzer class
getresourceasstream default_stopword_file
try
inputstreamreader reader   new inputstreamreader stream
// make sure it is unmodifiable as we expose it in the outer class
return collections unmodifiableset wordlistloader getwordset reader  stopword_file_comment
finally
stream close
private final version matchversion
/**
* create a new smartchineseanalyzer, using the default stopword list.
*/
public smartchineseanalyzer version matchversion
this matchversion  true
/**
* <p>
* create a new smartchineseanalyzer, optionally using the default stopword list.
* </p>
* <p>
* the included default stopword list is simply a list of punctuation.
* if you do not use this list, punctuation will not be removed from the text!
* </p>
*
* @param usedefaultstopwords true to use the default stopword list.
*/
public smartchineseanalyzer version matchversion  boolean usedefaultstopwords
stopwords   usedefaultstopwords ? defaultsetholder default_stop_set
collections empty_set
this matchversion   matchversion
/**
* <p>
* create a new smartchineseanalyzer, using the provided {@link set} of stopwords.
* </p>
* <p>
* note: the set should include punctuation, unless you want to index punctuation!
* </p>
* @param stopwords {@link set} of stopwords to use.
*/
public smartchineseanalyzer version matchversion  set stopwords
this stopwords   stopwords  null?collections empty_set stopwords
this matchversion   matchversion
@override
public tokenstream tokenstream string fieldname  reader reader
tokenstream result   new sentencetokenizer reader
result   new wordtokenfilter result
// result = new lowercasefilter(result);
// lowercasefilter is not needed, as segtokenfilter lowercases basic latin text.
// the porter stemming is too strict, this is not a bug, this is a feature:)
result   new porterstemfilter result
if   stopwords isempty
result   new stopfilter stopfilter getenablepositionincrementsversiondefault matchversion
result  stopwords  false
return result
private static final class savedstreams
tokenizer tokenstream
tokenstream filteredtokenstream
@override
public tokenstream reusabletokenstream string fieldname  reader reader
throws ioexception
savedstreams streams    savedstreams  getprevioustokenstream
if  streams    null
streams   new savedstreams
setprevioustokenstream streams
streams tokenstream   new sentencetokenizer reader
streams filteredtokenstream   new wordtokenfilter streams tokenstream
streams filteredtokenstream   new porterstemfilter streams filteredtokenstream
if   stopwords isempty
streams filteredtokenstream   new stopfilter stopfilter getenablepositionincrementsversiondefault matchversion
streams filteredtokenstream  stopwords  false
else
streams tokenstream reset reader
streams filteredtokenstream reset       reset wordtokenfilter's state
return streams filteredtokenstream