package org apache lucene analysis de
// this file is encoded in utf-8
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io file
import java io ioexception
import java io reader
import java util arrays
import java util hashset
import java util map
import java util set
import org apache lucene analysis analyzer
import org apache lucene analysis chararrayset
import org apache lucene analysis lowercasefilter
import org apache lucene analysis stopfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenizer
import org apache lucene analysis wordlistloader
import org apache lucene analysis standard standardfilter
import org apache lucene analysis standard standardtokenizer
import org apache lucene analysis standard standardanalyzer      for javadoc
import org apache lucene util version
/**
* {@link analyzer} for german language.
* <p>
* supports an external list of stopwords (words that
* will not be indexed at all) and an external list of exclusions (word that will
* not be stemmed, but indexed).
* a default set of stopwords is used unless an alternative list is specified, but the
* exclusion list is empty by default.
* </p>
*
* <p><b>note</b>: this class uses the same {@link version}
* dependent settings as {@link standardanalyzer}.</p>
*/
public class germananalyzer extends analyzer
/**
* list of typical german stopwords.
* @deprecated use {@link #getdefaultstopset()} instead
*/
//todo make this private in 3.1
public final static string german_stop_words
/**
* returns a set of default german-stopwords
* @return a set of default german-stopwords
*/
public static final set<?> getdefaultstopset
return defaultsetholder default_set
private static class defaultsetholder
private static final set<?> default_set   chararrayset unmodifiableset new chararrayset
arrays aslist german_stop_words   false
/**
* contains the stopwords used with the {@link stopfilter}.
*/
//todo make this final in 3.1
private set<?> stopset
/**
* contains words that should be indexed but not stemmed.
*/
// todo make this final in 3.1
private set<?> exclusionset
private final version matchversion
/**
* builds an analyzer with the default stop words:
* {@link #getdefaultstopset()}.
*/
public germananalyzer version matchversion
this matchversion  defaultsetholder default_set
/**
* builds an analyzer with the given stop words
*
* @param matchversion
*          lucene compatibility version
* @param stopwords
*          a stopword set
*/
public germananalyzer version matchversion  set<?> stopwords
this matchversion  stopwords  chararrayset empty_set
/**
* builds an analyzer with the given stop words
*
* @param matchversion
*          lucene compatibility version
* @param stopwords
*          a stopword set
* @param stemexclusionset
*          a stemming exclusion set
*/
public germananalyzer version matchversion  set<?> stopwords  set<?> stemexclusionset
stopset   chararrayset unmodifiableset chararrayset copy stopwords
exclusionset   chararrayset unmodifiableset chararrayset copy stemexclusionset
setoverridestokenstreammethod germananalyzer class
this matchversion   matchversion
/**
* builds an analyzer with the given stop words.
* @deprecated use {@link #germananalyzer(version, set)}
*/
public germananalyzer version matchversion  string    stopwords
this matchversion  stopfilter makestopset stopwords
/**
* builds an analyzer with the given stop words.
* @deprecated use {@link #germananalyzer(version, set)}
*/
public germananalyzer version matchversion  map<? ?> stopwords
this matchversion  stopwords keyset
/**
* builds an analyzer with the given stop words.
* @deprecated use {@link #germananalyzer(version, set)}
*/
public germananalyzer version matchversion  file stopwords  throws ioexception
this matchversion  wordlistloader getwordset stopwords
/**
* builds an exclusionlist from an array of strings.
* @deprecated use {@link #germananalyzer(version, set, set)} instead
*/
public void setstemexclusiontable string exclusionlist
exclusionset   stopfilter makestopset exclusionlist
setprevioustokenstream null      force a new stemmer to be created
/**
* builds an exclusionlist from a {@link map}
* @deprecated use {@link #germananalyzer(version, set, set)} instead
*/
public void setstemexclusiontable map exclusionlist
exclusionset   new hashset exclusionlist keyset
setprevioustokenstream null      force a new stemmer to be created
/**
* builds an exclusionlist from the words contained in the given file.
* @deprecated use {@link #germananalyzer(version, set, set)} instead
*/
public void setstemexclusiontable file exclusionlist  throws ioexception
exclusionset   wordlistloader getwordset exclusionlist
setprevioustokenstream null      force a new stemmer to be created
/**
* creates a {@link tokenstream} which tokenizes all the text in the provided {@link reader}.
*
* @return a {@link tokenstream} built from a {@link standardtokenizer} filtered with
*         {@link standardfilter}, {@link lowercasefilter}, {@link stopfilter}, and
*         {@link germanstemfilter}
*/
@override
public tokenstream tokenstream string fieldname  reader reader
tokenstream result   new standardtokenizer matchversion  reader
result   new standardfilter result
result   new lowercasefilter result
result   new stopfilter stopfilter getenablepositionincrementsversiondefault matchversion
result  stopset
result   new germanstemfilter result  exclusionset
return result
private class savedstreams
tokenizer source
tokenstream result
/**
* returns a (possibly reused) {@link tokenstream} which tokenizes all the text
* in the provided {@link reader}.
*
* @return a {@link tokenstream} built from a {@link standardtokenizer} filtered with
*         {@link standardfilter}, {@link lowercasefilter}, {@link stopfilter}, and
*         {@link germanstemfilter}
*/
@override
public tokenstream reusabletokenstream string fieldname  reader reader  throws ioexception
if  overridestokenstreammethod
// lucene-1678: force fallback to tokenstream() if we
// have been subclassed and that subclass overrides
// tokenstream but not reusabletokenstream
return tokenstream fieldname  reader
savedstreams streams    savedstreams  getprevioustokenstream
if  streams    null
streams   new savedstreams
streams source   new standardtokenizer matchversion  reader
streams result   new standardfilter streams source
streams result   new lowercasefilter streams result
streams result   new stopfilter stopfilter getenablepositionincrementsversiondefault matchversion
streams result  stopset
streams result   new germanstemfilter streams result  exclusionset
setprevioustokenstream streams
else
streams source reset reader
return streams result