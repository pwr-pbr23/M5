/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql exec
import java io filenotfoundexception
import java io ioexception
import java util arraylist
import java util arrays
import java util hashmap
import java util list
import java util map
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop conf configuration
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop hive ql exec persistence rowcontainer
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql plan joindesc
import org apache hadoop hive ql plan operatordesc
import org apache hadoop hive ql plan tabledesc
import org apache hadoop hive serde2 serde
import org apache hadoop hive serde2 serdeexception
import org apache hadoop hive serde2 objectinspector objectinspector
import org apache hadoop hive serde2 objectinspector objectinspectorfactory
import org apache hadoop hive serde2 objectinspector structfield
import org apache hadoop hive serde2 objectinspector structobjectinspector
import org apache hadoop io longwritable
import org apache hadoop util reflectionutils
/**
* at runtime in join, we output big keys in one table into one corresponding
* directories, and all same keys in other tables into different dirs(one for
* each table). the directories will look like:
* <ul>
* <li>
* dir-t1-bigkeys(containing big keys in t1), dir-t2-keys(containing keys which
* is big in t1),dir-t3-keys(containing keys which is big in t1), ...
* <li>
* dir-t1-keys(containing keys which is big in t2), dir-t2-bigkeys(containing
* big keys in t2),dir-t3-keys(containing keys which is big in t2), ...
* <li>
* dir-t1-keys(containing keys which is big in t3), dir-t2-keys(containing big
* keys in t3),dir-t3-bigkeys(containing keys which is big in t3), ... .....
* </ul>
*
* <p>
* for each skew key, we first write all values to a local tmp file. at the time
* of ending the current group, the local tmp file will be uploaded to hdfs.
* right now, we use one file per skew key.
*
* <p>
* for more info, please see https://issues.apache.org/jira/browse/hive-964.
*
*/
public class skewjoinhandler
protected static final log log   logfactory getlog skewjoinhandler class
getname
public int currbigkeytag    1
private int rownumber   0
private int currtag    1
private int skewkeydefinition    1
private map<byte  structobjectinspector> skewkeystableobjectinspector   null
private map<byte  serde> tblserializers   null
private map<byte  tabledesc> tbldesc   null
private map<byte  boolean> bigkeysexistingmap   null
private longwritable skewjoinfollowupjobs
private final boolean noouterjoin
configuration hconf   null
list<object> dummykey   null
string taskid
private final commonjoinoperator<? extends operatordesc> joinop
private final int numaliases
private final joindesc conf
public skewjoinhandler commonjoinoperator<? extends operatordesc> joinop
this joinop   joinop
numaliases   joinop numaliases
conf   joinop getconf
noouterjoin   joinop noouterjoin
public void initiliaze configuration hconf
this hconf   hconf
joindesc desc   joinop getconf
skewkeydefinition   desc getskewkeydefinition
skewkeystableobjectinspector   new hashmap<byte  structobjectinspector>
numaliases
tbldesc   desc getskewkeysvaluestables
tblserializers   new hashmap<byte  serde> numaliases
bigkeysexistingmap   new hashmap<byte  boolean> numaliases
taskid   utilities gettaskid hconf
int filtermap   desc getfiltermap
for  int i   0  i < numaliases  i
byte alias   conf gettagorder
list<objectinspector> skewtablekeyinspectors   new arraylist<objectinspector>
structobjectinspector soi    structobjectinspector  joinop inputobjinspectors
structfield sf   soi getstructfieldref utilities reducefield key
tostring
list<? extends structfield> keyfields     structobjectinspector  sf
getfieldobjectinspector    getallstructfieldrefs
int keyfieldsize   keyfields size
for  int k   0  k < keyfieldsize  k
skewtablekeyinspectors add keyfields get k  getfieldobjectinspector
tabledesc joinkeydesc   desc getkeytabledesc
list<string> keycolnames   utilities getcolumnnames joinkeydesc
getproperties
structobjectinspector structtblkeyinpector   objectinspectorfactory
getstandardstructobjectinspector keycolnames  skewtablekeyinspectors
try
serde serializer    serde  reflectionutils newinstance tbldesc get
alias  getdeserializerclass    null
serializer initialize null  tbldesc get alias  getproperties
tblserializers put  byte  i  serializer
catch  serdeexception e
log error     e getmessage    e
joinop handleskewjoin   false
break
boolean hasfilter   filtermap    null    filtermap    null
tabledesc valtbldesc   joinutil getspilltabledesc alias
joinop spilltabledesc  conf   hasfilter
list<string> valcolnames   new arraylist<string>
if  valtbldesc    null
valcolnames   utilities getcolumnnames valtbldesc getproperties
structobjectinspector structtblvalinpector   objectinspectorfactory
getstandardstructobjectinspector valcolnames
joinop joinvaluesstandardobjectinspectors get  byte  i
structobjectinspector structtblinpector   objectinspectorfactory
getunionstructobjectinspector arrays
aslist new structobjectinspector  structtblvalinpector  structtblkeyinpector
skewkeystableobjectinspector put  byte  i  structtblinpector
// reset rowcontainer's serde, objectinspector, and tabledesc.
for  int i   0  i < numaliases  i
byte alias   conf gettagorder
rowcontainer<arraylist<object>> rc    rowcontainer joinop storage get byte
valueof  byte  i
if  rc    null
rc setserde tblserializers get  byte  i   skewkeystableobjectinspector
get  byte  i
rc settabledesc tbldesc get alias
void endgroup   throws ioexception  hiveexception
if  skewkeyincurrentgroup
string specpath   conf getbigkeysdirmap   get  byte  currbigkeytag
rowcontainer<arraylist<object>> bigkey    rowcontainer joinop storage get byte
valueof  byte  currbigkeytag
path outputpath   getoperatoroutputpath specpath
filesystem destfs   outputpath getfilesystem hconf
bigkey copytodfsdirecory destfs  outputpath
for  int i   0  i < numaliases  i
if    byte  i     currbigkeytag
continue
rowcontainer<arraylist<object>> values    rowcontainer joinop storage get byte
valueof  byte  i
if  values    null
specpath   conf getsmallkeysdirmap   get  byte  currbigkeytag  get
byte  i
values copytodfsdirecory destfs  getoperatoroutputpath specpath
skewkeyincurrentgroup   false
boolean skewkeyincurrentgroup   false
public void handleskew int tag  throws hiveexception
if  joinop newgroupstarted    tag    currtag
rownumber   0
currtag   tag
if  joinop newgroupstarted
currbigkeytag    1
joinop newgroupstarted   false
dummykey    list<object>  joinop getgroupkeyobject
skewkeyincurrentgroup   false
for  int i   0  i < numaliases  i
rowcontainer<arraylist<object>> rc    rowcontainer joinop storage get byte
valueof  byte  i
if  rc    null
rc setkeyobject dummykey
rownumber
if  currbigkeytag     1     tag < numaliases   1
rownumber >  skewkeydefinition
// the first time we see a big key. if this key is not in the last
// table (the last table can always be streamed), we define that we get
// a skew key now.
currbigkeytag   tag
updateskewjoinjobcounter tag
// right now we assume that the group by is an arraylist object. it may
// change in future.
if    dummykey instanceof list
throw new runtimeexception
skewkeyincurrentgroup   true
bigkeysexistingmap put byte valueof  byte  currbigkeytag   boolean true
public void close boolean abort  throws hiveexception
if   abort
try
endgroup
commit
catch  ioexception e
throw new hiveexception e
else
for  int bigkeytbl   0  bigkeytbl < numaliases  bigkeytbl
// if we did not see a skew key in this table, continue to next
// table
if   bigkeysexistingmap get  byte  bigkeytbl
continue
try
string specpath   conf getbigkeysdirmap   get  byte  bigkeytbl
path bigkeypath   getoperatoroutputpath specpath
filesystem fs   bigkeypath getfilesystem hconf
delete bigkeypath  fs
for  int smallkeytbl   0  smallkeytbl < numaliases  smallkeytbl
if    byte  smallkeytbl     bigkeytbl
continue
specpath   conf getsmallkeysdirmap   get  byte  bigkeytbl  get
byte  smallkeytbl
delete getoperatoroutputpath specpath   fs
catch  ioexception e
throw new hiveexception e
private void delete path operatoroutputpath  filesystem fs
try
fs delete operatoroutputpath  true
catch  ioexception e
log error e
private void commit   throws ioexception
for  int bigkeytbl   0  bigkeytbl < numaliases  bigkeytbl
// if we did not see a skew key in this table, continue to next table
// we are trying to avoid an extra call of filesystem.exists()
boolean existing   bigkeysexistingmap get byte valueof  byte  bigkeytbl
if  existing    null     existing
continue
string specpath   conf getbigkeysdirmap   get
byte valueof  byte  bigkeytbl
commitoutputpathtofinalpath specpath  false
for  int smallkeytbl   0  smallkeytbl < numaliases  smallkeytbl
if  smallkeytbl    bigkeytbl
continue
specpath   conf getsmallkeysdirmap
get byte valueof  byte  bigkeytbl   get
byte valueof  byte  smallkeytbl
// the file may not exist, and we just ignore this
commitoutputpathtofinalpath specpath  true
private void commitoutputpathtofinalpath string specpath
boolean ignorenonexisting  throws ioexception
path outpath   getoperatoroutputpath specpath
path finalpath   getoperatorfinalpath specpath
filesystem fs   outpath getfilesystem hconf
// for local file system in hadoop-0.17.2.1, it will throw ioexception when
// file not existing.
try
if   fs rename outpath  finalpath
throw new ioexception     finalpath
catch  filenotfoundexception e
if   ignorenonexisting
throw e
catch  ioexception e
if   fs exists outpath     ignorenonexisting
return
throw e
private path getoperatoroutputpath string specpath  throws ioexception
path tmppath   utilities totemppath specpath
return new path tmppath  utilities totemppath taskid
private path getoperatorfinalpath string specpath  throws ioexception
path tmppath   utilities totemppath specpath
return new path tmppath  taskid
public void setskewjoinjobcounter longwritable skewjoinfollowupjobs
this skewjoinfollowupjobs   skewjoinfollowupjobs
public void updateskewjoinjobcounter int tag
this skewjoinfollowupjobs set this skewjoinfollowupjobs get     1