/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql ppd
import java util arraylist
import java util hashmap
import java util hashset
import java util iterator
import java util list
import java util map
import java util map entry
import java util set
import java util stack
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop hive conf hiveconf
import org apache hadoop hive ql exec columninfo
import org apache hadoop hive ql exec filteroperator
import org apache hadoop hive ql exec functionregistry
import org apache hadoop hive ql exec joinoperator
import org apache hadoop hive ql exec operator
import org apache hadoop hive ql exec operatorfactory
import org apache hadoop hive ql exec rowschema
import org apache hadoop hive ql exec tablescanoperator
import org apache hadoop hive ql exec utilities
import org apache hadoop hive ql lib node
import org apache hadoop hive ql lib nodeprocessor
import org apache hadoop hive ql lib nodeprocessorctx
import org apache hadoop hive ql metadata hivestoragehandler
import org apache hadoop hive ql metadata hivestoragepredicatehandler
import org apache hadoop hive ql metadata table
import org apache hadoop hive ql parse astnode
import org apache hadoop hive ql parse basesemanticanalyzer
import org apache hadoop hive ql parse hiveparser
import org apache hadoop hive ql parse opparsecontext
import org apache hadoop hive ql parse rowresolver
import org apache hadoop hive ql parse semanticexception
import org apache hadoop hive ql plan exprnodecolumndesc
import org apache hadoop hive ql plan exprnodedesc
import org apache hadoop hive ql plan exprnodedescutils
import org apache hadoop hive ql plan exprnodegenericfuncdesc
import org apache hadoop hive ql plan filterdesc
import org apache hadoop hive ql plan joinconddesc
import org apache hadoop hive ql plan joindesc
import org apache hadoop hive ql plan operatordesc
import org apache hadoop hive ql plan tablescandesc
import org apache hadoop hive serde2 deserializer
import org apache hadoop hive serde2 typeinfo typeinfofactory
import org apache hadoop mapred jobconf
/**
* operator factory for predicate pushdown processing of operator graph each
* operator determines the pushdown predicates by walking the expression tree.
* each operator merges its own pushdown predicates with those of its children
* finally the tablescan operator gathers all the predicates and inserts a
* filter operator after itself. todo: further optimizations 1) multi-insert
* case 2) create a filter operator for those predicates that couldn't be pushed
* to the previous operators in the data flow 3) merge multiple sequential
* filter predicates into so that plans are more readable 4) remove predicates
* from filter operators that have been pushed. currently these pushed
* predicates are evaluated twice.
*/
public final class opprocfactory
protected static final log log   logfactory getlog opprocfactory class
getname
/**
* processor for script operator prevents any predicates being pushed.
*/
public static class scriptppd extends defaultppd implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
log info     nd getname
operator  nd  getidentifier
// script operator is a black-box to hive so no optimization here
// assuming that nothing can be pushed above the script op
// same with limit op
// create a filter with all children predicates
opwalkerinfo owi    opwalkerinfo  procctx
if  hiveconf getboolvar owi getparsecontext   getconf
hiveconf confvars hiveppdremoveduplicatefilters
exprwalkerinfo unpushedpreds   mergechildrenpred nd  owi  null  false
return createfilter  operator nd  unpushedpreds  owi
return null
public static class udtfppd extends defaultppd implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
log info     nd getname
operator  nd  getidentifier
//predicates for udtf wont be candidates for its children. so, nothing to
//optimize here. see lateral_view_ppd.q for example.
return null
public static class lateralviewforwardppd extends defaultppd implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
log info     nd getname
operator  nd  getidentifier
opwalkerinfo owi    opwalkerinfo  procctx
// the lateral view forward operator has 2 children, a select(*) and
// a select(cols) (for the udtf operator) the child at index 0 is the
// select(*) because that's the way that the dag was constructed. we
// only want to get the predicates from the select(*).
exprwalkerinfo childpreds   owi
getprunedpreds  operator<? extends operatordesc>  nd getchildren
get 0
owi putprunedpreds  operator<? extends operatordesc>  nd  childpreds
return null
/**
* combines predicates of its child into a single expression and adds a filter
* op as new child.
*/
public static class tablescanppd extends defaultppd implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
log info     nd getname
operator  nd  getidentifier
opwalkerinfo owi    opwalkerinfo  procctx
tablescanoperator tsop    tablescanoperator  nd
mergewithchildrenpred tsop  owi  null  null  false
exprwalkerinfo pushdownpreds   owi getprunedpreds tsop
return createfilter tsop  pushdownpreds  owi
/**
* determines the push down predicates in its where expression and then
* combines it with the push down predicates that are passed from its children.
*/
public static class filterppd extends defaultppd implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
log info     nd getname
operator  nd  getidentifier
opwalkerinfo owi    opwalkerinfo  procctx
operator<? extends operatordesc> op
operator<? extends operatordesc>  nd
exprnodedesc predicate      filteroperator  nd  getconf    getpredicate
exprwalkerinfo ewi   new exprwalkerinfo
// don't push a sampling predicate since createfilter() always creates filter
// with issamplepred = false. also, the filterop with sampling pred is always
// a child of tablescan, so there is no need to push this predicate.
if     filteroperator op  getconf   getissamplingpred
// get pushdown predicates for this operator's predicate
ewi   exprwalkerprocfactory extractpushdownpreds owi  op  predicate
if   ewi isdeterministic
/* predicate is not deterministic */
if  op getchildren      null    op getchildren   size      1
createfilter op  owi
getprunedpreds  operator<? extends operatordesc>   op
getchildren   get 0     owi
return null
if  hiveconf getboolvar owi getparsecontext   getconf
hiveconf confvars hiveppdremoveduplicatefilters
// add this filter for deletion, if it does not have non-final candidates
if  ewi getnonfinalcandidates   values   isempty
owi addcandidatefilterop  filteroperator op
logexpr nd  ewi
owi putprunedpreds  operator<? extends operatordesc>  nd  ewi
// merge it with children predicates
boolean hasunpushedpredicates   mergewithchildrenpred nd  owi  ewi  null  false
if  hiveconf getboolvar owi getparsecontext   getconf
hiveconf confvars hiveppdremoveduplicatefilters
if  hasunpushedpredicates
exprwalkerinfo unpushedpreds   mergechildrenpred nd  owi  null  false
return createfilter  operator nd  unpushedpreds  owi
return null
/**
* determines predicates for which alias can be pushed to it's parents. see
* the comments for getqualifiedaliases function.
*/
public static class joinppd extends defaultppd implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
log info     nd getname
operator  nd  getidentifier
opwalkerinfo owi    opwalkerinfo  procctx
set<string> aliases   getqualifiedaliases  joinoperator  nd  owi
getrowresolver nd
// we pass null for aliases here because mergewithchildrenpred filters
// aliases in the children node context and we need to filter them in
// the current joinoperator's context
boolean hasunpushedpredicates
mergewithchildrenpred nd  owi  null  null  false
exprwalkerinfo prunepreds
owi getprunedpreds  operator<? extends operatordesc>  nd
if  prunepreds    null
set<string> toremove   new hashset<string>
// we don't push down any expressions that refer to aliases that can;t
// be pushed down per getqualifiedaliases
for  string key   prunepreds getfinalcandidates   keyset
if   aliases contains key
toremove add key
for  string alias   toremove
for  exprnodedesc expr
prunepreds getfinalcandidates   get alias
// add expr to the list of predicates rejected from further pushing
// so that we know to add it in createfilter()
prunepreds addalias expr  alias
prunepreds addnonfinalcandidate expr
prunepreds getfinalcandidates   remove alias
if  hiveconf getboolvar owi getparsecontext   getconf
hiveconf confvars hiveppdrecognizetransitivity
applyfiltertransitivity  joinoperator  nd  owi
if  hiveconf getboolvar owi getparsecontext   getconf
hiveconf confvars hiveppdremoveduplicatefilters
// here, we add all the "non-final candidiates", ie. the predicates
// rejected from pushdown through this operator to unpushedpreds
// and pass it to createfilter
exprwalkerinfo unpushedpreds   new exprwalkerinfo
for  entry<string  list<exprnodedesc>> entry
prunepreds getnonfinalcandidates   entryset
for  exprnodedesc expr   entry getvalue
assert prunepreds getnewtooldexprmap   containskey expr
exprnodedesc oldexpr   prunepreds getnewtooldexprmap   get expr
unpushedpreds addalias oldexpr  entry getkey
unpushedpreds addfinalcandidate oldexpr
return createfilter  operator nd  unpushedpreds  owi
return null
/**
* adds additional pushdown predicates for a join operator by replicating
* filters transitively over all the equijoin conditions.
*
* if we have a predicate "t.col=1" and the equijoin conditions
* "t.col=s.col" and "t.col=u.col", we add the filters "s.col=1" and
* "u.col=1". note that this does not depend on the types of joins (ie.
* inner, left/right/full outer) between the tables s, t and u because if
* a predicate, eg. "t.col=1" is present in getfinalcandidates() at this
* point, we have already verified that it can be pushed down, so any rows
* emitted must satisfy s.col=t.col=u.col=1 and replicating the filters
* like this is ok.
*/
private void applyfiltertransitivity joinoperator nd  opwalkerinfo owi
throws semanticexception
exprwalkerinfo prunepreds
owi getprunedpreds  operator<? extends operatordesc>  nd
if  prunepreds    null
// we want to use the row resolvers of the parents of the join op
// because the rowresolver refers to the output columns of an operator
// and the filters at this point refer to the input columns of the join
// operator.
map<string  rowresolver> aliastorr
new hashmap<string  rowresolver>
for  operator<? extends operatordesc> o    nd  getparentoperators
for  string alias   owi getrowresolver o  gettablenames
aliastorr put alias  owi getrowresolver o
// eqexpressions is a list of arraylist<astnode>'s, one for each table
// in the join. then for each i, j and k, the join condition is that
// eqexpressions[i][k]=eqexpressions[j][k] (*) (ie. the columns referenced
// by the corresponding astnodes are equal). for example, if the query
// was select * from a join b on a.col=b.col and a.col2=b.col2 left
// outer join c on b.col=c.col and b.col2=c.col2 where c.col=1,
// eqexpressions would be [[a.col1, a.col2], [b.col1, b.col2],
// [c.col1, c.col2]].
//
// numequalities is the number of equal columns in each equality
// "chain" and numcolumns is the number of such chains.
//
// note that (*) is guaranteed to be true for the
// join operator: if the equijoin condititions can't be expressed in
// these equal-length lists of equal columns (for example if we had the
// query select * from a join b on a.col=b.col and a.col2=b.col2 left
// outer join c on b.col=c.col), more than one join operator is used.
arraylist<arraylist<astnode>> eqexpressions
owi getparsecontext   getjoincontext   get nd  getexpressions
int numcolumns   eqexpressions size
int numequalities   eqexpressions get 0  size
// joins[i] is the join between table i and i+1 in the joinoperator
joinconddesc joins    nd  getconf   getconds
// oldfilters contains the filters to be pushed down
map<string  list<exprnodedesc>> oldfilters
prunepreds getfinalcandidates
map<string  list<exprnodedesc>> newfilters
new hashmap<string  list<exprnodedesc>>
// we loop through for each chain of equalities
for  int i 0  i<numequalities  i
// equalcolumns[i] is the columninfo corresponding to the ith term
// of the equality or null if the term is not a simple column
// reference
columninfo equalcolumns new columninfo
for  int j 0  j<numcolumns  j
equalcolumns
getcolumninfofromast eqexpressions get j  get i   aliastorr
for  int j 0  j<numcolumns  j
for  int k 0  k<numcolumns  k
if  j    k    equalcolumns   null
equalcolumns    null
// terms j and k in the equality chain are simple columns,
// so we can replace instances of column j with column k
// in the filter and ad the replicated filter.
columninfo left   equalcolumns
columninfo right   equalcolumns
if  oldfilters get left gettabalias       null
for  exprnodedesc expr
oldfilters get left gettabalias
// only replicate the filter if there is exactly one column
// referenced
set<string> colsreferenced
new hashset<string> expr getcols
if  colsreferenced size      1
colsreferenced contains left getinternalname
exprnodedesc newexpr   expr clone
// replace the column reference in the filter
replacecolumnreference newexpr  left getinternalname
right getinternalname
if  newfilters get right gettabalias       null
newfilters put right gettabalias
new arraylist<exprnodedesc>
newfilters get right gettabalias    add newexpr
for  entry<string  list<exprnodedesc>> aliastofilters
newfilters entryset
owi getprunedpreds  operator<? extends operatordesc>  nd
addpushdowns aliastofilters getkey    aliastofilters getvalue
/**
* replaces the columninfo for the column referred to by an astnode
* representing "table.column" or null if the astnode is not in that form
*/
private columninfo getcolumninfofromast astnode nd
map<string  rowresolver> aliastorr  throws semanticexception
// this bit is messy since we are parsing an astnode at this point
if  nd gettype    hiveparser dot
if  nd getchildcount    2
if  nd getchild 0  gettype    hiveparser tok_table_or_col
nd getchild 0  getchildcount    1
nd getchild 1  gettype    hiveparser identifier
// we unescape the identifiers and make them lower case--this
// really shouldn't be done here, but getexpressions gives us the
// raw astnodes. the same thing is done in semanticanalyzer.
// parsejoincondpopulatealias().
string alias   basesemanticanalyzer unescapeidentifier
nd getchild 0  getchild 0  gettext   tolowercase
string column   basesemanticanalyzer unescapeidentifier
nd getchild 1  gettext   tolowercase
rowresolver rr aliastorr get alias
if  rr    null
return null
return rr get alias  column
return null
/**
* replaces all instances of oldcolumn with newcolumn in the
* exprcolumndesc's of the exprnodedesc
*/
private void replacecolumnreference exprnodedesc expr
string oldcolumn  string newcolumn
if  expr instanceof exprnodecolumndesc
if    exprnodecolumndesc  expr  getcolumn   equals oldcolumn
exprnodecolumndesc  expr  setcolumn newcolumn
if  expr getchildren      null
for  exprnodedesc childexpr   expr getchildren
replacecolumnreference childexpr  oldcolumn  newcolumn
/**
* figures out the aliases for whom it is safe to push predicates based on
* ansi sql semantics. the join conditions are left associative so "a
* right outer join b left outer join c inner join d" is interpreted as
* "((a right outer join b) left outer join c) inner join d".  for inner
* joins, both the left and right join subexpressions are considered for
* pushing down aliases, for the right outer join, the right subexpression
* is considered and the left ignored and for the left outer join, the
* left subexpression is considered and the left ignored. here, aliases b
* and d are eligible to be pushed up.
*
* todo: further optimization opportunity for the case a.c1 = b.c1 and b.c2
* = c.c2 a and b are first joined and then the result with c. but the
* second join op currently treats a and b as separate aliases and thus
* disallowing predicate expr containing both tables a and b (such as a.c3
* + a.c4 > 20). such predicates also can be pushed just above the second
* join and below the first join
*
* @param op
*          join operator
* @param rr
*          row resolver
* @return set of qualified aliases
*/
private set<string> getqualifiedaliases joinoperator op  rowresolver rr
set<string> aliases   new hashset<string>
joinconddesc conds   op getconf   getconds
map<integer  set<string>> postoaliasmap   op getpostoaliasmap
int i
for  i conds length 1  i> 0  i
if  conds gettype      joindesc inner_join
aliases addall postoaliasmap get i 1
else if  conds gettype      joindesc full_outer_join
break
else if  conds gettype      joindesc right_outer_join
aliases addall postoaliasmap get i 1
break
else if  conds gettype      joindesc left_outer_join
continue
if i     1
aliases addall postoaliasmap get 0
set<string> aliases2   rr gettablenames
aliases retainall aliases2
return aliases
/**
* processor for reducesink operator.
*
*/
public static class reducesinkppd extends defaultppd implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
log info     nd getname
operator  nd  getidentifier
opwalkerinfo owi    opwalkerinfo  procctx
set<string> aliases   owi getrowresolver nd  gettablenames
boolean ignorealiases   false
if  aliases size      1    aliases contains
// reduce sink of group by operator
ignorealiases   true
boolean hasunpushedpredicates   mergewithchildrenpred nd  owi  null  aliases  ignorealiases
if  hiveconf getboolvar owi getparsecontext   getconf
hiveconf confvars hiveppdremoveduplicatefilters
if  hasunpushedpredicates
operator<? extends operatordesc> op
operator<? extends operatordesc>  nd
operator<? extends operatordesc> childoperator   op getchildoperators   get 0
if childoperator getparentoperators   size    1
owi getcandidatefilterops   clear
return null
/**
* default processor which just merges its children.
*/
public static class defaultppd implements nodeprocessor
@override
public object process node nd  stack<node> stack  nodeprocessorctx procctx
object    nodeoutputs  throws semanticexception
log info     nd getname
operator  nd  getidentifier
opwalkerinfo owi    opwalkerinfo  procctx
boolean hasunpushedpredicates   mergewithchildrenpred nd  owi  null  null  false
if  hiveconf getboolvar owi getparsecontext   getconf
hiveconf confvars hiveppdremoveduplicatefilters
if  hasunpushedpredicates
exprwalkerinfo unpushedpreds   mergechildrenpred nd  owi  null  false
return createfilter  operator nd  unpushedpreds  owi
return null
/**
* @param nd
* @param ewi
*/
protected void logexpr node nd  exprwalkerinfo ewi
for  entry<string  list<exprnodedesc>> e   ewi getfinalcandidates
entryset
log info     nd getname
e getkey
for  exprnodedesc n   e getvalue
log info     n getexprstring
/**
* take current operators pushdown predicates and merges them with
* children's pushdown predicates.
*
* @param nd
*          current operator
* @param owi
*          operator context during this walk
* @param ewi
*          pushdown predicates (part of expression walker info)
* @param aliases
*          aliases that this operator can pushdown. null means that all
*          aliases can be pushed down
* @param ignorealiases
* @throws semanticexception
*/
protected boolean mergewithchildrenpred node nd  opwalkerinfo owi
exprwalkerinfo ewi  set<string> aliases  boolean ignorealiases
throws semanticexception
boolean hasunpushedpredicates   false
if  nd getchildren      null    nd getchildren   size   > 1
// ppd for multi-insert query is not yet implemented
// no-op for leafs
return hasunpushedpredicates
operator<? extends operatordesc> op
operator<? extends operatordesc>  nd
exprwalkerinfo childpreds   owi
getprunedpreds  operator<? extends operatordesc>  nd getchildren
get 0
if  childpreds    null
return hasunpushedpredicates
if  ewi    null
ewi   new exprwalkerinfo
for  entry<string  list<exprnodedesc>> e   childpreds
getfinalcandidates   entryset
if  ignorealiases    aliases    null    aliases contains e getkey
e getkey      null
// e.getkey() (alias) can be null in case of constant expressions. see
// input8.q
exprwalkerinfo extractpushdownpreds   exprwalkerprocfactory
extractpushdownpreds owi  op  e getvalue
if   extractpushdownpreds getnonfinalcandidates   isempty
hasunpushedpredicates   true
ewi merge extractpushdownpreds
logexpr nd  extractpushdownpreds
else
hasunpushedpredicates   true
owi putprunedpreds  operator<? extends operatordesc>  nd  ewi
return hasunpushedpredicates
protected exprwalkerinfo mergechildrenpred node nd  opwalkerinfo owi
set<string> excludedaliases  boolean ignorealiases
throws semanticexception
if  nd getchildren      null
return null
operator<? extends operatordesc> op    operator<? extends operatordesc> nd
exprwalkerinfo ewi   new exprwalkerinfo
for  operator<? extends operatordesc> child   op getchildoperators
exprwalkerinfo childpreds   owi getprunedpreds child
if  childpreds    null
continue
for  entry<string  list<exprnodedesc>> e   childpreds
getfinalcandidates   entryset
if  ignorealiases    excludedaliases    null
excludedaliases contains e getkey       e getkey      null
ewi addpushdowns e getkey    e getvalue
logexpr nd  ewi
return ewi
protected static object createfilter operator op
exprwalkerinfo pushdownpreds  opwalkerinfo owi
if  pushdownpreds    null    pushdownpreds getfinalcandidates      null
pushdownpreds getfinalcandidates   size      0
return null
rowresolver inputrr   owi getrowresolver op
// combine all predicates into a single expression
list<exprnodedesc> preds   null
exprnodedesc condn   null
iterator<list<exprnodedesc>> iterator   pushdownpreds getfinalcandidates
values   iterator
while  iterator hasnext
preds   iterator next
int i   0
if  condn    null
condn   preds get 0
i
for    i < preds size    i
exprnodedesc next   preds get i
if   exprnodedescutils containspredicate condn  next
condn   exprnodedescutils mergepredicates condn  next
if  condn    null
return null
if  op instanceof tablescanoperator
boolean pushfiltertostorage
hiveconf hiveconf   owi getparsecontext   getconf
pushfiltertostorage
hiveconf getboolvar hiveconf confvars hiveoptppd_storage
if  pushfiltertostorage
condn   pushfiltertostoragehandler
tablescanoperator  op
condn
owi
hiveconf
if  condn    null
// we pushed the whole thing down
return null
// add new filter op
list<operator<? extends operatordesc>> originalchilren   op
getchildoperators
op setchildoperators null
operator<filterdesc> output   operatorfactory getandmakechild
new filterdesc condn  false   new rowschema inputrr getcolumninfos
op
output setchildoperators originalchilren
for  operator<? extends operatordesc> ch   originalchilren
list<operator<? extends operatordesc>> parentoperators   ch
getparentoperators
int pos   parentoperators indexof op
assert pos     1
parentoperators remove pos
parentoperators add pos  output      add the new op as the old
opparsecontext ctx   new opparsecontext inputrr
owi put output  ctx
if  hiveconf getboolvar owi getparsecontext   getconf
hiveconf confvars hiveppdremoveduplicatefilters
// remove the candidate filter ops
for  filteroperator fop   owi getcandidatefilterops
list<operator<? extends operatordesc>> children   fop getchildoperators
list<operator<? extends operatordesc>> parents   fop getparentoperators
for  operator<? extends operatordesc> parent   parents
parent getchildoperators   addall children
parent removechild fop
for  operator<? extends operatordesc> child   children
child getparentoperators   addall parents
child removeparent fop
owi getcandidatefilterops   clear
return output
/**
* attempts to push a predicate down into a storage handler.  for
* native tables, this is a no-op.
*
* @param tablescanop table scan against which predicate applies
*
* @param originalpredicate predicate to be pushed down
*
* @param owi object walk info
*
* @param hiveconf hive configuration
*
* @return portion of predicate which needs to be evaluated
* by hive as a post-filter, or null if it was possible
* to push down the entire predicate
*/
private static exprnodedesc pushfiltertostoragehandler
tablescanoperator tablescanop
exprnodedesc originalpredicate
opwalkerinfo owi
hiveconf hiveconf
tablescandesc tablescandesc   tablescanop getconf
table tbl   owi getparsecontext   gettoptotable   get tablescanop
if  hiveconf getboolvar hiveconf  hiveconf confvars hiveoptindexfilter
// attach the original predicate to the table scan operator for index
// optimizations that require the pushed predicate before pcr & later
// optimizations are applied
tablescandesc setfilterexpr originalpredicate
if   tbl isnonnative
return originalpredicate
hivestoragehandler storagehandler   tbl getstoragehandler
if    storagehandler instanceof hivestoragepredicatehandler
// the storage handler does not provide predicate decomposition
// support, so we'll implement the entire filter in hive.  however,
// we still provide the full predicate to the storage handler in
// case it wants to do any of its own prefiltering.
tablescandesc setfilterexpr originalpredicate
return originalpredicate
hivestoragepredicatehandler predicatehandler
hivestoragepredicatehandler  storagehandler
jobconf jobconf   new jobconf owi getparsecontext   getconf
utilities setcolumnnamelist jobconf  tablescanop
utilities setcolumntypelist jobconf  tablescanop
utilities copytablejobpropertiestoconf
utilities gettabledesc tbl
jobconf
deserializer deserializer   tbl getdeserializer
hivestoragepredicatehandler decomposedpredicate decomposed
predicatehandler decomposepredicate
jobconf
deserializer
originalpredicate
if  decomposed    null
// not able to push anything down
if  log isdebugenabled
log debug
originalpredicate getexprstring
return originalpredicate
if  log isdebugenabled
log debug
originalpredicate getexprstring
if  decomposed pushedpredicate    null
log debug
decomposed pushedpredicate getexprstring
if  decomposed residualpredicate    null
log debug
decomposed residualpredicate getexprstring
tablescandesc setfilterexpr decomposed pushedpredicate
return decomposed residualpredicate
public static nodeprocessor getfilterproc
return new filterppd
public static nodeprocessor getjoinproc
return new joinppd
public static nodeprocessor getrsproc
return new reducesinkppd
public static nodeprocessor gettsproc
return new tablescanppd
public static nodeprocessor getdefaultproc
return new defaultppd
public static nodeprocessor getscrproc
return new scriptppd
public static nodeprocessor getlimproc
return new scriptppd
public static nodeprocessor getudtfproc
return new udtfppd
public static nodeprocessor getlvfproc
return new lateralviewforwardppd
private opprocfactory
// prevent instantiation