/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql exec
import java io serializable
import java util arraylist
import java util arrays
import java util hashmap
import java util hashset
import java util linkedhashmap
import java util list
import java util map
import java util map entry
import java util properties
import java util set
import org apache hadoop conf configuration
import org apache hadoop fs path
import org apache hadoop hive conf hiveconf
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata virtualcolumn
import org apache hadoop hive ql plan mapredwork
import org apache hadoop hive ql plan operatordesc
import org apache hadoop hive ql plan partitiondesc
import org apache hadoop hive ql plan tablescandesc
import org apache hadoop hive ql plan api operatortype
import org apache hadoop hive serde2 deserializer
import org apache hadoop hive serde2 serdeexception
import org apache hadoop hive serde2 serdestats
import org apache hadoop hive serde2 serdeutils
import org apache hadoop hive serde2 objectinspector objectinspector
import org apache hadoop hive serde2 objectinspector objectinspectorfactory
import org apache hadoop hive serde2 objectinspector structobjectinspector
import org apache hadoop hive serde2 objectinspector primitive primitiveobjectinspectorfactory
import org apache hadoop hive serde2 typeinfo primitivetypeinfo
import org apache hadoop io longwritable
import org apache hadoop io text
import org apache hadoop io writable
import org apache hadoop util stringutils
/**
* map operator. this triggers overall map side processing. this is a little
* different from regular operators in that it starts off by processing a
* writable data structure from a table (instead of a hive object).
**/
public class mapoperator extends operator<mapredwork> implements serializable  cloneable
private static final long serialversionuid   1l
/**
* counter.
*
*/
public static enum counter
deserialize_errors
private final transient longwritable deserialize_error_count   new longwritable
private transient deserializer deserializer
private transient object rowwithpart
private transient writable vcvalues
private transient list<virtualcolumn> vcs
private transient object rowwithpartandvc
private transient structobjectinspector rowobjectinspector
private transient boolean ispartitioned
private transient boolean hasvc
private map<mapinputpath  mapopctx> opctxmap
private final set<mapinputpath> listinputpaths   new hashset<mapinputpath>
private map<operator<? extends operatordesc>  arraylist<string>> operatortopaths
private final map<operator<? extends operatordesc>  mapopctx> childrenoptoopctxmap
new hashmap<operator<? extends operatordesc>  mapopctx>
private arraylist<operator<? extends operatordesc>> extrachildrentoclose   null
private static class mapinputpath
string path
string alias
operator<? extends operatordesc> op
/**
* @param path
* @param alias
* @param op
*/
public mapinputpath string path  string alias
operator<? extends operatordesc> op
this path   path
this alias   alias
this op   op
@override
public boolean equals object o
if  o instanceof mapinputpath
mapinputpath mobj    mapinputpath  o
if  mobj    null
return false
return path equals mobj path     alias equals mobj alias
op equals mobj op
return false
@override
public int hashcode
int ret    path    null  ? 0   path hashcode
ret     alias    null  ? 0   alias hashcode
ret     op    null  ? 0   op hashcode
return ret
public operator<? extends operatordesc> getop
return op
public void setop operator<? extends operatordesc> op
this op   op
private static class mapopctx
boolean ispartitioned
structobjectinspector rawrowobjectinspector     without partition
structobjectinspector partobjectinspector     partition
structobjectinspector rowobjectinspector
object rowwithpart
object rowwithpartandvc
deserializer deserializer
public string tablename
public string partname
/**
* @param ispartitioned
* @param rowobjectinspector
* @param rowwithpart
*/
public mapopctx boolean ispartitioned
structobjectinspector rowobjectinspector
structobjectinspector rawrowobjectinspector
structobjectinspector partobjectinspector
object rowwithpart
object rowwithpartandvc
deserializer deserializer
this ispartitioned   ispartitioned
this rowobjectinspector   rowobjectinspector
this rawrowobjectinspector   rawrowobjectinspector
this partobjectinspector   partobjectinspector
this rowwithpart   rowwithpart
this rowwithpartandvc   rowwithpartandvc
this deserializer   deserializer
/**
* @return the ispartitioned
*/
public boolean ispartitioned
return ispartitioned
/**
* @return the rowobjectinspector
*/
public structobjectinspector getrowobjectinspector
return rowobjectinspector
/**
* @return the rowwithpart
*/
public object getrowwithpart
return rowwithpart
/**
* @return the rowwithpartandvc
*/
public object getrowwithpartandvc
return rowwithpartandvc
/**
* @return the deserializer
*/
public deserializer getdeserializer
return deserializer
/**
* initializes this map op as the root of the tree. it sets jobconf &
* mapredwork and starts initialization of the operator tree rooted at this
* op.
*
* @param hconf
* @param mrwork
* @throws hiveexception
*/
public void initializeasroot configuration hconf  mapredwork mrwork
throws hiveexception
setconf mrwork
setchildren hconf
initialize hconf  null
private mapopctx initobjectinspector mapredwork conf
configuration hconf  string onefile  throws hiveexception
classnotfoundexception  instantiationexception  illegalaccessexception
serdeexception
partitiondesc td   conf getpathtopartitioninfo   get onefile
linkedhashmap<string  string> partspec   td getpartspec
properties tblprops   td getproperties
class sdclass   td getdeserializerclass
if  sdclass    null
string classname   td getserdeclassname
if   classname           classname    null
throw new hiveexception
td getproperties   getproperty
sdclass   hconf getclassbyname classname
string tablename   string valueof tblprops getproperty
string partname   string valueof partspec
// hiveconf.setvar(hconf, hiveconf.confvars.hivetablename, tablename);
// hiveconf.setvar(hconf, hiveconf.confvars.hivepartitionname, partname);
deserializer deserializer    deserializer  sdclass newinstance
deserializer initialize hconf  tblprops
structobjectinspector rawrowobjectinspector    structobjectinspector  deserializer
getobjectinspector
mapopctx opctx   null
// next check if this table has partitions and if so
// get the list of partition names as well as allocate
// the serdes for the partition columns
string pcols   tblprops
getproperty org apache hadoop hive metastore api hive_metastoreconstants meta_table_partition_columns
// log log = logfactory.getlog(mapoperator.class.getname());
if  pcols    null    pcols length   > 0
string partkeys   pcols trim   split
list<string> partnames   new arraylist<string> partkeys length
object partvalues   new object
list<objectinspector> partobjectinspectors   new arraylist<objectinspector>
partkeys length
for  int i   0  i < partkeys length  i
string key   partkeys
partnames add key
// partitions do not exist for this table
if  partspec    null
partvalues   new text
else
partvalues   new text partspec get key
partobjectinspectors
add primitiveobjectinspectorfactory writablestringobjectinspector
structobjectinspector partobjectinspector   objectinspectorfactory
getstandardstructobjectinspector partnames  partobjectinspectors
object rowwithpart   new object
rowwithpart   partvalues
structobjectinspector rowobjectinspector   objectinspectorfactory
getunionstructobjectinspector arrays
aslist new structobjectinspector  rawrowobjectinspector  partobjectinspector
// log.info("dump " + tablename + " " + partname + " " +
// rowobjectinspector.gettypename());
opctx   new mapopctx true  rowobjectinspector  rawrowobjectinspector  partobjectinspector
rowwithpart  null  deserializer
else
// log.info("dump2 " + tablename + " " + partname + " " +
// rowobjectinspector.gettypename());
opctx   new mapopctx false  rawrowobjectinspector  rawrowobjectinspector  null  null
null  deserializer
opctx tablename   tablename
opctx partname   partname
return opctx
/**
* set the inspectors given a input. since a mapper can span multiple partitions, the inspectors
* need to be changed if the input changes
**/
private void setinspectorinput mapinputpath inp
operator<? extends operatordesc> op   inp getop
deserializer   opctxmap get inp  getdeserializer
ispartitioned   opctxmap get inp  ispartitioned
rowwithpart   opctxmap get inp  getrowwithpart
rowwithpartandvc   opctxmap get inp  getrowwithpartandvc
rowobjectinspector   opctxmap get inp  getrowobjectinspector
if  listinputpaths contains inp
return
listinputpaths add inp
if  op instanceof tablescanoperator
structobjectinspector rawrowobjectinspector   opctxmap get inp  rawrowobjectinspector
structobjectinspector partobjectinspector   opctxmap get inp  partobjectinspector
tablescanoperator tsop    tablescanoperator  op
tablescandesc tsdesc   tsop getconf
if  tsdesc    null
this vcs   tsdesc getvirtualcols
if  vcs    null    vcs size   > 0
this hasvc   true
list<string> vcnames   new arraylist<string> vcs size
this vcvalues   new writable
list<objectinspector> vcsobjectinspectors   new arraylist<objectinspector> vcs size
for  int i   0  i < vcs size    i
virtualcolumn vc   vcs get i
vcsobjectinspectors add
primitiveobjectinspectorfactory getprimitivewritableobjectinspector
primitivetypeinfo  vc gettypeinfo    getprimitivecategory
vcnames add vc getname
structobjectinspector vcstructobjectinspector   objectinspectorfactory
getstandardstructobjectinspector vcnames
vcsobjectinspectors
if  ispartitioned
this rowwithpartandvc   new object
this rowwithpartandvc   this rowwithpart
else
this rowwithpartandvc   new object
if  partobjectinspector    null
this rowobjectinspector   objectinspectorfactory getunionstructobjectinspector arrays
aslist new structobjectinspector
rowobjectinspector  vcstructobjectinspector
else
this rowobjectinspector   objectinspectorfactory getunionstructobjectinspector arrays
aslist new structobjectinspector
rawrowobjectinspector  partobjectinspector
vcstructobjectinspector
opctxmap get inp  rowobjectinspector   this rowobjectinspector
opctxmap get inp  rowwithpartandvc   this rowwithpartandvc
public void setchildren configuration hconf  throws hiveexception
path fpath   new path  new path hiveconf getvar hconf
hiveconf confvars hadoopmapfilename    touri   getpath
arraylist<operator<? extends operatordesc>> children
new arraylist<operator<? extends operatordesc>>
opctxmap   new hashmap<mapinputpath  mapopctx>
operatortopaths   new hashmap<operator<? extends operatordesc>  arraylist<string>>
statsmap put counter deserialize_errors  deserialize_error_count
try
for  string onefile   conf getpathtoaliases   keyset
mapopctx opctx   initobjectinspector conf  hconf  onefile
path onepath   new path new path onefile  touri   getpath
list<string> aliases   conf getpathtoaliases   get onefile
for  string onealias   aliases
operator<? extends operatordesc> op   conf getaliastowork   get
onealias
log info     onealias
onefile
mapinputpath inp   new mapinputpath onefile  onealias  op
opctxmap put inp  opctx
if  operatortopaths get op     null
operatortopaths put op  new arraylist<string>
operatortopaths get op  add onefile
op setparentoperators new arraylist<operator<? extends operatordesc>>
op getparentoperators   add this
// check for the operators who will process rows coming to this map
// operator
if   onepath touri   relativize fpath touri    equals fpath touri
children add op
childrenoptoopctxmap put op  opctx
log info     op getname
opctxmap get inp  getrowobjectinspector   gettypename
setinspectorinput inp
if  children size      0
// didn't find match for input file path in configuration!
// serious problem ..
log error
fpath touri   getpath
throw new hiveexception
// we found all the operators that we are supposed to process.
setchildoperators children
catch  exception e
throw new hiveexception e
@override
public void initializeop configuration hconf  throws hiveexception
// set that parent initialization is done and call initialize on children
state   state init
list<operator<? extends operatordesc>> children   getchildoperators
for  entry<operator<? extends operatordesc>  mapopctx> entry   childrenoptoopctxmap
entryset
operator<? extends operatordesc> child   entry getkey
mapopctx mapopctx   entry getvalue
// add alias, table name, and partitions to hadoop conf so that their
// children will
// inherit these
hiveconf setvar hconf  hiveconf confvars hivetablename
mapopctx tablename
hiveconf setvar hconf  hiveconf confvars hivepartitionname
mapopctx partname
child initialize hconf  new objectinspector  mapopctx getrowobjectinspector
for  entry<mapinputpath  mapopctx> entry   opctxmap entryset
// add alias, table name, and partitions to hadoop conf so that their
// children will
// inherit these
hiveconf setvar hconf  hiveconf confvars hivetablename
entry getvalue   tablename
hiveconf setvar hconf  hiveconf confvars hivepartitionname  entry
getvalue   partname
mapinputpath input   entry getkey
operator<? extends operatordesc> op   input op
// op is not in the children list, so need to remember it and close it
// afterwards
if  children indexof op      1
if  extrachildrentoclose    null
extrachildrentoclose   new arraylist<operator<? extends operatordesc>>
extrachildrentoclose add op
op initialize hconf  new objectinspector  entry getvalue   getrowobjectinspector
/**
* close extra child operators that are initialized but are not executed.
*/
@override
public void closeop boolean abort  throws hiveexception
if  extrachildrentoclose    null
for  operator<? extends operatordesc> op   extrachildrentoclose
op close abort
// change the serializer etc. since it is a new file, and split can span
// multiple files/partitions.
@override
public void cleanupinputfilechangedop   throws hiveexception
path fpath   new path  new path this getexeccontext   getcurrentinputfile
touri   getpath
for  string onefile   conf getpathtoaliases   keyset
path onepath   new path new path onefile  touri   getpath
// check for the operators who will process rows coming to this map
// operator
if   onepath touri   relativize fpath touri    equals fpath touri
string onealias   conf getpathtoaliases   get onefile  get 0
operator<? extends operatordesc> op
conf getaliastowork   get onealias
log info     onealias       onefile
mapinputpath inp   new mapinputpath onefile  onealias  op
setinspectorinput inp
break
public void process writable value  throws hiveexception
// a mapper can span multiple files/partitions.
// the serializers need to be reset if the input file changed
if   this getexeccontext      null
this getexeccontext   inputfilechanged
// the child operators cleanup if input file has changed
cleanupinputfilechanged
execmappercontext context   getexeccontext
object row   null
try
if  this hasvc
this rowwithpartandvc   deserializer deserialize value
int vcpos   ispartitioned ? 2   1
if  context    null
populatevirtualcolumnvalues context  vcs  vcvalues  deserializer
this rowwithpartandvc   this vcvalues
else if   ispartitioned
row   deserializer deserialize  writable  value
else
rowwithpart   deserializer deserialize  writable  value
catch  exception e
// serialize the row and output.
string rawrowstring
try
rawrowstring   value tostring
catch  exception e2
rawrowstring
stringutils stringifyexception e2
// todo: policy on deserialization errors
deserialize_error_count set deserialize_error_count get     1
throw new hiveexception     rawrowstring  e
try
if  this hasvc
forward this rowwithpartandvc  this rowobjectinspector
else if   ispartitioned
forward row  rowobjectinspector
else
forward rowwithpart  rowobjectinspector
catch  exception e
// serialize the row and output the error message.
string rowstring
try
if  this hasvc
rowstring   serdeutils getjsonstring rowwithpartandvc  rowobjectinspector
else if   ispartitioned
rowstring   serdeutils getjsonstring row  rowobjectinspector
else
rowstring   serdeutils getjsonstring rowwithpart  rowobjectinspector
catch  exception e2
rowstring
stringutils stringifyexception e2
throw new hiveexception     rowstring  e
public static writable populatevirtualcolumnvalues execmappercontext ctx
list<virtualcolumn> vcs  writable vcvalues  deserializer deserializer
if  vcs    null
return vcvalues
if  vcvalues    null
vcvalues   new writable
for  int i   0  i < vcs size    i
virtualcolumn vc   vcs get i
if  vc equals virtualcolumn filename
if  ctx inputfilechanged
vcvalues   new text ctx getcurrentinputfile
else if  vc equals virtualcolumn blockoffset
long current   ctx getiocxt   getcurrentblockstart
longwritable old    longwritable  vcvalues
if  old    null
old   new longwritable current
vcvalues   old
continue
if  current    old get
old set current
else if  vc equals virtualcolumn rowoffset
long current   ctx getiocxt   getcurrentrow
longwritable old    longwritable  vcvalues
if  old    null
old   new longwritable current
vcvalues   old
continue
if  current    old get
old set current
else if  vc equals virtualcolumn rawdatasize
long current   0l
serdestats stats   deserializer getserdestats
if stats    null
current   stats getrawdatasize
longwritable old    longwritable  vcvalues
if  old    null
old   new longwritable current
vcvalues   old
continue
if  current    old get
old set current
return vcvalues
@override
public void processop object row  int tag  throws hiveexception
throw new hiveexception
@override
public string getname
return getoperatorname
static public string getoperatorname
return
@override
public operatortype gettype
return null