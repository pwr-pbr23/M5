/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql parse
import java io serializable
import java io unsupportedencodingexception
import java util arraylist
import java util arrays
import java util hashmap
import java util hashset
import java util iterator
import java util linkedhashmap
import java util linkedhashset
import java util list
import java util map
import org antlr runtime tree commontree
import org antlr runtime tree tree
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop hive conf hiveconf
import org apache hadoop hive metastore metastoreutils
import org apache hadoop hive metastore api fieldschema
import org apache hadoop hive metastore api order
import org apache hadoop hive ql context
import org apache hadoop hive ql errormsg
import org apache hadoop hive ql queryproperties
import org apache hadoop hive ql exec fetchtask
import org apache hadoop hive ql exec task
import org apache hadoop hive ql exec utilities
import org apache hadoop hive ql hooks lineageinfo
import org apache hadoop hive ql hooks readentity
import org apache hadoop hive ql hooks writeentity
import org apache hadoop hive ql io ignorekeytextoutputformat
import org apache hadoop hive ql io rcfileinputformat
import org apache hadoop hive ql io rcfileoutputformat
import org apache hadoop hive ql lib node
import org apache hadoop hive ql metadata hive
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata invalidtableexception
import org apache hadoop hive ql metadata partition
import org apache hadoop hive ql metadata table
import org apache hadoop hive ql plan planutils
import org apache hadoop hive ql session sessionstate
import org apache hadoop hive ql session sessionstate loghelper
import org apache hadoop hive serde serdeconstants
import org apache hadoop hive serde2 columnar columnarserde
import org apache hadoop mapred sequencefileinputformat
import org apache hadoop mapred sequencefileoutputformat
import org apache hadoop mapred textinputformat
/**
* basesemanticanalyzer.
*
*/
public abstract class basesemanticanalyzer
protected final hive db
protected final hiveconf conf
protected list<task<? extends serializable>> roottasks
protected fetchtask fetchtask
protected final log log
protected final loghelper console
protected context ctx
protected hashmap<string  string> idtotablenamemap
protected queryproperties queryproperties
public static int hive_column_order_asc   1
public static int hive_column_order_desc   0
/**
* readentitites that are passed to the hooks.
*/
protected hashset<readentity> inputs
/**
* list of writeentities that are passed to the hooks.
*/
protected hashset<writeentity> outputs
/**
* lineage information for the query.
*/
protected lineageinfo linfo
protected tableaccessinfo tableaccessinfo
protected static final string textfile_input   textinputformat class
getname
protected static final string textfile_output   ignorekeytextoutputformat class
getname
protected static final string sequencefile_input   sequencefileinputformat class
getname
protected static final string sequencefile_output   sequencefileoutputformat class
getname
protected static final string rcfile_input   rcfileinputformat class
getname
protected static final string rcfile_output   rcfileoutputformat class
getname
protected static final string columnar_serde   columnarserde class getname
class rowformatparams
string fielddelim   null
string fieldescape   null
string collitemdelim   null
string mapkeydelim   null
string linedelim   null
protected void analyzerowformat analyzecreatecommonvars shared  astnode child  throws semanticexception
child    astnode  child getchild 0
int numchildrowformat   child getchildcount
for  int numc   0  numc < numchildrowformat  numc
astnode rowchild    astnode  child getchild numc
switch  rowchild gettoken   gettype
case hiveparser tok_tablerowformatfield
fielddelim   unescapesqlstring rowchild getchild 0
gettext
if  rowchild getchildcount   >  2
fieldescape   unescapesqlstring rowchild
getchild 1  gettext
break
case hiveparser tok_tablerowformatcollitems
collitemdelim   unescapesqlstring rowchild
getchild 0  gettext
break
case hiveparser tok_tablerowformatmapkeys
mapkeydelim   unescapesqlstring rowchild getchild 0
gettext
break
case hiveparser tok_tablerowformatlines
linedelim   unescapesqlstring rowchild getchild 0
gettext
if   linedelim equals
linedelim equals
throw new semanticexception semanticanalyzer generateerrormessage rowchild
errormsg lines_terminated_by_non_newline getmsg
break
default
assert false
class analyzecreatecommonvars
string serde   null
map<string  string> serdeprops   new hashmap<string  string>
class storageformat
string inputformat   null
string outputformat   null
string storagehandler   null
protected boolean fillstorageformat astnode child  analyzecreatecommonvars shared
boolean storageformat   false
switch child gettoken   gettype
case hiveparser tok_tblsequencefile
inputformat   sequencefile_input
outputformat   sequencefile_output
storageformat   true
break
case hiveparser tok_tbltextfile
inputformat   textfile_input
outputformat   textfile_output
storageformat   true
break
case hiveparser tok_tblrcfile
inputformat   rcfile_input
outputformat   rcfile_output
if  shared serde    null
shared serde   columnar_serde
storageformat   true
break
case hiveparser tok_tablefileformat
inputformat   unescapesqlstring child getchild 0  gettext
outputformat   unescapesqlstring child getchild 1  gettext
storageformat   true
break
case hiveparser tok_storagehandler
storagehandler   unescapesqlstring child getchild 0  gettext
if  child getchildcount      2
readprops
astnode   child getchild 1  getchild 0
shared serdeprops
storageformat   true
break
return storageformat
protected void filldefaultstorageformat analyzecreatecommonvars shared
if   inputformat    null      storagehandler    null
if    equalsignorecase conf getvar hiveconf confvars hivedefaultfileformat
inputformat   sequencefile_input
outputformat   sequencefile_output
else if    equalsignorecase conf getvar hiveconf confvars hivedefaultfileformat
inputformat   rcfile_input
outputformat   rcfile_output
shared serde   columnar_serde
else
inputformat   textfile_input
outputformat   textfile_output
public basesemanticanalyzer hiveconf conf  throws semanticexception
try
this conf   conf
db   hive get conf
roottasks   new arraylist<task<? extends serializable>>
log   logfactory getlog this getclass   getname
console   new loghelper log
idtotablenamemap   new hashmap<string  string>
inputs   new linkedhashset<readentity>
outputs   new linkedhashset<writeentity>
catch  exception e
throw new semanticexception e
public hashmap<string  string> getidtotablenamemap
return idtotablenamemap
public abstract void analyzeinternal astnode ast  throws semanticexception
public void init
//no-op
public void initctx context ctx
this ctx   ctx
public void analyze astnode ast  context ctx  throws semanticexception
initctx ctx
init
analyzeinternal ast
public void validate   throws semanticexception
// implementations may choose to override this
public list<task<? extends serializable>> getroottasks
return roottasks
/**
* @return the fetchtask
*/
public fetchtask getfetchtask
return fetchtask
/**
* @param fetchtask
*          the fetchtask to set
*/
public void setfetchtask fetchtask fetchtask
this fetchtask   fetchtask
protected void reset
roottasks   new arraylist<task<? extends serializable>>
public static string stripquotes string val
return planutils stripquotes val
public static string charsetstring string charsetname  string charsetstring
throws semanticexception
try
// the character set name starts with a _, so strip that
charsetname   charsetname substring 1
if  charsetstring charat 0
return new string unescapesqlstring charsetstring  getbytes
charsetname
else    hex input is also supported
assert charsetstring charat 0
assert charsetstring charat 1
charsetstring   charsetstring substring 2
byte barray   new byte
int j   0
for  int i   0  i < charsetstring length    i    2
int val   character digit charsetstring charat i   16    16
character digit charsetstring charat i   1   16
if  val > 127
val   val   256
barray    byte val
string res   new string barray  charsetname
return res
catch  unsupportedencodingexception e
throw new semanticexception e
/**
* get dequoted name from a table/column node.
* @param tableorcolumnnode the table or column node
* @return for table node, db.tab or tab. for column node column.
*/
public static string getunescapedname astnode tableorcolumnnode
return getunescapedname tableorcolumnnode  null
public static string getunescapedname astnode tableorcolumnnode  string currentdatabase
if  tableorcolumnnode gettoken   gettype      hiveparser tok_tabname
// table node
if  tableorcolumnnode getchildcount      2
string dbname   unescapeidentifier tableorcolumnnode getchild 0  gettext
string tablename   unescapeidentifier tableorcolumnnode getchild 1  gettext
return dbname       tablename
string tablename   unescapeidentifier tableorcolumnnode getchild 0  gettext
if  currentdatabase    null
return currentdatabase       tablename
return tablename
// column node
return unescapeidentifier tableorcolumnnode gettext
/**
* get the unqualified name from a table node.
*
* this method works for table names qualified with their schema (e.g., "db.table")
* and table names without schema qualification. in both cases, it returns
* the table name without the schema.
*
* @param node the table node
* @return the table name without schema qualification
*         (i.e., if name is "db.table" or "table", returns "table")
*/
public static string getunescapedunqualifiedtablename astnode node
assert node getchildcount   <  2
if  node getchildcount      2
node    astnode  node getchild 1
return getunescapedname node
/**
* remove the encapsulating "`" pair from the identifier. we allow users to
* use "`" to escape identifier for table names, column names and aliases, in
* case that coincide with hive language keywords.
*/
public static string unescapeidentifier string val
if  val    null
return null
if  val charat 0          val charat val length     1
val   val substring 1  val length     1
return val
/**
* converts parsed key/value properties pairs into a map.
*
* @param prop astnode parent of the key/value pairs
*
* @param mapprop property map which receives the mappings
*/
public static void readprops
astnode prop  map<string  string> mapprop
for  int propchild   0  propchild < prop getchildcount    propchild
string key   unescapesqlstring prop getchild propchild  getchild 0
gettext
string value   unescapesqlstring prop getchild propchild  getchild 1
gettext
mapprop put key  value
@suppresswarnings
public static string unescapesqlstring string b
character enclosure   null
// some of the strings can be passed in as unicode. for example, the
// delimiter can be passed in as \002 - so, we first check if the
// string is a unicode number, else go back to the old behavior
stringbuilder sb   new stringbuilder b length
for  int i   0  i < b length    i
char currentchar   b charat i
if  enclosure    null
if  currentchar         b charat i
enclosure   currentchar
// ignore all other chars outside the enclosure
continue
if  enclosure equals currentchar
enclosure   null
continue
if  currentchar          i   4 < b length
char i1   b charat i   1
char i2   b charat i   2
char i3   b charat i   3
if   i1 >       i1 <         i2 >       i2 <
i3 >       i3 <
byte bval    byte    i3          i2        8      i1        8   8
byte bvalarr   new byte
bvalarr   bval
string tmp   new string bvalarr
sb append tmp
i    3
continue
if  currentchar          i   2 < b length
char n   b charat i   1
switch  n
case
sb append
break
case
sb append
break
case
sb append  "
break
case
sb append
break
case
sb append
break
case
sb append
break
case
sb append
break
case
sb append
break
case
sb append
break
// the following 2 lines are exactly what mysql does
case
sb append
break
case
sb append
break
default
sb append n
i
else
sb append currentchar
return sb tostring
public hashset<readentity> getinputs
return inputs
public hashset<writeentity> getoutputs
return outputs
/**
* @return the schema for the fields which will be produced
* when the statement is executed, or null if not known
*/
public list<fieldschema> getresultschema
return null
protected list<fieldschema> getcolumns astnode ast  throws semanticexception
return getcolumns ast  true
protected void handlegenericfileformat astnode node  throws semanticexception
astnode child    astnode node getchild 0
throw new semanticexception
child    null ?     child gettext
/**
* get the list of fieldschema out of the astnode.
*/
public static list<fieldschema> getcolumns astnode ast  boolean lowercase  throws semanticexception
list<fieldschema> collist   new arraylist<fieldschema>
int numch   ast getchildcount
for  int i   0  i < numch  i
fieldschema col   new fieldschema
astnode child    astnode  ast getchild i
string name   child getchild 0  gettext
if lowercase
name   name tolowercase
// child 0 is the name of the column
col setname unescapeidentifier name
// child 1 is the type of the column
astnode typechild    astnode   child getchild 1
col settype gettypestringfromast typechild
// child 2 is the optional comment of the column
if  child getchildcount      3
col setcomment unescapesqlstring child getchild 2  gettext
collist add col
return collist
protected list<string> getcolumnnames astnode ast
list<string> collist   new arraylist<string>
int numch   ast getchildcount
for  int i   0  i < numch  i
astnode child    astnode  ast getchild i
collist add unescapeidentifier child gettext    tolowercase
return collist
protected list<order> getcolumnnamesorder astnode ast
list<order> collist   new arraylist<order>
int numch   ast getchildcount
for  int i   0  i < numch  i
astnode child    astnode  ast getchild i
if  child gettoken   gettype      hiveparser tok_tabsortcolnameasc
collist add new order unescapeidentifier child getchild 0  gettext    tolowercase
hive_column_order_asc
else
collist add new order unescapeidentifier child getchild 0  gettext    tolowercase
hive_column_order_desc
return collist
protected static string gettypestringfromast astnode typenode
throws semanticexception
switch  typenode gettype
case hiveparser tok_list
return serdeconstants list_type_name
gettypestringfromast  astnode  typenode getchild 0
case hiveparser tok_map
return serdeconstants map_type_name
gettypestringfromast  astnode  typenode getchild 0
gettypestringfromast  astnode  typenode getchild 1
case hiveparser tok_struct
return getstructtypestringfromast typenode
case hiveparser tok_uniontype
return getuniontypestringfromast typenode
default
return ddlsemanticanalyzer gettypename typenode gettype
private static string getstructtypestringfromast astnode typenode
throws semanticexception
string typestr   serdeconstants struct_type_name
typenode    astnode  typenode getchild 0
int children   typenode getchildcount
if  children <  0
throw new semanticexception
stringbuilder buffer   new stringbuilder typestr
for  int i   0  i < children  i
astnode child    astnode  typenode getchild i
buffer append unescapeidentifier child getchild 0  gettext     append
buffer append gettypestringfromast  astnode  child getchild 1
if  i < children   1
buffer append
buffer append
return buffer tostring
private static string getuniontypestringfromast astnode typenode
throws semanticexception
string typestr   serdeconstants union_type_name
typenode    astnode  typenode getchild 0
int children   typenode getchildcount
if  children <  0
throw new semanticexception
stringbuilder buffer   new stringbuilder typestr
for  int i   0  i < children  i
buffer append gettypestringfromast  astnode  typenode getchild i
if  i < children   1
buffer append
buffer append
typestr   buffer tostring
return typestr
/**
* tablespec.
*
*/
public static class tablespec
public string tablename
public table tablehandle
public map<string  string> partspec     has to use linkedhashmap to enforce order
public partition parthandle
public int numdynparts     number of dynamic partition columns
public list<partition> partitions     involved partitions in tablescanoperator filesinkoperator
public static enum spectype  table_only  static_partition  dynamic_partition
public spectype spectype
public tablespec hive db  hiveconf conf  astnode ast
throws semanticexception
this db  conf  ast  true  false
public tablespec hive db  hiveconf conf  astnode ast
boolean allowdynamicpartitionsspec  boolean allowpartialpartitionsspec
throws semanticexception
assert  ast gettoken   gettype      hiveparser tok_tab
ast gettoken   gettype      hiveparser tok_table_partition
ast gettoken   gettype      hiveparser tok_tabtype
ast gettoken   gettype      hiveparser tok_createtable
int childindex   0
numdynparts   0
try
// get table metadata
tablename   getunescapedname  astnode ast getchild 0
boolean testmode   conf getboolvar hiveconf confvars hivetestmode
if  testmode
tablename   conf getvar hiveconf confvars hivetestmodeprefix
tablename
if  ast gettoken   gettype      hiveparser tok_createtable
tablehandle   db gettable tablename
catch  invalidtableexception ite
throw new semanticexception errormsg invalid_table getmsg ast
getchild 0    ite
catch  hiveexception e
throw new semanticexception errormsg generic_error getmsg ast
getchild childindex   e getmessage     e
// get partition metadata if partition specified
if  ast getchildcount      2    ast gettoken   gettype      hiveparser tok_createtable
childindex   1
astnode partspec    astnode  ast getchild 1
partitions   new arraylist<partition>
// partspec is a mapping from partition column name to its value.
partspec   new linkedhashmap<string  string> partspec getchildcount
for  int i   0  i < partspec getchildcount      i
astnode partspec_val    astnode  partspec getchild i
string val   null
string colname   unescapeidentifier partspec_val getchild 0  gettext   tolowercase
if  partspec_val getchildcount   < 2       dp in the form of t partition  ds  hr
if  allowdynamicpartitionsspec
numdynparts
else
throw new semanticexception errormsg invalid_partition
getmsg
else      in the form of t partition  ds
val   stripquotes partspec_val getchild 1  gettext
partspec put colname  val
// check if the columns specified in the partition() clause are actually partition columns
utilities validatepartspec tablehandle  partspec
// check if the partition spec is valid
if  numdynparts > 0
list<fieldschema> parts   tablehandle getpartitionkeys
int numstapart   parts size     numdynparts
if  numstapart    0
conf getvar hiveconf confvars dynamicpartitioningmode  equalsignorecase
throw new semanticexception errormsg dynamic_partition_strict_mode getmsg
// check the partitions in partspec be the same as defined in table schema
if  partspec keyset   size      parts size
errorpartspec partspec  parts
iterator<string> itrpskeys   partspec keyset   iterator
for  fieldschema fs  parts
if   itrpskeys next   tolowercase   equals fs getname   tolowercase
errorpartspec partspec  parts
// check if static partition appear after dynamic partitions
for  fieldschema fs  parts
if  partspec get fs getname   tolowercase       null
if  numstapart > 0       found a dp  but there exists st as subpartition
throw new semanticexception
errormsg partition_dyn_sta_order getmsg ast getchild childindex
break
else
numstapart
parthandle   null
spectype   spectype dynamic_partition
else
try
if  allowpartialpartitionsspec
partitions   db getpartitions tablehandle  partspec
else
// this doesn't create partition.
parthandle   db getpartition tablehandle  partspec  false
if  parthandle    null
// if partspec doesn't exists in db, return a delegate one
// and the actual partition is created in movetask
parthandle   new partition tablehandle  partspec  null
else
partitions add parthandle
catch  hiveexception e
throw new semanticexception
errormsg invalid_partition getmsg ast getchild childindex    e
spectype   spectype static_partition
else
spectype   spectype table_only
public map<string  string> getpartspec
return this partspec
public void setpartspec map<string  string> partspec
this partspec   partspec
@override
public string tostring
if  parthandle    null
return parthandle tostring
else
return tablehandle tostring
/**
* gets the lineage information.
*
* @return lineageinfo associated with the query.
*/
public lineageinfo getlineageinfo
return linfo
/**
* sets the lineage information.
*
* @param linfo the lineageinfo structure that is set in the optimization phase.
*/
public void setlineageinfo lineageinfo linfo
this linfo   linfo
/**
* gets the table access information.
*
* @return tableaccessinfo associated with the query.
*/
public tableaccessinfo gettableaccessinfo
return tableaccessinfo
/**
* sets the table access information.
*
* @param tainfo the tableaccessinfo structure that is set in the optimization phase.
*/
public void settableaccessinfo tableaccessinfo tableaccessinfo
this tableaccessinfo   tableaccessinfo
protected hashmap<string  string> extractpartitionspecs tree partspec
throws semanticexception
hashmap<string  string> partspec   new linkedhashmap<string  string>
for  int i   0  i < partspec getchildcount      i
commontree partspec_val    commontree  partspec getchild i
string val   stripquotes partspec_val getchild 1  gettext
partspec put partspec_val getchild 0  gettext   tolowercase    val
return partspec
/**
* checks if given specification is proper specification for prefix of
* partition cols, for table partitioned by ds, hr, min valid ones are
* (ds='2008-04-08'), (ds='2008-04-08', hr='12'), (ds='2008-04-08', hr='12', min='30')
* invalid one is for example (ds='2008-04-08', min='30')
* @param spec specification key-value map
* @return true if the specification is prefix; never returns false, but throws
* @throws hiveexception
*/
final public boolean isvalidprefixspec table ttable  map<string  string> spec
throws hiveexception
// todo - types need to be checked.
list<fieldschema> partcols   ttable getpartitionkeys
if  partcols    null     partcols size      0
if  spec    null
throw new hiveexception
spec
else
return true
if  spec    null
throw new hiveexception
iterator<string> itrpskeys   spec keyset   iterator
for  fieldschema fs  partcols
if  itrpskeys hasnext
break
if   itrpskeys next   tolowercase   equals
fs getname   tolowercase
errorpartspec spec  partcols
if itrpskeys hasnext
errorpartspec spec  partcols
return true
private static void errorpartspec map<string  string> partspec
list<fieldschema> parts  throws semanticexception
stringbuilder sb
new stringbuilder
for  fieldschema fs   parts
sb append fs getname    append
sb setlength sb length     2      remove the last
sb append
iterator<string> itrpskeys   partspec keyset   iterator
while  itrpskeys hasnext
sb append itrpskeys next    append
sb setlength sb length     2      remove the last
sb append
throw new semanticexception errormsg partspec_differ_from_schema
getmsg sb tostring
public hive getdb
return db
public queryproperties getqueryproperties
return queryproperties
/**
* given a astnode, return list of values.
*
* use case:
*   create table xyz list bucketed (col1) with skew (1,2,5)
*   ast node is for (1,2,5)
* @param ast
* @return
*/
protected list<string> getskewedvaluefromastnode astnode ast
list<string> collist   new arraylist<string>
int numch   ast getchildcount
for  int i   0  i < numch  i
astnode child    astnode  ast getchild i
collist add stripquotes child gettext    tolowercase
return collist
/**
* retrieve skewed values from astnode.
*
* @param node
* @return
* @throws semanticexception
*/
protected list<string> getskewedvaluesfromastnode node node  throws semanticexception
list<string> result   null
tree leafvnode     astnode  node  getchild 0
if  leafvnode    null
throw new semanticexception
errormsg skewed_table_no_column_value getmsg
else
astnode lvastnode    astnode  leafvnode
if  lvastnode gettoken   gettype      hiveparser tok_tabcolvalue
throw new semanticexception
errormsg skewed_table_no_column_value getmsg
else
result   new arraylist<string> getskewedvaluefromastnode lvastnode
return result
/**
* analyze list bucket column names
*
* @param skewedcolnames
* @param child
* @return
* @throws semanticexception
*/
protected list<string> analyzeskewedtablddlcolnames list<string> skewedcolnames  astnode child
throws semanticexception
tree nnode   child getchild 0
if  nnode    null
throw new semanticexception errormsg skewed_table_no_column_name getmsg
else
astnode nastnode    astnode  nnode
if  nastnode gettoken   gettype      hiveparser tok_tabcolname
throw new semanticexception errormsg skewed_table_no_column_name getmsg
else
skewedcolnames   getcolumnnames nastnode
return skewedcolnames
/**
* handle skewed values in ddl.
*
* it can be used by both skewed by ... on () and set skewed location ().
*
* @param skewedvalues
* @param child
* @throws semanticexception
*/
protected void analyzeddlskewedvalues list<list<string>> skewedvalues  astnode child
throws semanticexception
tree vnode   child getchild 1
if  vnode    null
throw new semanticexception errormsg skewed_table_no_column_value getmsg
astnode vastnode    astnode  vnode
switch  vastnode gettoken   gettype
case hiveparser tok_tabcolvalue
for  string str   getskewedvaluefromastnode vastnode
list<string> slist   new arraylist<string> arrays aslist str
skewedvalues add slist
break
case hiveparser tok_tabcolvalue_pair
arraylist<node> vlnodes   vastnode getchildren
for  node node   vlnodes
if     astnode  node  gettoken   gettype      hiveparser tok_tabcolvalues
throw new semanticexception
errormsg skewed_table_no_column_value getmsg
else
skewedvalues add getskewedvaluesfromastnode node
break
default
break
/**
* process stored as directories
*
* @param child
* @return
*/
protected boolean analyzestoredaddirs astnode child
boolean storedasdirs   false
if   child getchildcount      3
astnode  child getchild 2   gettoken   gettype
hiveparser tok_storedasdirs
storedasdirs   true
return storedasdirs