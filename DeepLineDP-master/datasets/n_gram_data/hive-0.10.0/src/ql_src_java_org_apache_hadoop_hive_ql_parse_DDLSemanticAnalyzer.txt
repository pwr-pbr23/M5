/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql parse
import static org apache hadoop hive ql parse hiveparser tok_cascade
import static org apache hadoop hive ql parse hiveparser tok_databasecomment
import static org apache hadoop hive ql parse hiveparser tok_databaselocation
import static org apache hadoop hive ql parse hiveparser tok_databaseproperties
import static org apache hadoop hive ql parse hiveparser tok_ifexists
import static org apache hadoop hive ql parse hiveparser tok_ifnotexists
import static org apache hadoop hive ql parse hiveparser tok_showdatabases
import java io serializable
import java net uri
import java net urisyntaxexception
import java util arraylist
import java util hashmap
import java util hashset
import java util iterator
import java util linkedhashmap
import java util linkedlist
import java util list
import java util map
import java util map entry
import java util properties
import java util set
import org antlr runtime tree commontree
import org antlr runtime tree tree
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop fs path
import org apache hadoop hive conf hiveconf
import org apache hadoop hive conf hiveconf confvars
import org apache hadoop hive metastore warehouse
import org apache hadoop hive metastore api fieldschema
import org apache hadoop hive metastore api index
import org apache hadoop hive metastore api metaexception
import org apache hadoop hive metastore api order
import org apache hadoop hive metastore api principaltype
import org apache hadoop hive metastore api skewedinfo
import org apache hadoop hive ql driver
import org apache hadoop hive ql errormsg
import org apache hadoop hive ql exec archiveutils
import org apache hadoop hive ql exec fetchtask
import org apache hadoop hive ql exec task
import org apache hadoop hive ql exec taskfactory
import org apache hadoop hive ql exec utilities
import org apache hadoop hive ql hooks readentity
import org apache hadoop hive ql hooks writeentity
import org apache hadoop hive ql index hiveindex
import org apache hadoop hive ql index hiveindex indextype
import org apache hadoop hive ql index hiveindexhandler
import org apache hadoop hive ql io ignorekeytextoutputformat
import org apache hadoop hive ql io rcfileinputformat
import org apache hadoop hive ql lib node
import org apache hadoop hive ql metadata hive
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata hiveutils
import org apache hadoop hive ql metadata partition
import org apache hadoop hive ql metadata table
import org apache hadoop hive ql plan addpartitiondesc
import org apache hadoop hive ql plan alterdatabasedesc
import org apache hadoop hive ql plan alterindexdesc
import org apache hadoop hive ql plan alterindexdesc alterindextypes
import org apache hadoop hive ql plan altertabledesc
import org apache hadoop hive ql plan altertabledesc altertabletypes
import org apache hadoop hive ql plan altertablesimpledesc
import org apache hadoop hive ql plan createdatabasedesc
import org apache hadoop hive ql plan createindexdesc
import org apache hadoop hive ql plan ddlwork
import org apache hadoop hive ql plan descdatabasedesc
import org apache hadoop hive ql plan descfunctiondesc
import org apache hadoop hive ql plan desctabledesc
import org apache hadoop hive ql plan dropdatabasedesc
import org apache hadoop hive ql plan dropindexdesc
import org apache hadoop hive ql plan droptabledesc
import org apache hadoop hive ql plan fetchwork
import org apache hadoop hive ql plan grantdesc
import org apache hadoop hive ql plan grantrevokeroleddl
import org apache hadoop hive ql plan loadtabledesc
import org apache hadoop hive ql plan locktabledesc
import org apache hadoop hive ql plan movework
import org apache hadoop hive ql plan msckdesc
import org apache hadoop hive ql plan partitionspec
import org apache hadoop hive ql plan planutils
import org apache hadoop hive ql plan principaldesc
import org apache hadoop hive ql plan privilegedesc
import org apache hadoop hive ql plan privilegeobjectdesc
import org apache hadoop hive ql plan renamepartitiondesc
import org apache hadoop hive ql plan revokedesc
import org apache hadoop hive ql plan roleddldesc
import org apache hadoop hive ql plan showcolumnsdesc
import org apache hadoop hive ql plan showcreatetabledesc
import org apache hadoop hive ql plan showdatabasesdesc
import org apache hadoop hive ql plan showfunctionsdesc
import org apache hadoop hive ql plan showgrantdesc
import org apache hadoop hive ql plan showindexesdesc
import org apache hadoop hive ql plan showlocksdesc
import org apache hadoop hive ql plan showpartitionsdesc
import org apache hadoop hive ql plan showtablestatusdesc
import org apache hadoop hive ql plan showtablesdesc
import org apache hadoop hive ql plan showtblpropertiesdesc
import org apache hadoop hive ql plan statswork
import org apache hadoop hive ql plan switchdatabasedesc
import org apache hadoop hive ql plan tabledesc
import org apache hadoop hive ql plan unlocktabledesc
import org apache hadoop hive ql security authorization privilege
import org apache hadoop hive ql security authorization privilegeregistry
import org apache hadoop hive ql session sessionstate
import org apache hadoop hive serde serdeconstants
import org apache hadoop hive serde2 lazy lazysimpleserde
import org apache hadoop mapred inputformat
import org apache hadoop mapred textinputformat
/**
* ddlsemanticanalyzer.
*
*/
public class ddlsemanticanalyzer extends basesemanticanalyzer
private static final log log   logfactory getlog ddlsemanticanalyzer class
private static final map<integer  string> tokentotypename   new hashmap<integer  string>
private final set<string> reservedpartitionvalues
static
tokentotypename put hiveparser tok_boolean  serdeconstants boolean_type_name
tokentotypename put hiveparser tok_tinyint  serdeconstants tinyint_type_name
tokentotypename put hiveparser tok_smallint  serdeconstants smallint_type_name
tokentotypename put hiveparser tok_int  serdeconstants int_type_name
tokentotypename put hiveparser tok_bigint  serdeconstants bigint_type_name
tokentotypename put hiveparser tok_float  serdeconstants float_type_name
tokentotypename put hiveparser tok_double  serdeconstants double_type_name
tokentotypename put hiveparser tok_string  serdeconstants string_type_name
tokentotypename put hiveparser tok_binary  serdeconstants binary_type_name
tokentotypename put hiveparser tok_date  serdeconstants date_type_name
tokentotypename put hiveparser tok_datetime  serdeconstants datetime_type_name
tokentotypename put hiveparser tok_timestamp  serdeconstants timestamp_type_name
public static string gettypename int token  throws semanticexception
// date and datetime types aren't currently supported
if  token    hiveparser tok_date    token    hiveparser tok_datetime
throw new semanticexception errormsg unsupported_type getmsg
return tokentotypename get token
static class tablepartition
string tablename
hashmap<string  string> partspec   null
public tablepartition
public tablepartition astnode tblpart  throws semanticexception
tablename   unescapeidentifier tblpart getchild 0  gettext
if  tblpart getchildcount   > 1
astnode part    astnode  tblpart getchild 1
if  part gettoken   gettype      hiveparser tok_partspec
this partspec   ddlsemanticanalyzer getpartspec part
public ddlsemanticanalyzer hiveconf conf  throws semanticexception
super conf
reservedpartitionvalues   new hashset<string>
// partition can't have this name
reservedpartitionvalues add hiveconf getvar conf  confvars defaultpartitionname
reservedpartitionvalues add hiveconf getvar conf  confvars default_zookeeper_partition_name
// partition value can't end in this suffix
reservedpartitionvalues add hiveconf getvar conf  confvars metastore_int_original
reservedpartitionvalues add hiveconf getvar conf  confvars metastore_int_archived
reservedpartitionvalues add hiveconf getvar conf  confvars metastore_int_extracted
@override
public void analyzeinternal astnode ast  throws semanticexception
switch  ast gettoken   gettype
case hiveparser tok_altertable_partition
astnode tablepart    astnode  ast getchild 0
tablepartition tblpart   new tablepartition tablepart
string tablename   tblpart tablename
hashmap<string  string> partspec   tblpart partspec
ast    astnode  ast getchild 1
if  ast gettoken   gettype      hiveparser tok_altertable_fileformat
analyzealtertablefileformat ast  tablename  partspec
else if  ast gettoken   gettype      hiveparser tok_altertable_alterparts_protectmode
analyzealtertableprotectmode ast  tablename  partspec
else if  ast gettoken   gettype      hiveparser tok_altertable_location
analyzealtertablelocation ast  tablename  partspec
else if  ast gettoken   gettype      hiveparser tok_altertable_alterparts_mergefiles
analyzealtertablepartmergefiles tablepart  ast  tablename  partspec
else if  ast gettoken   gettype      hiveparser tok_altertable_serializer
analyzealtertableserde ast  tablename  partspec
else if  ast gettoken   gettype      hiveparser tok_altertable_serdeproperties
analyzealtertableserdeprops ast  tablename  partspec
else if  ast gettoken   gettype      hiveparser tok_altertable_renamepart
analyzealtertablerenamepart ast  tablename  partspec
else if  ast gettoken   gettype      hiveparser tok_altertblpart_skewed_location
analyzealtertableskewedlocation ast  tablename  partspec
break
case hiveparser tok_droptable
analyzedroptable ast  false
break
case hiveparser tok_createindex
analyzecreateindex ast
break
case hiveparser tok_dropindex
analyzedropindex ast
break
case hiveparser tok_desctable
ctx setresfile new path ctx getlocaltmpfileuri
analyzedescribetable ast
break
case hiveparser tok_showdatabases
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowdatabases ast
break
case hiveparser tok_showtables
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowtables ast
break
case hiveparser tok_showcolumns
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowcolumns ast
break
case hiveparser tok_show_tablestatus
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowtablestatus ast
break
case hiveparser tok_show_tblproperties
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowtableproperties ast
break
case hiveparser tok_showfunctions
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowfunctions ast
break
case hiveparser tok_showlocks
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowlocks ast
break
case hiveparser tok_descfunction
ctx setresfile new path ctx getlocaltmpfileuri
analyzedescfunction ast
break
case hiveparser tok_descdatabase
ctx setresfile new path ctx getlocaltmpfileuri
analyzedescdatabase ast
break
case hiveparser tok_msck
ctx setresfile new path ctx getlocaltmpfileuri
analyzemetastorecheck ast
break
case hiveparser tok_dropview
analyzedroptable ast  true
break
case hiveparser tok_alterview_properties
analyzealtertableprops ast  true
break
case hiveparser tok_alterview_addparts
// for alter view add partition, we wrapped the add to discriminate
// view from table; unwrap it now
analyzealtertableaddparts  astnode  ast getchild 0   true
break
case hiveparser tok_alterview_dropparts
// for alter view drop partition, we wrapped the drop to discriminate
// view from table; unwrap it now
analyzealtertabledropparts  astnode  ast getchild 0   true
break
case hiveparser tok_alterview_rename
// for alter view rename, we wrapped the rename to discriminate
// view from table; unwrap it now
analyzealtertablerename   astnode  ast getchild 0    true
break
case hiveparser tok_altertable_rename
analyzealtertablerename ast  false
break
case hiveparser tok_altertable_touch
analyzealtertabletouch ast
break
case hiveparser tok_altertable_archive
analyzealtertablearchive ast  false
break
case hiveparser tok_altertable_unarchive
analyzealtertablearchive ast  true
break
case hiveparser tok_altertable_addcols
analyzealtertablemodifycols ast  altertabletypes addcols
break
case hiveparser tok_altertable_replacecols
analyzealtertablemodifycols ast  altertabletypes replacecols
break
case hiveparser tok_altertable_renamecol
analyzealtertablerenamecol ast
break
case hiveparser tok_altertable_addparts
analyzealtertableaddparts ast  false
break
case hiveparser tok_altertable_dropparts
analyzealtertabledropparts ast  false
break
case hiveparser tok_altertable_properties
analyzealtertableprops ast  false
break
case hiveparser tok_altertable_cluster_sort
analyzealtertableclustersort ast
break
case hiveparser tok_alterindex_rebuild
analyzealterindexrebuild ast
break
case hiveparser tok_alterindex_properties
analyzealterindexprops ast
break
case hiveparser tok_showpartitions
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowpartitions ast
break
case hiveparser tok_show_createtable
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowcreatetable ast
break
case hiveparser tok_showindexes
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowindexes ast
break
case hiveparser tok_locktable
analyzelocktable ast
break
case hiveparser tok_unlocktable
analyzeunlocktable ast
break
case hiveparser tok_createdatabase
analyzecreatedatabase ast
break
case hiveparser tok_dropdatabase
analyzedropdatabase ast
break
case hiveparser tok_switchdatabase
analyzeswitchdatabase ast
break
case hiveparser tok_alterdatabase_properties
analyzealterdatabase ast
break
case hiveparser tok_createrole
analyzecreaterole ast
break
case hiveparser tok_droprole
analyzedroprole ast
break
case hiveparser tok_show_role_grant
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowrolegrant ast
break
case hiveparser tok_grant_role
analyzegrantrevokerole true  ast
break
case hiveparser tok_revoke_role
analyzegrantrevokerole false  ast
break
case hiveparser tok_grant
analyzegrant ast
break
case hiveparser tok_show_grant
ctx setresfile new path ctx getlocaltmpfileuri
analyzeshowgrant ast
break
case hiveparser tok_revoke
analyzerevoke ast
break
case hiveparser tok_altertable_skewed
analyzealtertableskewedby ast
break
default
throw new semanticexception
private void analyzegrantrevokerole boolean grant  astnode ast
list<principaldesc> principaldesc   analyzeprincipallistdef
astnode  ast getchild 0
list<string> roles   new arraylist<string>
for  int i   1  i < ast getchildcount    i
roles add unescapeidentifier ast getchild i  gettext
string roleownername
if  sessionstate get      null
sessionstate get   getauthenticator      null
roleownername   sessionstate get   getauthenticator   getusername
grantrevokeroleddl grantrevokeroleddl   new grantrevokeroleddl grant
roles  principaldesc  roleownername  principaltype user  true
roottasks add taskfactory get new ddlwork getinputs    getoutputs
grantrevokeroleddl   conf
private void analyzeshowgrant astnode ast  throws semanticexception
privilegeobjectdesc privhiveobj   null
astnode principal    astnode  ast getchild 0
principaltype type   principaltype user
switch  principal gettype
case hiveparser tok_user
type   principaltype user
break
case hiveparser tok_group
type   principaltype group
break
case hiveparser tok_role
type   principaltype role
break
string principalname   unescapeidentifier principal getchild 0  gettext
principaldesc principaldesc   new principaldesc principalname  type
list<string> cols   null
if  ast getchildcount   > 1
astnode child    astnode  ast getchild 1
if  child gettoken   gettype      hiveparser tok_priv_object_col
privhiveobj   new privilegeobjectdesc
privhiveobj setobject unescapeidentifier child getchild 0  gettext
if  child getchildcount   > 1
for  int i   1  i < child getchildcount    i
astnode grandchild    astnode  child getchild i
if  grandchild gettoken   gettype      hiveparser tok_partspec
privhiveobj setpartspec ddlsemanticanalyzer getpartspec grandchild
else if  grandchild gettoken   gettype      hiveparser tok_tabcolname
cols   getcolumnnames  astnode  grandchild
else
privhiveobj settable child getchild i     null
if  privhiveobj    null    cols    null
throw new semanticexception
cols tostring
showgrantdesc showgrant   new showgrantdesc ctx getresfile   tostring
principaldesc  privhiveobj  cols
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showgrant   conf
private void analyzegrant astnode ast  throws semanticexception
list<privilegedesc> privilegedesc   analyzeprivilegelistdef
astnode  ast getchild 0
list<principaldesc> principaldesc   analyzeprincipallistdef
astnode  ast getchild 1
boolean grantoption   false
privilegeobjectdesc privilegeobj   null
if  ast getchildcount   > 2
for  int i   2  i < ast getchildcount    i
astnode astchild    astnode  ast getchild i
if  astchild gettype      hiveparser tok_grant_with_option
grantoption   true
else if  astchild gettype      hiveparser tok_priv_object
privilegeobj   analyzeprivilegeobject astchild  getoutputs
string username   null
if  sessionstate get      null
sessionstate get   getauthenticator      null
username   sessionstate get   getauthenticator   getusername
grantdesc grantdesc   new grantdesc privilegeobj  privilegedesc
principaldesc  username  principaltype user  grantoption
roottasks add taskfactory get new ddlwork getinputs    getoutputs
grantdesc   conf
private void analyzerevoke astnode ast  throws semanticexception
list<privilegedesc> privilegedesc   analyzeprivilegelistdef
astnode  ast getchild 0
list<principaldesc> principaldesc   analyzeprincipallistdef
astnode  ast getchild 1
privilegeobjectdesc hiveobj   null
if  ast getchildcount   > 2
astnode astchild    astnode  ast getchild 2
hiveobj   analyzeprivilegeobject astchild  getoutputs
revokedesc revokedesc   new revokedesc privilegedesc  principaldesc  hiveobj
roottasks add taskfactory get new ddlwork getinputs    getoutputs
revokedesc   conf
private privilegeobjectdesc analyzeprivilegeobject astnode ast
hashset<writeentity> outputs
throws semanticexception
privilegeobjectdesc subject   new privilegeobjectdesc
subject setobject unescapeidentifier ast getchild 0  gettext
if  ast getchildcount   > 1
for  int i   0  i < ast getchildcount    i
astnode astchild    astnode  ast getchild i
if  astchild gettoken   gettype      hiveparser tok_partspec
subject setpartspec ddlsemanticanalyzer getpartspec astchild
else
subject settable ast getchild 0     null
try
if  subject gettable
table tbl   db gettable subject getobject
if  subject getpartspec      null
partition part   db getpartition tbl  subject getpartspec    false
outputs add new writeentity part
else
outputs add new writeentity tbl
catch  hiveexception e
throw new semanticexception e
return subject
private list<principaldesc> analyzeprincipallistdef astnode node
list<principaldesc> principallist   new arraylist<principaldesc>
for  int i   0  i < node getchildcount    i
astnode child    astnode  node getchild i
principaltype type   null
switch  child gettype
case hiveparser tok_user
type   principaltype user
break
case hiveparser tok_group
type   principaltype group
break
case hiveparser tok_role
type   principaltype role
break
string principalname   unescapeidentifier child getchild 0  gettext
principaldesc principaldesc   new principaldesc principalname  type
principallist add principaldesc
return principallist
private list<privilegedesc> analyzeprivilegelistdef astnode node
throws semanticexception
list<privilegedesc> ret   new arraylist<privilegedesc>
for  int i   0  i < node getchildcount    i
astnode privilegedef    astnode  node getchild i
astnode privilegetype    astnode  privilegedef getchild 0
privilege privobj   privilegeregistry getprivilege privilegetype gettype
if  privobj    null
throw new semanticexception     privilegetype gettype
list<string> cols   null
if  privilegedef getchildcount   > 1
cols   getcolumnnames  astnode  privilegedef getchild 1
privilegedesc privilegedesc   new privilegedesc privobj  cols
ret add privilegedesc
return ret
private void analyzecreaterole astnode ast
string rolename   unescapeidentifier ast getchild 0  gettext
roleddldesc createroledesc   new roleddldesc rolename
roleddldesc roleoperation create_role
roottasks add taskfactory get new ddlwork getinputs    getoutputs
createroledesc   conf
private void analyzedroprole astnode ast
string rolename   unescapeidentifier ast getchild 0  gettext
roleddldesc createroledesc   new roleddldesc rolename
roleddldesc roleoperation drop_role
roottasks add taskfactory get new ddlwork getinputs    getoutputs
createroledesc   conf
private void analyzeshowrolegrant astnode ast
astnode child    astnode  ast getchild 0
principaltype principaltype   principaltype user
switch  child gettype
case hiveparser tok_user
principaltype   principaltype user
break
case hiveparser tok_group
principaltype   principaltype group
break
case hiveparser tok_role
principaltype   principaltype role
break
string principalname   unescapeidentifier child getchild 0  gettext
roleddldesc createroledesc   new roleddldesc principalname  principaltype
roleddldesc roleoperation show_role_grant  null
createroledesc setresfile ctx getresfile   tostring
roottasks add taskfactory get new ddlwork getinputs    getoutputs
createroledesc   conf
private void analyzealterdatabase astnode ast  throws semanticexception
string dbname   unescapeidentifier ast getchild 0  gettext
map<string  string> dbprops   null
for  int i   1  i < ast getchildcount    i
astnode childnode    astnode  ast getchild i
switch  childnode gettoken   gettype
case hiveparser tok_databaseproperties
dbprops   ddlsemanticanalyzer getprops  astnode  childnode getchild 0
break
default
throw new semanticexception
// currently alter database command can only change properties
alterdatabasedesc alterdesc   new alterdatabasedesc dbname  null  null  false
alterdesc setdatabaseproperties dbprops
roottasks add taskfactory get new ddlwork getinputs    getoutputs    alterdesc
conf
private void analyzecreatedatabase astnode ast  throws semanticexception
string dbname   unescapeidentifier ast getchild 0  gettext
boolean ifnotexists   false
string dbcomment   null
string dblocation   null
map<string  string> dbprops   null
for  int i   1  i < ast getchildcount    i
astnode childnode    astnode  ast getchild i
switch  childnode gettoken   gettype
case hiveparser tok_ifnotexists
ifnotexists   true
break
case hiveparser tok_databasecomment
dbcomment   unescapesqlstring childnode getchild 0  gettext
break
case tok_databaseproperties
dbprops   ddlsemanticanalyzer getprops  astnode  childnode getchild 0
break
case tok_databaselocation
dblocation   unescapesqlstring childnode getchild 0  gettext
break
default
throw new semanticexception
createdatabasedesc createdatabasedesc
new createdatabasedesc dbname  dbcomment  dblocation  ifnotexists
if  dbprops    null
createdatabasedesc setdatabaseproperties dbprops
roottasks add taskfactory get new ddlwork getinputs    getoutputs
createdatabasedesc   conf
private void analyzedropdatabase astnode ast  throws semanticexception
string dbname   unescapeidentifier ast getchild 0  gettext
boolean ifexists   false
boolean ifcascade   false
if  null    ast getfirstchildwithtype hiveparser tok_ifexists
ifexists   true
if  null    ast getfirstchildwithtype hiveparser tok_cascade
ifcascade   true
dropdatabasedesc dropdatabasedesc   new dropdatabasedesc dbname  ifexists  ifcascade
roottasks add taskfactory get new ddlwork getinputs    getoutputs    dropdatabasedesc   conf
private void analyzeswitchdatabase astnode ast
string dbname   unescapeidentifier ast getchild 0  gettext
switchdatabasedesc switchdatabasedesc   new switchdatabasedesc dbname
roottasks add taskfactory get new ddlwork getinputs    getoutputs
switchdatabasedesc   conf
private void analyzedroptable astnode ast  boolean expectview
throws semanticexception
string tablename   getunescapedname  astnode  ast getchild 0
boolean ifexists    ast getfirstchildwithtype hiveparser tok_ifexists     null
// we want to signal an error if the table/view doesn't exist and we're
// configured not to fail silently
boolean throwexception
ifexists     hiveconf getboolvar conf  confvars dropignoresnonexistent
try
table tab   db gettable db getcurrentdatabase    tablename  throwexception
if  tab    null
inputs add new readentity tab
outputs add new writeentity tab
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tablename
droptabledesc droptbldesc   new droptabledesc
tablename  expectview  ifexists  true
roottasks add taskfactory get new ddlwork getinputs    getoutputs
droptbldesc   conf
private void analyzecreateindex astnode ast  throws semanticexception
string indexname   unescapeidentifier ast getchild 0  gettext
string typename   unescapesqlstring ast getchild 1  gettext
string tablename   getunescapedname  astnode  ast getchild 2
list<string> indexedcols   getcolumnnames  astnode  ast getchild 3
indextype indextype   hiveindex getindextype typename
if  indextype    null
typename   indextype gethandlerclsname
else
try
class forname typename
catch  exception e
throw new semanticexception    e
string indextablename   null
boolean deferredrebuild   false
string location   null
map<string  string> tblprops   null
map<string  string> idxprops   null
string indexcomment   null
rowformatparams rowformatparams   new rowformatparams
storageformat storageformat   new storageformat
analyzecreatecommonvars shared   new analyzecreatecommonvars
for  int idx   4  idx < ast getchildcount    idx
astnode child    astnode  ast getchild idx
if  storageformat fillstorageformat child  shared
continue
switch  child gettoken   gettype
case hiveparser tok_tablerowformat
rowformatparams analyzerowformat shared  child
break
case hiveparser tok_createindex_indextblname
astnode ch    astnode  child getchild 0
indextablename   getunescapedname  astnode  ch
break
case hiveparser tok_deferred_rebuildindex
deferredrebuild   true
break
case hiveparser tok_tablelocation
location   unescapesqlstring child getchild 0  gettext
break
case hiveparser tok_tableproperties
tblprops   ddlsemanticanalyzer getprops  astnode  child getchild 0
break
case hiveparser tok_indexproperties
idxprops   ddlsemanticanalyzer getprops  astnode  child getchild 0
break
case hiveparser tok_tableserializer
child    astnode  child getchild 0
shared serde   unescapesqlstring child getchild 0  gettext
if  child getchildcount      2
readprops  astnode   child getchild 1  getchild 0
shared serdeprops
break
case hiveparser tok_indexcomment
child    astnode  child getchild 0
indexcomment   unescapesqlstring child gettext
storageformat filldefaultstorageformat shared
createindexdesc crtindexdesc   new createindexdesc tablename  indexname
indexedcols  indextablename  deferredrebuild  storageformat inputformat
storageformat outputformat
storageformat storagehandler  typename  location  idxprops  tblprops
shared serde  shared serdeprops  rowformatparams collitemdelim
rowformatparams fielddelim  rowformatparams fieldescape
rowformatparams linedelim  rowformatparams mapkeydelim  indexcomment
task<?> createindex
taskfactory get new ddlwork getinputs    getoutputs    crtindexdesc   conf
roottasks add createindex
private void analyzedropindex astnode ast  throws semanticexception
string indexname   unescapeidentifier ast getchild 0  gettext
string tablename   getunescapedname  astnode  ast getchild 1
boolean ifexists    ast getfirstchildwithtype hiveparser tok_ifexists     null
// we want to signal an error if the index doesn't exist and we're
// configured not to ignore this
boolean throwexception
ifexists     hiveconf getboolvar conf  confvars dropignoresnonexistent
if  throwexception
try
index idx   db getindex tablename  indexname
catch  hiveexception e
throw new semanticexception errormsg invalid_index getmsg indexname
dropindexdesc dropidxdesc   new dropindexdesc indexname  tablename
roottasks add taskfactory get new ddlwork getinputs    getoutputs
dropidxdesc   conf
private void analyzealterindexrebuild astnode ast  throws semanticexception
string basetablename   unescapeidentifier ast getchild 0  gettext
string indexname   unescapeidentifier ast getchild 1  gettext
hashmap<string  string> partspec   null
tree part   ast getchild 2
if  part    null
partspec   extractpartitionspecs part
list<task<?>> indexbuilder   getindexbuildermapred basetablename  indexname  partspec
roottasks addall indexbuilder
// handle updating index timestamps
alterindexdesc alteridxdesc   new alterindexdesc alterindextypes updatetimestamp
alteridxdesc setindexname indexname
alteridxdesc setbasetablename basetablename
alteridxdesc setdbname db getcurrentdatabase
alteridxdesc setspec partspec
task<?> tstask   taskfactory get new ddlwork alteridxdesc   conf
for  task<?> t   indexbuilder
t adddependenttask tstask
private void analyzealterindexprops astnode ast
throws semanticexception
string basetablename   getunescapedname  astnode  ast getchild 0
string indexname   unescapeidentifier ast getchild 1  gettext
hashmap<string  string> mapprop   getprops  astnode   ast getchild 2
getchild 0
alterindexdesc alteridxdesc
new alterindexdesc alterindextypes addprops
alteridxdesc setprops mapprop
alteridxdesc setindexname indexname
alteridxdesc setbasetablename basetablename
alteridxdesc setdbname db getcurrentdatabase
roottasks add taskfactory get new ddlwork alteridxdesc   conf
private list<task<?>> getindexbuildermapred string basetablename  string indexname
hashmap<string  string> partspec  throws semanticexception
try
string dbname   db getcurrentdatabase
index index   db getindex dbname  basetablename  indexname
table indextbl   db gettable dbname  index getindextablename
string basetblname   index getorigtablename
table basetbl   db gettable dbname  basetblname
string handlercls   index getindexhandlerclass
hiveindexhandler handler   hiveutils getindexhandler conf  handlercls
list<partition> indextblpartitions   null
list<partition> basetblpartitions   null
if  indextbl    null
indextblpartitions   new arraylist<partition>
basetblpartitions   preparepartitions basetbl  partspec
indextbl  db  indextblpartitions
list<task<?>> ret   handler generateindexbuildtasklist basetbl
index  indextblpartitions  basetblpartitions  indextbl  getinputs    getoutputs
return ret
catch  exception e
throw new semanticexception e
private list<partition> preparepartitions
org apache hadoop hive ql metadata table basetbl
hashmap<string  string> partspec
org apache hadoop hive ql metadata table indextbl  hive db
list<partition> indextblpartitions
throws hiveexception  metaexception
list<partition> basetblpartitions   new arraylist<partition>
if  partspec    null
// if partspec is specified, then only producing index for that
// partition
partition part   db getpartition basetbl  partspec  false
if  part    null
throw new hiveexception
warehouse makepartname partspec  false
basetbl gettablename
basetblpartitions add part
partition indexpart   db getpartition indextbl  partspec  false
if  indexpart    null
indexpart   db createpartition indextbl  partspec
indextblpartitions add indexpart
else if  basetbl ispartitioned
// if no partition is specified, create indexes for all partitions one
// by one.
basetblpartitions   db getpartitions basetbl
for  partition basepart   basetblpartitions
hashmap<string  string> pspec   basepart getspec
partition indexpart   db getpartition indextbl  pspec  false
if  indexpart    null
indexpart   db createpartition indextbl  pspec
indextblpartitions add indexpart
return basetblpartitions
private void validatealtertabletype table tbl  altertabletypes op  throws semanticexception
validatealtertabletype tbl  op  false
private void validatealtertabletype table tbl  altertabletypes op  boolean expectview
throws semanticexception
if  tbl isview
if   expectview
throw new semanticexception errormsg alter_command_for_views getmsg
switch  op
case addpartition
case droppartition
case renamepartition
case addprops
case rename
// allow this form
break
default
throw new semanticexception errormsg alter_view_disallowed_op getmsg op tostring
else
if  expectview
throw new semanticexception errormsg alter_command_for_tables getmsg
if  tbl isnonnative
throw new semanticexception errormsg alter_table_non_native getmsg tbl gettablename
private void analyzealtertableprops astnode ast  boolean expectview
throws semanticexception
string tablename   getunescapedname  astnode  ast getchild 0
hashmap<string  string> mapprop   getprops  astnode   ast getchild 1
getchild 0
altertabledesc altertbldesc
new altertabledesc altertabletypes addprops  expectview
altertbldesc setprops mapprop
altertbldesc setoldname tablename
addinputsoutputsaltertable tablename  null  altertbldesc
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
private void analyzealtertableserdeprops astnode ast  string tablename
hashmap<string  string> partspec
throws semanticexception
hashmap<string  string> mapprop   getprops  astnode   ast getchild 0
getchild 0
altertabledesc altertbldesc   new altertabledesc
altertabletypes addserdeprops
altertbldesc setprops mapprop
altertbldesc setoldname tablename
altertbldesc setpartspec partspec
addinputsoutputsaltertable tablename  partspec  altertbldesc
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
private void analyzealtertableserde astnode ast  string tablename
hashmap<string  string> partspec
throws semanticexception
string serdename   unescapesqlstring ast getchild 0  gettext
altertabledesc altertbldesc   new altertabledesc altertabletypes addserde
if  ast getchildcount   > 1
hashmap<string  string> mapprop   getprops  astnode   ast getchild 1
getchild 0
altertbldesc setprops mapprop
altertbldesc setoldname tablename
altertbldesc setserdename serdename
altertbldesc setpartspec partspec
addinputsoutputsaltertable tablename  partspec  altertbldesc
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
private void analyzealtertablefileformat astnode ast  string tablename
hashmap<string  string> partspec
throws semanticexception
string inputformat   null
string outputformat   null
string storagehandler   null
string serde   null
astnode child    astnode  ast getchild 0
switch  child gettoken   gettype
case hiveparser tok_tablefileformat
inputformat   unescapesqlstring   astnode  child getchild 0   gettoken
gettext
outputformat   unescapesqlstring   astnode  child getchild 1   gettoken
gettext
try
class forname inputformat
class forname outputformat
catch  classnotfoundexception e
throw new semanticexception e
break
case hiveparser tok_storagehandler
storagehandler
unescapesqlstring   astnode  child getchild 1   gettoken   gettext
try
class forname storagehandler
catch  classnotfoundexception e
throw new semanticexception e
break
case hiveparser tok_tblsequencefile
inputformat   sequencefile_input
outputformat   sequencefile_output
break
case hiveparser tok_tbltextfile
inputformat   textfile_input
outputformat   textfile_output
break
case hiveparser tok_tblrcfile
inputformat   rcfile_input
outputformat   rcfile_output
serde   columnar_serde
break
case hiveparser tok_fileformat_generic
handlegenericfileformat child
break
altertabledesc altertbldesc   new altertabledesc tablename  inputformat
outputformat  serde  storagehandler  partspec
addinputsoutputsaltertable tablename  partspec  altertbldesc
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
private void addinputsoutputsaltertable string tablename  hashmap<string  string> partspec
throws semanticexception
addinputsoutputsaltertable tablename  partspec  null
private void addinputsoutputsaltertable string tablename  hashmap<string  string> partspec
altertabledesc desc  throws semanticexception
table tab   null
try
tab   db gettable db getcurrentdatabase    tablename  true
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tablename
inputs add new readentity tab
if   partspec    null      partspec isempty
outputs add new writeentity tab
else
list<partition> allpartitions   null
try
if  desc    null    desc getop      altertabledesc altertabletypes alterprotectmode
partition part   db getpartition tab  partspec  false
allpartitions   new arraylist<partition> 1
allpartitions add part
else
allpartitions   db getpartitions tab  partspec
if  allpartitions    null    allpartitions size      0
throw new semanticexception errormsg invalid_partition getmsg partspec tostring
catch  hiveexception e
throw new semanticexception errormsg invalid_partition getmsg partspec tostring     e
if  allpartitions    null
for  partition part   allpartitions
outputs add new writeentity part
if  desc    null
validatealtertabletype tab  desc getop    desc getexpectview
private void analyzealtertablelocation astnode ast  string tablename
hashmap<string  string> partspec  throws semanticexception
string newlocation   unescapesqlstring ast getchild 0  gettext
altertabledesc altertbldesc   new altertabledesc tablename  newlocation  partspec
addinputsoutputsaltertable tablename  partspec  altertbldesc
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
private void analyzealtertableprotectmode astnode ast  string tablename
hashmap<string  string> partspec
throws semanticexception
altertabledesc altertbldesc
new altertabledesc altertabletypes alterprotectmode
altertbldesc setoldname tablename
altertbldesc setpartspec partspec
astnode child    astnode  ast getchild 0
switch  child gettoken   gettype
case hiveparser tok_enable
altertbldesc setprotectmodeenable true
break
case hiveparser tok_disable
altertbldesc setprotectmodeenable false
break
default
throw new semanticexception
astnode grandchild    astnode  child getchild 0
switch  grandchild gettoken   gettype
case hiveparser tok_offline
altertbldesc setprotectmodetype altertabledesc protectmodetype offline
break
case hiveparser tok_no_drop
if  grandchild getchildcount   > 0
altertbldesc setprotectmodetype altertabledesc protectmodetype no_drop_cascade
else
altertbldesc setprotectmodetype altertabledesc protectmodetype no_drop
break
case hiveparser tok_readonly
throw new semanticexception
default
throw new semanticexception
addinputsoutputsaltertable tablename  partspec  altertbldesc
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
private void analyzealtertablepartmergefiles astnode tablepartast  astnode ast
string tablename  hashmap<string  string> partspec
throws semanticexception
altertablepartmergefilesdesc mergedesc   new altertablepartmergefilesdesc
tablename  partspec
list<string> inputdir   new arraylist<string>
path oldtblpartloc   null
path newtblpartloc   null
table tblobj   null
try
tblobj   db gettable tablename
list<string> bucketcols   null
class<? extends inputformat> inputformatclass   null
boolean isarchived   false
boolean checkindex   hiveconf getboolvar conf
hiveconf confvars hive_concatenate_check_index
if  checkindex
list<index> indexes   db getindexes tblobj getdbname    tablename
short max_value
if  indexes    null    indexes size   > 0
throw new semanticexception
tablename
if  tblobj ispartitioned
if  partspec    null
throw new semanticexception     tablename
else
partition part   db getpartition tblobj  partspec  false
if  part    null
throw new semanticexception     tablename
bucketcols   part getbucketcols
inputformatclass   part getinputformatclass
isarchived   archiveutils isarchived part
path tabpath   tblobj getpath
path partpath   part getpartitionpath
// if the table is in a different dfs than the partition,
// replace the partition's dfs with the table's dfs.
newtblpartloc   new path tabpath touri   getscheme    tabpath touri
getauthority    partpath touri   getpath
oldtblpartloc   partpath
else
inputformatclass   tblobj getinputformatclass
bucketcols   tblobj getbucketcols
// input and output are the same
oldtblpartloc   tblobj getpath
newtblpartloc   tblobj getpath
// throw a hiveexception for non-rcfile.
if   inputformatclass equals rcfileinputformat class
throw new semanticexception
// throw a hiveexception if the table/partition is bucketized
if  bucketcols    null    bucketcols size   > 0
throw new semanticexception
// throw a hiveexception if the table/partition is archived
if  isarchived
throw new semanticexception
inputdir add oldtblpartloc tostring
mergedesc setinputdir inputdir
addinputsoutputsaltertable tablename  partspec
ddlwork ddlwork   new ddlwork getinputs    getoutputs    mergedesc
ddlwork setneedlock true
task<? extends serializable> mergetask   taskfactory get ddlwork  conf
tabledesc tbldesc   utilities gettabledesc tblobj
string querytmpdir   ctx getexternaltmpfileuri newtblpartloc touri
mergedesc setoutputdir querytmpdir
loadtabledesc ltd   new loadtabledesc querytmpdir  querytmpdir  tbldesc
partspec    null ? new hashmap<string  string>     partspec
task<movework> movetsk   taskfactory get new movework null  null  ltd  null  false
conf
mergetask adddependenttask movetsk
if  conf getboolvar hiveconf confvars hivestatsautogather
statswork statdesc
if  oldtblpartloc equals newtblpartloc
// if we're merging to the same location, we can avoid some metastore calls
tablespec tablepart   new tablespec this db  conf  tablepartast
statdesc   new statswork tablepart
else
statdesc   new statswork ltd
statdesc setnostatsaggregator true
statdesc setstatsreliable conf getboolvar hiveconf confvars hive_stats_reliable
task<? extends serializable> stattask   taskfactory get statdesc  conf
movetsk adddependenttask stattask
roottasks add mergetask
catch  exception e
throw new semanticexception e
private void analyzealtertableclustersort astnode ast
throws semanticexception
string tablename   getunescapedname  astnode  ast getchild 0
table tab   null
try
tab   db gettable db getcurrentdatabase    tablename  true
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tablename
inputs add new readentity tab
outputs add new writeentity tab
validatealtertabletype tab  altertabletypes addclustersortcolumn
if  ast getchildcount      1
// this means that we want to turn off bucketing
altertabledesc altertbldesc   new altertabledesc tablename   1
new arraylist<string>    new arraylist<order>
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
else
astnode buckets    astnode  ast getchild 1
list<string> bucketcols   getcolumnnames  astnode  buckets getchild 0
list<order> sortcols   new arraylist<order>
int numbuckets    1
if  buckets getchildcount      2
numbuckets    integer valueof buckets getchild 1  gettext     intvalue
else
sortcols   getcolumnnamesorder  astnode  buckets getchild 1
numbuckets    integer valueof buckets getchild 2  gettext     intvalue
if  numbuckets <  0
throw new semanticexception errormsg invalid_bucket_number getmsg
altertabledesc altertbldesc   new altertabledesc tablename  numbuckets
bucketcols  sortcols
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
static hashmap<string  string> getprops astnode prop
hashmap<string  string> mapprop   new hashmap<string  string>
readprops prop  mapprop
return mapprop
/**
* utility class to resolve qualifiedname
*/
static class qualifiednameutil
// delimiter to check dot delimited qualified names
static string delimiter
/**
* get the fully qualified name in the ast. e.g. the ast of the form ^(dot
* ^(dot a b) c) will generate a name of the form a.b.c
*
* @param ast
*          the ast from which the qualified name has to be extracted
* @return string
*/
static public string getfullyqualifiedname astnode ast
if  ast getchildcount      0
return ast gettext
else if  ast getchildcount      2
return getfullyqualifiedname  astnode  ast getchild 0
getfullyqualifiedname  astnode  ast getchild 1
else if  ast getchildcount      3
return getfullyqualifiedname  astnode  ast getchild 0
getfullyqualifiedname  astnode  ast getchild 1
getfullyqualifiedname  astnode  ast getchild 2
else
return null
// assume the first component of dot delimited name is tablename
// get the attempttablename
static public string getattempttablename hive db  string qualifiedname  boolean iscolumn
// check whether the name starts with table
// describe table
// describe table.column
// decribe table column
string tablename   qualifiedname substring 0
qualifiedname indexof        1 ?
qualifiedname length     qualifiedname indexof
try
table tab   db gettable tablename
if  tab    null
if  iscolumn
// if attempt to get columnpath
// return the whole qualifiedname(table.column or table)
return qualifiedname
else
// if attempt to get tablename
// return table
return tablename
catch  hiveexception e
// assume the first dot delimited component is tablename
// ok if it is not
// do nothing when having exception
return null
return null
// get database name
static public string getdbname hive db  astnode ast
string dbname   null
string fullyqualifiedname   getfullyqualifiedname ast
// if database.table or database.table.column or table.column
// first try the first component of the dot separated name
if  ast getchildcount   >  2
dbname   fullyqualifiedname substring 0
fullyqualifiedname indexof        1 ?
fullyqualifiedname length
fullyqualifiedname indexof
try
// if the database name is not valid
// it is table.column
// return null as dbname
if   db databaseexists dbname
return null
catch  hiveexception e
return null
else
// in other cases, return null
// database is not validated if null
return null
return dbname
// get table name
static public string gettablename hive db  astnode ast
throws semanticexception
string tablename   null
string fullyqualifiedname   getfullyqualifiedname ast
// assume the first component of dot delimited name is tablename
string attempttablename   getattempttablename db  fullyqualifiedname  false
if  attempttablename    null
return attempttablename
// if the name does not start with table
// it should start with database
// describe database.table
// describe database.table column
if  fullyqualifiedname split delimiter  length    3
// if describe database.table.column
// invalid syntax exception
if  ast getchildcount      2
throw new semanticexception errormsg invalid_table_or_column getmsg fullyqualifiedname
else
// if describe database.table column
// return database.table as tablename
tablename   fullyqualifiedname substring 0
fullyqualifiedname lastindexof
else if  fullyqualifiedname split delimiter  length    2
// if describe database.table
// return database.table as tablename
tablename   fullyqualifiedname
else
// if fullyqualifiedname only have one component
// it is an invalid table
throw new semanticexception errormsg invalid_table getmsg fullyqualifiedname
return tablename
// get column path
static public string getcolpath
hive db
astnode parentast
astnode ast
string tablename
map<string  string> partspec
// if parent has two children
// it could be describe table key
// or describe table partition
if  parentast getchildcount      2    partspec    null
// if partitionspec is null
// it is describe table key
// return table as columnpath
return getfullyqualifiedname parentast
// assume the first component of dot delimited name is tablename
string attempttablename   getattempttablename db  tablename  true
if  attempttablename    null
return attempttablename
// if the name does not start with table
// it should start with database
// describe database.table
// describe database.table column
if  tablename split delimiter  length    3
// if describe database.table column
// return table.column as column path
return tablename substring
tablename indexof      1  tablename length
// in other cases, column path is the same as tablename
return tablename
// get partition metadata
static public map<string  string> getpartitionspec hive db  astnode ast  string tablename
throws semanticexception
// if ast has two children
// it could be describe table key
// or describe table partition
// check whether it is describe table partition
if  ast getchildcount      2
astnode partnode    astnode  ast getchild 1
hashmap<string  string> partspec   null
try
partspec   getpartspec partnode
catch  semanticexception e
// get exception in resolving partition
// it could be describe table key
// return null
// continue processing for describe table key
return null
table tab   null
try
tab   db gettable tablename
catch  hiveexception e
// if table not valid
// throw semantic exception
throw new semanticexception errormsg invalid_table getmsg tablename   e
if  partspec    null
partition part   null
try
part   db getpartition tab  partspec  false
catch  hiveexception e
// if get exception in finding partition
// it could be describe table key
// return null
// continue processing for describe table key
return null
// if partition is not found
// it is describe table partition
// invalid partition exception
if  part    null
throw new semanticexception errormsg invalid_partition getmsg partspec tostring
// it is describe table partition
// return partition metadata
return partspec
return null
/**
* create a fetchtask for a given table and thrift ddl schema.
*
* @param tablename
*          tablename
* @param schema
*          thrift ddl
*/
private fetchtask createfetchtask string schema
properties prop   new properties
prop setproperty serdeconstants serialization_format
prop setproperty serdeconstants serialization_null_format
string coltypes   schema split
prop setproperty    coltypes
prop setproperty    coltypes
fetchwork fetch   new fetchwork ctx getresfile   tostring    new tabledesc
lazysimpleserde class  textinputformat class
ignorekeytextoutputformat class  prop    1
fetch setserializationnullformat
return  fetchtask  taskfactory get fetch  conf
private void validatedatabase string databasename  throws semanticexception
try
if   db databaseexists databasename
throw new semanticexception errormsg database_not_exists getmsg databasename
catch  hiveexception e
throw new semanticexception errormsg database_not_exists getmsg databasename   e
private void validatetable string tablename  map<string  string> partspec
throws semanticexception
table tab   null
try
tab   db gettable tablename
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tablename   e
if  partspec    null
partition part   null
try
part   db getpartition tab  partspec  false
catch  hiveexception e
throw new semanticexception errormsg invalid_partition getmsg partspec tostring     e
if  part    null
throw new semanticexception errormsg invalid_partition getmsg partspec tostring
private void analyzedescribetable astnode ast  throws semanticexception
astnode tabletypeexpr    astnode  ast getchild 0
string qualifiedname
qualifiednameutil getfullyqualifiedname  astnode  tabletypeexpr getchild 0
string tablename
qualifiednameutil gettablename db   astnode  tabletypeexpr getchild 0
string dbname
qualifiednameutil getdbname db   astnode  tabletypeexpr getchild 0
map<string  string> partspec
qualifiednameutil getpartitionspec db  tabletypeexpr  tablename
string colpath   qualifiednameutil getcolpath
db  tabletypeexpr   astnode  tabletypeexpr getchild 0   qualifiedname  partspec
// if database is not the one currently using
// validate database
if  dbname    null
validatedatabase dbname
if  partspec    null
validatetable tablename  partspec
desctabledesc desctbldesc   new desctabledesc
ctx getresfile    tablename  partspec  colpath
if  ast getchildcount      2
int descoptions   ast getchild 1  gettype
desctbldesc setformatted descoptions    hiveparser kw_formatted
desctbldesc setext descoptions    hiveparser kw_extended
roottasks add taskfactory get new ddlwork getinputs    getoutputs
desctbldesc   conf
setfetchtask createfetchtask desctabledesc getschema
log info
/**
* describe database.
*
* @param ast
* @throws semanticexception
*/
private void analyzedescdatabase astnode ast  throws semanticexception
boolean isextended
string dbname
if  ast getchildcount      1
dbname   stripquotes ast getchild 0  gettext
isextended   false
else if  ast getchildcount      2
dbname   stripquotes ast getchild 0  gettext
isextended   true
else
throw new semanticexception
descdatabasedesc descdbdesc   new descdatabasedesc ctx getresfile
dbname  isextended
roottasks add taskfactory get new ddlwork getinputs    getoutputs    descdbdesc   conf
setfetchtask createfetchtask descdbdesc getschema
private static hashmap<string  string> getpartspec astnode partspec
throws semanticexception
hashmap<string  string> partspec   new linkedhashmap<string  string>
for  int i   0  i < partspec getchildcount      i
astnode partspec_val    astnode  partspec getchild i
string val   stripquotes partspec_val getchild 1  gettext
partspec put partspec_val getchild 0  gettext   tolowercase    val
return partspec
private void analyzeshowpartitions astnode ast  throws semanticexception
showpartitionsdesc showpartsdesc
string tablename   getunescapedname  astnode  ast getchild 0
list<map<string  string>> partspecs   getpartitionspecs ast
// we only can have a single partition spec
assert  partspecs size   <  1
map<string  string> partspec   null
if  partspecs size   > 0
partspec   partspecs get 0
validatetable tablename  null
showpartsdesc   new showpartitionsdesc tablename  ctx getresfile    partspec
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showpartsdesc   conf
setfetchtask createfetchtask showpartsdesc getschema
private void analyzeshowcreatetable astnode ast  throws semanticexception
showcreatetabledesc showcreatetbldesc
string tablename   getunescapedname  astnode ast getchild 0
showcreatetbldesc   new showcreatetabledesc tablename  ctx getresfile   tostring
try
table tab   db gettable tablename  true
if  tab gettabletype      org apache hadoop hive metastore tabletype index_table
throw new semanticexception errormsg show_createtable_index getmsg tablename
inputs add new readentity tab
catch  semanticexception e
throw e
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tablename
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showcreatetbldesc   conf
setfetchtask createfetchtask showcreatetbldesc getschema
private void analyzeshowdatabases astnode ast  throws semanticexception
showdatabasesdesc showdatabasesdesc
if  ast getchildcount      1
string databasepattern   unescapesqlstring ast getchild 0  gettext
showdatabasesdesc   new showdatabasesdesc ctx getresfile    databasepattern
else
showdatabasesdesc   new showdatabasesdesc ctx getresfile
roottasks add taskfactory get new ddlwork getinputs    getoutputs    showdatabasesdesc   conf
setfetchtask createfetchtask showdatabasesdesc getschema
private void analyzeshowtables astnode ast  throws semanticexception
showtablesdesc showtblsdesc
string dbname   db getcurrentdatabase
string tablenames   null
if  ast getchildcount   > 3
throw new semanticexception errormsg generic_error getmsg
switch  ast getchildcount
case 1     uses a pattern
tablenames   unescapesqlstring ast getchild 0  gettext
showtblsdesc   new showtablesdesc ctx getresfile    dbname  tablenames
break
case 2     specifies a db
assert  ast getchild 0  gettype      hiveparser tok_from
dbname   unescapeidentifier ast getchild 1  gettext
validatedatabase dbname
showtblsdesc   new showtablesdesc ctx getresfile    dbname
break
case 3     uses a pattern and specifies a db
assert  ast getchild 0  gettype      hiveparser tok_from
dbname   unescapeidentifier ast getchild 1  gettext
tablenames   unescapesqlstring ast getchild 2  gettext
validatedatabase dbname
showtblsdesc   new showtablesdesc ctx getresfile    dbname  tablenames
break
default     no pattern or db
showtblsdesc   new showtablesdesc ctx getresfile    dbname
break
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showtblsdesc   conf
setfetchtask createfetchtask showtblsdesc getschema
private void analyzeshowcolumns astnode ast  throws semanticexception
showcolumnsdesc showcolumnsdesc
string dbname   null
string tablename   null
switch  ast getchildcount
case 1
tablename   getunescapedname  astnode  ast getchild 0
break
case 2
dbname   getunescapedname  astnode  ast getchild 0
tablename   getunescapedname  astnode  ast getchild 1
break
default
break
try
table tab   null
if  dbname    null
tab   db gettable tablename  true
else
tab   db gettable dbname  tablename  true
inputs add new readentity tab
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tablename
showcolumnsdesc   new showcolumnsdesc ctx getresfile    dbname  tablename
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showcolumnsdesc   conf
setfetchtask createfetchtask showcolumnsdesc getschema
private void analyzeshowtablestatus astnode ast  throws semanticexception
showtablestatusdesc showtblstatusdesc
string tablenames   getunescapedname  astnode  ast getchild 0
string dbname   db getcurrentdatabase
int children   ast getchildcount
hashmap<string  string> partspec   null
if  children >  2
if  children > 3
throw new semanticexception errormsg generic_error getmsg
for  int i   1  i < children  i
astnode child    astnode  ast getchild i
if  child gettoken   gettype      hiveparser identifier
dbname   unescapeidentifier child gettext
else if  child gettoken   gettype      hiveparser tok_partspec
partspec   getpartspec child
else
throw new semanticexception errormsg generic_error getmsg
if  partspec    null
validatetable tablenames  partspec
showtblstatusdesc   new showtablestatusdesc ctx getresfile   tostring    dbname
tablenames  partspec
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showtblstatusdesc   conf
setfetchtask createfetchtask showtblstatusdesc getschema
private void analyzeshowtableproperties astnode ast  throws semanticexception
showtblpropertiesdesc showtblpropertiesdesc
string tablenames   getunescapedname  astnode  ast getchild 0
string dbname   db getcurrentdatabase
string propertyname   null
if  ast getchildcount   > 1
propertyname   unescapesqlstring ast getchild 1  gettext
validatetable tablenames  null
showtblpropertiesdesc   new showtblpropertiesdesc ctx getresfile   tostring    tablenames
propertyname
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showtblpropertiesdesc   conf
setfetchtask createfetchtask showtblpropertiesdesc getschema
private void analyzeshowindexes astnode ast  throws semanticexception
showindexesdesc showindexesdesc
string tablename   getunescapedname  astnode  ast getchild 0
showindexesdesc   new showindexesdesc tablename  ctx getresfile
if  ast getchildcount      2
int descoptions   ast getchild 1  gettype
showindexesdesc setformatted descoptions    hiveparser kw_formatted
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showindexesdesc   conf
setfetchtask createfetchtask showindexesdesc getschema
/**
* add the task according to the parsed command tree. this is used for the cli
* command "show functions;".
*
* @param ast
*          the parsed command tree.
* @throws semanticexception
*           parsin failed
*/
private void analyzeshowfunctions astnode ast  throws semanticexception
showfunctionsdesc showfuncsdesc
if  ast getchildcount      1
string funcnames   stripquotes ast getchild 0  gettext
showfuncsdesc   new showfunctionsdesc ctx getresfile    funcnames
else
showfuncsdesc   new showfunctionsdesc ctx getresfile
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showfuncsdesc   conf
setfetchtask createfetchtask showfuncsdesc getschema
/**
* add the task according to the parsed command tree. this is used for the cli
* command "show locks;".
*
* @param ast
*          the parsed command tree.
* @throws semanticexception
*           parsing failed
*/
private void analyzeshowlocks astnode ast  throws semanticexception
string tablename   null
hashmap<string  string> partspec   null
boolean isextended   false
if  ast getchildcount   >  1
// table for which show locks is being executed
for  int i   0  i < ast getchildcount    i
astnode child    astnode  ast getchild i
if  child gettype      hiveparser tok_tabtype
astnode tabletypeexpr    astnode  child
tablename
qualifiednameutil getfullyqualifiedname  astnode  tabletypeexpr getchild 0
// get partition metadata if partition specified
if  tabletypeexpr getchildcount      2
astnode partspec    astnode  tabletypeexpr getchild 1
partspec   getpartspec partspec
else if  child gettype      hiveparser kw_extended
isextended   true
showlocksdesc showlocksdesc   new showlocksdesc ctx getresfile    tablename
partspec  isextended
roottasks add taskfactory get new ddlwork getinputs    getoutputs
showlocksdesc   conf
setfetchtask createfetchtask showlocksdesc getschema
// need to initialize the lock manager
ctx setneedlockmgr true
/**
* add the task according to the parsed command tree. this is used for the cli
* command "lock table ..;".
*
* @param ast
*          the parsed command tree.
* @throws semanticexception
*           parsing failed
*/
private void analyzelocktable astnode ast
throws semanticexception
string tablename   getunescapedname  astnode  ast getchild 0   tolowercase
string mode   unescapeidentifier ast getchild 1  gettext   touppercase
list<map<string  string>> partspecs   getpartitionspecs ast
// we only can have a single partition spec
assert  partspecs size   <  1
map<string  string> partspec   null
if  partspecs size   > 0
partspec   partspecs get 0
locktabledesc locktbldesc   new locktabledesc tablename  mode  partspec
hiveconf getvar conf  confvars hivequeryid
locktbldesc setquerystr this ctx getcmd
roottasks add taskfactory get new ddlwork getinputs    getoutputs
locktbldesc   conf
// need to initialize the lock manager
ctx setneedlockmgr true
/**
* add the task according to the parsed command tree. this is used for the cli
* command "unlock table ..;".
*
* @param ast
*          the parsed command tree.
* @throws semanticexception
*           parsing failed
*/
private void analyzeunlocktable astnode ast
throws semanticexception
string tablename   getunescapedname  astnode  ast getchild 0
list<map<string  string>> partspecs   getpartitionspecs ast
// we only can have a single partition spec
assert  partspecs size   <  1
map<string  string> partspec   null
if  partspecs size   > 0
partspec   partspecs get 0
unlocktabledesc unlocktbldesc   new unlocktabledesc tablename  partspec
roottasks add taskfactory get new ddlwork getinputs    getoutputs
unlocktbldesc   conf
// need to initialize the lock manager
ctx setneedlockmgr true
/**
* add the task according to the parsed command tree. this is used for the cli
* command "describe function;".
*
* @param ast
*          the parsed command tree.
* @throws semanticexception
*           parsing failed
*/
private void analyzedescfunction astnode ast  throws semanticexception
string funcname
boolean isextended
if  ast getchildcount      1
funcname   stripquotes ast getchild 0  gettext
isextended   false
else if  ast getchildcount      2
funcname   stripquotes ast getchild 0  gettext
isextended   true
else
throw new semanticexception
descfunctiondesc descfuncdesc   new descfunctiondesc ctx getresfile
funcname  isextended
roottasks add taskfactory get new ddlwork getinputs    getoutputs
descfuncdesc   conf
setfetchtask createfetchtask descfuncdesc getschema
private void analyzealtertablerename astnode ast  boolean expectview  throws semanticexception
string tblname   getunescapedname  astnode  ast getchild 0
altertabledesc altertbldesc   new altertabledesc tblname
getunescapedname  astnode  ast getchild 1    expectview
addinputsoutputsaltertable tblname  null  altertbldesc
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
private void analyzealtertablerenamecol astnode ast  throws semanticexception
string tblname   getunescapedname  astnode  ast getchild 0
string newcomment   null
string newtype   null
newtype   gettypestringfromast  astnode  ast getchild 3
boolean first   false
string flagcol   null
astnode positionnode   null
if  ast getchildcount      6
newcomment   unescapesqlstring ast getchild 4  gettext
positionnode    astnode  ast getchild 5
else if  ast getchildcount      5
if  ast getchild 4  gettype      hiveparser stringliteral
newcomment   unescapesqlstring ast getchild 4  gettext
else
positionnode    astnode  ast getchild 4
if  positionnode    null
if  positionnode getchildcount      0
first   true
else
flagcol   unescapeidentifier positionnode getchild 0  gettext
string oldcolname   ast getchild 1  gettext
string newcolname   ast getchild 2  gettext
/* validate the operation of renaming a column name. */
table tab   null
try
tab   db gettable tblname
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tblname   e
skewedinfo skewinfo   tab getttable   getsd   getskewedinfo
if   null    skewinfo
null    skewinfo getskewedcolnames
skewinfo getskewedcolnames   contains oldcolname
throw new semanticexception oldcolname
errormsg alter_table_not_allowed_rename_skewed_column getmsg
altertabledesc altertbldesc   new altertabledesc tblname
unescapeidentifier oldcolname   unescapeidentifier newcolname
newtype  newcomment  first  flagcol
addinputsoutputsaltertable tblname  null  altertbldesc
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
private void analyzealtertablerenamepart astnode ast  string tblname
hashmap<string  string> oldpartspec  throws semanticexception
map<string  string> newpartspec   extractpartitionspecs  astnode  ast getchild 0
if  newpartspec    null
throw new semanticexception     ast
table tab   null
try
tab   db gettable db getcurrentdatabase    tblname  false
if  tab    null
inputs add new readentity tab
else
throw new semanticexception errormsg invalid_table getmsg tblname
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tblname
validatealtertabletype tab  altertabletypes renamepartition
list<map<string  string>> partspecs   new arraylist<map<string  string>>
partspecs add oldpartspec
partspecs add newpartspec
addtablepartsoutputs tblname  partspecs
renamepartitiondesc renamepartitiondesc   new renamepartitiondesc
db getcurrentdatabase    tblname  oldpartspec  newpartspec
roottasks add taskfactory get new ddlwork getinputs    getoutputs
renamepartitiondesc   conf
private void analyzealtertablemodifycols astnode ast
altertabletypes altertype  throws semanticexception
string tblname   getunescapedname  astnode  ast getchild 0
list<fieldschema> newcols   getcolumns  astnode  ast getchild 1
altertabledesc altertbldesc   new altertabledesc tblname  newcols
altertype
addinputsoutputsaltertable tblname  null  altertbldesc
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
private void analyzealtertabledropparts astnode ast  boolean expectview
throws semanticexception
string tblname   getunescapedname  astnode  ast getchild 0
// get table metadata
list<partitionspec> partspecs   getfullpartitionspecs ast
table tab   null
try
tab   db gettable db getcurrentdatabase    tblname  false
if  tab    null
inputs add new readentity tab
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tblname
validatealtertabletype tab  altertabletypes droppartition  expectview
// find out if all partition columns are strings. this is needed for jdo
boolean stringpartitioncolumns   true
list<fieldschema> partcols   tab getpartcols
for  fieldschema partcol   partcols
if   partcol gettype   tolowercase   equals
stringpartitioncolumns   false
break
// only equality is supported for non-string partition columns
if   stringpartitioncolumns
for  partitionspec partspec   partspecs
if  partspec isnonequalityoperator
throw new semanticexception
errormsg drop_partition_non_string_partcols_nonequality getmsg
if  partspecs    null
boolean ifexists    ast getfirstchildwithtype hiveparser tok_ifexists     null
// we want to signal an error if the partition doesn't exist and we're
// configured not to fail silently
boolean throwexception
ifexists     hiveconf getboolvar conf  confvars dropignoresnonexistent
addtabledroppartsoutputs tblname  partspecs  throwexception  stringpartitioncolumns
droptabledesc droptbldesc
new droptabledesc tblname  partspecs  expectview  stringpartitioncolumns
roottasks add taskfactory get new ddlwork getinputs    getoutputs
droptbldesc   conf
/**
* add one or more partitions to a table. useful when the data has been copied
* to the right location by some other process.
*
* @param ast
*          the parsed command tree.
*
* @param expectview
*          true for alter view, false for alter table.
*
* @throws semanticexception
*           parsing failed
*/
private void analyzealtertableaddparts commontree ast  boolean expectview
throws semanticexception
string tblname   getunescapedname  astnode  ast getchild 0
boolean isview   false
table tab   null
try
tab   db gettable db getcurrentdatabase    tblname  false
if  tab    null
inputs add new readentity tab
isview   tab isview
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tblname
validatealtertabletype tab  altertabletypes addpartition  expectview
// partition name to value
list<map<string  string>> partspecs   getpartitionspecs ast
addtablepartsoutputs tblname  partspecs
iterator<map<string  string>> partiter   partspecs iterator
string currentlocation   null
map<string  string> currentpart   null
boolean ifnotexists   false
list<addpartitiondesc> partitiondescs   new arraylist<addpartitiondesc>
int numch   ast getchildcount
for  int num   1  num < numch  num
commontree child    commontree  ast getchild num
switch  child gettoken   gettype
case hiveparser tok_ifnotexists
ifnotexists   true
break
case hiveparser tok_partspec
if  currentpart    null
validatepartitionvalues currentpart
addpartitiondesc addpartitiondesc   new addpartitiondesc
db getcurrentdatabase    tblname  currentpart
currentlocation  ifnotexists  expectview
partitiondescs add addpartitiondesc
// create new partition, set values
currentlocation   null
currentpart   partiter next
break
case hiveparser tok_partitionlocation
// if location specified, set in partition
currentlocation   unescapesqlstring child getchild 0  gettext
break
default
throw new semanticexception     child
// add the last one
if  currentpart    null
validatepartitionvalues currentpart
addpartitiondesc addpartitiondesc   new addpartitiondesc
db getcurrentdatabase    tblname  currentpart
currentlocation  ifnotexists  expectview
partitiondescs add addpartitiondesc
for  addpartitiondesc addpartitiondesc   partitiondescs
roottasks add taskfactory get new ddlwork getinputs    getoutputs
addpartitiondesc   conf
if  isview
// compile internal query to capture underlying table partition
// dependencies
stringbuilder cmd   new stringbuilder
cmd append
cmd append hiveutils unparseidentifier tblname
cmd append
boolean firstor   true
for  addpartitiondesc partitiondesc   partitiondescs
// perform this check early so that we get a better error message.
try
// note that isvalidspec throws an exception (it never
// actually returns false).
tab isvalidspec partitiondesc getpartspec
catch  hiveexception ex
throw new semanticexception ex getmessage    ex
if  firstor
firstor   false
else
cmd append
boolean firstand   true
cmd append
for  map entry<string  string> entry   partitiondesc getpartspec   entryset
if  firstand
firstand   false
else
cmd append
cmd append hiveutils unparseidentifier entry getkey
cmd append
cmd append hiveutils escapestring entry getvalue
cmd append
cmd append
driver driver   new driver conf
int rc   driver compile cmd tostring
if  rc    0
throw new semanticexception errormsg no_valid_partn getmsg
inputs addall driver getplan   getinputs
/**
* rewrite the metadata for one or more partitions in a table. useful when
* an external process modifies files on hdfs and you want the pre/post
* hooks to be fired for the specified partition.
*
* @param ast
*          the parsed command tree.
* @throws semanticexception
*           parsin failed
*/
private void analyzealtertabletouch commontree ast
throws semanticexception
string tblname   getunescapedname  astnode  ast getchild 0
table tab
try
tab   db gettable db getcurrentdatabase    tblname  false
if  tab    null
inputs add new readentity tab
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tblname
validatealtertabletype tab  altertabletypes touch
// partition name to value
list<map<string  string>> partspecs   getpartitionspecs ast
if  partspecs size      0
altertablesimpledesc touchdesc   new altertablesimpledesc
db getcurrentdatabase    tblname  null
altertabledesc altertabletypes touch
outputs add new writeentity tab
roottasks add taskfactory get new ddlwork getinputs    getoutputs
touchdesc   conf
else
addtablepartsoutputs tblname  partspecs
for  map<string  string> partspec   partspecs
altertablesimpledesc touchdesc   new altertablesimpledesc
db getcurrentdatabase    tblname  partspec
altertabledesc altertabletypes touch
roottasks add taskfactory get new ddlwork getinputs    getoutputs
touchdesc   conf
private void analyzealtertablearchive commontree ast  boolean isunarchive
throws semanticexception
if   conf getboolvar hiveconf confvars hivearchiveenabled
throw new semanticexception errormsg archive_methods_disabled getmsg
string tblname   getunescapedname  astnode  ast getchild 0
// partition name to value
list<map<string  string>> partspecs   getpartitionspecs ast
table tab   null
try
tab   db gettable db getcurrentdatabase    tblname  false
if  tab    null
inputs add new readentity tab
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tblname
addtablepartsoutputs tblname  partspecs  true
validatealtertabletype tab  altertabletypes archive
if  partspecs size   > 1
throw new semanticexception isunarchive ?
errormsg unarchive_on_muli_parts getmsg
errormsg archive_on_muli_parts getmsg
if  partspecs size      0
throw new semanticexception errormsg archive_on_table getmsg
map<string  string> partspec   partspecs get 0
try
isvalidprefixspec tab  partspec
catch  hiveexception e
throw new semanticexception e getmessage    e
altertablesimpledesc archivedesc   new altertablesimpledesc
db getcurrentdatabase    tblname  partspec
isunarchive ? altertabletypes unarchive   altertabletypes archive
roottasks add taskfactory get new ddlwork getinputs    getoutputs
archivedesc   conf
/**
* verify that the information in the metastore matches up with the data on
* the fs.
*
* @param ast
*          query tree.
* @throws semanticexception
*/
private void analyzemetastorecheck commontree ast  throws semanticexception
string tablename   null
boolean repair   false
if  ast getchildcount   > 0
repair   ast getchild 0  gettype      hiveparser kw_repair
if   repair
tablename   getunescapedname  astnode  ast getchild 0
else if  ast getchildcount   > 1
tablename   getunescapedname  astnode  ast getchild 1
list<map<string  string>> specs   getpartitionspecs ast
msckdesc checkdesc   new msckdesc tablename  specs  ctx getresfile
repair
roottasks add taskfactory get new ddlwork getinputs    getoutputs
checkdesc   conf
/**
* get the partition specs from the tree.
*
* @param ast
*          tree to extract partitions from.
* @return a list of partition name to value mappings.
* @throws semanticexception
*/
private list<map<string  string>> getpartitionspecs commontree ast
throws semanticexception
list<map<string  string>> partspecs   new arraylist<map<string  string>>
int childindex   0
// get partition metadata if partition specified
for  childindex   1  childindex < ast getchildcount    childindex
tree partspec   ast getchild childindex
// sanity check
if  partspec gettype      hiveparser tok_partspec
map<string  string> partspec   new linkedhashmap<string  string>
for  int i   0  i < partspec getchildcount      i
commontree partspec_val    commontree  partspec getchild i
string val   stripquotes partspec_val getchild 1  gettext
partspec put partspec_val getchild 0  gettext   tolowercase    val
partspecs add partspec
return partspecs
/**
* get the partition specs from the tree. this stores the full specification
* with the comparator operator into the output list.
*
* @param ast
*          tree to extract partitions from.
* @return a list of partitionspec objects which contain the mapping from
*         key to operator and value.
* @throws semanticexception
*/
private list<partitionspec> getfullpartitionspecs commontree ast
throws semanticexception
list<partitionspec> partspeclist   new arraylist<partitionspec>
for  int childindex   1  childindex < ast getchildcount    childindex
tree partspectree   ast getchild childindex
if  partspectree gettype      hiveparser tok_partspec
partitionspec partspec   new partitionspec
for  int i   0  i < partspectree getchildcount      i
commontree partspecsinglekey    commontree  partspectree getchild i
assert  partspecsinglekey gettype      hiveparser tok_partval
string key   partspecsinglekey getchild 0  gettext   tolowercase
string operator   partspecsinglekey getchild 1  gettext
string val   partspecsinglekey getchild 2  gettext
partspec addpredicate key  operator  val
partspeclist add partspec
return partspeclist
/**
* certain partition values are are used by hive. e.g. the default partition
* in dynamic partitioning and the intermediate partition values used in the
* archiving process. naturally, prohibit the user from creating partitions
* with these reserved values. the check that this function is more
* restrictive than the actual limitation, but it's simpler. should be okay
* since the reserved names are fairly long and uncommon.
*/
private void validatepartitionvalues map<string  string> partspec
throws semanticexception
for  entry<string  string> e   partspec entryset
for  string s   reservedpartitionvalues
if  e getvalue   contains s
throw new semanticexception errormsg reserved_part_val getmsg
e getvalue         s
/**
* add the table partitions to be modified in the output, so that it is available for the
* pre-execution hook. if the partition does not exist, no error is thrown.
*/
private void addtablepartsoutputs string tblname  list<map<string  string>> partspecs
throws semanticexception
addtablepartsoutputs tblname  partspecs  false  false  null
/**
* add the table partitions to be modified in the output, so that it is available for the
* pre-execution hook. if the partition does not exist, no error is thrown.
*/
private void addtablepartsoutputs string tblname  list<map<string  string>> partspecs
boolean allowmany
throws semanticexception
addtablepartsoutputs tblname  partspecs  false  allowmany  null
/**
* add the table partitions to be modified in the output, so that it is available for the
* pre-execution hook. if the partition does not exist, throw an error if
* throwifnonexistent is true, otherwise ignore it.
*/
private void addtablepartsoutputs string tblname  list<map<string  string>> partspecs
boolean throwifnonexistent  boolean allowmany  astnode ast
throws semanticexception
table tab
try
tab   db gettable tblname
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tblname
iterator<map<string  string>> i
int index
for  i   partspecs iterator    index   1  i hasnext      index
map<string  string> partspec   i next
list<partition> parts   null
if  allowmany
try
parts   db getpartitions tab  partspec
catch  hiveexception e
log error
else
parts   new arraylist<partition>
try
partition p   db getpartition tab  partspec  false
if  p    null
parts add p
catch  hiveexception e
log debug
if  parts isempty
if  throwifnonexistent
throw new semanticexception errormsg invalid_partition getmsg ast getchild index
for  partition p   parts
outputs add new writeentity p
/**
* add the table partitions to be modified in the output, so that it is available for the
* pre-execution hook. if the partition does not exist, throw an error if
* throwifnonexistent is true, otherwise ignore it.
*/
private void addtabledroppartsoutputs string tblname  list<partitionspec> partspecs
boolean throwifnonexistent  boolean stringpartitioncolumns
throws semanticexception
table tab
try
tab   db gettable tblname
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tblname
iterator<partitionspec> i
int index
for  i   partspecs iterator    index   1  i hasnext      index
partitionspec partspec   i next
list<partition> parts   null
if  stringpartitioncolumns
try
parts   db getpartitionsbyfilter tab  partspec tostring
catch  exception e
throw new semanticexception errormsg invalid_partition getmsg partspec tostring     e
else
try
parts   db getpartitions tab  partspec getpartspecwithoutoperator
catch  exception e
throw new semanticexception errormsg invalid_partition getmsg partspec tostring     e
if  parts isempty
if  throwifnonexistent
throw new semanticexception errormsg invalid_partition getmsg partspec tostring
for  partition p   parts
outputs add new writeentity p
/**
* analyze alter table's skewed table
*
* @param ast
*          node
* @throws semanticexception
*/
private void analyzealtertableskewedby astnode ast  throws semanticexception
/**
* throw an error if the user tries to use the ddl with
* hive.internal.ddl.list.bucketing.enable set to false.
*/
hiveconf hiveconf   sessionstate get   getconf
if    hiveconf getboolvar hiveconf confvars hive_internal_ddl_list_bucketing_enable
throw new semanticexception errormsg hive_internal_ddl_list_bucketing_disabled getmsg
string tablename   getunescapedname  astnode  ast getchild 0
table tab   null
try
tab   db gettable db getcurrentdatabase    tablename  true
catch  hiveexception e
throw new semanticexception errormsg invalid_table getmsg tablename
inputs add new readentity tab
outputs add new writeentity tab
validatealtertabletype tab  altertabletypes addskewedby
if  ast getchildcount      1
/* convert a skewed table to non-skewed table. */
altertabledesc altertbldesc   new altertabledesc tablename  true
new arraylist<string>    new arraylist<list<string>>
altertbldesc setstoredassubdirectories false
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
else
switch    astnode  ast getchild 1   gettoken   gettype
case hiveparser tok_tableskewed
handlealtertableskewedby ast  tablename  tab
break
case hiveparser tok_storedasdirs
handlealtertabledisablestoredasdirs tablename  tab
break
default
assert false
/**
* handle alter table <name> not stored as directories
*
* @param tablename
* @param tab
* @throws semanticexception
*/
private void handlealtertabledisablestoredasdirs string tablename  table tab
throws semanticexception
list<string> skewedcolnames   tab getskewedcolnames
list<list<string>> skewedcolvalues   tab getskewedcolvalues
if   skewedcolnames    null      skewedcolnames size      0      skewedcolvalues    null
skewedcolvalues size      0
throw new semanticexception errormsg alter_tbl_storedasdir_not_skewed getmsg tablename
altertabledesc altertbldesc   new altertabledesc tablename  false
skewedcolnames  skewedcolvalues
altertbldesc setstoredassubdirectories false
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
/**
* process "alter table <name> skewed by .. on .. stored as directories
* @param ast
* @param tablename
* @param tab
* @throws semanticexception
*/
private void handlealtertableskewedby astnode ast  string tablename  table tab
throws semanticexception
list<string> skewedcolnames   new arraylist<string>
list<list<string>> skewedvalues   new arraylist<list<string>>
/* skewed column names. */
astnode skewednode    astnode  ast getchild 1
skewedcolnames   analyzeskewedtablddlcolnames skewedcolnames  skewednode
/* skewed value. */
analyzeddlskewedvalues skewedvalues  skewednode
// stored as directories
boolean storedasdirs   analyzestoredaddirs skewednode
altertabledesc altertbldesc   new altertabledesc tablename  false
skewedcolnames  skewedvalues
altertbldesc setstoredassubdirectories storedasdirs
/**
* validate information about skewed table
*/
altertbldesc settable tab
altertbldesc validate
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
/**
* analyze skewed column names
*
* @param skewedcolnames
* @param child
* @return
* @throws semanticexception
*/
private list<string> analyzealtertableskewedcolnames list<string> skewedcolnames
astnode child  throws semanticexception
tree nnode   child getchild 0
if  nnode    null
throw new semanticexception errormsg skewed_table_no_column_name getmsg
else
astnode nastnode    astnode  nnode
if  nastnode gettoken   gettype      hiveparser tok_tabcolname
throw new semanticexception errormsg skewed_table_no_column_name getmsg
else
skewedcolnames   getcolumnnames nastnode
return skewedcolnames
/**
* given a astnode, return list of values.
*
* use case:
* create table xyz list bucketed (col1) with skew (1,2,5)
* ast node is for (1,2,5)
*
* @param ast
* @return
*/
private list<string> getcolumnvalues astnode ast
list<string> collist   new arraylist<string>
int numch   ast getchildcount
for  int i   0  i < numch  i
astnode child    astnode  ast getchild i
collist add stripquotes child gettext    tolowercase
return collist
/**
* analyze alter table's skewed location
*
* @param ast
* @param tablename
* @param partspec
* @throws semanticexception
*/
private void analyzealtertableskewedlocation astnode ast  string tablename
hashmap<string  string> partspec  throws semanticexception
/**
* throw an error if the user tries to use the ddl with
* hive.internal.ddl.list.bucketing.enable set to false.
*/
hiveconf hiveconf   sessionstate get   getconf
if    hiveconf getboolvar hiveconf confvars hive_internal_ddl_list_bucketing_enable
throw new semanticexception errormsg hive_internal_ddl_list_bucketing_disabled getmsg
/**
* retrieve mappings from parser
*/
map<list<string>  string> locations   new hashmap<list<string>  string>
arraylist<node> locnodes   ast getchildren
if  null    locnodes
throw new semanticexception errormsg alter_tbl_skewed_loc_no_loc getmsg
else
for  node locnode   locnodes
// tok_skewed_locations
astnode locastnode    astnode  locnode
arraylist<node> loclistnodes   locastnode getchildren
if  null    loclistnodes
throw new semanticexception errormsg alter_tbl_skewed_loc_no_loc getmsg
else
for  node loclistnode   loclistnodes
// tok_skewed_location_list
astnode loclistastnode    astnode  loclistnode
arraylist<node> locmapnodes   loclistastnode getchildren
if  null    locmapnodes
throw new semanticexception errormsg alter_tbl_skewed_loc_no_loc getmsg
else
for  node locmapnode   locmapnodes
// tok_skewed_location_map
astnode locmapastnode    astnode  locmapnode
arraylist<node> locmapastnodemaps   locmapastnode getchildren
if   null    locmapastnodemaps      locmapastnodemaps size      2
throw new semanticexception errormsg alter_tbl_skewed_loc_no_map getmsg
else
list<string> keylist   new linkedlist<string>
astnode node    astnode  locmapastnodemaps get 0
if  node gettoken   gettype      hiveparser tok_tabcolvalues
keylist   getskewedvaluesfromastnode node
else if  isconstant node
keylist add planutils
stripquotes node gettext
else
throw new semanticexception errormsg skewed_table_no_column_value getmsg
string newlocation   planutils
stripquotes unescapesqlstring   astnode  locmapastnodemaps get 1
gettext
validateskewedlocationstring newlocation
locations put keylist  newlocation
altertabledesc altertbldesc   new altertabledesc tablename  locations  partspec
addinputsoutputsaltertable tablename  partspec
roottasks add taskfactory get new ddlwork getinputs    getoutputs
altertbldesc   conf
/**
* check if the node is constant.
*
* @param node
* @return
*/
private boolean isconstant astnode node
boolean result   false
switch node gettoken   gettype
case hiveparser number
result   true
break
case hiveparser stringliteral
result   true
break
case hiveparser bigintliteral
result   true
break
case hiveparser smallintliteral
result   true
break
case hiveparser tinyintliteral
result   true
break
case hiveparser charsetname
result   true
break
case hiveparser kw_true
case hiveparser kw_false
result   true
break
default
break
return result
private void validateskewedlocationstring string newlocation  throws semanticexception
/* validate location string. */
try
uri locuri   new uri newlocation
if   locuri isabsolute      locuri getscheme      null
locuri getscheme   trim   equals
throw new semanticexception
newlocation
catch  urisyntaxexception e
throw new semanticexception e