/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql optimizer
import java io serializable
import java util arraylist
import java util hashset
import java util list
import java util map
import java util set
import java util stack
import org apache hadoop hive conf hiveconf
import org apache hadoop hive metastore warehouse
import org apache hadoop hive metastore api metaexception
import org apache hadoop hive ql drivercontext
import org apache hadoop hive ql errormsg
import org apache hadoop hive ql exec operator
import org apache hadoop hive ql exec tablescanoperator
import org apache hadoop hive ql exec task
import org apache hadoop hive ql exec taskfactory
import org apache hadoop hive ql io rcfile stats partialscanwork
import org apache hadoop hive ql lib node
import org apache hadoop hive ql lib nodeprocessor
import org apache hadoop hive ql lib nodeprocessorctx
import org apache hadoop hive ql metadata partition
import org apache hadoop hive ql metadata table
import org apache hadoop hive ql optimizer genmrproccontext genmapredctx
import org apache hadoop hive ql parse basesemanticanalyzer tablespec
import org apache hadoop hive ql parse parsecontext
import org apache hadoop hive ql parse prunedpartitionlist
import org apache hadoop hive ql parse qbparseinfo
import org apache hadoop hive ql parse semanticexception
import org apache hadoop hive ql plan mapredwork
import org apache hadoop hive ql plan operatordesc
import org apache hadoop hive ql plan statswork
/**
* processor for the rule - table scan.
*/
public class genmrtablescan1 implements nodeprocessor
public genmrtablescan1
/**
* table sink encountered.
*
* @param nd
*          the table sink operator encountered
* @param opprocctx
*          context
*/
public object process node nd  stack<node> stack  nodeprocessorctx opprocctx
object    nodeoutputs  throws semanticexception
tablescanoperator op    tablescanoperator  nd
genmrproccontext ctx    genmrproccontext  opprocctx
parsecontext parsectx   ctx getparsectx
map<operator<? extends operatordesc>  genmapredctx> mapcurrctx   ctx getmapcurrctx
// create a dummy mapreduce task
mapredwork currwork   genmapredutils getmapredwork parsectx
task<? extends serializable> currtask   taskfactory get currwork  parsectx getconf
operator<? extends operatordesc> currtopop   op
ctx setcurrtask currtask
ctx setcurrtopop currtopop
for  string alias   parsectx gettopops   keyset
operator<? extends operatordesc> currop   parsectx gettopops   get alias
if  currop    op
string curraliasid   alias
ctx setcurraliasid curraliasid
mapcurrctx put op  new genmapredctx currtask  curraliasid
qbparseinfo parseinfo   parsectx getqb   getparseinfo
if  parseinfo isanalyzecommand
//   analyze table t [partition (...)] compute statistics;
// the plan consists of a simple mapredtask followed by a statstask.
// the mr task is just a simple tablescanoperator
statswork statswork   new statswork parsectx getqb   getparseinfo   gettablespec
statswork setaggkey op getconf   getstatsaggprefix
statswork setstatsreliable
parsectx getconf   getboolvar hiveconf confvars hive_stats_reliable
task<statswork> statstask   taskfactory get statswork  parsectx getconf
currtask adddependenttask statstask
if   ctx getroottasks   contains currtask
ctx getroottasks   add currtask
// analyze table t [partition (...)] compute statistics noscan;
// the plan consists of a statstask only.
if  parseinfo isnoscananalyzecommand
statstask setparenttasks null
statswork setnoscananalyzecommand true
ctx getroottasks   remove currtask
ctx getroottasks   add statstask
// analyze table t [partition (...)] compute statistics partialscan;
if  parseinfo ispartialscananalyzecommand
handlepartialscancommand op  ctx  parsectx  currtask  parseinfo  statswork  statstask
currwork getmapwork   setgatheringstats true
if  currwork getreducework      null
currwork getreducework   setgatheringstats true
// note: here we should use the new partition predicate pushdown api to get a list of pruned list,
// and pass it to settaskplan as the last parameter
set<partition> confirmedpartns   new hashset<partition>
tablespec tblspec   parseinfo gettablespec
if  tblspec spectype    tablespec spectype static_partition
// static partition
if  tblspec parthandle    null
confirmedpartns add tblspec parthandle
else
// partial partition spec has null parthandle
assert parseinfo isnoscananalyzecommand
confirmedpartns addall tblspec partitions
else if  tblspec spectype    tablespec spectype dynamic_partition
// dynamic partition
confirmedpartns addall tblspec partitions
if  confirmedpartns size   > 0
table source   parsectx getqb   getmetadata   gettableforalias alias
prunedpartitionlist partlist   new prunedpartitionlist source  confirmedpartns  false
genmapredutils settaskplan curraliasid  currtopop  currtask  false  ctx  partlist
else      non partitioned table
genmapredutils settaskplan curraliasid  currtopop  currtask  false  ctx
return true
assert false
return null
/**
* handle partial scan command.
*
* it is composed of partialscantask followed by statstask .
* @param op
* @param ctx
* @param parsectx
* @param currtask
* @param parseinfo
* @param statswork
* @param statstask
* @throws semanticexception
*/
private void handlepartialscancommand tablescanoperator op  genmrproccontext ctx
parsecontext parsectx
task<? extends serializable> currtask  qbparseinfo parseinfo  statswork statswork
task<statswork> statstask  throws semanticexception
string aggregationkey   op getconf   getstatsaggprefix
list<string> inputpaths   new arraylist<string>
switch  parseinfo gettablespec   spectype
case table_only
inputpaths add parseinfo gettablespec   tablehandle getpath   tostring
break
case static_partition
partition part   parseinfo gettablespec   parthandle
try
aggregationkey    warehouse makepartpath part getspec
catch  metaexception e
throw new semanticexception errormsg analyze_table_partialscan_aggkey getmsg
part getpartitionpath   tostring     e getmessage
inputpaths add part getpartitionpath   tostring
break
default
assert false
// scan work
partialscanwork scanwork   new partialscanwork inputpaths
scanwork setmappercannotspanpartns true
scanwork setaggkey aggregationkey
// stats work
statswork setpartialscananalyzecommand true
// partial scan task
drivercontext drivercxt   new drivercontext
task<partialscanwork> pstask   taskfactory get scanwork  parsectx getconf
pstask initialize parsectx getconf    null  drivercxt
pstask setwork scanwork
// task dependency
ctx getroottasks   remove currtask
ctx getroottasks   add pstask
pstask adddependenttask statstask
list<task<? extends serializable>> parenttasks   new arraylist<task<? extends serializable>>
parenttasks add pstask
statstask setparenttasks parenttasks