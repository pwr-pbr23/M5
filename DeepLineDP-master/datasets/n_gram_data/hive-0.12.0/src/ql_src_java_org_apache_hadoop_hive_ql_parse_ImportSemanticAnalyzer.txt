/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql parse
import java io ioexception
import java net uri
import java net urisyntaxexception
import java util arraylist
import java util collections
import java util comparator
import java util iterator
import java util linkedhashmap
import java util list
import java util map
import java util treemap
import org antlr runtime tree tree
import org apache commons lang objectutils
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop hive conf hiveconf
import org apache hadoop hive metastore tabletype
import org apache hadoop hive metastore warehouse
import org apache hadoop hive metastore api fieldschema
import org apache hadoop hive metastore api metaexception
import org apache hadoop hive metastore api order
import org apache hadoop hive metastore api partition
import org apache hadoop hive ql errormsg
import org apache hadoop hive ql exec task
import org apache hadoop hive ql exec taskfactory
import org apache hadoop hive ql exec utilities
import org apache hadoop hive ql hooks writeentity
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata invalidtableexception
import org apache hadoop hive ql metadata table
import org apache hadoop hive ql plan addpartitiondesc
import org apache hadoop hive ql plan copywork
import org apache hadoop hive ql plan createtabledesc
import org apache hadoop hive ql plan ddlwork
import org apache hadoop hive ql plan loadtabledesc
import org apache hadoop hive ql plan movework
import org apache hadoop hive ql session sessionstate
import org apache hadoop hive serde serdeconstants
/**
* importsemanticanalyzer.
*
*/
public class importsemanticanalyzer extends basesemanticanalyzer
public static final string metadata_name
public importsemanticanalyzer hiveconf conf  throws semanticexception
super conf
private boolean tableexists   false
public boolean existstable
return tableexists
@override
public void analyzeinternal astnode ast  throws semanticexception
try
tree fromtree   ast getchild 0
// initialize load path
string tmppath   stripquotes fromtree gettext
uri fromuri   eximutil getvalidateduri conf  tmppath
filesystem fs   filesystem get fromuri  conf
string dbname   null
createtabledesc tbldesc   null
list<addpartitiondesc> partitiondescs   new arraylist<addpartitiondesc>
path frompath   new path fromuri getscheme    fromuri getauthority
fromuri getpath
try
path metadatapath   new path frompath  metadata_name
map entry<org apache hadoop hive metastore api table
list<partition>> rv    eximutil readmetadata fs  metadatapath
dbname   sessionstate get   getcurrentdatabase
org apache hadoop hive metastore api table table   rv getkey
tbldesc    new createtabledesc
table gettablename
false     isexternal  set to false here  can be overwritten by the
// import stmt
table getsd   getcols
table getpartitionkeys
table getsd   getbucketcols
table getsd   getsortcols
table getsd   getnumbuckets
null  null  null  null  null     these 5 delims passed as serde params
null     comment passed as table params
table getsd   getinputformat
table getsd   getoutputformat
null     location  set to null here  can be
// overwritten by the import stmt
table getsd   getserdeinfo   getserializationlib
null     storagehandler passed as table params
table getsd   getserdeinfo   getparameters
table getparameters    false
null    table getsd   getskewedinfo    ? null   table getsd   getskewedinfo
getskewedcolnames
null    table getsd   getskewedinfo    ? null   table getsd   getskewedinfo
getskewedcolvalues
tbldesc setstoredassubdirectories table getsd   isstoredassubdirectories
list<fieldschema> partcols   tbldesc getpartcols
list<string> partcolnames   new arraylist<string> partcols size
for  fieldschema fsc   partcols
partcolnames add fsc getname
list<partition> partitions   rv getvalue
for  partition partition   partitions
addpartitiondesc partdesc   new addpartitiondesc dbname  tbldesc gettablename
eximutil makepartspec tbldesc getpartcols    partition getvalues
partition getsd   getlocation    partition getparameters
partdesc setinputformat partition getsd   getinputformat
partdesc setoutputformat partition getsd   getoutputformat
partdesc setnumbuckets partition getsd   getnumbuckets
partdesc setcols partition getsd   getcols
partdesc setserializationlib partition getsd   getserdeinfo   getserializationlib
partdesc setserdeparams partition getsd   getserdeinfo   getparameters
partdesc setbucketcols partition getsd   getbucketcols
partdesc setsortcols partition getsd   getsortcols
partdesc setlocation new path frompath
warehouse makepartname tbldesc getpartcols    partition getvalues     tostring
partitiondescs add partdesc
catch  ioexception e
throw new semanticexception errormsg invalid_path getmsg    e
log debug
for  int i   1  i < ast getchildcount      i
astnode child    astnode  ast getchild i
switch  child gettoken   gettype
case hiveparser kw_external
tbldesc setexternal true
break
case hiveparser tok_tablelocation
string location   unescapesqlstring child getchild 0  gettext
location   eximutil relativetoabsolutepath conf  location
tbldesc setlocation location
break
case hiveparser tok_tab
tree tabletree   child getchild 0
// initialize destination table/partition
string tablename   getunescapedname  astnode tabletree
tbldesc settablename tablename
// get partition metadata if partition specified
linkedhashmap<string  string> partspec   new linkedhashmap<string  string>
if  child getchildcount      2
astnode partspec    astnode  child getchild 1
// partspec is a mapping from partition column name to its value.
for  int j   0  j < partspec getchildcount      j
astnode partspec_val    astnode  partspec getchild j
string val   null
string colname   unescapeidentifier partspec_val getchild 0
gettext   tolowercase
if  partspec_val getchildcount   < 2       dp in the form of t
// partition (ds, hr)
throw new semanticexception
errormsg invalid_partition
getmsg
else      in the form of t partition  ds
val   stripquotes partspec_val getchild 1  gettext
partspec put colname  val
boolean found   false
for  iterator<addpartitiondesc> partniter   partitiondescs
listiterator    partniter hasnext
addpartitiondesc addpartitiondesc   partniter next
if   found    addpartitiondesc getpartspec   equals partspec
found   true
else
partniter remove
if   found
throw new semanticexception
errormsg invalid_partition
getmsg
if  tbldesc gettablename      null
throw new semanticexception errormsg need_table_specification getmsg
else
conf set    tbldesc gettablename
for  addpartitiondesc addpartitiondesc   partitiondescs
addpartitiondesc settablename tbldesc gettablename
warehouse wh   new warehouse conf
try
table table   db gettable tbldesc gettablename
checktable table  tbldesc
log debug     tbldesc gettablename
tableexists   true
conf set    table getdatalocation   tostring
if  table ispartitioned
log debug
for  addpartitiondesc addpartitiondesc   partitiondescs
if  db getpartition table  addpartitiondesc getpartspec    false     null
roottasks add addsinglepartition fromuri  fs  tbldesc  table  wh  addpartitiondesc
else
throw new semanticexception
errormsg partition_exists
getmsg partspectostring addpartitiondesc getpartspec
else
log debug
checktargetlocationempty fs  new path table getdatalocation
tostring
loadtable fromuri  table
outputs add new writeentity table
catch  invalidtableexception e
log debug     tbldesc gettablename
task<?> t   taskfactory get new ddlwork getinputs    getoutputs
tbldesc   conf
table table   new table dbname  tbldesc gettablename
string currentdb   sessionstate get   getcurrentdatabase
conf set
wh gettablepath db getdatabasecurrent
tbldesc gettablename    tostring
if   tbldesc getpartcols      null      tbldesc getpartcols   size      0
for  addpartitiondesc addpartitiondesc   partitiondescs
t adddependenttask
addsinglepartition fromuri  fs  tbldesc  table  wh  addpartitiondesc
else
log debug
if  tbldesc isexternal       tbldesc getlocation      null
log debug
path datapath   new path fromuri tostring
tbldesc setlocation datapath tostring
else
path tablepath   null
if  tbldesc getlocation      null
tablepath   new path tbldesc getlocation
else
tablepath   wh gettablepath db getdatabasecurrent    tbldesc gettablename
checktargetlocationempty fs  tablepath
t adddependenttask loadtable fromuri  table
roottasks add t
//inputs.add(new readentity(fromuri.tostring(),
//  fromuri.getscheme().equals("hdfs") ? true : false));
catch  semanticexception e
throw e
catch  exception e
throw new semanticexception errormsg generic_error getmsg    e
private task<?> loadtable uri fromuri  table table
path datapath   new path fromuri tostring
string tmpuri   ctx getexternaltmpfileuri fromuri
task<?> copytask   taskfactory get new copywork datapath tostring
tmpuri  false   conf
loadtabledesc loadtablework   new loadtabledesc tmpuri tostring
ctx getexternaltmpfileuri fromuri
utilities gettabledesc table   new treemap<string  string>
false
task<?> loadtabletask   taskfactory get new movework getinputs
getoutputs    loadtablework  null  false   conf
copytask adddependenttask loadtabletask
roottasks add copytask
return loadtabletask
private task<?> addsinglepartition uri fromuri  filesystem fs  createtabledesc tbldesc
table table  warehouse wh
addpartitiondesc addpartitiondesc  throws metaexception  ioexception  hiveexception
if  tbldesc isexternal      tbldesc getlocation      null
log debug
partspectostring addpartitiondesc getpartspec
// addpartitiondesc already has the right partition location
task<?> addparttask   taskfactory get new ddlwork getinputs
getoutputs    addpartitiondesc   conf
return addparttask
else
string srclocation   addpartitiondesc getlocation
path tgtpath   null
if  tbldesc getlocation      null
if  table getdatalocation      null
tgtpath   new path table getdatalocation   tostring
warehouse makepartpath addpartitiondesc getpartspec
else
tgtpath   new path wh gettablepath
db getdatabasecurrent    tbldesc gettablename
warehouse makepartpath addpartitiondesc getpartspec
else
tgtpath   new path tbldesc getlocation
warehouse makepartpath addpartitiondesc getpartspec
checktargetlocationempty fs  tgtpath
addpartitiondesc setlocation tgtpath tostring
log debug
partspectostring addpartitiondesc getpartspec
srclocation
string tmpuri   ctx getexternaltmpfileuri fromuri
task<?> copytask   taskfactory get new copywork srclocation
tmpuri  false   conf
task<?> addparttask   taskfactory get new ddlwork getinputs
getoutputs    addpartitiondesc   conf
loadtabledesc loadtablework   new loadtabledesc tmpuri
ctx getexternaltmpfileuri fromuri
utilities gettabledesc table
addpartitiondesc getpartspec    true
loadtablework setinherittablespecs false
task<?> loadparttask   taskfactory get new movework
getinputs    getoutputs    loadtablework  null  false
conf
copytask adddependenttask loadparttask
addparttask adddependenttask loadparttask
roottasks add copytask
return addparttask
private void checktargetlocationempty filesystem fs  path targetpath
throws ioexception  semanticexception
log debug     targetpath tostring
if  fs exists targetpath
filestatus status   fs liststatus targetpath
if  status length > 0
log debug     status getpath   tostring
targetpath tostring
throw new semanticexception errormsg table_data_exists getmsg
private static string partspectostring map<string  string> partspec
stringbuilder sb   new stringbuilder
boolean firsttime   true
for  map entry<string  string> entry   partspec entryset
if   firsttime
sb append
firsttime   false
sb append entry getkey
sb append
sb append entry getvalue
return sb tostring
private static void checktable table table  createtabledesc tabledesc
throws semanticexception  urisyntaxexception
eximutil validatetable table
if   table ispartitioned
if  tabledesc isexternal         the import statement specified external
throw new semanticexception
errormsg incompatible_schema
getmsg
else
if  tabledesc isexternal         the import statement specified external
if   table gettabletype   equals tabletype external_table
throw new semanticexception
errormsg incompatible_schema
getmsg
if   table ispartitioned
if  tabledesc getlocation      null       import statement specified
// location
if   table getdatalocation
equals new uri tabledesc getlocation
throw new semanticexception
errormsg incompatible_schema getmsg
// check column order and types
list<fieldschema> existingtablecols   table getcols
list<fieldschema> importedtablecols   tabledesc getcols
if   eximutil schemacompare importedtablecols  existingtablecols
throw new semanticexception
errormsg incompatible_schema
getmsg
// check partitioning column order and types
list<fieldschema> existingtablepartcols   table getpartcols
list<fieldschema> importedtablepartcols   tabledesc getpartcols
if   eximutil schemacompare importedtablepartcols  existingtablepartcols
throw new semanticexception
errormsg incompatible_schema
getmsg
// check table params
map<string  string> existingtableparams   table getparameters
map<string  string> importedtableparams   tabledesc gettblprops
string error   checkparams existingtableparams  importedtableparams
new string
if  error    null
throw new semanticexception
errormsg incompatible_schema
getmsg     error
// check if/of/serde
string existingifc   table getinputformatclass   getname
string importedifc   tabledesc getinputformat
string existingofc   table getoutputformatclass   getname
string importedofc   tabledesc getoutputformat
if    existingifc equals importedifc
existingofc equals importedofc
throw new semanticexception
errormsg incompatible_schema
getmsg
string existingserde   table getserializationlib
string importedserde   tabledesc getsername
if   existingserde equals importedserde
throw new semanticexception
errormsg incompatible_schema
getmsg
string existingserdeformat   table
getserdeparam serdeconstants serialization_format
string importedserdeformat   tabledesc getserdeprops   get
serdeconstants serialization_format
if   objectutils equals existingserdeformat  importedserdeformat
throw new semanticexception
errormsg incompatible_schema
getmsg
// check bucket/sort cols
if   objectutils equals table getbucketcols    tabledesc getbucketcols
throw new semanticexception
errormsg incompatible_schema
getmsg
list<order> existingorder   table getsortcols
list<order> importedorder   tabledesc getsortcols
// safely sorting
final class ordercomparator implements comparator<order>
@override
public int compare order o1  order o2
if  o1 getorder   < o2 getorder
return  1
else
if  o1 getorder      o2 getorder
return 0
else
return 1
if  existingorder    null
if  importedorder    null
collections sort existingorder  new ordercomparator
collections sort importedorder  new ordercomparator
if   existingorder equals importedorder
throw new semanticexception
errormsg incompatible_schema
getmsg
else
if  importedorder    null
throw new semanticexception
errormsg incompatible_schema
getmsg
private static string checkparams map<string  string> map1
map<string  string> map2  string keys
if  map1    null
if  map2    null
for  string key   keys
string v1   map1 get key
string v2   map2 get key
if   objectutils equals v1  v2
return     key
else
for  string key   keys
if  map1 get key     null
return     key
else
if  map2    null
for  string key   keys
if  map2 get key     null
return     key
return null