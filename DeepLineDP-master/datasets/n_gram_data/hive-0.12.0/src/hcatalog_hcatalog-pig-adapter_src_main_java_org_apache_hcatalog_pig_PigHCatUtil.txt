/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing,
* software distributed under the license is distributed on an
* "as is" basis, without warranties or conditions of any
* kind, either express or implied.  see the license for the
* specific language governing permissions and limitations
* under the license.
*/
package org apache hcatalog pig
import java io ioexception
import java util arraylist
import java util arrays
import java util hashmap
import java util list
import java util map
import java util map entry
import java util properties
import org apache hadoop conf configuration
import org apache hadoop hive conf hiveconf
import org apache hadoop hive metastore hivemetastoreclient
import org apache hadoop hive metastore metastoreutils
import org apache hadoop hive metastore api nosuchobjectexception
import org apache hadoop hive ql metadata table
import org apache hadoop mapreduce job
import org apache hcatalog common hcatconstants
import org apache hcatalog common hcatexception
import org apache hcatalog common hcatutil
import org apache hcatalog data hcatrecord
import org apache hcatalog data pair
import org apache hcatalog data schema hcatfieldschema
import org apache hcatalog data schema hcatfieldschema type
import org apache hcatalog data schema hcatschema
import org apache pig loadpushdown requiredfield
import org apache pig pigexception
import org apache pig resourceschema
import org apache pig resourceschema resourcefieldschema
import org apache pig data databag
import org apache pig data databytearray
import org apache pig data datatype
import org apache pig data defaultdatabag
import org apache pig data tuple
import org apache pig data tuplefactory
import org apache pig impl logicallayer schema schema
import org apache pig impl util udfcontext
import org apache pig impl util utils
import org slf4j logger
import org slf4j loggerfactory
/**
* @deprecated use/modify {@link org.apache.hive.hcatalog.pig.pighcatutil} instead
*/
class pighcatutil
private static final logger log   loggerfactory getlogger pighcatutil class
static final int pig_exception_code   1115     http   wiki apache org pig pigerrorhandlingfunctionalspecification#error_codes
private static final string default_db   metastoreutils default_database_name
private final map<pair<string  string>  table> hcattablecache
new hashmap<pair<string  string>  table>
private static final tuplefactory tupfac   tuplefactory getinstance
private static boolean pighasbooleansupport   false
/**
* determine if the current pig version supports boolean columns. this works around a
* dependency conflict preventing hcatalog from requiring a version of pig with boolean
* field support and should be removed once hcatalog-466 has been resolved.
*/
static
// details:
//
// pig-1429 added support for boolean fields, which shipped in 0.10.0;
// this version of pig depends on antlr 3.4.
//
// hcatalog depends heavily on hive, which at this time uses antlr 3.0.1.
//
// antlr 3.0.1 and 3.4 are incompatible, so pig 0.10.0 and hive cannot be depended on in the
// same project. pig 0.8.0 did not use antlr for its parser and can coexist with hive,
// so that pig version is depended on by hcatalog at this time.
try
schema schema   utils getschemafromstring
pighasbooleansupport    schema getfield    type    datatype boolean
catch  throwable e
// pass
if   pighasbooleansupport
log info
hcatconstants hcat_data_convert_boolean_to_integer
static public pair<string  string> getdbtablenames string location  throws ioexception
// the location string will be of the form:
// <database name>.<table name> - parse it and
// communicate the information to hcatinputformat
try
return hcatutil getdbandtablename location
catch  ioexception e
string locationerrmsg
location
throw new pigexception locationerrmsg  pig_exception_code
static public string gethcatserveruri job job
return job getconfiguration   get hiveconf confvars metastoreuris varname
static public string gethcatserverprincipal job job
return job getconfiguration   get hcatconstants hcat_metastore_principal
private static hivemetastoreclient gethivemetaclient string serveruri
string serverkerberosprincipal  class<?> clazz  throws exception
hiveconf hiveconf   new hiveconf clazz
if  serveruri    null
hiveconf set
hiveconf setvar hiveconf confvars metastoreuris  serveruri trim
if  serverkerberosprincipal    null
hiveconf setboolvar hiveconf confvars metastore_use_thrift_sasl  true
hiveconf setvar hiveconf confvars metastore_kerberos_principal  serverkerberosprincipal
try
return hcatutil gethiveclient hiveconf
catch  exception e
throw new exception     serveruri      e
hcatschema gethcatschema list<requiredfield> fields  string signature  class<?> classforudfclookup  throws ioexception
if  fields    null
return null
properties props   udfcontext getudfcontext   getudfproperties
classforudfclookup  new string signature
hcatschema hcattableschema    hcatschema  props get hcatconstants hcat_table_schema
arraylist<hcatfieldschema> fcols   new arraylist<hcatfieldschema>
for  requiredfield rf   fields
fcols add hcattableschema getfields   get rf getindex
return new hcatschema fcols
public table gettable string location  string hcatserveruri  string hcatserverprincipal  throws ioexception
pair<string  string> loc_server   new pair<string  string> location  hcatserveruri
table hcattable   hcattablecache get loc_server
if  hcattable    null
return hcattable
pair<string  string> dbtablepair   pighcatutil getdbtablenames location
string dbname   dbtablepair first
string tablename   dbtablepair second
table table   null
hivemetastoreclient client   null
try
client   gethivemetaclient hcatserveruri  hcatserverprincipal  pighcatutil class
table   hcatutil gettable client  dbname  tablename
catch  nosuchobjectexception nsoe
throw new pigexception     nsoe getmessage    pig_exception_code      prettier error messages to frontend
catch  exception e
throw new ioexception e
finally
hcatutil closehiveclientquietly client
hcattablecache put loc_server  table
return table
public static resourceschema getresourceschema hcatschema hcatschema  throws ioexception
list<resourcefieldschema> rfschemalist   new arraylist<resourcefieldschema>
for  hcatfieldschema hfs   hcatschema getfields
resourcefieldschema rfschema
rfschema   getresourceschemafromfieldschema hfs
rfschemalist add rfschema
resourceschema rschema   new resourceschema
rschema setfields rfschemalist toarray new resourcefieldschema
return rschema
private static resourcefieldschema getresourceschemafromfieldschema hcatfieldschema hfs
throws ioexception
resourcefieldschema rfschema
// if we are dealing with a bag or tuple column - need to worry about subschema
if  hfs gettype      type struct
rfschema   new resourcefieldschema
setname hfs getname
setdescription hfs getcomment
settype getpigtype hfs
setschema gettuplesubschema hfs
else if  hfs gettype      type array
rfschema   new resourcefieldschema
setname hfs getname
setdescription hfs getcomment
settype getpigtype hfs
setschema getbagsubschema hfs
else
rfschema   new resourcefieldschema
setname hfs getname
setdescription hfs getcomment
settype getpigtype hfs
setschema null      no munging inner schemas
return rfschema
protected static resourceschema getbagsubschema hcatfieldschema hfs  throws ioexception
// there are two cases - array<type> and array<struct<...>>
// in either case the element type of the array is represented in a
// tuple field schema in the bag's field schema - the second case (struct)
// more naturally translates to the tuple - in the first case (array<type>)
// we simulate the tuple by putting the single field in a tuple
properties props   udfcontext getudfcontext   getclientsystemprops
string innertuplename   hcatconstants hcat_pig_inner_tuple_name_default
if  props    null    props containskey hcatconstants hcat_pig_inner_tuple_name
innertuplename   props getproperty hcatconstants hcat_pig_inner_tuple_name
replaceall    hfs getname
string innerfieldname   hcatconstants hcat_pig_inner_field_name_default
if  props    null    props containskey hcatconstants hcat_pig_inner_field_name
innerfieldname   props getproperty hcatconstants hcat_pig_inner_field_name
replaceall    hfs getname
resourcefieldschema bagsubfieldschemas   new resourcefieldschema
bagsubfieldschemas   new resourcefieldschema   setname innertuplename
setdescription
settype datatype tuple
hcatfieldschema arrayelementfieldschema   hfs getarrayelementschema   get 0
if  arrayelementfieldschema gettype      type struct
bagsubfieldschemas setschema gettuplesubschema arrayelementfieldschema
else if  arrayelementfieldschema gettype      type array
resourceschema s   new resourceschema
list<resourcefieldschema> lrfs   arrays aslist getresourceschemafromfieldschema arrayelementfieldschema
s setfields lrfs toarray new resourcefieldschema
bagsubfieldschemas setschema s
else
resourcefieldschema innertuplefieldschemas   new resourcefieldschema
innertuplefieldschemas   new resourcefieldschema   setname innerfieldname
setdescription
settype getpigtype arrayelementfieldschema
setschema null      the element type is not a tuple   so no subschema
bagsubfieldschemas setschema new resourceschema   setfields innertuplefieldschemas
resourceschema s   new resourceschema   setfields bagsubfieldschemas
return s
private static resourceschema gettuplesubschema hcatfieldschema hfs  throws ioexception
// for each struct subfield, create equivalent resourcefieldschema
resourceschema s   new resourceschema
list<resourcefieldschema> lrfs   new arraylist<resourcefieldschema>
for  hcatfieldschema subfield   hfs getstructsubschema   getfields
lrfs add getresourceschemafromfieldschema subfield
s setfields lrfs toarray new resourcefieldschema
return s
/**
* @param hfs the field schema of the column
* @return corresponding pig type
* @throws ioexception
*/
static public byte getpigtype hcatfieldschema hfs  throws ioexception
return getpigtype hfs gettype
static public byte getpigtype type type  throws ioexception
if  type    type string
return datatype chararray
if   type    type int      type    type smallint      type    type tinyint
return datatype integer
if  type    type array
return datatype bag
if  type    type struct
return datatype tuple
if  type    type map
return datatype map
if  type    type bigint
return datatype long
if  type    type float
return datatype float
if  type    type double
return datatype double
if  type    type binary
return datatype bytearray
if  type    type boolean    pighasbooleansupport
return datatype boolean
throw new pigexception     type tostring
pig_exception_code
public static tuple transformtotuple hcatrecord hr  hcatschema hs  throws exception
if  hr    null
return null
return transformtotuple hr getall    hs
@suppresswarnings
public static object extractpigobject object o  hcatfieldschema hfs  throws exception
object result
type itemtype   hfs gettype
switch  itemtype
case binary
result    o    null  ? null   new databytearray  byte  o
break
case struct
result   transformtotuple  list<object>  o  hfs
break
case array
result   transformtobag  list<? extends object>  o  hfs
break
case map
result   transformtopigmap  map<object  object>  o  hfs
break
default
result   o
break
return result
private static tuple transformtotuple list<? extends object> objlist  hcatfieldschema hfs  throws exception
try
return transformtotuple objlist  hfs getstructsubschema
catch  exception e
if  hfs gettype      type struct
throw new exception     hfs gettype    e
else
throw e
private static tuple transformtotuple list<? extends object> objlist  hcatschema hs  throws exception
if  objlist    null
return null
tuple t   tupfac newtuple objlist size
list<hcatfieldschema> subfields   hs getfields
for  int i   0  i < subfields size    i
t set i  extractpigobject objlist get i   subfields get i
return t
private static map<string  object> transformtopigmap map<object  object> map  hcatfieldschema hfs  throws exception
if  map    null
return null
map<string  object> result   new hashmap<string  object>
for  entry<object  object> entry   map entryset
// since map key for pig has to be strings
result put entry getkey   tostring    extractpigobject entry getvalue    hfs getmapvalueschema   get 0
return result
@suppresswarnings
private static databag transformtobag list<? extends object> list  hcatfieldschema hfs  throws exception
if  list    null
return null
hcatfieldschema elementsubfieldschema   hfs getarrayelementschema   getfields   get 0
databag db   new defaultdatabag
for  object o   list
tuple tuple
if  elementsubfieldschema gettype      type struct
tuple   transformtotuple  list<object>  o  elementsubfieldschema
else
// bags always contain tuples
tuple   tupfac newtuple extractpigobject o  elementsubfieldschema
db add tuple
return db
private static void validatehcatschemafollowspigrules hcatschema tblschema  throws pigexception
for  hcatfieldschema hcatfield   tblschema getfields
validatehcatfieldfollowspigrules hcatfield
private static void validatehcatfieldfollowspigrules hcatfieldschema hcatfield  throws pigexception
try
type htype   hcatfield gettype
switch  htype
case boolean
if   pighasbooleansupport
throw new pigexception
hcatfield  pighcatutil pig_exception_code
break
case array
validatehcatschemafollowspigrules hcatfield getarrayelementschema
break
case struct
validatehcatschemafollowspigrules hcatfield getstructsubschema
break
case map
// key is only string
if  hcatfield getmapkeytype      type string
log info     hcatfield getname
hcatfield getmapkeytype
validatehcatschemafollowspigrules hcatfield getmapvalueschema
break
catch  hcatexception e
throw new pigexception     hcatfield  pighcatutil pig_exception_code  e
public static void validatehcattableschemafollowspigrules hcatschema hcattableschema  throws ioexception
validatehcatschemafollowspigrules hcattableschema
public static void getconfigfromudfproperties properties p  configuration config  string propname
if  p getproperty propname     null
config set propname  p getproperty propname
public static void saveconfigintoudfproperties properties p  configuration config  string propname
if  config get propname     null
p setproperty propname  config get propname