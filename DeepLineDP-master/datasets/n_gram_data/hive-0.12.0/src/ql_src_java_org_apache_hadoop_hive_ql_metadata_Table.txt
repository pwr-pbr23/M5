/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql metadata
import java io ioexception
import java io serializable
import java net uri
import java util arraylist
import java util arrays
import java util hashmap
import java util iterator
import java util linkedhashmap
import java util list
import java util map
import java util properties
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop hive common javautils
import org apache hadoop hive metastore metastoreutils
import org apache hadoop hive metastore protectmode
import org apache hadoop hive metastore tabletype
import org apache hadoop hive metastore api fieldschema
import org apache hadoop hive metastore api index
import org apache hadoop hive metastore api metaexception
import org apache hadoop hive metastore api order
import org apache hadoop hive metastore api serdeinfo
import org apache hadoop hive metastore api skewedinfo
import org apache hadoop hive metastore api storagedescriptor
import org apache hadoop hive ql io hivefileformatutils
import org apache hadoop hive ql io hiveoutputformat
import org apache hadoop hive ql io hivesequencefileoutputformat
import org apache hadoop hive serde serdeconstants
import org apache hadoop hive serde2 deserializer
import org apache hadoop hive serde2 metadatatypedcolumnsetserde
import org apache hadoop hive serde2 serdeexception
import org apache hadoop hive serde2 serdeutils
import org apache hadoop hive serde2 objectinspector structfield
import org apache hadoop hive serde2 objectinspector structobjectinspector
import org apache hadoop io writable
import org apache hadoop io writablecomparable
import org apache hadoop mapred inputformat
import org apache hadoop mapred sequencefileinputformat
/**
* a hive table: is a fundamental unit of data in hive that shares a common schema/ddl.
*
* please note that the ql code should always go through methods of this class to access the
* metadata, instead of directly accessing org.apache.hadoop.hive.metastore.api.table.  this
* helps to isolate the metastore code and the ql code.
*/
public class table implements serializable
private static final long serialversionuid   1l
static final private log log   logfactory getlog
private org apache hadoop hive metastore api table ttable
/**
* these fields are all cached fields.  the information comes from ttable.
*/
private deserializer deserializer
private class<? extends hiveoutputformat> outputformatclass
private class<? extends inputformat> inputformatclass
private uri uri
private hivestoragehandler storagehandler
/**
* used only for serialization.
*/
public table
public table org apache hadoop hive metastore api table table
ttable   table
if   isview
// this will set up field: inputformatclass
getinputformatclass
// this will set up field: outputformatclass
getoutputformatclass
public table string databasename  string tablename
this getemptytable databasename  tablename
/**
* this function should only be used in serialization.
* we should never call this function to modify the fields, because
* the cached fields will become outdated.
*/
public org apache hadoop hive metastore api table getttable
return ttable
/**
* this function should only be called by java serialization.
*/
public void setttable org apache hadoop hive metastore api table ttable
this ttable   ttable
/**
* initialize an emtpy table.
*/
static org apache hadoop hive metastore api table
getemptytable string databasename  string tablename
storagedescriptor sd   new storagedescriptor
sd setserdeinfo new serdeinfo
sd setnumbuckets  1
sd setbucketcols new arraylist<string>
sd setcols new arraylist<fieldschema>
sd setparameters new hashmap<string  string>
sd setsortcols new arraylist<order>
sd getserdeinfo   setparameters new hashmap<string  string>
// we have to use metadatatypedcolumnsetserde because lazysimpleserde does
// not support a table with no columns.
sd getserdeinfo   setserializationlib metadatatypedcolumnsetserde class getname
sd getserdeinfo   getparameters   put serdeconstants serialization_format
sd setinputformat sequencefileinputformat class getname
sd setoutputformat hivesequencefileoutputformat class getname
skewedinfo skewinfo   new skewedinfo
skewinfo setskewedcolnames new arraylist<string>
skewinfo setskewedcolvalues new arraylist<list<string>>
skewinfo setskewedcolvaluelocationmaps new hashmap<list<string>  string>
sd setskewedinfo skewinfo
org apache hadoop hive metastore api table t   new org apache hadoop hive metastore api table
t setsd sd
t setpartitionkeys new arraylist<fieldschema>
t setparameters new hashmap<string  string>
t settabletype tabletype managed_table tostring
t setdbname databasename
t settablename tablename
return t
public void checkvalidity   throws hiveexception
// check for validity
string name   ttable gettablename
if  null    name    name length      0
metastoreutils validatename name
throw new hiveexception     name
if  0    getcols   size
throw new hiveexception
if   isview
if  null    getdeserializerfrommetastore
throw new hiveexception
if  null    getinputformatclass
throw new hiveexception
if  null    getoutputformatclass
throw new hiveexception
if  isview
assert getvieworiginaltext      null
assert getviewexpandedtext      null
else
assert getvieworiginaltext      null
assert getviewexpandedtext      null
iterator<fieldschema> itercols   getcols   iterator
list<string> colnames   new arraylist<string>
while  itercols hasnext
string colname   itercols next   getname
if   metastoreutils validatename colname
throw new hiveexception     colname
iterator<string> iter   colnames iterator
while  iter hasnext
string oldcolname   iter next
if  colname equalsignorecase oldcolname
throw new hiveexception     colname
colnames add colname tolowercase
if  getpartcols      null
// there is no overlap between columns and partitioning columns
iterator<fieldschema> partcolsiter   getpartcols   iterator
while  partcolsiter hasnext
string partcol   partcolsiter next   getname
if  colnames contains partcol tolowercase
throw new hiveexception     partcol
return
public void setinputformatclass class<? extends inputformat> inputformatclass
this inputformatclass   inputformatclass
ttable getsd   setinputformat inputformatclass getname
public void setoutputformatclass class<? extends hiveoutputformat> outputformatclass
this outputformatclass   outputformatclass
ttable getsd   setoutputformat outputformatclass getname
final public properties getmetadata
return metastoreutils gettablemetadata ttable
final public path getpath
string location   ttable getsd   getlocation
if  location    null
return null
return new path location
final public string gettablename
return ttable gettablename
final public uri getdatalocation
if  uri    null
path path   getpath
if  path    null
uri   path touri
return uri
final public deserializer getdeserializer
if  deserializer    null
deserializer   getdeserializerfrommetastore
return deserializer
private deserializer getdeserializerfrommetastore
try
return metastoreutils getdeserializer hive get   getconf    ttable
catch  metaexception e
throw new runtimeexception e
catch  hiveexception e
throw new runtimeexception e
public hivestoragehandler getstoragehandler
if  storagehandler    null
return storagehandler
try
storagehandler   hiveutils getstoragehandler
hive get   getconf
getproperty
org apache hadoop hive metastore api hive_metastoreconstants meta_table_storage
catch  exception e
throw new runtimeexception e
return storagehandler
final public class<? extends inputformat> getinputformatclass
if  inputformatclass    null
try
string classname   ttable getsd   getinputformat
if  classname    null
if  getstoragehandler      null
return null
inputformatclass   getstoragehandler   getinputformatclass
else
inputformatclass    class<? extends inputformat>
class forname classname  true  javautils getclassloader
catch  classnotfoundexception e
throw new runtimeexception e
return inputformatclass
final public class<? extends hiveoutputformat> getoutputformatclass
// replace fileoutputformat for backward compatibility
boolean storagehandler   false
if  outputformatclass    null
try
string classname   ttable getsd   getoutputformat
class<?> c
if  classname    null
if  getstoragehandler      null
return null
c   getstoragehandler   getoutputformatclass
else
c   class forname classname  true
javautils getclassloader
if   hiveoutputformat class isassignablefrom c
if  getstoragehandler      null
storagehandler   true
else
storagehandler   false
outputformatclass   hivefileformatutils getoutputformatsubstitute c storagehandler
else
outputformatclass    class<? extends hiveoutputformat> c
catch  classnotfoundexception e
throw new runtimeexception e
return outputformatclass
final public boolean isvalidspec map<string  string> spec
throws hiveexception
// todo - types need to be checked.
list<fieldschema> partcols   ttable getpartitionkeys
if  partcols    null     partcols size      0
if  spec    null
throw new hiveexception
spec
else
return true
if   spec    null      spec size      partcols size
throw new hiveexception
spec
for  fieldschema field   partcols
if  spec get field getname       null
throw new hiveexception field getname
spec
return true
public void setproperty string name  string value
ttable getparameters   put name  value
public string getproperty string name
return ttable getparameters   get name
public void settabletype tabletype tabletype
ttable settabletype tabletype tostring
public tabletype gettabletype
return enum valueof tabletype class  ttable gettabletype
public arraylist<structfield> getfields
arraylist<structfield> fields   new arraylist<structfield>
try
deserializer decoder   getdeserializer
// expand out all the columns of the table
structobjectinspector structobjectinspector    structobjectinspector  decoder
getobjectinspector
list<? extends structfield> fld_lst   structobjectinspector
getallstructfieldrefs
for  structfield field   fld_lst
fields add field
catch  serdeexception e
throw new runtimeexception e
return fields
public structfield getfield string fld
try
structobjectinspector structobjectinspector    structobjectinspector  getdeserializer
getobjectinspector
return structobjectinspector getstructfieldref fld
catch  exception e
throw new runtimeexception e
@override
public string tostring
return ttable gettablename
/* (non-javadoc)
* @see java.lang.object#hashcode()
*/
@override
public int hashcode
final int prime   31
int result   1
result   prime   result     ttable    null  ? 0   ttable hashcode
return result
/* (non-javadoc)
* @see java.lang.object#equals(java.lang.object)
*/
@override
public boolean equals object obj
if  this    obj
return true
if  obj    null
return false
if  getclass      obj getclass
return false
table other    table  obj
if  ttable    null
if  other ttable    null
return false
else if   ttable equals other ttable
return false
return true
public list<fieldschema> getpartcols
list<fieldschema> partkeys   ttable getpartitionkeys
if  partkeys    null
partkeys   new arraylist<fieldschema>
ttable setpartitionkeys partkeys
return partkeys
public boolean ispartitionkey string colname
for  fieldschema key   getpartcols
if  key getname   tolowercase   equals colname
return true
return false
// todo merge this with getbucketcols function
public string getbucketingdimensionid
list<string> bcols   ttable getsd   getbucketcols
if  bcols    null    bcols size      0
return null
if  bcols size   > 1
log warn this
return bcols get 0
public void setdatalocation uri uri
this uri   uri
ttable getsd   setlocation uri tostring
public void unsetdatalocation
this uri   null
ttable getsd   unsetlocation
public void setbucketcols list<string> bucketcols  throws hiveexception
if  bucketcols    null
return
for  string col   bucketcols
if   isfield col
throw new hiveexception     col
getcols
ttable getsd   setbucketcols bucketcols
public void setsortcols list<order> sortorder  throws hiveexception
ttable getsd   setsortcols sortorder
public void setskewedvaluelocationmap list<string> vallist  string dirname
throws hiveexception
map<list<string>  string> mappings   ttable getsd   getskewedinfo
getskewedcolvaluelocationmaps
if  null    mappings
mappings   new hashmap<list<string>  string>
ttable getsd   getskewedinfo   setskewedcolvaluelocationmaps mappings
// add or update new mapping
mappings put vallist  dirname
public map<list<string> string> getskewedcolvaluelocationmaps
return  ttable getsd   getskewedinfo      null  ? ttable getsd   getskewedinfo
getskewedcolvaluelocationmaps     new hashmap<list<string>  string>
public void setskewedcolvalues list<list<string>> skewedvalues  throws hiveexception
ttable getsd   getskewedinfo   setskewedcolvalues skewedvalues
public list<list<string>> getskewedcolvalues
return  ttable getsd   getskewedinfo      null  ? ttable getsd   getskewedinfo
getskewedcolvalues     new arraylist<list<string>>
public void setskewedcolnames list<string> skewedcolnames  throws hiveexception
ttable getsd   getskewedinfo   setskewedcolnames skewedcolnames
public list<string> getskewedcolnames
return  ttable getsd   getskewedinfo      null  ? ttable getsd   getskewedinfo
getskewedcolnames     new arraylist<string>
public skewedinfo getskewedinfo
return ttable getsd   getskewedinfo
public void setskewedinfo skewedinfo skewedinfo  throws hiveexception
ttable getsd   setskewedinfo skewedinfo
public boolean isstoredassubdirectories
return ttable getsd   isstoredassubdirectories
public void setstoredassubdirectories boolean storedassubdirectories  throws hiveexception
ttable getsd   setstoredassubdirectories storedassubdirectories
private boolean isfield string col
for  fieldschema field   getcols
if  field getname   equals col
return true
return false
public list<fieldschema> getcols
boolean getcolsfromserde   serdeutils shouldgetcolsfromserde
getserializationlib
if   getcolsfromserde
return ttable getsd   getcols
else
try
return hive getfieldsfromdeserializer gettablename    getdeserializer
catch  hiveexception e
log error     getserializationlib    e
return new arraylist<fieldschema>
/**
* returns a list of all the columns of the table (data columns + partition
* columns in that order.
*
* @return list<fieldschema>
*/
public list<fieldschema> getallcols
arraylist<fieldschema> f_list   new arraylist<fieldschema>
f_list addall getpartcols
f_list addall getcols
return f_list
public void setpartcols list<fieldschema> partcols
ttable setpartitionkeys partcols
public string getdbname
return ttable getdbname
public int getnumbuckets
return ttable getsd   getnumbuckets
/**
* replaces the directory corresponding to the table by srcf. works by
* deleting the table directory and renaming the source directory.
*
* @param srcf
*          source directory
*/
protected void replacefiles path srcf  throws hiveexception
path tabledest    new path getdatalocation   getpath
hive replacefiles srcf  tabledest  tabledest  hive get   getconf
/**
* inserts files specified into the partition. works by moving files
*
* @param srcf
*          files to be moved. leaf directories or globbed file paths
*/
protected void copyfiles path srcf  throws hiveexception
filesystem fs
try
fs   filesystem get getdatalocation    hive get   getconf
hive copyfiles hive get   getconf    srcf  new path getdatalocation   getpath     fs
catch  ioexception e
throw new hiveexception    e
public void setinputformatclass string name  throws hiveexception
if  name    null
inputformatclass   null
ttable getsd   setinputformat null
return
try
setinputformatclass  class<? extends inputformat<writablecomparable  writable>>  class
forname name  true  javautils getclassloader
catch  classnotfoundexception e
throw new hiveexception     name  e
public void setoutputformatclass string name  throws hiveexception
if  name    null
outputformatclass   null
ttable getsd   setoutputformat null
return
try
class<?> origin   class forname name  true  javautils getclassloader
setoutputformatclass hivefileformatutils
getoutputformatsubstitute origin false
catch  classnotfoundexception e
throw new hiveexception     name  e
public boolean ispartitioned
if  getpartcols      null
return false
return  getpartcols   size      0
public void setfields list<fieldschema> fields
ttable getsd   setcols fields
public void setnumbuckets int nb
ttable getsd   setnumbuckets nb
/**
* @return the owner of the table.
* @see org.apache.hadoop.hive.metastore.api.table#getowner()
*/
public string getowner
return ttable getowner
/**
* @return the table parameters.
* @see org.apache.hadoop.hive.metastore.api.table#getparameters()
*/
public map<string  string> getparameters
return ttable getparameters
/**
* @return the retention on the table.
* @see org.apache.hadoop.hive.metastore.api.table#getretention()
*/
public int getretention
return ttable getretention
/**
* @param owner
* @see org.apache.hadoop.hive.metastore.api.table#setowner(java.lang.string)
*/
public void setowner string owner
ttable setowner owner
/**
* @param retention
* @see org.apache.hadoop.hive.metastore.api.table#setretention(int)
*/
public void setretention int retention
ttable setretention retention
private serdeinfo getserdeinfo
return ttable getsd   getserdeinfo
public void setserializationlib string lib
getserdeinfo   setserializationlib lib
public string getserializationlib
return getserdeinfo   getserializationlib
public string getserdeparam string param
return getserdeinfo   getparameters   get param
public string setserdeparam string param  string value
return getserdeinfo   getparameters   put param  value
public list<string> getbucketcols
return ttable getsd   getbucketcols
public list<order> getsortcols
return ttable getsd   getsortcols
public void settablename string tablename
ttable settablename tablename
public void setdbname string databasename
ttable setdbname databasename
public list<fieldschema> getpartitionkeys
return ttable getpartitionkeys
/**
* @return the original view text, or null if this table is not a view
*/
public string getvieworiginaltext
return ttable getvieworiginaltext
/**
* @param vieworiginaltext
*          the original view text to set
*/
public void setvieworiginaltext string vieworiginaltext
ttable setvieworiginaltext vieworiginaltext
/**
* @return the expanded view text, or null if this table is not a view
*/
public string getviewexpandedtext
return ttable getviewexpandedtext
public void clearserdeinfo
ttable getsd   getserdeinfo   getparameters   clear
/**
* @param viewexpandedtext
*          the expanded view text to set
*/
public void setviewexpandedtext string viewexpandedtext
ttable setviewexpandedtext viewexpandedtext
/**
* @return whether this table is actually a view
*/
public boolean isview
return tabletype virtual_view equals gettabletype
/**
* @return whether this table is actually an index table
*/
public boolean isindextable
return tabletype index_table equals gettabletype
/**
* creates a partition name -> value spec map object
*
* @param tp
*          use the information from this partition.
* @return partition name to value mapping.
*/
public linkedhashmap<string  string> createspec
org apache hadoop hive metastore api partition tp
list<fieldschema> fsl   getpartcols
list<string> tpl   tp getvalues
linkedhashmap<string  string> spec   new linkedhashmap<string  string>
for  int i   0  i < fsl size    i
fieldschema fs   fsl get i
string value   tpl get i
spec put fs getname    value
return spec
public table copy   throws hiveexception
return new table ttable deepcopy
public void setcreatetime int createtime
ttable setcreatetime createtime
public int getlastaccesstime
return ttable getlastaccesstime
public void setlastaccesstime int lastaccesstime
ttable setlastaccesstime lastaccesstime
public boolean isnonnative
return getproperty
org apache hadoop hive metastore api hive_metastoreconstants meta_table_storage

/**
* @param protectmode
*/
public void setprotectmode protectmode protectmode
map<string  string> parameters   ttable getparameters
string pm   protectmode tostring
if  pm    null
parameters put protectmode parameter_name  pm
else
parameters remove protectmode parameter_name
ttable setparameters parameters
/**
* @return protect mode
*/
public protectmode getprotectmode
map<string  string> parameters   ttable getparameters
if   parameters containskey protectmode parameter_name
return new protectmode
else
return protectmode getprotectmodefromstring
parameters get protectmode parameter_name
/**
* @return true protect mode indicates the table if offline.
*/
public boolean isoffline
return getprotectmode   offline
/**
* @return true if protect mode attribute of the partition indicate
* that it is ok to drop the partition
*/
public boolean candrop
protectmode mode   getprotectmode
return   mode nodrop     mode offline     mode readonly     mode nodropcascade
/**
* @return true if protect mode attribute of the table indicate
* that it is ok to write the table
*/
public boolean canwrite
protectmode mode   getprotectmode
return   mode offline     mode readonly
/**
* @return include the db name
*/
public string getcompletename
return getdbname         gettablename
/**
* @return list containing indexes names if there are indexes on this table
* @throws hiveexception
**/
public list<index> getallindexes short max  throws hiveexception
hive hive   hive get
return hive getindexes getttable   getdbname    getttable   gettablename    max
@suppresswarnings
public filestatus getsortedpaths
try
// previously, this got the filesystem of the table, which could be
// different from the filesystem of the partition.
filesystem fs   filesystem get getpath   touri    hive get
getconf
string pathpattern   getpath   tostring
if  getnumbuckets   > 0
pathpattern   pathpattern
log info     pathpattern
filestatus srcs   fs globstatus new path pathpattern
arrays sort srcs
for  filestatus src   srcs
log info     src getpath
if  srcs length    0
return null
return srcs
catch  exception e
throw new runtimeexception    e