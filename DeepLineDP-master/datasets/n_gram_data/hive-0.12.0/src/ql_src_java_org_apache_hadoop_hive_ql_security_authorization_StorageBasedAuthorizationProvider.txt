/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql security authorization
import java io filenotfoundexception
import java io ioexception
import java security accesscontrolexception
import java util enumset
import java util list
import javax security auth login loginexception
import org apache hadoop conf configuration
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop fs permission fsaction
import org apache hadoop fs permission fspermission
import org apache hadoop hive conf hiveconf
import org apache hadoop hive metastore hivemetastore hmshandler
import org apache hadoop hive metastore warehouse
import org apache hadoop hive metastore api database
import org apache hadoop hive metastore api metaexception
import org apache hadoop hive ql metadata authorizationexception
import org apache hadoop hive ql metadata hive
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata partition
import org apache hadoop hive ql metadata table
/**
* storagebasedauthorizationprovider is an implementation of
* hivemetastoreauthorizationprovider that tries to look at the hdfs
* permissions of files and directories associated with objects like
* databases, tables and partitions to determine whether or not an
* operation is allowed. the rule of thumb for which location to check
* in hdfs is as follows:
*
* create : on location specified, or on location determined from metadata
* reads : not checked (the preeventlistener does not have an event to fire)
* updates : on location in metadata
* deletes : on location in metadata
*
* if the location does not yet exist, as the case is with creates, it steps
* out to the parent directory recursively to determine its permissions till
* it finds a parent that does exist.
*/
public class storagebasedauthorizationprovider extends hiveauthorizationproviderbase
implements hivemetastoreauthorizationprovider
private warehouse wh
private boolean isrunfrommetastore   false
/**
* make sure that the warehouse variable is set up properly.
* @throws metaexception if unable to instantiate
*/
private void initwh   throws metaexception  hiveexception
if  wh    null
if  isrunfrommetastore
// note, although hiveproxy has a method that allows us to check if we're being
// called from the metastore or from the client, we don't have an initialized hiveproxy
// till we explicitly initialize it as being from the client side. so, we have a
// chicken-and-egg problem. so, we now track whether or not we're running from client-side
// in the sbap itself.
hive_db   new hiveproxy hive get new hiveconf getconf    storagebasedauthorizationprovider class
this wh   new warehouse getconf
if  this wh    null
// if wh is still null after just having initialized it, bail out - something's very wrong.
throw new illegalstateexception
else
// not good if we reach here, this was initialized at setmetastorehandler() time.
// this means handler.getwh() is returning null. error out.
throw new illegalstateexception
@override
public void init configuration conf  throws hiveexception
hive_db   new hiveproxy
@override
public void authorize privilege readrequiredpriv  privilege writerequiredpriv
throws hiveexception  authorizationexception
// currently not used in hive code-base, but intended to authorize actions
// that are directly user-level. as there's no storage based aspect to this,
// we can follow one of two routes:
// a) we can allow by default - that way, this call stays out of the way
// b) we can deny by default - that way, no privileges are authorized that
// is not understood and explicitly allowed.
// both approaches have merit, but given that things like grants and revokes
// that are user-level do not make sense from the context of storage-permission
// based auth, denying seems to be more canonical here.
throw new authorizationexception storagebasedauthorizationprovider class getname
@override
public void authorize database db  privilege readrequiredpriv  privilege writerequiredpriv
throws hiveexception  authorizationexception
path path   getdblocation db
authorize path  readrequiredpriv  writerequiredpriv
@override
public void authorize table table  privilege readrequiredpriv  privilege writerequiredpriv
throws hiveexception  authorizationexception
// table path can be null in the case of a new create table - in this case,
// we try to determine what the path would be after the create table is issued.
path path   null
try
initwh
string location   table getttable   getsd   getlocation
if  location    null    location isempty
path   wh gettablepath hive_db getdatabase table getdbname     table gettablename
else
path   new path location
catch  metaexception ex
throw hiveexception ex
authorize path  readrequiredpriv  writerequiredpriv
@override
public void authorize partition part  privilege readrequiredpriv  privilege writerequiredpriv
throws hiveexception  authorizationexception
authorize part gettable    part  readrequiredpriv  writerequiredpriv
private void authorize table table  partition part  privilege readrequiredpriv
privilege writerequiredpriv
throws hiveexception  authorizationexception
// partition path can be null in the case of a new create partition - in this case,
// we try to default to checking the permissions of the parent table
if  part getlocation      null
authorize table  readrequiredpriv  writerequiredpriv
else
authorize part getpartitionpath    readrequiredpriv  writerequiredpriv
@override
public void authorize table table  partition part  list<string> columns
privilege readrequiredpriv  privilege writerequiredpriv  throws hiveexception
authorizationexception
// in a simple storage-based auth, we have no information about columns
// living in different files, so we do simple partition-auth and ignore
// the columns parameter.
authorize part gettable    part  readrequiredpriv  writerequiredpriv
@override
public void setmetastorehandler hmshandler handler
hive_db sethandler handler
this wh   handler getwh
this isrunfrommetastore   true
/**
* given a privilege, return what fsactions are required
*/
protected fsaction getfsaction privilege priv
switch  priv getpriv
case all
return fsaction read_write
case alter_data
return fsaction write
case alter_metadata
return fsaction write
case create
return fsaction write
case drop
return fsaction write
case index
throw new authorizationexception
case lock
throw new authorizationexception
case select
return fsaction read
case show_database
return fsaction read
case unknown
default
throw new authorizationexception
/**
* given a privilege[], find out what all fsactions are required
*/
protected enumset<fsaction> getfsactions privilege privs
enumset<fsaction> actions   enumset noneof fsaction class
if  privs    null
return actions
for  privilege priv   privs
actions add getfsaction priv
return actions
/**
* authorization privileges against a path.
*
* @param path
*          a filesystem path
* @param readrequiredpriv
*          a list of privileges needed for inputs.
* @param writerequiredpriv
*          a list of privileges needed for outputs.
*/
public void authorize path path  privilege readrequiredpriv  privilege writerequiredpriv
throws hiveexception  authorizationexception
try
enumset<fsaction> actions   getfsactions readrequiredpriv
actions addall getfsactions writerequiredpriv
if  actions isempty
return
checkpermissions getconf    path  actions
catch  accesscontrolexception ex
throw authorizationexception ex
catch  loginexception ex
throw authorizationexception ex
catch  ioexception ex
throw hiveexception ex
/**
* checks the permissions for the given path and current user on hadoop fs.
* if the given path does not exists, it checks for its parent folder.
*/
protected void checkpermissions final configuration conf  final path path
final enumset<fsaction> actions  throws ioexception  loginexception
if  path    null
throw new illegalargumentexception
final filesystem fs   path getfilesystem conf
if  fs exists path
checkpermissions fs  path  actions
authenticator getusername    authenticator getgroupnames
else if  path getparent      null
// find the ancestor which exists to check its permissions
path par   path getparent
while  par    null
if  fs exists par
break
par   par getparent
checkpermissions fs  par  actions
authenticator getusername    authenticator getgroupnames
/**
* checks the permissions for the given path and current user on hadoop fs. if the given path
* does not exists, it returns.
*/
@suppresswarnings
protected static void checkpermissions final filesystem fs  final path path
final enumset<fsaction> actions  string user  list<string> groups  throws ioexception
accesscontrolexception
final filestatus stat
try
stat   fs getfilestatus path
catch  filenotfoundexception fnfe
// file named by path doesn't exist; nothing to validate.
return
catch  org apache hadoop fs permission accesscontrolexception ace
// older hadoop version will throw this @deprecated exception.
throw accesscontrolexception ace
final fspermission dirperms   stat getpermission
final string grp   stat getgroup
for  fsaction action   actions
if  user equals stat getowner
if  dirperms getuseraction   implies action
continue
if  groups contains grp
if  dirperms getgroupaction   implies action
continue
if  dirperms getotheraction   implies action
continue
throw new accesscontrolexception     action
path       user
protected path getdblocation database db  throws hiveexception
try
initwh
string location   db getlocationuri
if  location    null
return wh getdefaultdatabasepath db getname
else
return wh getdnspath wh getdatabasepath db
catch  metaexception ex
throw hiveexception ex
private hiveexception hiveexception exception e
return new hiveexception e
private authorizationexception authorizationexception exception e
return new authorizationexception e
private static accesscontrolexception accesscontrolexception
org apache hadoop fs permission accesscontrolexception e
accesscontrolexception ace   new accesscontrolexception e getmessage
ace initcause e
return ace