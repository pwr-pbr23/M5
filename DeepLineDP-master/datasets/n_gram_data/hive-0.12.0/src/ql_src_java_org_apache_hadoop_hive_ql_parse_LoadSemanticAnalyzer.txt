/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql parse
import java io ioexception
import java io serializable
import java net uri
import java net urisyntaxexception
import java util linkedhashmap
import java util list
import java util map
import org antlr runtime tree tree
import org apache commons httpclient uriexception
import org apache commons httpclient util uriutil
import org apache commons lang stringutils
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop hive conf hiveconf
import org apache hadoop hive metastore api fieldschema
import org apache hadoop hive ql errormsg
import org apache hadoop hive ql exec task
import org apache hadoop hive ql exec taskfactory
import org apache hadoop hive ql exec utilities
import org apache hadoop hive ql hooks writeentity
import org apache hadoop hive ql metadata hive
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata partition
import org apache hadoop hive ql plan copywork
import org apache hadoop hive ql plan loadtabledesc
import org apache hadoop hive ql plan movework
import org apache hadoop hive ql plan statswork
/**
* loadsemanticanalyzer.
*
*/
public class loadsemanticanalyzer extends basesemanticanalyzer
private boolean islocal
private boolean isoverwrite
public loadsemanticanalyzer hiveconf conf  throws semanticexception
super conf
public static filestatus matchfilesordir filesystem fs  path path
throws ioexception
filestatus srcs   fs globstatus path
if   srcs    null     srcs length    1
if  srcs isdir
srcs   fs liststatus srcs getpath
return  srcs
private uri initializefromuri string frompath  throws ioexception
urisyntaxexception
uri fromuri   new path frompath  touri
string fromscheme   fromuri getscheme
string fromauthority   fromuri getauthority
string path   fromuri getpath
// generate absolute path relative to current directory or hdfs home
// directory
if   path startswith
if  islocal
path   uriutil decode  new path system getproperty     path  touri   tostring
else
path   new path new path     system getproperty
path  tostring
// set correct scheme and authority
if  stringutils isempty fromscheme
if  islocal
// file for local
fromscheme
else
// use default values from fs.default.name
uri defaulturi   filesystem get conf  geturi
fromscheme   defaulturi getscheme
fromauthority   defaulturi getauthority
// if scheme is specified but not authority then use the default authority
if    fromscheme equals        stringutils isempty fromauthority
uri defaulturi   filesystem get conf  geturi
fromauthority   defaulturi getauthority
log debug fromscheme       fromauthority       path
return new uri fromscheme  fromauthority  path  null  null
private void applyconstraints uri fromuri  uri touri  tree ast
boolean islocal  throws semanticexception
// local mode implies that scheme should be "file"
// we can change this going forward
if  islocal     fromuri getscheme   equals
throw new semanticexception errormsg illegal_path getmsg ast
file  local
try
filestatus srcs   matchfilesordir filesystem get fromuri  conf
new path fromuri getscheme    fromuri getauthority    fromuri
getpath
if  srcs    null    srcs length    0
throw new semanticexception errormsg invalid_path getmsg ast
fromuri
for  filestatus onesrc   srcs
if  onesrc isdir
throw new semanticexception errormsg invalid_path getmsg ast
onesrc getpath   tostring
catch  ioexception e
// has to use full name to make sure it does not conflict with
// org.apache.commons.lang.stringutils
throw new semanticexception errormsg invalid_path getmsg ast   e
// only in 'local' mode do we copy stuff from one place to another.
// reject different scheme/authority in other cases.
if   islocal
stringutils equals fromuri getscheme    touri getscheme        stringutils
equals fromuri getauthority    touri getauthority
string reason       fromuri tostring
touri tostring
default fs name
hive metastore warehouse dir
throw new semanticexception errormsg illegal_path getmsg ast  reason
@override
public void analyzeinternal astnode ast  throws semanticexception
islocal   false
isoverwrite   false
tree fromtree   ast getchild 0
tree tabletree   ast getchild 1
if  ast getchildcount      4
islocal   true
isoverwrite   true
if  ast getchildcount      3
if  ast getchild 2  gettext   tolowercase   equals
islocal   true
else
isoverwrite   true
// initialize load path
uri fromuri
try
string frompath   stripquotes fromtree gettext
fromuri   initializefromuri frompath
catch  ioexception e
throw new semanticexception errormsg invalid_path getmsg fromtree  e
getmessage     e
catch  urisyntaxexception e
throw new semanticexception errormsg invalid_path getmsg fromtree  e
getmessage     e
// initialize destination table/partition
tablespec ts   new tablespec db  conf   astnode  tabletree
if  ts tablehandle isoffline
throw new semanticexception
errormsg offline_table_or_partition getmsg     ts tablename
if  ts tablehandle isview
throw new semanticexception errormsg dml_against_view getmsg
if  ts tablehandle isnonnative
throw new semanticexception errormsg load_into_non_native getmsg
if ts tablehandle isstoredassubdirectories
throw new semanticexception errormsg load_into_stored_as_dir getmsg
uri touri    ts parthandle    null  ? ts parthandle getdatalocation
ts tablehandle getdatalocation
list<fieldschema> parts   ts tablehandle getpartitionkeys
if   parts    null    parts size   > 0
ts partspec    null    ts partspec size      0
throw new semanticexception errormsg need_partition_error getmsg
// make sure the arguments make sense
applyconstraints fromuri  touri  fromtree  islocal
task<? extends serializable> rtask   null
// create copy work
if  islocal
// if the local keyword is specified - we will always make a copy. this
// might seem redundant in the case
// that the hive warehouse is also located in the local file system - but
// that's just a test case.
string copyuristr   ctx getexternaltmpfileuri touri
uri copyuri   uri create copyuristr
try
rtask   taskfactory get new copywork uriutil decode fromuri tostring     copyuristr
conf
catch  uriexception e
throw new semanticexception errormsg invalid_path getmsg fromtree  e
getmessage     e
fromuri   copyuri
// create final load/move work
string loadtmppath   ctx getexternaltmpfileuri touri
map<string  string> partspec   ts getpartspec
if  partspec    null
partspec   new linkedhashmap<string  string>
outputs add new writeentity ts tablehandle
else
try
partition part   hive get   getpartition ts tablehandle  partspec  false
if  part    null
if  part isoffline
throw new semanticexception errormsg offline_table_or_partition
getmsg ts tablename       part getname
outputs add new writeentity part
else
outputs add new writeentity ts tablehandle
catch hiveexception e
throw new semanticexception e
loadtabledesc loadtablework
try
loadtablework   new loadtabledesc uriutil decode fromuri tostring
loadtmppath  utilities gettabledesc ts tablehandle   partspec  isoverwrite
catch  uriexception e1
throw new semanticexception errormsg invalid_path getmsg fromtree  e1
getmessage     e1
task<? extends serializable> childtask   taskfactory get new movework getinputs
getoutputs    loadtablework  null  true   conf
if  rtask    null
rtask adddependenttask childtask
else
rtask   childtask
roottasks add rtask
// the user asked for stats to be collected.
// some stats like number of rows require a scan of the data
// however, some other stats, like number of files, do not require a complete scan
// update the stats which do not require a complete scan.
task<? extends serializable> stattask   null
if  conf getboolvar hiveconf confvars hivestatsautogather
statswork statdesc   new statswork loadtablework
statdesc setnostatsaggregator true
statdesc setclearaggregatorstats true
statdesc setstatsreliable conf getboolvar hiveconf confvars hive_stats_reliable
stattask   taskfactory get statdesc  conf
// hive-3334 has been filed for load file with index auto update
if  hiveconf getboolvar conf  hiveconf confvars hiveindexautoupdate
indexupdater indexupdater   new indexupdater loadtablework  getinputs    conf
try
list<task<? extends serializable>> indexupdatetasks   indexupdater generateupdatetasks
for  task<? extends serializable> updatetask   indexupdatetasks
//load data will either have a copy & move or just a move,
// we always want the update to be dependent on the move
childtask adddependenttask updatetask
if  stattask    null
updatetask adddependenttask stattask
catch  hiveexception e
console printinfo
else if  stattask    null
childtask adddependenttask stattask