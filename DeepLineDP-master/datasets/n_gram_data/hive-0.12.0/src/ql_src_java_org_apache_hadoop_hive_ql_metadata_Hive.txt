/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql metadata
import static org apache hadoop hive metastore api hive_metastoreconstants meta_table_storage
import static org apache hadoop hive serde serdeconstants collection_delim
import static org apache hadoop hive serde serdeconstants escape_char
import static org apache hadoop hive serde serdeconstants field_delim
import static org apache hadoop hive serde serdeconstants line_delim
import static org apache hadoop hive serde serdeconstants mapkey_delim
import static org apache hadoop hive serde serdeconstants serialization_format
import static org apache hadoop hive serde serdeconstants string_type_name
import java io filenotfoundexception
import java io ioexception
import java util arraylist
import java util arrays
import java util hashmap
import java util hashset
import java util iterator
import java util linkedhashmap
import java util linkedhashset
import java util list
import java util map
import java util map entry
import java util set
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop fs fsshell
import org apache hadoop fs path
import org apache hadoop hive common fileutils
import org apache hadoop hive conf hiveconf
import org apache hadoop hive metastore hivemetaexception
import org apache hadoop hive metastore hivemetahook
import org apache hadoop hive metastore hivemetahookloader
import org apache hadoop hive metastore hivemetastoreclient
import org apache hadoop hive metastore imetastoreclient
import org apache hadoop hive metastore metastoreutils
import org apache hadoop hive metastore retryingmetastoreclient
import org apache hadoop hive metastore tabletype
import org apache hadoop hive metastore warehouse
import org apache hadoop hive metastore api alreadyexistsexception
import org apache hadoop hive metastore api columnstatistics
import org apache hadoop hive metastore api database
import org apache hadoop hive metastore api fieldschema
import org apache hadoop hive metastore api hiveobjectprivilege
import org apache hadoop hive metastore api hiveobjectref
import org apache hadoop hive metastore api hiveobjecttype
import org apache hadoop hive metastore api index
import org apache hadoop hive metastore api invalidoperationexception
import org apache hadoop hive metastore api metaexception
import org apache hadoop hive metastore api nosuchobjectexception
import org apache hadoop hive metastore api order
import org apache hadoop hive metastore api principalprivilegeset
import org apache hadoop hive metastore api principaltype
import org apache hadoop hive metastore api privilegebag
import org apache hadoop hive metastore api role
import org apache hadoop hive metastore api serdeinfo
import org apache hadoop hive metastore api skewedinfo
import org apache hadoop hive metastore api hive_metastoreconstants
import org apache hadoop hive ql exec utilities
import org apache hadoop hive ql index hiveindexhandler
import org apache hadoop hive ql optimizer listbucketingpruner listbucketingprunerutils
import org apache hadoop hive ql session createtableautomaticgrant
import org apache hadoop hive ql session sessionstate
import org apache hadoop hive serde2 deserializer
import org apache hadoop hive serde2 serdeexception
import org apache hadoop hive serde2 lazy lazysimpleserde
import org apache hadoop mapred inputformat
import org apache hadoop util stringutils
import org apache thrift texception
import com google common collect sets
/**
* this class has functions that implement meta data/ddl operations using calls
* to the metastore.
* it has a metastore client instance it uses to communicate with the metastore.
*
* it is a thread local variable, and the instances is accessed using static
* get methods in this class.
*/
public class hive
static final private log log   logfactory getlog
private hiveconf conf   null
private imetastoreclient metastoreclient
private static threadlocal<hive> hivedb   new threadlocal<hive>
@override
protected synchronized hive initialvalue
return null
@override
public synchronized void remove
if  this get      null
this get   close
super remove
/**
* gets hive object for the current thread. if one is not initialized then a
* new one is created if the new configuration is different in metadata conf
* vars then a new one is created.
*
* @param c
*          new hive configuration
* @return hive object for current thread
* @throws hiveexception
*
*/
public static hive get hiveconf c  throws hiveexception
boolean needsrefresh   false
hive db   hivedb get
if  db    null
for  hiveconf confvars onevar   hiveconf metavars
// since metavars are all of different types, use string for comparison
string oldvar   db getconf   get onevar varname
string newvar   c get onevar varname
if  oldvar comparetoignorecase newvar     0
needsrefresh   true
break
return get c  needsrefresh
/**
* get a connection to metastore. see get(hiveconf) function for comments
*
* @param c
*          new conf
* @param needsrefresh
*          if true then creates a new one
* @return the connection to the metastore
* @throws hiveexception
*/
public static hive get hiveconf c  boolean needsrefresh  throws hiveexception
hive db   hivedb get
if  db    null    needsrefresh
closecurrent
c set
hive newdb   new hive c
hivedb set newdb
return newdb
db conf   c
return db
public static hive get   throws hiveexception
hive db   hivedb get
if  db    null
db   new hive new hiveconf hive class
hivedb set db
return db
public static void set hive hive
hivedb set hive
public static void closecurrent
hivedb remove
/**
* hive
*
* @param argfsroot
* @param c
*
*/
private hive hiveconf c  throws hiveexception
conf   c
/**
* closes the connection to metastore for the calling thread
*/
private void close
log debug
if  metastoreclient    null
metastoreclient close
metastoreclient   null
/**
* create a database
* @param db
* @param ifnotexist if true, will ignore alreadyexistsexception exception
* @throws alreadyexistsexception
* @throws hiveexception
*/
public void createdatabase database db  boolean ifnotexist
throws alreadyexistsexception  hiveexception
try
getmsc   createdatabase db
catch  alreadyexistsexception e
if   ifnotexist
throw e
catch  exception e
throw new hiveexception e
/**
* create a database. raise an error if a database with the same name already exists.
* @param db
* @throws alreadyexistsexception
* @throws hiveexception
*/
public void createdatabase database db  throws alreadyexistsexception  hiveexception
createdatabase db  false
/**
* drop a database.
* @param name
* @throws nosuchobjectexception
* @throws hiveexception
* @see org.apache.hadoop.hive.metastore.hivemetastoreclient#dropdatabase(java.lang.string)
*/
public void dropdatabase string name  throws hiveexception  nosuchobjectexception
dropdatabase name  true  false  false
/**
* drop a database
* @param name
* @param deletedata
* @param ignoreunknowndb if true, will ignore nosuchobjectexception
* @throws hiveexception
* @throws nosuchobjectexception
*/
public void dropdatabase string name  boolean deletedata  boolean ignoreunknowndb
throws hiveexception  nosuchobjectexception
dropdatabase name  deletedata  ignoreunknowndb  false
/**
* drop a database
* @param name
* @param deletedata
* @param ignoreunknowndb if true, will ignore nosuchobjectexception
* @param cascade           if true, delete all tables on the db if exists. othewise, the query
*                        will fail if table still exists.
* @throws hiveexception
* @throws nosuchobjectexception
*/
public void dropdatabase string name  boolean deletedata  boolean ignoreunknowndb  boolean cascade
throws hiveexception  nosuchobjectexception
try
getmsc   dropdatabase name  deletedata  ignoreunknowndb  cascade
catch  nosuchobjectexception e
throw e
catch  exception e
throw new hiveexception e
/**
* creates a table metdata and the directory for the table data
*
* @param tablename
*          name of the table
* @param columns
*          list of fields of the table
* @param partcols
*          partition keys of the table
* @param fileinputformat
*          class of the input format of the table data file
* @param fileoutputformat
*          class of the output format of the table data file
* @throws hiveexception
*           thrown if the args are invalid or if the metadata or the data
*           directory couldn't be created
*/
public void createtable string tablename  list<string> columns
list<string> partcols  class<? extends inputformat> fileinputformat
class<?> fileoutputformat  throws hiveexception
this createtable tablename  columns  partcols  fileinputformat
fileoutputformat   1  null
/**
* creates a table metdata and the directory for the table data
*
* @param tablename
*          name of the table
* @param columns
*          list of fields of the table
* @param partcols
*          partition keys of the table
* @param fileinputformat
*          class of the input format of the table data file
* @param fileoutputformat
*          class of the output format of the table data file
* @param bucketcount
*          number of buckets that each partition (or the table itself) should
*          be divided into
* @throws hiveexception
*           thrown if the args are invalid or if the metadata or the data
*           directory couldn't be created
*/
public void createtable string tablename  list<string> columns
list<string> partcols  class<? extends inputformat> fileinputformat
class<?> fileoutputformat  int bucketcount  list<string> bucketcols
throws hiveexception
if  columns    null
throw new hiveexception     tablename
table tbl   newtable tablename
tbl setinputformatclass fileinputformat getname
tbl setoutputformatclass fileoutputformat getname
for  string col   columns
fieldschema field   new fieldschema col  string_type_name
tbl getcols   add field
if  partcols    null
for  string partcol   partcols
fieldschema part   new fieldschema
part setname partcol
part settype string_type_name      default partition key
tbl getpartcols   add part
tbl setserializationlib lazysimpleserde class getname
tbl setnumbuckets bucketcount
tbl setbucketcols bucketcols
createtable tbl
/**
* updates the existing table metadata with the new metadata.
*
* @param tblname
*          name of the existing table
* @param newtbl
*          new name of the table. could be the old name
* @throws invalidoperationexception
*           if the changes in metadata is not acceptable
* @throws texception
*/
public void altertable string tblname  table newtbl
throws invalidoperationexception  hiveexception
table t   newtable tblname
try
// remove the ddl_time so it gets refreshed
if  newtbl getparameters      null
newtbl getparameters   remove hive_metastoreconstants ddl_time
getmsc   alter_table t getdbname    t gettablename    newtbl getttable
catch  metaexception e
throw new hiveexception    e
catch  texception e
throw new hiveexception    e
/**
* updates the existing index metadata with the new metadata.
*
* @param idxname
*          name of the existing index
* @param newidx
*          new name of the index. could be the old name
* @throws invalidoperationexception
*           if the changes in metadata is not acceptable
* @throws texception
*/
public void alterindex string dbname  string basetblname  string idxname  index newidx
throws invalidoperationexception  hiveexception
try
getmsc   alter_index dbname  basetblname  idxname  newidx
catch  metaexception e
throw new hiveexception    e
catch  texception e
throw new hiveexception    e
/**
* updates the existing partition metadata with the new metadata.
*
* @param tblname
*          name of the existing table
* @param newpart
*          new partition
* @throws invalidoperationexception
*           if the changes in metadata is not acceptable
* @throws texception
*/
public void alterpartition string tblname  partition newpart
throws invalidoperationexception  hiveexception
table t   newtable tblname
alterpartition t getdbname    t gettablename    newpart
/**
* updates the existing partition metadata with the new metadata.
*
* @param dbname
*          name of the exiting table's database
* @param tblname
*          name of the existing table
* @param newpart
*          new partition
* @throws invalidoperationexception
*           if the changes in metadata is not acceptable
* @throws texception
*/
public void alterpartition string dbname  string tblname  partition newpart
throws invalidoperationexception  hiveexception
try
// remove the ddl time so that it gets refreshed
if  newpart getparameters      null
newpart getparameters   remove hive_metastoreconstants ddl_time
getmsc   alter_partition dbname  tblname  newpart gettpartition
catch  metaexception e
throw new hiveexception    e
catch  texception e
throw new hiveexception    e
/**
* updates the existing table metadata with the new metadata.
*
* @param tblname
*          name of the existing table
* @param newparts
*          new partitions
* @throws invalidoperationexception
*           if the changes in metadata is not acceptable
* @throws texception
*/
public void alterpartitions string tblname  list<partition> newparts
throws invalidoperationexception  hiveexception
table t   newtable tblname
list<org apache hadoop hive metastore api partition> newtparts
new arraylist<org apache hadoop hive metastore api partition>
try
// remove the ddl time so that it gets refreshed
for  partition tmppart  newparts
if  tmppart getparameters      null
tmppart getparameters   remove hive_metastoreconstants ddl_time
newtparts add tmppart gettpartition
getmsc   alter_partitions t getdbname    t gettablename    newtparts
catch  metaexception e
throw new hiveexception    e
catch  texception e
throw new hiveexception    e
/**
* rename a old partition to new partition
*
* @param tbl
*          existing table
* @param oldpartspec
*          spec of old partition
* @param newpart
*          new partition
* @throws invalidoperationexception
*           if the changes in metadata is not acceptable
* @throws texception
*/
public void renamepartition table tbl  map<string  string> oldpartspec  partition newpart
throws hiveexception
try
map<string  string> newpartspec   newpart getspec
if  oldpartspec keyset   size      tbl getpartcols   size
newpartspec keyset   size      tbl getpartcols   size
throw new hiveexception
if   oldpartspec keyset   equals newpartspec keyset
throw new hiveexception
list<string> pvals   new arraylist<string>
for  fieldschema field   tbl getpartcols
string val   oldpartspec get field getname
if  val    null    val length      0
throw new hiveexception
field getname
else if  val    null
pvals add val
getmsc   renamepartition tbl getdbname    tbl gettablename    pvals
newpart gettpartition
catch  invalidoperationexception e
throw new hiveexception    e
catch  metaexception e
throw new hiveexception    e
catch  texception e
throw new hiveexception    e
public void alterdatabase string dbname  database db
throws hiveexception
try
getmsc   alterdatabase dbname  db
catch  metaexception e
throw new hiveexception     dbname  e
catch  nosuchobjectexception e
throw new hiveexception     dbname      e
catch  texception e
throw new hiveexception     dbname  e
/**
* creates the table with the give objects
*
* @param tbl
*          a table object
* @throws hiveexception
*/
public void createtable table tbl  throws hiveexception
createtable tbl  false
/**
* creates the table with the give objects
*
* @param tbl
*          a table object
* @param ifnotexists
*          if true, ignore alreadyexistsexception
* @throws hiveexception
*/
public void createtable table tbl  boolean ifnotexists  throws hiveexception
try
if  tbl getdbname      null      equals tbl getdbname   trim
tbl setdbname sessionstate get   getcurrentdatabase
if  tbl getcols   size      0
tbl setfields metastoreutils getfieldsfromdeserializer tbl gettablename
tbl getdeserializer
tbl checkvalidity
if  tbl getparameters      null
tbl getparameters   remove hive_metastoreconstants ddl_time
org apache hadoop hive metastore api table ttbl   tbl getttable
principalprivilegeset principalprivs   new principalprivilegeset
sessionstate ss   sessionstate get
if  ss    null
createtableautomaticgrant grants   ss getcreatetablegrants
if  grants    null
principalprivs setuserprivileges grants getusergrants
principalprivs setgroupprivileges grants getgroupgrants
principalprivs setroleprivileges grants getrolegrants
ttbl setprivileges principalprivs
getmsc   createtable ttbl
catch  alreadyexistsexception e
if   ifnotexists
throw new hiveexception e
catch  exception e
throw new hiveexception e
/**
*
* @param tablename
*          table name
* @param indexname
*          index name
* @param indexhandlerclass
*          index handler class
* @param indexedcols
*          index columns
* @param indextblname
*          index table's name
* @param deferredrebuild
*          referred build index table's data
* @param inputformat
*          input format
* @param outputformat
*          output format
* @param serde
* @param storagehandler
*          index table's storage handler
* @param location
*          location
* @param idxprops
*          idx
* @param serdeprops
*          serde properties
* @param collitemdelim
* @param fielddelim
* @param fieldescape
* @param linedelim
* @param mapkeydelim
* @throws hiveexception
*/
public void createindex string tablename  string indexname  string indexhandlerclass
list<string> indexedcols  string indextblname  boolean deferredrebuild
string inputformat  string outputformat  string serde
string storagehandler  string location
map<string  string> idxprops  map<string  string> tblprops  map<string  string> serdeprops
string collitemdelim  string fielddelim  string fieldescape
string linedelim  string mapkeydelim  string indexcomment
throws hiveexception
try
string dbname   sessionstate get   getcurrentdatabase
index old_index   null
try
old_index   getindex dbname  tablename  indexname
catch  exception e
if  old_index    null
throw new hiveexception     indexname       tablename       dbname
org apache hadoop hive metastore api table basetbl   getmsc   gettable dbname  tablename
if  basetbl gettabletype      tabletype virtual_view tostring
throw new hiveexception    tablename
if  indextblname    null
indextblname   metastoreutils getindextablename dbname  tablename  indexname
else
org apache hadoop hive metastore api table temp   null
try
temp   getmsc   gettable dbname  indextblname
catch  exception e
if  temp    null
throw new hiveexception     indextblname
org apache hadoop hive metastore api storagedescriptor storagedescriptor   basetbl getsd   deepcopy
serdeinfo serdeinfo   storagedescriptor getserdeinfo
if serde    null
serdeinfo setserializationlib serde
else
if  storagehandler    null
serdeinfo setserializationlib org apache hadoop hive serde2 lazy lazysimpleserde class getname
else
hivestoragehandler sh   hiveutils getstoragehandler getconf    storagehandler
string serdeclassname   sh getserdeclass   getname
serdeinfo setserializationlib serdeclassname
if  fielddelim    null
serdeinfo getparameters   put field_delim  fielddelim
serdeinfo getparameters   put serialization_format  fielddelim
if  fieldescape    null
serdeinfo getparameters   put escape_char  fieldescape
if  collitemdelim    null
serdeinfo getparameters   put collection_delim  collitemdelim
if  mapkeydelim    null
serdeinfo getparameters   put mapkey_delim  mapkeydelim
if  linedelim    null
serdeinfo getparameters   put line_delim  linedelim
if  serdeprops    null
iterator<entry<string  string>> iter   serdeprops entryset
iterator
while  iter hasnext
entry<string  string> m   iter next
serdeinfo getparameters   put m getkey    m getvalue
storagedescriptor setlocation null
if  location    null
storagedescriptor setlocation location
storagedescriptor setinputformat inputformat
storagedescriptor setoutputformat outputformat
map<string  string> params   new hashmap<string string>
list<fieldschema> indextblcols   new arraylist<fieldschema>
list<order> sortcols   new arraylist<order>
storagedescriptor setbucketcols null
int k   0
table metabasetbl   new table basetbl
for  int i   0  i < metabasetbl getcols   size    i
fieldschema col   metabasetbl getcols   get i
if  indexedcols contains col getname
indextblcols add col
sortcols add new order col getname    1
k
if  k    indexedcols size
throw new runtimeexception
storagedescriptor setcols indextblcols
storagedescriptor setsortcols sortcols
int time    int   system currenttimemillis     1000
org apache hadoop hive metastore api table tt   null
hiveindexhandler indexhandler   hiveutils getindexhandler this getconf    indexhandlerclass
if  indexhandler usesindextable
tt   new org apache hadoop hive ql metadata table dbname  indextblname  getttable
list<fieldschema> partkeys   basetbl getpartitionkeys
tt setpartitionkeys partkeys
tt settabletype tabletype index_table tostring
if  tblprops    null
for  entry<string  string> prop   tblprops entryset
tt puttoparameters prop getkey    prop getvalue
if  deferredrebuild
throw new runtimeexception   with deferred rebuild
index indexdesc   new index indexname  indexhandlerclass  dbname  tablename  time  time  indextblname
storagedescriptor  params  deferredrebuild
if  indexcomment    null
indexdesc getparameters   put    indexcomment
if  idxprops    null
indexdesc getparameters   putall idxprops
indexhandler analyzeindexdefinition basetbl  indexdesc  tt
this getmsc   createindex indexdesc  tt
catch  exception e
throw new hiveexception e
public index getindex string qualifiedindexname  throws hiveexception
string names   getqualifiednames qualifiedindexname
switch  names length
case 3
return getindex names  names  names
case 2
return getindex sessionstate get   getcurrentdatabase
names  names
default
throw new hiveexception     qualifiedindexname
public index getindex string basetablename  string indexname  throws hiveexception
table t   newtable basetablename
return this getindex t getdbname    t gettablename    indexname
public index getindex string dbname  string basetablename
string indexname  throws hiveexception
try
return this getmsc   getindex dbname  basetablename  indexname
catch  exception e
throw new hiveexception e
public boolean dropindex string db_name  string tbl_name  string index_name  boolean deletedata  throws hiveexception
try
return getmsc   dropindex db_name  tbl_name  index_name  deletedata
catch  nosuchobjectexception e
throw new hiveexception    e
catch  exception e
throw new hiveexception    e
/**
* drops table along with the data in it. if the table doesn't exist then it
* is a no-op
*
* @param tablename
*          table to drop
* @throws hiveexception
*           thrown if the drop fails
*/
public void droptable string tablename  throws hiveexception
table t   newtable tablename
droptable t getdbname    t gettablename    true  true
/**
* drops table along with the data in it. if the table doesn't exist then it
* is a no-op
*
* @param dbname
*          database where the table lives
* @param tablename
*          table to drop
* @throws hiveexception
*           thrown if the drop fails
*/
public void droptable string dbname  string tablename  throws hiveexception
droptable dbname  tablename  true  true
/**
* drops the table.
*
* @param dbname
* @param tablename
* @param deletedata
*          deletes the underlying data along with metadata
* @param ignoreunknowntab
*          an exception if thrown if this is falser and table doesn't exist
* @throws hiveexception
*/
public void droptable string dbname  string tablename  boolean deletedata
boolean ignoreunknowntab  throws hiveexception
try
getmsc   droptable dbname  tablename  deletedata  ignoreunknowntab
catch  nosuchobjectexception e
if   ignoreunknowntab
throw new hiveexception e
catch  exception e
throw new hiveexception e
public hiveconf getconf
return  conf
/**
* returns metadata for the table named tablename
* @param tablename the name of the table
* @return the table metadata
* @throws hiveexception if there's an internal error or if the
* table doesn't exist
*/
public table gettable final string tablename  throws hiveexception
table t   newtable tablename
return this gettable t getdbname    t gettablename    true
/**
* returns metadata for the table named tablename
* @param tablename the name of the table
* @param throwexception controls whether an exception is thrown or a returns a null
* @return the table metadata
* @throws hiveexception if there's an internal error or if the
* table doesn't exist
*/
public table gettable final string tablename  boolean throwexception  throws hiveexception
table t   newtable tablename
return this gettable t getdbname    t gettablename    throwexception
/**
* returns metadata of the table
*
* @param dbname
*          the name of the database
* @param tablename
*          the name of the table
* @return the table
* @exception hiveexception
*              if there's an internal error or if the table doesn't exist
*/
public table gettable final string dbname  final string tablename  throws hiveexception
if  tablename contains
table t   newtable tablename
return this gettable t getdbname    t gettablename    true
else
return this gettable dbname  tablename  true
/**
* returns metadata of the table
*
* @param dbname
*          the name of the database
* @param tablename
*          the name of the table
* @param throwexception
*          controls whether an exception is thrown or a returns a null
* @return the table or if throwexception is false a null value.
* @throws hiveexception
*/
public table gettable final string dbname  final string tablename
boolean throwexception  throws hiveexception
if  tablename    null    tablename equals
throw new hiveexception
// get the table from metastore
org apache hadoop hive metastore api table ttable   null
try
ttable   getmsc   gettable dbname  tablename
catch  nosuchobjectexception e
if  throwexception
log error stringutils stringifyexception e
throw new invalidtableexception tablename
return null
catch  exception e
throw new hiveexception     tablename  e
// for non-views, we need to do some extra fixes
if   tabletype virtual_view tostring   equals ttable gettabletype
// fix the non-printable chars
map<string  string> parameters   ttable getsd   getparameters
string sf   parameters get serialization_format
if  sf    null
char b   sf tochararray
if   b length    1      b < 10        ^a  ^b  ^c  ^d   t
parameters put serialization_format  integer tostring b
// use lazysimpleserde for metadatatypedcolumnsetserde.
// note: lazysimpleserde does not support tables with a single column of
// col
// of type "array<string>". this happens when the table is created using
// an
// earlier version of hive.
if  org apache hadoop hive serde2 metadatatypedcolumnsetserde class
getname   equals
ttable getsd   getserdeinfo   getserializationlib
ttable getsd   getcolssize   > 0
ttable getsd   getcols   get 0  gettype   indexof        1
ttable getsd   getserdeinfo   setserializationlib
org apache hadoop hive serde2 lazy lazysimpleserde class getname
table table   new table ttable
table checkvalidity
return table
/**
* get all table names for the current database.
* @return list of table names
* @throws hiveexception
*/
public list<string> getalltables   throws hiveexception
return getalltables sessionstate get   getcurrentdatabase
/**
* get all table names for the specified database.
* @param dbname
* @return list of table names
* @throws hiveexception
*/
public list<string> getalltables string dbname  throws hiveexception
return gettablesbypattern dbname
/**
* returns all existing tables from default database which match the given
* pattern. the matching occurs as per java regular expressions
*
* @param tablepattern
*          java re pattern
* @return list of table names
* @throws hiveexception
*/
public list<string> gettablesbypattern string tablepattern  throws hiveexception
return gettablesbypattern sessionstate get   getcurrentdatabase
tablepattern
/**
* returns all existing tables from the specified database which match the given
* pattern. the matching occurs as per java regular expressions.
* @param dbname
* @param tablepattern
* @return list of table names
* @throws hiveexception
*/
public list<string> gettablesbypattern string dbname  string tablepattern  throws hiveexception
try
return getmsc   gettables dbname  tablepattern
catch  exception e
throw new hiveexception e
/**
* returns all existing tables from the given database which match the given
* pattern. the matching occurs as per java regular expressions
*
* @param database
*          the database name
* @param tablepattern
*          java re pattern
* @return list of table names
* @throws hiveexception
*/
public list<string> gettablesfordb string database  string tablepattern
throws hiveexception
try
return getmsc   gettables database  tablepattern
catch  exception e
throw new hiveexception e
/**
* get all existing database names.
*
* @return list of database names.
* @throws hiveexception
*/
public list<string> getalldatabases   throws hiveexception
try
return getmsc   getalldatabases
catch  exception e
throw new hiveexception e
/**
* get all existing databases that match the given
* pattern. the matching occurs as per java regular expressions
*
* @param databasepattern
*          java re pattern
* @return list of database names
* @throws hiveexception
*/
public list<string> getdatabasesbypattern string databasepattern  throws hiveexception
try
return getmsc   getdatabases databasepattern
catch  exception e
throw new hiveexception e
public boolean grantprivileges privilegebag privileges
throws hiveexception
try
return getmsc   grant_privileges privileges
catch  exception e
throw new hiveexception e
/**
* @param privileges
*          a bag of privileges
* @return true on success
* @throws hiveexception
*/
public boolean revokeprivileges privilegebag privileges
throws hiveexception
try
return getmsc   revoke_privileges privileges
catch  exception e
throw new hiveexception e
/**
* query metadata to see if a database with the given name already exists.
*
* @param dbname
* @return true if a database with the given name already exists, false if
*         does not exist.
* @throws hiveexception
*/
public boolean databaseexists string dbname  throws hiveexception
return getdatabase dbname     null
/**
* get the database by name.
* @param dbname the name of the database.
* @return a database object if this database exists, null otherwise.
* @throws hiveexception
*/
public database getdatabase string dbname  throws hiveexception
try
return getmsc   getdatabase dbname
catch  nosuchobjectexception e
return null
catch  exception e
throw new hiveexception e
/**
* get the database object for current database
* @return a database object if this database exists, null otherwise.
* @throws hiveexception
*/
public database getdatabasecurrent   throws hiveexception
string currentdb   sessionstate get   getcurrentdatabase
return getdatabase currentdb
/**
* load a directory into a hive table partition - alters existing content of
* the partition with the contents of loadpath. - if the partition does not
* exist - one is created - files in loadpath are moved into hive. but the
* directory itself is not removed.
*
* @param loadpath
*          directory containing files to load into table
* @param tablename
*          name of table to be loaded.
* @param partspec
*          defines which partition needs to be loaded
* @param replace
*          if true - replace files in the partition, otherwise add files to
*          the partition
* @param holdddltime if true, force [re]create the partition
* @param inherittablespecs if true, on [re]creating the partition, take the
*          location/inputformat/outputformat/serde details from table spec
*/
public void loadpartition path loadpath  string tablename
map<string  string> partspec  boolean replace  boolean holdddltime
boolean inherittablespecs  boolean isskewedstoreassubdir
throws hiveexception
table tbl   gettable tablename
try
/**
* move files before creating the partition since down stream processes
* check for existence of partition in metadata before accessing the data.
* if partition is created before data is moved, downstream waiting
* processes might move forward with partial data
*/
partition oldpart   getpartition tbl  partspec  false
path oldpartpath   null
if oldpart    null
oldpartpath   oldpart getpartitionpath
path newpartpath   null
if  inherittablespecs
path partpath   new path tbl getdatalocation   getpath
warehouse makepartpath partspec
newpartpath   new path loadpath touri   getscheme    loadpath touri   getauthority
partpath touri   getpath
if oldpart    null
/*
* if we are moving the partition across filesystem boundaries
* inherit from the table properties. otherwise (same filesystem) use the
* original partition location.
*
* see: hive-1707 and hive-2117 for background
*/
filesystem oldpartpathfs   oldpartpath getfilesystem getconf
filesystem loadpathfs   loadpath getfilesystem getconf
if  oldpartpathfs equals loadpathfs
newpartpath   oldpartpath
else
newpartpath   oldpartpath
if  replace
hive replacefiles loadpath  newpartpath  oldpartpath  getconf
else
filesystem fs   filesystem get tbl getdatalocation    getconf
hive copyfiles conf  loadpath  newpartpath  fs
// recreate the partition if it existed before
if   holdddltime
partition newtpart   getpartition tbl  partspec  true  newpartpath tostring
inherittablespecs
if  isskewedstoreassubdir
org apache hadoop hive metastore api partition newcreatedtpart   newtpart gettpartition
skewedinfo skewedinfo   newcreatedtpart getsd   getskewedinfo
/* construct list bucketing location mappings from sub-directory name. */
map<list<string>  string> skewedcolvaluelocationmaps   constructlistbucketinglocationmap
newpartpath  skewedinfo
/* add list bucketing location mappings. */
skewedinfo setskewedcolvaluelocationmaps skewedcolvaluelocationmaps
newcreatedtpart getsd   setskewedinfo skewedinfo
alterpartition tbl gettablename    new partition tbl  newcreatedtpart
newtpart   getpartition tbl  partspec  true  newpartpath tostring    inherittablespecs
newcreatedtpart   newtpart gettpartition
catch  ioexception e
log error stringutils stringifyexception e
throw new hiveexception e
catch  metaexception e
log error stringutils stringifyexception e
throw new hiveexception e
catch  invalidoperationexception e
log error stringutils stringifyexception e
throw new hiveexception e
/**
* walk through sub-directory tree to construct list bucketing location map.
*
* @param fsta
* @param fsys
* @param skewedcolvaluelocationmaps
* @param newpartpath
* @param skewedinfo
* @throws ioexception
*/
private void walkdirtree filestatus fsta  filesystem fsys
map<list<string>  string> skewedcolvaluelocationmaps  path newpartpath  skewedinfo skewedinfo
throws ioexception
/* base case. it's leaf. */
if   fsta isdir
/* construct one location map if not exists. */
constructonelblocationmap fsta  skewedcolvaluelocationmaps  newpartpath  skewedinfo
return
/* dfs. */
filestatus children   fsys liststatus fsta getpath
if  children    null
for  filestatus child   children
walkdirtree child  fsys  skewedcolvaluelocationmaps  newpartpath  skewedinfo
/**
* construct a list bucketing location map
* @param fsta
* @param skewedcolvaluelocationmaps
* @param newpartpath
* @param skewedinfo
*/
private void constructonelblocationmap filestatus fsta
map<list<string>  string> skewedcolvaluelocationmaps
path newpartpath  skewedinfo skewedinfo
path lbdpath   fsta getpath   getparent
list<string> skewedvalue   new arraylist<string>
string lbdirname   fileutils unescapepathname lbdpath tostring
string partdirname   fileutils unescapepathname newpartpath tostring
string lbdirsuffix   lbdirname replace partdirname
string dirnames   lbdirsuffix split path separator
for  string dirname   dirnames
if   dirname    null      dirname length   > 0
// construct skewed-value to location map except default directory.
// why? query logic knows default-dir structure and don't need to get from map
if   dirname
equalsignorecase listbucketingprunerutils hive_list_bucketing_default_dir_name
string kv   dirname split
if  kv length    2
skewedvalue add kv
if   skewedvalue size   > 0      skewedvalue size      skewedinfo getskewedcolnames   size
skewedcolvaluelocationmaps containskey skewedvalue
skewedcolvaluelocationmaps put skewedvalue  lbdpath tostring
/**
* construct location map from path
*
* @param newpartpath
* @param skewedinfo
* @return
* @throws ioexception
* @throws filenotfoundexception
*/
private map<list<string>  string> constructlistbucketinglocationmap path newpartpath
skewedinfo skewedinfo  throws ioexception  filenotfoundexception
map<list<string>  string> skewedcolvaluelocationmaps   new hashmap<list<string>  string>
filesystem fsys   newpartpath getfilesystem conf
walkdirtree fsys getfilestatus newpartpath   fsys  skewedcolvaluelocationmaps  newpartpath
skewedinfo
return skewedcolvaluelocationmaps
/**
* given a source directory name of the load path, load all dynamically generated partitions
* into the specified table and return a list of strings that represent the dynamic partition
* paths.
* @param loadpath
* @param tablename
* @param partspec
* @param replace
* @param numdp number of dynamic partitions
* @param holdddltime
* @return a list of strings with the dynamic partition paths
* @throws hiveexception
*/
public arraylist<linkedhashmap<string  string>> loaddynamicpartitions path loadpath
string tablename  map<string  string> partspec  boolean replace
int numdp  boolean holdddltime  boolean listbucketingenabled
throws hiveexception
set<path> validpartitions   new hashset<path>
try
arraylist<linkedhashmap<string  string>> fullpartspecs
new arraylist<linkedhashmap<string  string>>
filesystem fs   loadpath getfilesystem conf
filestatus leafstatus   utilities getfilestatusrecurse loadpath  numdp 1  fs
// check for empty partitions
for  filestatus s   leafstatus
// check if the hadoop version supports sub-directories for tables/partitions
if  s isdir
conf getboolvar hiveconf confvars hive_hadoop_supports_subdirectories
// no leaves in this directory
log info     s getpath
else
try
validatepartitionnamecharacters
warehouse getpartvaluesfrompartname s getpath   getparent   tostring
catch  metaexception e
throw new hiveexception e
validpartitions add s getpath   getparent
if  validpartitions size      0
log warn
if  validpartitions size   > conf getintvar hiveconf confvars dynamicpartitionmaxparts
throw new hiveexception     validpartitions size
conf getintvar hiveconf confvars dynamicpartitionmaxparts
hiveconf confvars dynamicpartitionmaxparts varname
validpartitions size
// for each dynamically created dp directory, construct a full partition spec
// and load the partition based on that
iterator<path> iter   validpartitions iterator
while  iter hasnext
// get the dynamically created directory
path partpath   iter next
assert fs getfilestatus partpath  isdir
partpath
// generate a full partition specification
linkedhashmap<string  string> fullpartspec   new linkedhashmap<string  string> partspec
warehouse makespecfromname fullpartspec  partpath
fullpartspecs add fullpartspec
// finally load the partition -- move the file to the final table address
loadpartition partpath  tablename  fullpartspec  replace  holdddltime  true
listbucketingenabled
log info     partpath       fullpartspec
return fullpartspecs
catch  ioexception e
throw new hiveexception e
/**
* load a directory into a hive table. - alters existing content of table with
* the contents of loadpath. - if table does not exist - an exception is
* thrown - files in loadpath are moved into hive. but the directory itself is
* not removed.
*
* @param loadpath
*          directory containing files to load into table
* @param tablename
*          name of table to be loaded.
* @param replace
*          if true - replace files in the table, otherwise add files to table
* @param holdddltime
*/
public void loadtable path loadpath  string tablename  boolean replace
boolean holdddltime  throws hiveexception
table tbl   gettable tablename
if  replace
tbl replacefiles loadpath
else
tbl copyfiles loadpath
if   holdddltime
try
altertable tablename  tbl
catch  invalidoperationexception e
throw new hiveexception e
/**
* creates a partition.
*
* @param tbl
*          table for which partition needs to be created
* @param partspec
*          partition keys and their values
* @return created partition object
* @throws hiveexception
*           if table doesn't exist or partition already exists
*/
public partition createpartition table tbl  map<string  string> partspec
throws hiveexception
return createpartition tbl  partspec  null  null  null  null   1
null  null  null  null  null
/**
* creates a partition
*
* @param tbl
*          table for which partition needs to be created
* @param partspec
*          partition keys and their values
* @param location
*          location of this partition
* @param partparams
*          partition parameters
* @param inputformat the inputformat class
* @param outputformat the outputformat class
* @param numbuckets the number of buckets
* @param cols the column schema
* @param serializationlib the serde class
* @param serdeparams the serde parameters
* @param bucketcols the bucketing columns
* @param sortcols sort columns and order
*
* @return created partition object
* @throws hiveexception
*           if table doesn't exist or partition already exists
*/
public partition createpartition table tbl  map<string  string> partspec
path location  map<string  string> partparams  string inputformat  string outputformat
int numbuckets  list<fieldschema> cols
string serializationlib  map<string  string> serdeparams
list<string> bucketcols  list<order> sortcols  throws hiveexception
org apache hadoop hive metastore api partition partition   null
for  fieldschema field   tbl getpartcols
string val   partspec get field getname
if  val    null    val length      0
throw new hiveexception
field getname
try
partition tmppart   new partition tbl  partspec  location
// no need to clear ddl_time in parameters since we know it's
// not populated on construction.
org apache hadoop hive metastore api partition inpart
tmppart gettpartition
if  partparams    null
inpart setparameters partparams
if  inputformat    null
inpart getsd   setinputformat inputformat
if  outputformat    null
inpart getsd   setoutputformat outputformat
if  numbuckets     1
inpart getsd   setnumbuckets numbuckets
if  cols    null
inpart getsd   setcols cols
if  serializationlib    null
inpart getsd   getserdeinfo   setserializationlib serializationlib
if  serdeparams    null
inpart getsd   getserdeinfo   setparameters serdeparams
if  bucketcols    null
inpart getsd   setbucketcols bucketcols
if  sortcols    null
inpart getsd   setsortcols sortcols
partition   getmsc   add_partition inpart
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
return new partition tbl  partition
public partition getpartition table tbl  map<string  string> partspec
boolean forcecreate  throws hiveexception
return getpartition tbl  partspec  forcecreate  null  true
/**
* returns partition metadata
*
* @param tbl
*          the partition's table
* @param partspec
*          partition keys and values
* @param forcecreate
*          if this is true and partition doesn't exist then a partition is
*          created
* @param partpath the path where the partition data is located
* @param inherittablespecs whether to copy over the table specs for if/of/serde
* @return result partition object or null if there is no partition
* @throws hiveexception
*/
public partition getpartition table tbl  map<string  string> partspec
boolean forcecreate  string partpath  boolean inherittablespecs  throws hiveexception
if   tbl isvalidspec partspec
throw new hiveexception     partspec
list<string> pvals   new arraylist<string>
for  fieldschema field   tbl getpartcols
string val   partspec get field getname
// enable dynamic partitioning
if  val    null     hiveconf getboolvar conf  hiveconf confvars dynamicpartitioning
val length      0
throw new hiveexception
field getname
else if  val    null
pvals add val
org apache hadoop hive metastore api partition tpart   null
try
tpart   getmsc   getpartitionwithauthinfo tbl getdbname
tbl gettablename    pvals  getusername    getgroupnames
catch  nosuchobjectexception nsoe
// this means no partition exists for the given partition
// key value pairs - thrift cannot handle null return values, hence
// getpartition() throws nosuchobjectexception to indicate null partition
tpart   null
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
try
if  forcecreate
if  tpart    null
log debug     tbl gettablename
partspec
tpart   getmsc   appendpartition tbl getdbname    tbl gettablename    pvals
else
log debug     tbl gettablename
partspec
if  inherittablespecs
tpart getsd   setoutputformat tbl getttable   getsd   getoutputformat
tpart getsd   setinputformat tbl getttable   getsd   getinputformat
tpart getsd   getserdeinfo   setserializationlib tbl getserializationlib
tpart getsd   getserdeinfo   setparameters
tbl getttable   getsd   getserdeinfo   getparameters
tpart getsd   setbucketcols tbl getbucketcols
tpart getsd   setnumbuckets tbl getnumbuckets
tpart getsd   setsortcols tbl getsortcols
if  partpath    null    partpath trim   equals
throw new hiveexception
tpart getsd   setlocation partpath
string fullname   tbl gettablename
if   org apache commons lang stringutils isempty tbl getdbname
fullname   tbl getdbname         tbl gettablename
alterpartition fullname  new partition tbl  tpart
if  tpart    null
return null
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
return new partition tbl  tpart
public boolean droppartition string tblname  list<string> part_vals  boolean deletedata
throws hiveexception
table t   newtable tblname
return droppartition t getdbname    t gettablename    part_vals  deletedata
public boolean droppartition string db_name  string tbl_name
list<string> part_vals  boolean deletedata  throws hiveexception
try
return getmsc   droppartition db_name  tbl_name  part_vals  deletedata
catch  nosuchobjectexception e
throw new hiveexception    e
catch  exception e
throw new hiveexception    e
public list<string> getpartitionnames string tblname  short max  throws hiveexception
table t   newtable tblname
return getpartitionnames t getdbname    t gettablename    max
public list<string> getpartitionnames string dbname  string tblname  short max
throws hiveexception
list<string> names   null
try
names   getmsc   listpartitionnames dbname  tblname  max
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
return names
public list<string> getpartitionnames string dbname  string tblname
map<string  string> partspec  short max  throws hiveexception
list<string> names   null
table t   gettable dbname  tblname
list<string> pvals   metastoreutils getpvals t getpartcols    partspec
try
names   getmsc   listpartitionnames dbname  tblname  pvals  max
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
return names
/**
* get all the partitions that the table has
*
* @param tbl
*          object for which partition is needed
* @return list of partition objects
* @throws hiveexception
*/
public list<partition> getpartitions table tbl  throws hiveexception
if  tbl ispartitioned
list<org apache hadoop hive metastore api partition> tparts
try
tparts   getmsc   listpartitionswithauthinfo tbl getdbname    tbl gettablename
short   1  getusername    getgroupnames
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
list<partition> parts   new arraylist<partition> tparts size
for  org apache hadoop hive metastore api partition tpart   tparts
parts add new partition tbl  tpart
return parts
else
partition part   new partition tbl
arraylist<partition> parts   new arraylist<partition> 1
parts add part
return parts
/**
* get all the partitions; unlike {@link #getpartitions(table)}, does not include auth.
* @param tbl table for which partitions are needed
* @return list of partition objects
*/
public set<partition> getallpartitionsforpruner table tbl  throws hiveexception
if   tbl ispartitioned
return sets newhashset new partition tbl
list<org apache hadoop hive metastore api partition> tparts
try
tparts   getmsc   listpartitions tbl getdbname    tbl gettablename     short  1
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
set<partition> parts   new linkedhashset<partition> tparts size
for  org apache hadoop hive metastore api partition tpart   tparts
parts add new partition tbl  tpart
return parts
/**
* get all the partitions of the table that matches the given partial
* specification. partition columns whose value is can be anything should be
* an empty string.
*
* @param tbl
*          object for which partition is needed. must be partitioned.
* @param limit number of partitions to return
* @return list of partition objects
* @throws hiveexception
*/
public list<partition> getpartitions table tbl  map<string  string> partialpartspec
short limit
throws hiveexception
if   tbl ispartitioned
throw new hiveexception
list<string> partialpvals   metastoreutils getpvals tbl getpartcols    partialpartspec
list<org apache hadoop hive metastore api partition> partitions   null
try
partitions   getmsc   listpartitionswithauthinfo tbl getdbname    tbl gettablename
partialpvals  limit  getusername    getgroupnames
catch  exception e
throw new hiveexception e
list<partition> qlpartitions   new arraylist<partition>
for  org apache hadoop hive metastore api partition p   partitions
qlpartitions add  new partition tbl  p
return qlpartitions
/**
* get all the partitions of the table that matches the given partial
* specification. partition columns whose value is can be anything should be
* an empty string.
*
* @param tbl
*          object for which partition is needed. must be partitioned.
* @return list of partition objects
* @throws hiveexception
*/
public list<partition> getpartitions table tbl  map<string  string> partialpartspec
throws hiveexception
return getpartitions tbl  partialpartspec   short  1
/**
* get all the partitions of the table that matches the given partial
* specification. partition columns whose value is can be anything should be
* an empty string.
*
* @param tbl
*          object for which partition is needed. must be partitioned.
* @param partialpartspec
*          partial partition specification (some subpartitions can be empty).
* @return list of partition objects
* @throws hiveexception
*/
public list<partition> getpartitionsbynames table tbl
map<string  string> partialpartspec
throws hiveexception
if   tbl ispartitioned
throw new hiveexception
list<string> names   getpartitionnames tbl getdbname    tbl gettablename
partialpartspec   short  1
list<partition> partitions   getpartitionsbynames tbl  names
return partitions
/**
* get all partitions of the table that matches the list of given partition names.
*
* @param tbl
*          object for which partition is needed. must be partitioned.
* @param partnames
*          list of partition names
* @return list of partition objects
* @throws hiveexception
*/
public list<partition> getpartitionsbynames table tbl  list<string> partnames
throws hiveexception
if   tbl ispartitioned
throw new hiveexception
list<partition> partitions   new arraylist<partition> partnames size
int batchsize   hiveconf getintvar conf  hiveconf confvars metastore_batch_retrieve_max
// todo: might want to increase the default batch size. 1024 is viable; ms gets oom if too high.
int nparts   partnames size
int nbatches   nparts   batchsize
try
for  int i   0  i < nbatches    i
list<org apache hadoop hive metastore api partition> tparts
getmsc   getpartitionsbynames tbl getdbname    tbl gettablename
partnames sublist i batchsize   i 1  batchsize
if  tparts    null
for  org apache hadoop hive metastore api partition tpart  tparts
partitions add new partition tbl  tpart
if  nparts > nbatches   batchsize
list<org apache hadoop hive metastore api partition> tparts
getmsc   getpartitionsbynames tbl getdbname    tbl gettablename
partnames sublist nbatches batchsize  nparts
if  tparts    null
for  org apache hadoop hive metastore api partition tpart  tparts
partitions add new partition tbl  tpart
catch  exception e
throw new hiveexception e
return partitions
/**
* get a list of partitions by filter.
* @param tbl the table containing the partitions.
* @param filter a string represent partition predicates.
* @return a list of partitions satisfying the partition predicates.
* @throws hiveexception
* @throws metaexception
* @throws nosuchobjectexception
* @throws texception
*/
public list<partition> getpartitionsbyfilter table tbl  string filter
throws hiveexception  metaexception  nosuchobjectexception  texception
if   tbl ispartitioned
throw new hiveexception
list<org apache hadoop hive metastore api partition> tparts   getmsc   listpartitionsbyfilter
tbl getdbname    tbl gettablename    filter   short  1
list<partition> results   new arraylist<partition> tparts size
for  org apache hadoop hive metastore api partition tpart  tparts
partition part   new partition tbl  tpart
results add part
return results
public void validatepartitionnamecharacters list<string> partvals  throws hiveexception
try
getmsc   validatepartitionnamecharacters partvals
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
public void createrole string rolename  string ownername
throws hiveexception
try
getmsc   create_role new role rolename   1  ownername
catch  exception e
throw new hiveexception e
public void droprole string rolename  throws hiveexception
try
getmsc   drop_role rolename
catch  exception e
throw new hiveexception e
/**
* get all existing role names.
*
* @return list of role names.
* @throws hiveexception
*/
public list<string> getallrolenames   throws hiveexception
try
return getmsc   listrolenames
catch  exception e
throw new hiveexception e
public list<role> showrolegrant string principalname  principaltype principaltype  throws hiveexception
try
return getmsc   list_roles principalname  principaltype
catch  exception e
throw new hiveexception e
public boolean grantrole string rolename  string username
principaltype principaltype  string grantor  principaltype grantortype
boolean grantoption  throws hiveexception
try
return getmsc   grant_role rolename  username  principaltype  grantor
grantortype  grantoption
catch  exception e
throw new hiveexception e
public boolean revokerole string rolename  string username
principaltype principaltype   throws hiveexception
try
return getmsc   revoke_role rolename  username  principaltype
catch  exception e
throw new hiveexception e
public list<role> listroles string username   principaltype principaltype
throws hiveexception
try
return getmsc   list_roles username  principaltype
catch  exception e
throw new hiveexception e
/**
* @param objecttype
*          hive object type
* @param db_name
*          database name
* @param table_name
*          table name
* @param part_values
*          partition values
* @param column_name
*          column name
* @param user_name
*          user name
* @param group_names
*          group names
* @return the privilege set
* @throws hiveexception
*/
public principalprivilegeset get_privilege_set hiveobjecttype objecttype
string db_name  string table_name  list<string> part_values
string column_name  string user_name  list<string> group_names
throws hiveexception
try
hiveobjectref hiveobj   new hiveobjectref objecttype  db_name
table_name  part_values  column_name
return getmsc   get_privilege_set hiveobj  user_name  group_names
catch  exception e
throw new hiveexception e
/**
* @param objecttype
*          hive object type
* @param principalname
* @param principaltype
* @param dbname
* @param tablename
* @param partvalues
* @param columnname
* @return list of privileges
* @throws hiveexception
*/
public list<hiveobjectprivilege> showprivilegegrant
hiveobjecttype objecttype  string principalname
principaltype principaltype  string dbname  string tablename
list<string> partvalues  string columnname  throws hiveexception
try
hiveobjectref hiveobj   new hiveobjectref objecttype  dbname  tablename
partvalues  columnname
return getmsc   list_privileges principalname  principaltype  hiveobj
catch  exception e
throw new hiveexception e
// for each file or directory in 'srcs', make mapping for every file in src to safe name in dest
private static list<list<path>> checkpaths hiveconf conf
filesystem fs  filestatus srcs  path destf
boolean replace  throws hiveexception
list<list<path>> result   new arraylist<list<path>>
try
filestatus deststatus    replace    fs exists destf  ? fs getfilestatus destf    null
if  deststatus    null     deststatus isdir
throw new hiveexception     destf
for  filestatus src   srcs
filestatus items
if  src isdir
items   fs liststatus src getpath
arrays sort items
else
items   new filestatus  src
list<path> srctodest   new arraylist<path>
for  filestatus item   items
path itemsource   item getpath
if  utilities istemppath item
// this check is redundant because temp files are removed by
// execution layer before
// calling loadtable/partition. but leaving it in just in case.
fs delete itemsource  true
continue
if   conf getboolvar hiveconf confvars hive_hadoop_supports_subdirectories
item isdir
throw new hiveexception     src getpath
itemsource
// strip off the file type, if any so we don't make:
// 000000_0.gz -> 000000_0.gz_copy_1
string name   itemsource getname
string filetype
int index   name lastindexof
if  index >  0
filetype   name substring index
name   name substring 0  index
else
filetype
path itemdest   new path destf  itemsource getname
if   replace
// it's possible that the file we're copying may have the same
// relative name as an existing file in the "destf" directory.
// so let's make a quick check to see if we can rename any
// potential offenders so as to allow them to move into the
// "destf" directory. the scheme is dead simple: simply tack
// on "_copy_n" where n starts at 1 and works its way up until
// we find a free space.
// removed source file staging.. it's more confusing when faild.
for  int counter   1  fs exists itemdest     destexists result  itemdest   counter
itemdest   new path destf  name        counter    filetype
srctodest add new path itemsource  itemdest
result add srctodest
catch  ioexception e
throw new hiveexception    e
return result
private static boolean destexists list<list<path>> result  path proposed
for  list<path> sdpairs   result
for  path sdpair   sdpairs
if  sdpair equals proposed
return true
return false
//it is assumed that parent directory of the destf should already exist when this
//method is called. when the replace value is true, this method works a little different
//from mv command if the destf is a directory, it replaces the destf instead of moving under
//the destf. in this case, the replaced destf still preserves the original destf's permission
static protected boolean renamefile hiveconf conf  path srcf  path destf  filesystem fs
boolean replace  throws hiveexception
boolean success   false
boolean inheritperms   hiveconf getboolvar conf
hiveconf confvars hive_warehouse_subdir_inherit_perms
string group   null
string permission   null
try
if  inheritperms    replace
try
filestatus deststatus   fs getfilestatus destf
if  inheritperms
group   deststatus getgroup
permission  integer tostring deststatus getpermission   toshort    8
//if destf is an existing directory:
//if replace is true, delete followed by rename(mv) is equivalent to replace
//if replace is false, rename (mv) actually move the src under dest dir
//if destf is an existing file, rename is actually a replace, and do not need
// to delete the file first
if  replace    deststatus isdir
fs delete destf  true
catch  filenotfoundexception ignore
//if dest dir does not exist, any re
if  inheritperms
filestatus deststatus   fs getfilestatus destf getparent
group   deststatus getgroup
permission  integer tostring deststatus getpermission   toshort    8
success   fs rename srcf  destf
log debug  replace ?          srcf tostring
destf tostring          success
catch  ioexception ioe
throw new hiveexception     srcf       destf  ioe
if  success    inheritperms
//use fsshell to change group and permissions recursively
try
fsshell fshell   new fsshell
fshell setconf conf
fshell run new string       group  destf tostring
fshell run new string       permission  destf tostring
catch  exception e
throw new hiveexception     destf  e
return success
static protected void copyfiles hiveconf conf  path srcf  path destf  filesystem fs
throws hiveexception
boolean inheritperms   hiveconf getboolvar conf
hiveconf confvars hive_warehouse_subdir_inherit_perms
try
// create the destination if it does not exist
if   fs exists destf
fs mkdirs destf
if  inheritperms
fs setpermission destf  fs getfilestatus destf getparent    getpermission
catch  ioexception e
throw new hiveexception
e
filestatus srcs
try
srcs   fs globstatus srcf
catch  ioexception e
log error stringutils stringifyexception e
throw new hiveexception    e
if  srcs    null
log info     srcf
return
// srcs = new filestatus[0]; why is this needed?
// check that source and target paths exist
list<list<path>> result   checkpaths conf  fs  srcs  destf  false
// move it, move it
try
for  list<path> sdpairs   result
for  path sdpair   sdpairs
if   renamefile conf  sdpair  sdpair  fs  false
throw new ioexception     sdpair       sdpair
catch  ioexception e
throw new hiveexception    e
/**
* replaces files in the partition with new data set specified by srcf. works
* by renaming directory of srcf to the destination file.
* srcf, destf, and tmppath should resident in the same dfs, but the oldpath can be in a
* different dfs.
*
* @param srcf
*          source directory to be renamed to tmppath. it should be a
*          leaf directory where the final data files reside. however it
*          could potentially contain subdirectories as well.
* @param destf
*          the directory where the final data needs to go
* @param oldpath
*          the directory where the old data location, need to be cleaned up.
*/
static protected void replacefiles path srcf  path destf  path oldpath  hiveconf conf
throws hiveexception
try
filesystem fs   srcf getfilesystem conf
boolean inheritperms   hiveconf getboolvar conf
hiveconf confvars hive_warehouse_subdir_inherit_perms
// check if srcf contains nested sub-directories
filestatus srcs
try
srcs   fs globstatus srcf
catch  ioexception e
throw new hiveexception     srcf tostring    e
if  srcs    null
log info     srcf
return
list<list<path>> result   checkpaths conf  fs  srcs  destf  true
// point of no return -- delete oldpath only if it is not same as destf,
// otherwise, the oldpath/destf will be cleaned later just before move
if  oldpath    null      destf getfilesystem conf  equals oldpath getfilesystem conf
destf equals oldpath
try
filesystem fs2   oldpath getfilesystem conf
if  fs2 exists oldpath
// use fsshell to move data to .trash first rather than delete permanently
fsshell fshell   new fsshell
fshell setconf conf
fshell run new string    oldpath tostring
catch  exception e
//swallow the exception
log warn     oldpath tostring
// rename src directory to destf
if  srcs length    1    srcs isdir
// rename can fail if the parent doesn't exist
path destfp   destf getparent
if   fs exists destfp
boolean success   fs mkdirs destfp
if  inheritperms    success
fs setpermission destfp  fs getfilestatus destfp getparent    getpermission
boolean b   renamefile conf  srcs getpath    destf  fs  true
if   b
throw new hiveexception     srcs getpath
destf
else      srcf is a file or pattern containing wildcards
if   fs exists destf
boolean success   fs mkdirs destf
if  inheritperms    success
fs setpermission destf  fs getfilestatus destf getparent    getpermission
// srcs must be a list of files -- ensured by loadsemanticanalyzer
for  list<path> sdpairs   result
for  path sdpair   sdpairs
if   renamefile conf  sdpair  sdpair  fs  true
throw new ioexception     sdpair       sdpair
catch  ioexception e
throw new hiveexception e getmessage    e
public void exchangetablepartitions map<string  string> partitionspecs
string sourcedb  string sourcetable  string destdb
string destinationtablename  throws hiveexception
try
getmsc   exchange_partition partitionspecs  sourcedb  sourcetable  destdb
destinationtablename
catch  exception ex
log error stringutils stringifyexception ex
throw new hiveexception ex
/**
* creates a metastore client. currently it creates only jdbc based client as
* file based store support is removed
*
* @returns a meta store client
* @throws hivemetaexception
*           if a working client can't be created
*/
private imetastoreclient createmetastoreclient   throws metaexception
hivemetahookloader hookloader   new hivemetahookloader
public hivemetahook gethook
org apache hadoop hive metastore api table tbl
throws metaexception
try
if  tbl    null
return null
hivestoragehandler storagehandler
hiveutils getstoragehandler conf
tbl getparameters   get meta_table_storage
if  storagehandler    null
return null
return storagehandler getmetahook
catch  hiveexception ex
log error stringutils stringifyexception ex
throw new metaexception
ex getmessage
return retryingmetastoreclient getproxy conf  hookloader
hivemetastoreclient class getname
/**
*
* @return the metastore client for the current thread
* @throws metaexception
*/
private imetastoreclient getmsc   throws metaexception
if  metastoreclient    null
metastoreclient   createmetastoreclient
return metastoreclient
private string getusername
sessionstate ss   sessionstate get
if  ss    null    ss getauthenticator      null
return ss getauthenticator   getusername
return null
private list<string> getgroupnames
sessionstate ss   sessionstate get
if  ss    null    ss getauthenticator      null
return ss getauthenticator   getgroupnames
return null
public static list<fieldschema> getfieldsfromdeserializer string name
deserializer serde  throws hiveexception
try
return metastoreutils getfieldsfromdeserializer name  serde
catch  serdeexception e
throw new hiveexception
e getmessage    e
catch  metaexception e
throw new hiveexception
e getmessage    e
public list<index> getindexes string dbname  string tblname  short max  throws hiveexception
list<index> indexes   null
try
indexes   getmsc   listindexes dbname  tblname  max
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
return indexes
public boolean updatetablecolumnstatistics columnstatistics statsobj  throws hiveexception
try
return getmsc   updatetablecolumnstatistics statsobj
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
public boolean updatepartitioncolumnstatistics columnstatistics statsobj  throws hiveexception
try
return getmsc   updatepartitioncolumnstatistics statsobj
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
public columnstatistics gettablecolumnstatistics string dbname  string tablename  string colname
throws hiveexception
try
return getmsc   gettablecolumnstatistics dbname  tablename  colname
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
public columnstatistics getpartitioncolumnstatistics string dbname  string tablename
string partname  string colname  throws hiveexception
try
return getmsc   getpartitioncolumnstatistics dbname  tablename  partname  colname
catch  exception e
log error stringutils stringifyexception e
throw new hiveexception e
public boolean deletetablecolumnstatistics string dbname  string tablename  string colname
throws hiveexception
try
return getmsc   deletetablecolumnstatistics dbname  tablename  colname
catch exception e
log error stringutils stringifyexception e
throw new hiveexception e
public boolean deletepartitioncolumnstatistics string dbname  string tablename  string partname
string colname  throws hiveexception
try
return getmsc   deletepartitioncolumnstatistics dbname  tablename  partname  colname
catch exception e
log error stringutils stringifyexception e
throw new hiveexception e
public table newtable string tablename  throws hiveexception
string names   getqualifiednames tablename
switch  names length
case 2
return new table names  names
case 1
return new table sessionstate get   getcurrentdatabase    names
default
try
throw new hiveexception     tablename
catch exception e
e printstacktrace
throw new hiveexception     tablename
public string getdelegationtoken string owner  string renewer
throws hiveexception
try
return getmsc   getdelegationtoken owner  renewer
catch exception e
log error stringutils stringifyexception e
throw new hiveexception e
public void canceldelegationtoken string tokenstrform
throws hiveexception
try
getmsc   canceldelegationtoken tokenstrform
catch exception e
log error stringutils stringifyexception e
throw new hiveexception e
private static string getqualifiednames string qualifiedname
return qualifiedname split