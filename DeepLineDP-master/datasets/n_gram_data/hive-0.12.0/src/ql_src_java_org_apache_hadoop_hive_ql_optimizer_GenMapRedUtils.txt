/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hive ql optimizer
import java io serializable
import java util arraylist
import java util hashmap
import java util iterator
import java util linkedhashmap
import java util list
import java util map
import java util map entry
import java util properties
import java util set
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop fs path
import org apache hadoop hive conf hiveconf
import org apache hadoop hive ql context
import org apache hadoop hive ql exec conditionaltask
import org apache hadoop hive ql exec demuxoperator
import org apache hadoop hive ql exec joinoperator
import org apache hadoop hive ql exec operator
import org apache hadoop hive ql exec operatorfactory
import org apache hadoop hive ql exec reducesinkoperator
import org apache hadoop hive ql exec tablescanoperator
import org apache hadoop hive ql exec task
import org apache hadoop hive ql exec taskfactory
import org apache hadoop hive ql exec unionoperator
import org apache hadoop hive ql exec utilities
import org apache hadoop hive ql exec mr execdriver
import org apache hadoop hive ql exec mr mapredtask
import org apache hadoop hive ql hooks readentity
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata partition
import org apache hadoop hive ql optimizer genmrproccontext genmrunionctx
import org apache hadoop hive ql optimizer genmrproccontext genmapredctx
import org apache hadoop hive ql optimizer listbucketingpruner listbucketingpruner
import org apache hadoop hive ql optimizer ppr partitionpruner
import org apache hadoop hive ql parse opparsecontext
import org apache hadoop hive ql parse parsecontext
import org apache hadoop hive ql parse prunedpartitionlist
import org apache hadoop hive ql parse rowresolver
import org apache hadoop hive ql parse semanticexception
import org apache hadoop hive ql plan exprnodedesc
import org apache hadoop hive ql plan fetchwork
import org apache hadoop hive ql plan filesinkdesc
import org apache hadoop hive ql plan filterdesc sampledesc
import org apache hadoop hive ql plan mapwork
import org apache hadoop hive ql plan mapredlocalwork
import org apache hadoop hive ql plan mapredwork
import org apache hadoop hive ql plan operatordesc
import org apache hadoop hive ql plan partitiondesc
import org apache hadoop hive ql plan planutils
import org apache hadoop hive ql plan reducesinkdesc
import org apache hadoop hive ql plan reducework
import org apache hadoop hive ql plan tabledesc
import org apache hadoop hive ql plan tablescandesc
/**
* general utility common functions for the processor to convert operator into
* map-reduce tasks.
*/
public final class genmapredutils
private static log log
static
log   logfactory getlog
private static boolean needstagging reducework rwork
return rwork    null     rwork getreducer   getclass      joinoperator class
rwork getreducer   getclass      demuxoperator class
/**
* initialize the current plan by adding it to root tasks.
*
* @param op
*          the reduce sink operator encountered
* @param opprocctx
*          processing context
*/
public static void initplan reducesinkoperator op  genmrproccontext opprocctx
throws semanticexception
operator<? extends operatordesc> reducer   op getchildoperators   get 0
map<operator<? extends operatordesc>  genmapredctx> mapcurrctx
opprocctx getmapcurrctx
genmapredctx mapredctx   mapcurrctx get op getparentoperators   get 0
task<? extends serializable> currtask   mapredctx getcurrtask
mapredwork plan    mapredwork  currtask getwork
hashmap<operator<? extends operatordesc>  task<? extends serializable>> optaskmap
opprocctx getoptaskmap
operator<? extends operatordesc> currtopop   opprocctx getcurrtopop
optaskmap put reducer  currtask
plan setreducework new reducework
plan getreducework   setreducer reducer
reducesinkdesc desc   op getconf
plan getreducework   setnumreducetasks desc getnumreducers
if  needstagging plan getreducework
plan getreducework   setneedstagging true
assert currtopop    null
string curraliasid   opprocctx getcurraliasid
if   opprocctx isseenop currtask  currtopop
settaskplan curraliasid  currtopop  currtask  false  opprocctx
currtopop   null
curraliasid   null
opprocctx setcurrtask currtask
opprocctx setcurrtopop currtopop
opprocctx setcurraliasid curraliasid
/**
* initialize the current union plan.
*
* @param op
*          the reduce sink operator encountered
* @param opprocctx
*          processing context
*/
public static void initunionplan reducesinkoperator op  unionoperator currunionop
genmrproccontext opprocctx
task<? extends serializable> uniontask  throws semanticexception
operator<? extends operatordesc> reducer   op getchildoperators   get 0
mapredwork plan    mapredwork  uniontask getwork
hashmap<operator<? extends operatordesc>  task<? extends serializable>> optaskmap
opprocctx getoptaskmap
optaskmap put reducer  uniontask
plan setreducework new reducework
plan getreducework   setreducer reducer
plan getreducework   setreducer reducer
reducesinkdesc desc   op getconf
plan getreducework   setnumreducetasks desc getnumreducers
if  needstagging plan getreducework
plan getreducework   setneedstagging true
initunionplan opprocctx  currunionop  uniontask  false
private static void setunionplan genmrproccontext opprocctx
boolean local  task<? extends serializable> currtask  genmrunionctx uctx
boolean mergetask  throws semanticexception
operator<? extends operatordesc> currtopop   opprocctx getcurrtopop
if  currtopop    null
string curraliasid   opprocctx getcurraliasid
if  mergetask     opprocctx isseenop currtask  currtopop
settaskplan curraliasid  currtopop  currtask  local  opprocctx
currtopop   null
opprocctx setcurrtopop currtopop
else
list<string> tasktmpdirlst   uctx gettasktmpdir
if   tasktmpdirlst    null       tasktmpdirlst isempty
list<tabledesc> tt_desclst   uctx getttdesc
assert  tasktmpdirlst isempty       tt_desclst isempty
assert tasktmpdirlst size      tt_desclst size
int size   tasktmpdirlst size
assert local    false
list<operator<? extends operatordesc>> topoperators
uctx getlisttopoperators
mapredwork plan    mapredwork  currtask getwork
for  int pos   0  pos < size  pos
string tasktmpdir   tasktmpdirlst get pos
tabledesc tt_desc   tt_desclst get pos
mapwork mwork   plan getmapwork
if  mwork getpathtoaliases   get tasktmpdir     null
mwork getpathtoaliases   put tasktmpdir
new arraylist<string>
mwork getpathtoaliases   get tasktmpdir  add tasktmpdir
mwork getpathtopartitioninfo   put tasktmpdir
new partitiondesc tt_desc  null
mwork getaliastowork   put tasktmpdir  topoperators get pos
/*
* it is a idempotent function to add various intermediate files as the source
* for the union. the plan has already been created.
*/
public static void initunionplan genmrproccontext opprocctx  unionoperator currunionop
task<? extends serializable> currtask  boolean local
throws semanticexception
// in case of lateral views followed by a join, the same tree
// can be traversed more than one
if  currunionop    null
genmrunionctx uctx   opprocctx getuniontask currunionop
assert uctx    null
setunionplan opprocctx  local  currtask  uctx  false
/*
* join current union task to old task
*/
public static void joinunionplan genmrproccontext opprocctx
unionoperator currunionop
task<? extends serializable> currentuniontask
task<? extends serializable> existingtask  boolean local
throws semanticexception
assert currunionop    null
genmrunionctx uctx   opprocctx getuniontask currunionop
assert uctx    null
setunionplan opprocctx  local  existingtask  uctx  true
list<task<? extends serializable>> partasks   null
if  opprocctx getroottasks   contains currentuniontask
opprocctx getroottasks   remove currentuniontask
if   opprocctx getroottasks   contains existingtask
existingtask getparenttasks      null    existingtask getparenttasks   isempty
opprocctx getroottasks   add existingtask
if   currentuniontask    null      currentuniontask getparenttasks      null
currentuniontask getparenttasks   isempty
partasks   new arraylist<task<? extends serializable>>
partasks addall currentuniontask getparenttasks
object partaskarr   partasks toarray
for  object partask   partaskarr
task<? extends serializable>  partask
removedependenttask currentuniontask
if   currentuniontask    null      partasks    null
for  task<? extends serializable> partask   partasks
partask adddependenttask existingtask
if  opprocctx getroottasks   contains existingtask
opprocctx getroottasks   remove existingtask
opprocctx setcurrtask existingtask
/**
* merge the current task into the old task for the reducer
*
* @param currtask
*          the current task for the current reducer
* @param oldtask
*          the old task for the current reducer
* @param opprocctx
*          processing context
*/
public static void joinplan task<? extends serializable> currtask
task<? extends serializable> oldtask  genmrproccontext opprocctx
throws semanticexception
assert currtask    null    oldtask    null
operator<? extends operatordesc> currtopop   opprocctx getcurrtopop
list<task<? extends serializable>> partasks   null
// terminate the old task and make current task dependent on it
if  currtask getparenttasks      null
currtask getparenttasks   isempty
partasks   new arraylist<task<? extends serializable>>
partasks addall currtask getparenttasks
object partaskarr   partasks toarray
for  object element   partaskarr
task<? extends serializable>  element  removedependenttask currtask
if  currtopop    null
mergeinput currtopop  opprocctx  oldtask  false
if  partasks    null
for  task<? extends serializable> partask   partasks
partask adddependenttask oldtask
if  oldtask instanceof mapredtask    currtask instanceof mapredtask
mapredtask currtask  getwork   getmapwork
merginginto   mapredtask  oldtask  getwork   getmapwork
opprocctx setcurrtopop null
opprocctx setcurrtask oldtask
/**
* if currtopop is not set for input of the task, add input for to the task
*/
static boolean mergeinput operator<? extends operatordesc> currtopop
genmrproccontext opprocctx  task<? extends serializable> task  boolean local
throws semanticexception
if   opprocctx isseenop task  currtopop
string curraliasid   opprocctx getcurraliasid
settaskplan curraliasid  currtopop  task  local  opprocctx
return true
return false
/**
* met crs in prs(parenttask)-crs-op(childtask) case
* split and link two tasks by temporary file : prs-fs / ts-crs-op
*/
static void splitplan reducesinkoperator crs
task<? extends serializable> parenttask  task<? extends serializable> childtask
genmrproccontext opprocctx  throws semanticexception
assert parenttask    null    childtask    null
splittasks crs  parenttask  childtask  opprocctx
/**
* met crs in pop(parenttask with rs)-crs-cop(notask) case
* create new child task for crs-cop and link two tasks by temporary file : pop-fs / ts-crs-cop
*
* @param crs
*          the reduce sink operator encountered
* @param opprocctx
*          processing context
*/
static void splitplan reducesinkoperator crs  genmrproccontext opprocctx
throws semanticexception
// generate a new task
parsecontext parsectx   opprocctx getparsectx
task<? extends serializable> parenttask   opprocctx getcurrtask
mapredwork childplan   getmapredwork parsectx
task<? extends serializable> childtask   taskfactory get childplan  parsectx
getconf
operator<? extends operatordesc> reducer   crs getchildoperators   get 0
// add the reducer
reducework rwork   new reducework
childplan setreducework rwork
rwork setreducer reducer
reducesinkdesc desc   crs getconf
childplan getreducework   setnumreducetasks new integer desc getnumreducers
opprocctx getoptaskmap   put reducer  childtask
splittasks crs  parenttask  childtask  opprocctx
/**
* set the current task in the mapredwork.
*
* @param alias_id
*          current alias
* @param topop
*          the top operator of the stack
* @param plan
*          current plan
* @param local
*          whether you need to add to map-reduce or local work
* @param opprocctx
*          processing context
*/
public static void settaskplan string alias_id
operator<? extends operatordesc> topop  task<?> task  boolean local
genmrproccontext opprocctx  throws semanticexception
settaskplan alias_id  topop  task  local  opprocctx  null
private static readentity getparentviewinfo string alias_id
map<string  readentity> viewaliastoinput
string aliases   alias_id split
string currentalias   null
readentity currentinput   null
// find the immediate parent possible.
// for eg: for a query like 'select * from v3', where v3 -> v2, v2 -> v1, v1 -> t
// -> implies depends on.
// t's parent would be v1
for  int pos   0  pos < aliases length  pos
currentalias   currentalias    null ? aliases   currentalias       aliases
readentity input   viewaliastoinput get currentalias
if  input    null
return currentinput
currentinput   input
return currentinput
/**
* set the current task in the mapredwork.
*
* @param alias_id
*          current alias
* @param topop
*          the top operator of the stack
* @param plan
*          current plan
* @param local
*          whether you need to add to map-reduce or local work
* @param opprocctx
*          processing context
* @param plist
*          pruned partition list. if it is null it will be computed on-the-fly.
*/
public static void settaskplan string alias_id
operator<? extends operatordesc> topop  task<?> task  boolean local
genmrproccontext opprocctx  prunedpartitionlist plist  throws semanticexception
mapwork plan     mapredwork  task getwork    getmapwork
parsecontext parsectx   opprocctx getparsectx
set<readentity> inputs   opprocctx getinputs
arraylist<path> partdir   new arraylist<path>
arraylist<partitiondesc> partdesc   new arraylist<partitiondesc>
path tbldir   null
tabledesc tbldesc   null
prunedpartitionlist partslist   plist
plan setnametosplitsample parsectx getnametosplitsample
if  partslist    null
try
tablescanoperator tsop    tablescanoperator  topop
partslist   partitionpruner prune tsop  parsectx  alias_id
catch  semanticexception e
throw e
catch  hiveexception e
log error org apache hadoop util stringutils stringifyexception e
throw new semanticexception e getmessage    e
// generate the map work for this alias_id
// pass both confirmed and unknown partitions through the map-reduce
// framework
set<partition> parts   partslist getpartitions
partitiondesc aliaspartndesc   null
try
if   parts isempty
aliaspartndesc   utilities getpartitiondesc parts iterator   next
catch  hiveexception e
log error org apache hadoop util stringutils stringifyexception e
throw new semanticexception e getmessage    e
// the table does not have any partitions
if  aliaspartndesc    null
aliaspartndesc   new partitiondesc utilities gettabledesc parsectx
gettoptotable   get topop    null
map<string  string> props   parsectx gettoptoprops   get topop
if  props    null
properties target   aliaspartndesc getproperties
if  target    null
aliaspartndesc setproperties target   new properties
target putall props
plan getaliastopartninfo   put alias_id  aliaspartndesc
long sizeneeded   integer max_value
int filelimit    1
if  parsectx getgloballimitctx   isenable
long sizeperrow   hiveconf getlongvar parsectx getconf
hiveconf confvars hivelimitmaxrowsize
sizeneeded   parsectx getgloballimitctx   getgloballimit     sizeperrow
// for the optimization that reduce number of input file, we limit number
// of files allowed. if more than specific number of files have to be
// selected, we skip this optimization. since having too many files as
// inputs can cause unpredictable latency. it's not necessarily to be
// cheaper.
filelimit
hiveconf getintvar parsectx getconf    hiveconf confvars hivelimitoptlimitfile
if  sizeperrow <  0    filelimit <  0
log info
parsectx getgloballimitctx   disableopt
else if  parts isempty
log info
else
log info
sizeneeded
filelimit
boolean isfirstpart   true
boolean emptyinput   true
boolean singlepartition    parts size      1
// track the dependencies for the view. consider a query like: select * from v;
// where v is a view of the form: select * from t
// the dependencies should include v at depth 0, and t at depth 1 (inferred).
readentity parentviewinfo   getparentviewinfo alias_id  parsectx getviewaliastoinput
// the table should also be considered a part of inputs, even if the table is a
// partitioned table and whether any partition is selected or not
planutils addinput inputs
new readentity parsectx gettoptotable   get topop   parentviewinfo
for  partition part   parts
if  part gettable   ispartitioned
planutils addinput inputs  new readentity part  parentviewinfo
else
planutils addinput inputs  new readentity part gettable    parentviewinfo
// later the properties have to come from the partition as opposed
// to from the table in order to support versioning.
path paths   null
sampledesc sampledescr   parsectx getoptosamplepruner   get topop
// lookup list bucketing pruner
map<string  exprnodedesc> parttopruner   parsectx getoptoparttoskewedpruner   get topop
exprnodedesc listbucketingpruner    parttopruner    null  ? parttopruner get part getname

if  sampledescr    null
assert  listbucketingpruner    null
paths   samplepruner prune part  sampledescr
parsectx getgloballimitctx   disableopt
else if  listbucketingpruner    null
assert  sampledescr    null
/* use list bucketing prunner's path. */
paths   listbucketingpruner prune parsectx  part  listbucketingpruner
else
// now we only try the first partition, if the first partition doesn't
// contain enough size, we change to normal mode.
if  parsectx getgloballimitctx   isenable
if  isfirstpart
long sizeleft   sizeneeded
arraylist<path> retpathlist   new arraylist<path>
samplepruner limitpruneretstatus status   samplepruner limitprune part  sizeleft
filelimit  retpathlist
if  status equals samplepruner limitpruneretstatus nofile
continue
else if  status equals samplepruner limitpruneretstatus notqualify
log info     filelimit
sizeneeded
parsectx getgloballimitctx   disableopt
else
emptyinput   false
paths   new path
int index   0
for  path path   retpathlist
paths   path
if  status equals samplepruner limitpruneretstatus needallfiles     singlepartition
// if all files are needed to meet the size limit, we disable
// optimization. it usually happens for empty table/partition or
// table/partition with only one file. by disabling this
// optimization, we can avoid retrying the query if there is
// not sufficient rows.
parsectx getgloballimitctx   disableopt
isfirstpart   false
else
paths   new path
if   parsectx getgloballimitctx   isenable
paths   part getpath
// is it a partitioned table ?
if   part gettable   ispartitioned
assert   tbldir    null      tbldesc    null
tbldir   paths
tbldesc   utilities gettabledesc part gettable
else if  tbldesc    null
tbldesc   utilities gettabledesc part gettable
if  props    null
properties target   tbldesc getproperties
if  target    null
tbldesc setproperties target   new properties
target putall props
for  path p   paths
if  p    null
continue
string path   p tostring
if  log isdebugenabled
log debug     path       alias_id
partdir add p
try
if  part gettable   ispartitioned
partdesc add utilities getpartitiondesc part
else
partdesc add utilities getpartitiondescfromtabledesc tbldesc  part
catch  hiveexception e
log error org apache hadoop util stringutils stringifyexception e
throw new semanticexception e getmessage    e
if  emptyinput
parsectx getgloballimitctx   disableopt
iterator<path> iterpath   partdir iterator
iterator<partitiondesc> iterpartndesc   partdesc iterator
if   local
while  iterpath hasnext
assert iterpartndesc hasnext
string path   iterpath next   tostring
partitiondesc prtdesc   iterpartndesc next
// add the path to alias mapping
if  plan getpathtoaliases   get path     null
plan getpathtoaliases   put path  new arraylist<string>
plan getpathtoaliases   get path  add alias_id
plan getpathtopartitioninfo   put path  prtdesc
if  log isdebugenabled
log debug     path
assert plan getaliastowork   get alias_id     null
plan getaliastowork   put alias_id  topop
else
// populate local work if needed
mapredlocalwork localplan   plan getmaplocalwork
if  localplan    null
localplan   new mapredlocalwork
new linkedhashmap<string  operator<? extends operatordesc>>
new linkedhashmap<string  fetchwork>
assert localplan getaliastowork   get alias_id     null
assert localplan getaliastofetchwork   get alias_id     null
localplan getaliastowork   put alias_id  topop
if  tbldir    null
tbldesc   utilities gettabledesc partslist getsourcetable
localplan getaliastofetchwork   put
alias_id
new fetchwork fetchwork convertpathtostringarray partdir   partdesc  tbldesc
else
localplan getaliastofetchwork   put alias_id
new fetchwork tbldir tostring    tbldesc
plan setmaplocalwork localplan
opprocctx addseenop task  topop
/**
* set the current task in the mapredwork.
*
* @param alias
*          current alias
* @param topop
*          the top operator of the stack
* @param plan
*          current plan
* @param local
*          whether you need to add to map-reduce or local work
* @param tt_desc
*          table descriptor
*/
public static void settaskplan string path  string alias
operator<? extends operatordesc> topop  mapwork plan  boolean local
tabledesc tt_desc  throws semanticexception
if  path    null    alias    null
return
if   local
if  plan getpathtoaliases   get path     null
plan getpathtoaliases   put path  new arraylist<string>
plan getpathtoaliases   get path  add alias
plan getpathtopartitioninfo   put path  new partitiondesc tt_desc  null
plan getaliastowork   put alias  topop
else
// populate local work if needed
mapredlocalwork localplan   plan getmaplocalwork
if  localplan    null
localplan   new mapredlocalwork
new linkedhashmap<string  operator<? extends operatordesc>>
new linkedhashmap<string  fetchwork>
assert localplan getaliastowork   get alias     null
assert localplan getaliastofetchwork   get alias     null
localplan getaliastowork   put alias  topop
localplan getaliastofetchwork   put alias  new fetchwork alias  tt_desc
plan setmaplocalwork localplan
/**
* set key and value descriptor.
*
* @param plan
*          current plan
* @param topop
*          current top operator in the path
*/
public static void setkeyandvaluedesc reducework plan
operator<? extends operatordesc> topop
if  topop    null
return
if  topop instanceof reducesinkoperator
reducesinkoperator rs    reducesinkoperator  topop
plan setkeydesc rs getconf   getkeyserializeinfo
int tag   math max 0  rs getconf   gettag
list<tabledesc> tagtoschema   plan gettagtovaluedesc
while  tag   1 > tagtoschema size
tagtoschema add null
tagtoschema set tag  rs getconf   getvalueserializeinfo
else
list<operator<? extends operatordesc>> children   topop getchildoperators
if  children    null
for  operator<? extends operatordesc> op   children
setkeyandvaluedesc plan  op
/**
* set the key and value description for all the tasks rooted at the given
* task. loops over all the tasks recursively.
*
* @param task
*/
public static void setkeyandvaluedescfortasktree task<? extends serializable> task
if  task instanceof conditionaltask
list<task<? extends serializable>> listtasks     conditionaltask  task
getlisttasks
for  task<? extends serializable> tsk   listtasks
setkeyandvaluedescfortasktree tsk
else if  task instanceof execdriver
mapredwork work    mapredwork  task getwork
work getmapwork   deriveexplainattributes
hashmap<string  operator<? extends operatordesc>> opmap   work
getmapwork   getaliastowork
if  opmap    null     opmap isempty
for  operator<? extends operatordesc> op   opmap values
setkeyandvaluedesc work getreducework    op
if  task getchildtasks      null
return
for  task<? extends serializable> childtask   task getchildtasks
setkeyandvaluedescfortasktree childtask
/**
* create a new plan and return.
*
* @return the new plan
*/
public static mapredwork getmapredwork parsecontext parsectx
mapredwork work   getmapredworkfromconf parsectx getconf
work getmapwork   setnametosplitsample parsectx getnametosplitsample
return work
/**
* create a new plan and return. the pan won't contain the name to split
* sample information in parse context.
*
* @return the new plan
*/
public static mapredwork getmapredworkfromconf hiveconf conf
mapredwork mrwork   new mapredwork
mapwork work   mrwork getmapwork
boolean mappercannotspanpartns
conf getboolvar
hiveconf confvars hive_mapper_cannot_span_multiple_partitions
work setmappercannotspanpartns mappercannotspanpartns
work setpathtoaliases new linkedhashmap<string  arraylist<string>>
work setpathtopartitioninfo new linkedhashmap<string  partitiondesc>
work setaliastowork new linkedhashmap<string  operator<? extends operatordesc>>
work sethadoopsupportssplittable
conf getboolvar hiveconf confvars hive_combine_input_format_supports_splittable
return mrwork
/**
* insert in the map for the operator to row resolver.
*
* @param op
*          operator created
* @param rr
*          row resolver
* @param parsectx
*          parse context
*/
@suppresswarnings
public static operator<? extends operatordesc> putopinsertmap
operator<? extends operatordesc> op  rowresolver rr  parsecontext parsectx
opparsecontext ctx   new opparsecontext rr
parsectx getopparsectx   put op  ctx
return op
@suppresswarnings
/**
* split two tasks by creating a temporary file between them.
*
* @param op reduce sink operator being processed
* @param parenttask the parent task
* @param childtask the child task
* @param opprocctx context
**/
private static void splittasks reducesinkoperator op
task<? extends serializable> parenttask  task<? extends serializable> childtask
genmrproccontext opprocctx  throws semanticexception
if  op getnumparent      1
throw new illegalstateexception     op
op getparentoperators
parsecontext parsectx   opprocctx getparsectx
parenttask adddependenttask childtask
// root task cannot depend on any other task, therefore childtask cannot be
// a root task
list<task<? extends serializable>> roottasks   opprocctx getroottasks
if  roottasks contains childtask
roottasks remove childtask
// generate the temporary file
context basectx   parsectx getcontext
string tasktmpdir   basectx getmrtmpfileuri
operator<? extends operatordesc> parent   op getparentoperators   get 0
tabledesc tt_desc   planutils getintermediatefiletabledesc planutils
getfieldschemasfromrowschema parent getschema
// create a file sink operator for this file name
boolean compressintermediate   parsectx getconf   getboolvar
hiveconf confvars compressintermediate
filesinkdesc desc   new filesinkdesc tasktmpdir  tt_desc
compressintermediate
if  compressintermediate
desc setcompresscodec parsectx getconf   getvar
hiveconf confvars compressintermediatecodec
desc setcompresstype parsectx getconf   getvar
hiveconf confvars compressintermediatetype
operator<? extends operatordesc> fs_op   putopinsertmap operatorfactory
get desc  parent getschema     null  parsectx
// replace the reduce child with this operator
list<operator<? extends operatordesc>> childoplist   parent
getchildoperators
for  int pos   0  pos < childoplist size    pos
if  childoplist get pos     op
childoplist set pos  fs_op
break
list<operator<? extends operatordesc>> parentoplist
new arraylist<operator<? extends operatordesc>>
parentoplist add parent
fs_op setparentoperators parentoplist
// create a dummy tablescan operator on top of op
// tablescanoperator is implicitly created here for each mapoperator
rowresolver rowresolver   opprocctx getparsectx   getopparsectx   get parent  getrowresolver
operator<? extends operatordesc> ts_op   putopinsertmap operatorfactory
get tablescandesc class  parent getschema     rowresolver  parsectx
childoplist   new arraylist<operator<? extends operatordesc>>
childoplist add op
ts_op setchildoperators childoplist
op getparentoperators   set 0  ts_op
map<operator<? extends operatordesc>  genmapredctx> mapcurrctx
opprocctx getmapcurrctx
mapcurrctx put ts_op  new genmapredctx childtask  null
string streamdesc   tasktmpdir
mapredwork cplan    mapredwork  childtask getwork
operator<? extends operatordesc> reducer   op getchildoperators   get 0
if  needstagging cplan getreducework
string origstreamdesc
streamdesc
origstreamdesc   streamdesc
int pos   0
while  cplan getmapwork   getaliastowork   get streamdesc     null
streamdesc   origstreamdesc concat string valueof   pos
// todo: allocate work to remove the temporary files and make that
// dependent on the redtask
cplan getreducework   setneedstagging true
// add the path to alias mapping
settaskplan tasktmpdir  streamdesc  ts_op  cplan getmapwork    false  tt_desc
opprocctx setcurrtopop null
opprocctx setcurraliasid null
opprocctx setcurrtask childtask
opprocctx addrootifpossible parenttask
static boolean hasbranchfinished object    children
for  object child   children
if  child    null
return false
return true
/**
* replace the map-side operator tree associated with targetalias in
* target with the map-side operator tree associated with sourcealias in source.
* @param sourcealias
* @param targetalias
* @param source
* @param target
*/
public static void replacemapwork string sourcealias  string targetalias
mapwork source  mapwork target
map<string  arraylist<string>> sourcepathtoaliases   source getpathtoaliases
map<string  partitiondesc> sourcepathtopartitioninfo   source getpathtopartitioninfo
map<string  operator<? extends operatordesc>> sourcealiastowork   source getaliastowork
map<string  partitiondesc> sourcealiastopartninfo   source getaliastopartninfo
map<string  arraylist<string>> targetpathtoaliases   target getpathtoaliases
map<string  partitiondesc> targetpathtopartitioninfo   target getpathtopartitioninfo
map<string  operator<? extends operatordesc>> targetaliastowork   target getaliastowork
map<string  partitiondesc> targetaliastopartninfo   target getaliastopartninfo
if   sourcealiastowork containskey sourcealias
targetaliastowork containskey targetalias
// nothing to do if there is no operator tree associated with
// sourcealias in source or there is not operator tree associated
// with targetalias in target.
return
if  sourcealiastowork size   > 1
// if there are multiple aliases in source, we do not know
// how to merge.
return
// remove unnecessary information from target
targetaliastowork remove targetalias
targetaliastopartninfo remove targetalias
list<string> pathstoremove   new arraylist<string>
for  entry<string  arraylist<string>> entry  targetpathtoaliases entryset
arraylist<string> aliases   entry getvalue
aliases remove targetalias
if  aliases isempty
pathstoremove add entry getkey
for  string pathtoremove  pathstoremove
targetpathtoaliases remove pathtoremove
targetpathtopartitioninfo remove pathtoremove
// add new information from source to target
targetaliastowork put sourcealias  sourcealiastowork get sourcealias
targetaliastopartninfo putall sourcealiastopartninfo
targetpathtopartitioninfo putall sourcepathtopartitioninfo
list<string> pathstoadd   new arraylist<string>
for  entry<string  arraylist<string>> entry  sourcepathtoaliases entryset
arraylist<string> aliases   entry getvalue
if  aliases contains sourcealias
pathstoadd add entry getkey
for  string pathtoadd  pathstoadd
if   targetpathtoaliases containskey pathtoadd
targetpathtoaliases put pathtoadd  new arraylist<string>
targetpathtoaliases get pathtoadd  add sourcealias
private genmapredutils
// prevent instantiation