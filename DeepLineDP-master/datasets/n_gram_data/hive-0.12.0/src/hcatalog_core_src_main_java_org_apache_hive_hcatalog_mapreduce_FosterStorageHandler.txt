/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing,
* software distributed under the license is distributed on an
* "as is" basis, without warranties or conditions of any
* kind, either express or implied.  see the license for the
* specific language governing permissions and limitations
* under the license.
*/
package org apache hive hcatalog mapreduce
import org apache hadoop conf configuration
import org apache hadoop fs path
import org apache hadoop hive common fileutils
import org apache hadoop hive metastore hivemetahook
import org apache hadoop hive ql io rcfile
import org apache hadoop hive ql metadata hiveexception
import org apache hadoop hive ql metadata defaultstoragehandler
import org apache hadoop hive ql plan tabledesc
import org apache hadoop hive ql security authorization defaulthiveauthorizationprovider
import org apache hadoop hive ql security authorization hiveauthorizationprovider
import org apache hadoop hive serde2 serde
import org apache hadoop mapred inputformat
import org apache hadoop mapred jobconf
import org apache hadoop mapred outputformat
import org apache hive hcatalog common hcatconstants
import org apache hive hcatalog common hcatutil
import java io ioexception
import java util arraylist
import java util list
import java util map
/**
*  this class is used to encapsulate the inputformat, outputformat and serde
*  artifacts of tables which don't define a serde. this storagehandler assumes
*  the supplied storage artifacts are for a file-based storage system.
*/
public class fosterstoragehandler extends defaultstoragehandler
public configuration conf
/** the directory under which data is initially written for a partitioned table */
protected static final string dyntemp_dir_name
/** the directory under which data is initially written for a non partitioned table */
protected static final string temp_dir_name
private class<? extends inputformat> ifclass
private class<? extends outputformat> ofclass
private class<? extends serde> serdeclass
public fosterstoragehandler string ifname  string ofname  string serdename  throws classnotfoundexception
this  class<? extends inputformat>  class forname ifname
class<? extends outputformat>  class forname ofname
class<? extends serde>  class forname serdename
public fosterstoragehandler class<? extends inputformat> ifclass
class<? extends outputformat> ofclass
class<? extends serde> serdeclass
this ifclass   ifclass
this ofclass   ofclass
this serdeclass   serdeclass
@override
public class<? extends inputformat> getinputformatclass
return ifclass       to change body of overridden methods use file   settings   file templates
@override
public class<? extends outputformat> getoutputformatclass
return ofclass       to change body of overridden methods use file   settings   file templates
@override
public class<? extends serde> getserdeclass
return serdeclass     to change body of implemented methods use file   settings   file templates
@override
public hivemetahook getmetahook
return null
@override
public void configurejobconf tabledesc tabledesc  jobconf jobconf
//do nothing currently
@override
public void configureinputjobproperties tabledesc tabledesc
map<string  string> jobproperties
@override
public void configureoutputjobproperties tabledesc tabledesc
map<string  string> jobproperties
try
outputjobinfo jobinfo    outputjobinfo
hcatutil deserialize tabledesc getjobproperties   get
hcatconstants hcat_key_output_info
string parentpath   jobinfo gettableinfo   gettablelocation
string dynhash   tabledesc getjobproperties   get
hcatconstants hcat_dynamic_ptn_jobid
// for dynamic partitioned writes without all keyvalues specified,
// we create a temp dir for the associated write job
if  dynhash    null
parentpath   new path parentpath
dyntemp_dir_name   dynhash  tostring
string outputlocation
if   dynhash    null
boolean valueof  string tabledesc getproperties   get
jobinfo getlocation      null    jobinfo getlocation   length   > 0
// honor custom location for external table apart from what metadata specifies
// only if we're not using dynamic partitioning - see hive-5011
outputlocation   jobinfo getlocation
else if  dynhash    null    jobinfo getpartitionvalues   size      0
// for non-partitioned tables, we send them to the temp dir
outputlocation   temp_dir_name
else
list<string> cols   new arraylist<string>
list<string> values   new arraylist<string>
//get the output location in the order partition keys are defined for the table.
for  string name
jobinfo gettableinfo
getpartitioncolumns   getfieldnames
string value   jobinfo getpartitionvalues   get name
cols add name
values add value
outputlocation   fileutils makepartname cols  values
jobinfo setlocation new path parentpath  outputlocation  tostring
//only set output dir if partition is fully materialized
if  jobinfo getpartitionvalues   size
jobinfo gettableinfo   getpartitioncolumns   size
jobproperties put    jobinfo getlocation
//todo find a better home for this, rcfile specifc
jobproperties put rcfile column_number_conf_str
integer tooctalstring
jobinfo getoutputschema   getfields   size
jobproperties put hcatconstants hcat_key_output_info
hcatutil serialize jobinfo
catch  ioexception e
throw new illegalstateexception    e
public void configuretablejobproperties tabledesc tabledesc
map<string  string> jobproperties
return
outputformatcontainer getoutputformatcontainer
org apache hadoop mapred outputformat outputformat
return new fileoutputformatcontainer outputformat
@override
public configuration getconf
return conf
@override
public void setconf configuration conf
this conf   conf
@override
public hiveauthorizationprovider getauthorizationprovider
throws hiveexception
return new defaulthiveauthorizationprovider