/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*      http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache camel processor
import java util arraylist
import java util collection
import java util hashmap
import java util iterator
import java util list
import java util map
import java util concurrent callable
import java util concurrent completionservice
import java util concurrent concurrenthashmap
import java util concurrent concurrentmap
import java util concurrent countdownlatch
import java util concurrent executionexception
import java util concurrent executorcompletionservice
import java util concurrent executorservice
import java util concurrent future
import java util concurrent timeunit
import java util concurrent atomic atomicboolean
import java util concurrent atomic atomicinteger
import org apache camel asynccallback
import org apache camel asyncprocessor
import org apache camel camelcontext
import org apache camel camelexchangeexception
import org apache camel endpoint
import org apache camel errorhandlerfactory
import org apache camel exchange
import org apache camel navigate
import org apache camel processor
import org apache camel producer
import org apache camel traceable
import org apache camel processor aggregate aggregationstrategy
import org apache camel processor aggregate timeoutawareaggregationstrategy
import org apache camel spi routecontext
import org apache camel spi tracedroutenodes
import org apache camel spi unitofwork
import org apache camel support servicesupport
import org apache camel util asyncprocessorconverterhelper
import org apache camel util asyncprocessorhelper
import org apache camel util castutils
import org apache camel util eventhelper
import org apache camel util exchangehelper
import org apache camel util keyvalueholder
import org apache camel util objecthelper
import org apache camel util servicehelper
import org apache camel util stopwatch
import org apache camel util concurrent atomicexception
import org apache camel util concurrent atomicexchange
import org apache camel util concurrent submitorderedcompletionservice
import org slf4j logger
import org slf4j loggerfactory
import static org apache camel util objecthelper notnull
/**
* implements the multicast pattern to send a message exchange to a number of
* endpoints, each endpoint receiving a copy of the message exchange.
*
* @version
* @see pipeline
*/
public class multicastprocessor extends servicesupport implements asyncprocessor  navigate<processor>  traceable
private static final transient logger log   loggerfactory getlogger multicastprocessor class
/**
* class that represent each step in the multicast route to do
*/
static final class defaultprocessorexchangepair implements processorexchangepair
private final int index
private final processor processor
private final processor prepared
private final exchange exchange
private defaultprocessorexchangepair int index  processor processor  processor prepared  exchange exchange
this index   index
this processor   processor
this prepared   prepared
this exchange   exchange
public int getindex
return index
public exchange getexchange
return exchange
public producer getproducer
if  processor instanceof producer
return  producer  processor
return null
public processor getprocessor
return prepared
public void begin
// noop
public void done
// noop
/**
* class that represents prepared fine grained error handlers when processing multicasted/splitted exchanges
* <p/>
* see the <tt>createprocessorexchangepair</tt> and <tt>createerrorhandler</tt> methods.
*/
static final class preparederrorhandler extends keyvalueholder<routecontext  processor>
public preparederrorhandler routecontext key  processor value
super key  value
protected final processor onprepare
private final camelcontext camelcontext
private collection<processor> processors
private final aggregationstrategy aggregationstrategy
private final boolean parallelprocessing
private final boolean streaming
private final boolean stoponexception
private final executorservice executorservice
private final boolean shutdownexecutorservice
private executorservice aggregateexecutorservice
private final long timeout
private final concurrentmap<preparederrorhandler  processor> errorhandlers   new concurrenthashmap<preparederrorhandler  processor>
private final boolean shareunitofwork
public multicastprocessor camelcontext camelcontext  collection<processor> processors
this camelcontext  processors  null
public multicastprocessor camelcontext camelcontext  collection<processor> processors  aggregationstrategy aggregationstrategy
this camelcontext  processors  aggregationstrategy  false  null  false  false  false  0  null  false
public multicastprocessor camelcontext camelcontext  collection<processor> processors  aggregationstrategy aggregationstrategy
boolean parallelprocessing  executorservice executorservice  boolean shutdownexecutorservice
boolean streaming  boolean stoponexception  long timeout  processor onprepare  boolean shareunitofwork
notnull camelcontext
this camelcontext   camelcontext
this processors   processors
this aggregationstrategy   aggregationstrategy
this executorservice   executorservice
this shutdownexecutorservice   shutdownexecutorservice
this streaming   streaming
this stoponexception   stoponexception
// must enable parallel if executor service is provided
this parallelprocessing   parallelprocessing    executorservice    null
this timeout   timeout
this onprepare   onprepare
this shareunitofwork   shareunitofwork
@override
public string tostring
return     getprocessors
public string gettracelabel
return
public camelcontext getcamelcontext
return camelcontext
public void process exchange exchange  throws exception
asyncprocessorhelper process this  exchange
public boolean process exchange exchange  asynccallback callback
final atomicexchange result   new atomicexchange
final iterable<processorexchangepair> pairs
// multicast uses fine grained error handling on the output processors
// so use try .. catch to cater for this
boolean exhaust   false
try
boolean sync   true
pairs   createprocessorexchangepairs exchange
// after we have created the processors we consider the exchange as exhausted if an unhandled
// exception was thrown, (used in the catch block)
// if the processors is working in streaming model, the exchange could not be processed at this point.
exhaust    isstreaming
if  isparallelprocessing
// ensure an executor is set when running in parallel
objecthelper notnull executorservice     this
doprocessparallel exchange  result  pairs  isstreaming    callback
else
sync   doprocesssequential exchange  result  pairs  callback
if   sync
// the remainder of the multicast will be completed async
// so we break out now, then the callback will be invoked which then continue routing from where we left here
return false
catch  throwable e
exchange setexception e
// and do the done work
dodone exchange  null  callback  true  exhaust
return true
// multicasting was processed successfully
// and do the done work
exchange subexchange   result get      null ? result get     null
dodone exchange  subexchange  callback  true  exhaust
return true
protected void doprocessparallel final exchange original  final atomicexchange result  final iterable<processorexchangepair> pairs
final boolean streaming  final asynccallback callback  throws exception
objecthelper notnull executorservice     this
objecthelper notnull aggregateexecutorservice     this
final completionservice<exchange> completion
if  streaming
// execute tasks in parallel+streaming and aggregate in the order they are finished (out of order sequence)
completion   new executorcompletionservice<exchange> executorservice
else
// execute tasks in parallel and aggregate in the order the tasks are submitted (in order sequence)
completion   new submitorderedcompletionservice<exchange> executorservice
final atomicinteger total   new atomicinteger 0
final iterator<processorexchangepair> it   pairs iterator
if  it hasnext
// when parallel then aggregate on the fly
final atomicboolean running   new atomicboolean true
final atomicboolean alltaskssubmitted   new atomicboolean
final countdownlatch aggregationontheflydone   new countdownlatch 1
final atomicexception executionexception   new atomicexception
// issue task to execute in separate thread so it can aggregate on-the-fly
// while we submit new tasks, and those tasks complete concurrently
// this allows us to optimize work and reduce memory consumption
final aggregateontheflytask aggregateontheflytask   new aggregateontheflytask result  original  total  completion  running
aggregationontheflydone  alltaskssubmitted  executionexception
final atomicboolean aggregationtasksubmitted   new atomicboolean
log trace
while  it hasnext
final processorexchangepair pair   it next
final exchange subexchange   pair getexchange
updatenewexchange subexchange  total intvalue    pairs  it
completion submit new callable<exchange>
public exchange call   throws exception
// only start the aggregation task when the task is being executed to avoid staring
// the aggregation task to early and pile up too many threads
if  aggregationtasksubmitted compareandset false  true
// but only submit the task once
aggregateexecutorservice submit aggregateontheflytask
if   running get
// do not start processing the task if we are not running
return subexchange
try
doprocessparallel pair
catch  throwable e
subexchange setexception e
// decide whether to continue with the multicast or not; similar logic to the pipeline
integer number   getexchangeindex subexchange
boolean continueprocessing   pipelinehelper continueprocessing subexchange      number  log
if  stoponexception     continueprocessing
// signal to stop running
running set false
// throw caused exception
if  subexchange getexception      null
// wrap in exception to explain where it failed
throw new camelexchangeexception     number  subexchange  subexchange getexception
log trace    subexchange
return subexchange
total incrementandget
// signal all tasks has been submitted
log trace    total get
alltaskssubmitted set true
// its to hard to do parallel async routing so we let the caller thread be synchronously
// and have it pickup the replies and do the aggregation (eg we use a latch to wait)
// wait for aggregation to be done
log debug    total get    original getexchangeid
aggregationontheflydone await
// did we fail for whatever reason, if so throw that caused exception
if  executionexception get      null
if  log isdebugenabled
log debug    executionexception get   getmessage
throw executionexception get
// no everything is okay so we are done
log debug    total
/**
* task to aggregate on-the-fly for completed tasks when using parallel processing.
* <p/>
* this ensures lower memory consumption as we do not need to keep all completed tasks in memory
* before we perform aggregation. instead this separate thread will run and aggregate when new
* completed tasks is done.
* <p/>
* the logic is fairly complex as this implementation has to keep track how far it got, and also
* signal back to the <i>main</t> thread when its done, so the <i>main</t> thread can continue
* processing when the entire splitting is done.
*/
private final class aggregateontheflytask implements runnable
private final atomicexchange result
private final exchange original
private final atomicinteger total
private final completionservice<exchange> completion
private final atomicboolean running
private final countdownlatch aggregationontheflydone
private final atomicboolean alltaskssubmitted
private final atomicexception executionexception
private aggregateontheflytask atomicexchange result  exchange original  atomicinteger total
completionservice<exchange> completion  atomicboolean running
countdownlatch aggregationontheflydone  atomicboolean alltaskssubmitted
atomicexception executionexception
this result   result
this original   original
this total   total
this completion   completion
this running   running
this aggregationontheflydone   aggregationontheflydone
this alltaskssubmitted   alltaskssubmitted
this executionexception   executionexception
public void run
log trace    original getexchangeid
try
aggregateonthefly
catch  throwable e
if  e instanceof exception
executionexception set  exception  e
else
executionexception set objecthelper wrapruntimecamelexception e
finally
// must signal we are done so the latch can open and let the other thread continue processing
log debug    original getexchangeid
log trace    original getexchangeid
aggregationontheflydone countdown
private void aggregateonthefly   throws interruptedexception  executionexception
boolean timedout   false
boolean stoppedonexception   false
final stopwatch watch   new stopwatch
int aggregated   0
boolean done   false
// not a for loop as on the fly may still run
while   done
// check if we have already aggregate everything
if  alltaskssubmitted get      aggregated >  total get
log debug    aggregated
break
future<exchange> future
if  timedout
// we are timed out but try to grab if some tasks has been completed
// poll will return null if no tasks is present
future   completion poll
log trace    aggregated  future
else if  timeout > 0
long left   timeout   watch taken
if  left < 0
left   0
log trace    aggregated  left
future   completion poll left  timeunit milliseconds
else
log trace    aggregated
// we must not block so poll every second
future   completion poll 1  timeunit seconds
if  future    null
// and continue loop which will recheck if we are done
continue
if  future    null    timedout
// we are timed out and no more tasks complete so break out
break
else if  future    null
// timeout occurred
aggregationstrategy strategy   getaggregationstrategy null
if  strategy instanceof timeoutawareaggregationstrategy
// notify the strategy we timed out
exchange oldexchange   result get
if  oldexchange    null
// if they all timed out the result may not have been set yet, so use the original exchange
oldexchange   original
timeoutawareaggregationstrategy  strategy  timeout oldexchange  aggregated  total intvalue    timeout
else
// log a warn we timed out since it will not be aggregated and the exchange will be lost
log warn    timeout  aggregated
log debug    timeout  aggregated
timedout   true
// mark that index as timed out, which allows us to try to retrieve
// any already completed tasks in the next loop
if  completion instanceof submitorderedcompletionservice
submitorderedcompletionservice<?>  completion  timeouttask
else
// there is a result to aggregate
exchange subexchange   future get
// decide whether to continue with the multicast or not; similar logic to the pipeline
integer number   getexchangeindex subexchange
boolean continueprocessing   pipelinehelper continueprocessing subexchange      number  log
if  stoponexception     continueprocessing
// we want to stop on exception and an exception or failure occurred
// this is similar to what the pipeline does, so we should do the same to not surprise end users
// so we should set the failed exchange as the result and break out
result set subexchange
stoppedonexception   true
break
// we got a result so aggregate it
aggregationstrategy strategy   getaggregationstrategy subexchange
doaggregate strategy  result  subexchange
aggregated
if  timedout    stoppedonexception
if  timedout
log debug    timeout
if  stoppedonexception
log debug
// cancel tasks as we timed out (its safe to cancel done tasks)
running set false
protected boolean doprocesssequential exchange original  atomicexchange result  iterable<processorexchangepair> pairs  asynccallback callback  throws exception
atomicinteger total   new atomicinteger
iterator<processorexchangepair> it   pairs iterator
while  it hasnext
processorexchangepair pair   it next
exchange subexchange   pair getexchange
updatenewexchange subexchange  total get    pairs  it
boolean sync   doprocesssequential original  result  pairs  it  pair  callback  total
if   sync
if  log istraceenabled
log trace    pair getexchange   getexchangeid
// the remainder of the multicast will be completed async
// so we break out now, then the callback will be invoked which then continue routing from where we left here
return false
if  log istraceenabled
log trace    pair getexchange   getexchangeid
// decide whether to continue with the multicast or not; similar logic to the pipeline
// remember to test for stop on exception and aggregate before copying back results
boolean continueprocessing   pipelinehelper continueprocessing subexchange      total get    log
if  stoponexception     continueprocessing
if  subexchange getexception      null
// wrap in exception to explain where it failed
throw new camelexchangeexception     total get    subexchange  subexchange getexception
else
// we want to stop on exception, and the exception was handled by the error handler
// this is similar to what the pipeline does, so we should do the same to not surprise end users
// so we should set the failed exchange as the result and be done
result set subexchange
return true
log trace    total  subexchange
doaggregate getaggregationstrategy subexchange   result  subexchange
total incrementandget
log debug    total
return true
private boolean doprocesssequential final exchange original  final atomicexchange result
final iterable<processorexchangepair> pairs  final iterator<processorexchangepair> it
final processorexchangepair pair  final asynccallback callback  final atomicinteger total
boolean sync   true
final exchange exchange   pair getexchange
processor processor   pair getprocessor
final producer producer   pair getproducer
tracedroutenodes traced   exchange getunitofwork      null ? exchange getunitofwork   gettracedroutenodes     null
// compute time taken if sending to another endpoint
final stopwatch watch   producer    null ? new stopwatch     null
try
// prepare tracing starting from a new block
if  traced    null
traced pushblock
if  producer    null
eventhelper notifyexchangesending exchange getcontext    exchange  producer getendpoint
// let the prepared process it, remember to begin the exchange pair
asyncprocessor async   asyncprocessorconverterhelper convert processor
pair begin
sync   asyncprocessorhelper process async  exchange  new asynccallback
public void done boolean donesync
// we are done with the exchange pair
pair done
// okay we are done, so notify the exchange was sent
if  producer    null
long timetaken   watch stop
endpoint endpoint   producer getendpoint
// emit event that the exchange was sent to the endpoint
eventhelper notifyexchangesent exchange getcontext    exchange  endpoint  timetaken
// we only have to handle async completion of the routing slip
if  donesync
return
// continue processing the multicast asynchronously
exchange subexchange   exchange
// decide whether to continue with the multicast or not; similar logic to the pipeline
// remember to test for stop on exception and aggregate before copying back results
boolean continueprocessing   pipelinehelper continueprocessing subexchange      total get    log
if  stoponexception     continueprocessing
if  subexchange getexception      null
// wrap in exception to explain where it failed
subexchange setexception new camelexchangeexception     total  subexchange  subexchange getexception
else
// we want to stop on exception, and the exception was handled by the error handler
// this is similar to what the pipeline does, so we should do the same to not surprise end users
// so we should set the failed exchange as the result and be done
result set subexchange
// and do the done work
dodone original  subexchange  callback  false  true
return
try
doaggregate getaggregationstrategy subexchange   result  subexchange
catch  throwable e
// wrap in exception to explain where it failed
subexchange setexception new camelexchangeexception     total  subexchange  e
// and do the done work
dodone original  subexchange  callback  false  true
return
total incrementandget
// maybe there are more processors to multicast
while  it hasnext
// prepare and run the next
processorexchangepair pair   it next
subexchange   pair getexchange
updatenewexchange subexchange  total get    pairs  it
boolean sync   doprocesssequential original  result  pairs  it  pair  callback  total
if   sync
log trace    original getexchangeid
return
// decide whether to continue with the multicast or not; similar logic to the pipeline
// remember to test for stop on exception and aggregate before copying back results
continueprocessing   pipelinehelper continueprocessing subexchange      total get    log
if  stoponexception     continueprocessing
if  subexchange getexception      null
// wrap in exception to explain where it failed
subexchange setexception new camelexchangeexception     total  subexchange  subexchange getexception
else
// we want to stop on exception, and the exception was handled by the error handler
// this is similar to what the pipeline does, so we should do the same to not surprise end users
// so we should set the failed exchange as the result and be done
result set subexchange
// and do the done work
dodone original  subexchange  callback  false  true
return
// must catch any exceptions from aggregation
try
doaggregate getaggregationstrategy subexchange   result  subexchange
catch  throwable e
// wrap in exception to explain where it failed
subexchange setexception new camelexchangeexception     total  subexchange  e
// and do the done work
dodone original  subexchange  callback  false  true
return
total incrementandget
// do the done work
subexchange   result get      null ? result get     null
dodone original  subexchange  callback  false  true
finally
// pop the block so by next round we have the same staring point and thus the tracing looks accurate
if  traced    null
traced popblock
return sync
private void doprocessparallel final processorexchangepair pair  throws exception
final exchange exchange   pair getexchange
processor processor   pair getprocessor
producer producer   pair getproducer
tracedroutenodes traced   exchange getunitofwork      null ? exchange getunitofwork   gettracedroutenodes     null
// compute time taken if sending to another endpoint
stopwatch watch   null
if  producer    null
watch   new stopwatch
try
// prepare tracing starting from a new block
if  traced    null
traced pushblock
if  producer    null
eventhelper notifyexchangesending exchange getcontext    exchange  producer getendpoint
// let the prepared process it, remember to begin the exchange pair
asyncprocessor async   asyncprocessorconverterhelper convert processor
pair begin
// we invoke it synchronously as parallel async routing is too hard
asyncprocessorhelper process async  exchange
finally
pair done
// pop the block so by next round we have the same staring point and thus the tracing looks accurate
if  traced    null
traced popblock
if  producer    null
long timetaken   watch stop
endpoint endpoint   producer getendpoint
// emit event that the exchange was sent to the endpoint
// this is okay to do here in the finally block, as the processing is not using the async routing engine
//( we invoke it synchronously as parallel async routing is too hard)
eventhelper notifyexchangesent exchange getcontext    exchange  endpoint  timetaken
/**
* common work which must be done when we are done multicasting.
* <p/>
* this logic applies for both running synchronous and asynchronous as there are multiple exist points
* when using the asynchronous routing engine. and therefore we want the logic in one method instead
* of being scattered.
*
* @param original    the original exchange
* @param subexchange the current sub exchange, can be <tt>null</tt> for the synchronous part
* @param callback    the callback
* @param donesync    the <tt>donesync</tt> parameter to call on callback
* @param exhaust     whether or not error handling is exhausted
*/
protected void dodone exchange original  exchange subexchange  asynccallback callback  boolean donesync  boolean exhaust
// cleanup any per exchange aggregation strategy
removeaggregationstrategyfromexchange original
if  original getexception      null    subexchange    null    subexchange getexception      null
// multicast uses error handling on its output processors and they have tried to redeliver
// so we shall signal back to the other error handlers that we are exhausted and they should not
// also try to redeliver as we will then do that twice
original setproperty exchange redelivery_exhausted  exhaust
if  subexchange    null
// and copy the current result to original so it will contain this result of this eip
exchangehelper copyresults original  subexchange
callback done donesync
/**
* aggregate the {@link exchange} with the current result
*
* @param strategy the aggregation strategy to use
* @param result   the current result
* @param exchange the exchange to be added to the result
*/
protected synchronized void doaggregate aggregationstrategy strategy  atomicexchange result  exchange exchange
if  strategy    null
// prepare the exchanges for aggregation
exchange oldexchange   result get
exchangehelper prepareaggregation oldexchange  exchange
result set strategy aggregate oldexchange  exchange
protected void updatenewexchange exchange exchange  int index  iterable<processorexchangepair> allpairs
iterator<processorexchangepair> it
exchange setproperty exchange multicast_index  index
if  it hasnext
exchange setproperty exchange multicast_complete  boolean false
else
exchange setproperty exchange multicast_complete  boolean true
protected integer getexchangeindex exchange exchange
return exchange getproperty exchange multicast_index  integer class
protected iterable<processorexchangepair> createprocessorexchangepairs exchange exchange  throws exception
list<processorexchangepair> result   new arraylist<processorexchangepair> processors size
int index   0
for  processor processor   processors
// copy exchange, and do not share the unit of work
exchange copy   exchangehelper createcorrelatedcopy exchange  false
// if we share unit of work, we need to prepare the child exchange
if  isshareunitofwork
preparesharedunitofwork copy  exchange
// and add the pair
routecontext routecontext   exchange getunitofwork      null ? exchange getunitofwork   getroutecontext     null
result add createprocessorexchangepair index    processor  copy  routecontext
if  exchange getexception      null
// force any exceptions occurred during creation of exchange paris to be thrown
// before returning the answer;
throw exchange getexception
return result
/**
* creates the {@link processorexchangepair} which holds the processor and exchange to be send out.
* <p/>
* you <b>must</b> use this method to create the instances of {@link processorexchangepair} as they
* need to be specially prepared before use.
*
* @param index        the index
* @param processor    the processor
* @param exchange     the exchange
* @param routecontext the route context
* @return prepared for use
*/
protected processorexchangepair createprocessorexchangepair int index  processor processor  exchange exchange
routecontext routecontext
processor prepared   processor
// set property which endpoint we send to
settoendpoint exchange  prepared
// rework error handling to support fine grained error handling
prepared   createerrorhandler routecontext  exchange  prepared
// invoke on prepare on the exchange if specified
if  onprepare    null
try
onprepare process exchange
catch  exception e
exchange setexception e
return new defaultprocessorexchangepair index  processor  prepared  exchange
protected processor createerrorhandler routecontext routecontext  exchange exchange  processor processor
processor answer
if  routecontext    null
// wrap the producer in error handler so we have fine grained error handling on
// the output side instead of the input side
// this is needed to support redelivery on that output alone and not doing redelivery
// for the entire multicast block again which will start from scratch again
// create key for cache
final preparederrorhandler key   new preparederrorhandler routecontext  processor
// lookup cached first to reuse and preserve memory
answer   errorhandlers get key
if  answer    null
log trace    processor
return answer
log trace    processor
errorhandlerfactory builder   routecontext getroute   geterrorhandlerbuilder
// create error handler (create error handler directly to keep it light weight,
// instead of using processordefinition.wrapinerrorhandler)
try
processor   builder createerrorhandler routecontext  processor
// and wrap in unit of work processor so the copy exchange also can run under uow
answer   createunitofworkprocessor routecontext  processor  exchange
// must start the error handler
servicehelper startservices answer
catch  exception e
throw objecthelper wrapruntimecamelexception e
// add to cache
errorhandlers putifabsent key  answer
else
// and wrap in unit of work processor so the copy exchange also can run under uow
answer   createunitofworkprocessor routecontext  processor  exchange
return answer
/**
* strategy to create the {@link unitofworkprocessor} to be used for the sub route
*
* @param routecontext the route context
* @param processor    the processor wrapped in this unit of work processor
* @param exchange     the exchange
* @return the unit of work processor
*/
protected unitofworkprocessor createunitofworkprocessor routecontext routecontext  processor processor  exchange exchange
unitofwork parent   exchange getproperty exchange parent_unit_of_work  unitofwork class
if  parent    null
return new childunitofworkprocessor parent  routecontext  processor
else
return new unitofworkprocessor routecontext  processor
/**
* prepares the exchange for participating in a shared unit of work
* <p/>
* this ensures a child exchange can access its parent {@link unitofwork} when it participate
* in a shared unit of work.
*
* @param childexchange  the child exchange
* @param parentexchange the parent exchange
*/
protected void preparesharedunitofwork exchange childexchange  exchange parentexchange
childexchange setproperty exchange parent_unit_of_work  parentexchange getunitofwork
protected void dostart   throws exception
if  isparallelprocessing      executorservice    null
throw new illegalargumentexception
if  timeout > 0     isparallelprocessing
throw new illegalargumentexception
if  isparallelprocessing      aggregateexecutorservice    null
// use unbounded thread pool so we ensure the aggregate on-the-fly task always will have assigned a thread
// and run the tasks when the task is submitted. if not then the aggregate task may not be able to run
// and signal completion during processing, which would lead to what would appear as a dead-lock or a slow processing
string name   getclass   getsimplename
aggregateexecutorservice   createaggregateexecutorservice name
servicehelper startservices processors
/**
* strategy to create the thread pool for the aggregator background task which waits for and aggregates
* completed tasks when running in parallel mode.
*
* @param name  the suggested name for the background thread
* @return the thread pool
*/
protected synchronized executorservice createaggregateexecutorservice string name
// use a cached thread pool so we each on-the-fly task has a dedicated thread to process completions as they come in
return camelcontext getexecutorservicemanager   newcachedthreadpool this  name
@override
protected void dostop   throws exception
servicehelper stopservices processors  errorhandlers
@override
protected void doshutdown   throws exception
servicehelper stopandshutdownservices processors  errorhandlers
// only clear error handlers when shutting down
errorhandlers clear
if  shutdownexecutorservice    executorservice    null
getcamelcontext   getexecutorservicemanager   shutdownnow executorservice
protected static void settoendpoint exchange exchange  processor processor
if  processor instanceof producer
producer producer    producer  processor
exchange setproperty exchange to_endpoint  producer getendpoint   getendpointuri
protected aggregationstrategy getaggregationstrategy exchange exchange
aggregationstrategy answer   null
// prefer to use per exchange aggregation strategy over a global strategy
if  exchange    null
map<?  ?> property   exchange getproperty exchange aggregation_strategy  map class
map<object  aggregationstrategy> map   castutils cast property
if  map    null
answer   map get this
if  answer    null
// fallback to global strategy
answer   getaggregationstrategy
return answer
/**
* sets the given {@link org.apache.camel.processor.aggregate.aggregationstrategy} on the {@link exchange}.
*
* @param exchange            the exchange
* @param aggregationstrategy the strategy
*/
protected void setaggregationstrategyonexchange exchange exchange  aggregationstrategy aggregationstrategy
map<?  ?> property   exchange getproperty exchange aggregation_strategy  map class
map<object  aggregationstrategy> map   castutils cast property
if  map    null
map   new hashmap<object  aggregationstrategy>
// store the strategy using this processor as the key
// (so we can store multiple strategies on the same exchange)
map put this  aggregationstrategy
exchange setproperty exchange aggregation_strategy  map
/**
* removes the associated {@link org.apache.camel.processor.aggregate.aggregationstrategy} from the {@link exchange}
* which must be done after use.
*
* @param exchange the current exchange
*/
protected void removeaggregationstrategyfromexchange exchange exchange
map<?  ?> property   exchange getproperty exchange aggregation_strategy  map class
map<object  aggregationstrategy> map   castutils cast property
if  map    null
return
// remove the strategy using this processor as the key
map remove this
/**
* is the multicast processor working in streaming mode?
* <p/>
* in streaming mode:
* <ul>
* <li>we use {@link iterable} to ensure we can send messages as soon as the data becomes available</li>
* <li>for parallel processing, we start aggregating responses as they get send back to the processor;
* this means the {@link org.apache.camel.processor.aggregate.aggregationstrategy} has to take care of handling out-of-order arrival of exchanges</li>
* </ul>
*/
public boolean isstreaming
return streaming
/**
* should the multicast processor stop processing further exchanges in case of an exception occurred?
*/
public boolean isstoponexception
return stoponexception
/**
* returns the producers to multicast to
*/
public collection<processor> getprocessors
return processors
/**
* an optional timeout in millis when using parallel processing
*/
public long gettimeout
return timeout
/**
* use {@link #getaggregationstrategy(org.apache.camel.exchange)} instead.
*/
public aggregationstrategy getaggregationstrategy
return aggregationstrategy
public boolean isparallelprocessing
return parallelprocessing
public boolean isshareunitofwork
return shareunitofwork
public list<processor> next
if   hasnext
return null
return new arraylist<processor> processors
public boolean hasnext
return processors    null     processors isempty