package org apache lucene index
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io ioexception
import java util arrays
import org apache lucene analysis tokenattributes termattribute
import org apache lucene document fieldable
import org apache lucene util unicodeutil
final class termshashperfield extends inverteddocconsumerperfield
final termshashconsumerperfield consumer
final termshashperfield nextperfield
final termshashperthread perthread
final documentswriter docstate docstate
final fieldinvertstate fieldstate
termattribute termatt
// copied from our perthread
final charblockpool charpool
final intblockpool intpool
final byteblockpool bytepool
final int streamcount
final int numpostingint
final fieldinfo fieldinfo
boolean postingscompacted
int numpostings
private int postingshashsize   4
private int postingshashhalfsize   postingshashsize 2
private int postingshashmask   postingshashsize 1
private rawpostinglist postingshash   new rawpostinglist
private rawpostinglist p
public termshashperfield docinverterperfield docinverterperfield  final termshashperthread perthread  final termshashperthread nextperthread  final fieldinfo fieldinfo
this perthread   perthread
intpool   perthread intpool
charpool   perthread charpool
bytepool   perthread bytepool
docstate   perthread docstate
fieldstate   docinverterperfield fieldstate
this consumer   perthread consumer addfield this  fieldinfo
streamcount   consumer getstreamcount
numpostingint   2 streamcount
this fieldinfo   fieldinfo
if  nextperthread    null
nextperfield    termshashperfield  nextperthread addfield docinverterperfield  fieldinfo
else
nextperfield   null
void shrinkhash int targetsize
assert postingscompacted    numpostings    0
// cannot use arrayutil.shrink because we require power
// of 2:
int newsize   postingshash length
while newsize >  8    newsize 4 > targetsize
newsize    2
if  newsize    postingshash length
postingshash   new rawpostinglist
postingshashsize   newsize
postingshashhalfsize   newsize 2
postingshashmask   newsize 1
public void reset
if   postingscompacted
compactpostings
assert numpostings <  postingshash length
if  numpostings > 0
perthread termshash recyclepostings postingshash  numpostings
arrays fill postingshash  0  numpostings  null
numpostings   0
postingscompacted   false
if  nextperfield    null
nextperfield reset
synchronized public void abort
reset
if  nextperfield    null
nextperfield abort
public void initreader byteslicereader reader  rawpostinglist p  int stream
assert stream < streamcount
final int ints   intpool buffers
final int upto   p intstart   documentswriter int_block_mask
reader init bytepool
p bytestart stream byteblockpool first_level_size
ints
private synchronized void compactpostings
int upto   0
for int i 0 i<postingshashsize i
if  postingshash    null
if  upto < i
postingshash   postingshash
postingshash   null
upto
assert upto    numpostings
postingscompacted   true
/** collapse the hash table & sort in-place. */
public rawpostinglist sortpostings
compactpostings
quicksort postingshash  0  numpostings 1
return postingshash
void quicksort rawpostinglist postings  int lo  int hi
if  lo >  hi
return
else if  hi    1 lo
if  comparepostings postings  postings  > 0
final rawpostinglist tmp   postings
postings   postings
postings   tmp
return
int mid    lo   hi  >>> 1
if  comparepostings postings  postings  > 0
rawpostinglist tmp   postings
postings   postings
postings   tmp
if  comparepostings postings  postings  > 0
rawpostinglist tmp   postings
postings   postings
postings   tmp
if  comparepostings postings  postings  > 0
rawpostinglist tmp2   postings
postings   postings
postings   tmp2
int left   lo   1
int right   hi   1
if  left >  right
return
rawpostinglist partition   postings
for
while  comparepostings postings  partition  > 0
right
while  left < right    comparepostings postings  partition  <  0
left
if  left < right
rawpostinglist tmp   postings
postings   postings
postings   tmp
right
else
break
quicksort postings  lo  left
quicksort postings  left   1  hi
/** compares term text for two posting instance and
*  returns -1 if p1 < p2; 1 if p1 > p2; else 0. */
int comparepostings rawpostinglist p1  rawpostinglist p2
if  p1    p2
return 0
final char text1   charpool buffers
int pos1   p1 textstart   documentswriter char_block_mask
final char text2   charpool buffers
int pos2   p2 textstart   documentswriter char_block_mask
assert text1    text2    pos1    pos2
while true
final char c1   text1
final char c2   text2
if  c1    c2
if  0xffff    c2
return 1
else if  0xffff    c1
return  1
else
return c1 c2
else
// this method should never compare equal postings
// unless p1==p2
assert c1    0xffff
/** test whether the text for current rawpostinglist p equals
*  current tokentext. */
private boolean postingequals final char tokentext  final int tokentextlen
final char text   perthread charpool buffers
assert text    null
int pos   p textstart   documentswriter char_block_mask
int tokenpos   0
for  tokenpos<tokentextlen pos   tokenpos
if  tokentext    text
return false
return 0xffff    text
private boolean docall
private boolean donextcall
void start fieldable f
termatt    termattribute  fieldstate attributesource addattribute termattribute class
consumer start f
if  nextperfield    null
nextperfield start f
boolean start fieldable fields  int count  throws ioexception
docall   consumer start fields  count
if  nextperfield    null
donextcall   nextperfield start fields  count
return docall    donextcall
// secondary entry point (for 2nd & subsequent termshash),
// because token text has already been "interned" into
// textstart, so we hash by textstart
public void add int textstart  throws ioexception
int code   textstart
int hashpos   code   postingshashmask
assert  postingscompacted
// locate rawpostinglist in hash
p   postingshash
if  p    null    p textstart    textstart
// conflict: keep searching different locations in
// the hash table.
final int inc     code>>8  code  1
do
code    inc
hashpos   code   postingshashmask
p   postingshash
while  p    null    p textstart    textstart
if  p    null
// first time we are seeing this token since we last
// flushed the hash.
// refill?
if  0    perthread freepostingscount
perthread morepostings
// pull next free rawpostinglist from free list
p   perthread freepostings
assert p    null
p textstart   textstart
assert postingshash    null
postingshash   p
numpostings
if  numpostings    postingshashhalfsize
rehashpostings 2 postingshashsize
// init stream slices
if  numpostingint   intpool intupto > documentswriter int_block_size
intpool nextbuffer
if  documentswriter byte_block_size   bytepool byteupto < numpostingint byteblockpool first_level_size
bytepool nextbuffer
intuptos   intpool buffer
intuptostart   intpool intupto
intpool intupto    streamcount
p intstart   intuptostart   intpool intoffset
for int i 0 i<streamcount i
final int upto   bytepool newslice byteblockpool first_level_size
intuptos   upto   bytepool byteoffset
p bytestart   intuptos
consumer newterm p
else
intuptos   intpool buffers
intuptostart   p intstart   documentswriter int_block_mask
consumer addterm p
// primary entry point (for first termshash)
void add   throws ioexception
assert  postingscompacted
// we are first in the chain so we must "intern" the
// term text into textstart address
// get the text of this term.
final char tokentext   termatt termbuffer
final int tokentextlen   termatt termlength
// compute hashcode & replace any invalid utf16 sequences
int downto   tokentextlen
int code   0
while  downto > 0
char ch   tokentext
if  ch >  unicodeutil uni_sur_low_start    ch <  unicodeutil uni_sur_low_end
if  0    downto
// unpaired
ch   tokentext   unicodeutil uni_replacement_char
else
final char ch2   tokentext
if  ch2 >  unicodeutil uni_sur_high_start    ch2 <  unicodeutil uni_sur_high_end
// ok: high followed by low.  this is a valid
// surrogate pair.
code     code 31    ch  31 ch2
downto
continue
else
// unpaired
ch   tokentext   unicodeutil uni_replacement_char
else if  ch >  unicodeutil uni_sur_high_start    ch <  unicodeutil uni_sur_high_end
// unpaired
ch   tokentext   unicodeutil uni_replacement_char
code    code 31    ch
int hashpos   code   postingshashmask
// locate rawpostinglist in hash
p   postingshash
if  p    null     postingequals tokentext  tokentextlen
// conflict: keep searching different locations in
// the hash table.
final int inc     code>>8  code  1
do
code    inc
hashpos   code   postingshashmask
p   postingshash
while  p    null     postingequals tokentext  tokentextlen
if  p    null
// first time we are seeing this token since we last
// flushed the hash.
final int textlen1   1 tokentextlen
if  textlen1   charpool charupto > documentswriter char_block_size
if  textlen1 > documentswriter char_block_size
// just skip this term, to remain as robust as
// possible during indexing.  a tokenfilter
// can be inserted into the analyzer chain if
// other behavior is wanted (pruning the term
// to a prefix, throwing an exception, etc).
if  docstate maxtermprefix    null
docstate maxtermprefix   new string tokentext  0  30
consumer skippinglongterm
return
charpool nextbuffer
// refill?
if  0    perthread freepostingscount
perthread morepostings
// pull next free rawpostinglist from free list
p   perthread freepostings
assert p    null
final char text   charpool buffer
final int textupto   charpool charupto
p textstart   textupto   charpool charoffset
charpool charupto    textlen1
system arraycopy tokentext  0  text  textupto  tokentextlen
text   0xffff
assert postingshash    null
postingshash   p
numpostings
if  numpostings    postingshashhalfsize
rehashpostings 2 postingshashsize
// init stream slices
if  numpostingint   intpool intupto > documentswriter int_block_size
intpool nextbuffer
if  documentswriter byte_block_size   bytepool byteupto < numpostingint byteblockpool first_level_size
bytepool nextbuffer
intuptos   intpool buffer
intuptostart   intpool intupto
intpool intupto    streamcount
p intstart   intuptostart   intpool intoffset
for int i 0 i<streamcount i
final int upto   bytepool newslice byteblockpool first_level_size
intuptos   upto   bytepool byteoffset
p bytestart   intuptos
consumer newterm p
else
intuptos   intpool buffers
intuptostart   p intstart   documentswriter int_block_mask
consumer addterm p
if  donextcall
nextperfield add p textstart
int intuptos
int intuptostart
void writebyte int stream  byte b
int upto   intuptos
byte bytes   bytepool buffers
assert bytes    null
int offset   upto   documentswriter byte_block_mask
if  bytes    0
// end of slice; allocate a new one
offset   bytepool allocslice bytes  offset
bytes   bytepool buffer
intuptos   offset   bytepool byteoffset
bytes   b
intuptos
public void writebytes int stream  byte b  int offset  int len
// todo: optimize
final int end   offset   len
for int i offset i<end i
writebyte stream  b
void writevint int stream  int i
assert stream < streamcount
while   i   ~0x7f     0
writebyte stream   byte   i   0x7f    0x80
i >>>  7
writebyte stream   byte  i
void finish   throws ioexception
consumer finish
if  nextperfield    null
nextperfield finish
/** called when postings hash is too small (> 50%
*  occupied) or too large (< 20% occupied). */
void rehashpostings final int newsize
final int newmask   newsize 1
rawpostinglist newhash   new rawpostinglist
for int i 0 i<postingshashsize i
rawpostinglist p0   postingshash
if  p0    null
int code
if  perthread primary
final int start   p0 textstart   documentswriter char_block_mask
final char text   charpool buffers
int pos   start
while text    0xffff
pos
code   0
while  pos > start
code    code 31    text
else
code   p0 textstart
int hashpos   code   newmask
assert hashpos >  0
if  newhash    null
final int inc     code>>8  code  1
do
code    inc
hashpos   code   newmask
while  newhash    null
newhash   p0
postingshashmask   newmask
postingshash   newhash
postingshashsize   newsize
postingshashhalfsize   newsize >> 1