package org apache lucene analysis cz
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import org apache lucene analysis analyzer
import org apache lucene analysis lowercasefilter
import org apache lucene analysis stopfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenizer
import org apache lucene analysis wordlistloader
import org apache lucene analysis standard standardfilter
import org apache lucene analysis standard standardtokenizer
import java io
import java util hashset
import java util set
/**
* {@link analyzer} for czech language.
* <p>
* supports an external list of stopwords (words that
* will not be indexed at all).
* a default set of stopwords is used unless an alternative list is specified.
* </p>
*/
public final class czechanalyzer extends analyzer
/**
* list of typical stopwords.
*/
public final static string czech_stop_words
/**
* contains the stopwords used with the {@link stopfilter}.
*/
private set stoptable
/**
* builds an analyzer with the default stop words ({@link #czech_stop_words}).
*/
public czechanalyzer
stoptable   stopfilter makestopset  czech_stop_words
/**
* builds an analyzer with the given stop words.
*/
public czechanalyzer  string stopwords
stoptable   stopfilter makestopset  stopwords
public czechanalyzer  hashset stopwords
stoptable   stopwords
/**
* builds an analyzer with the given stop words.
*/
public czechanalyzer  file stopwords   throws ioexception
stoptable   wordlistloader getwordset  stopwords
/**
* loads stopwords hash from resource stream (file, database...).
* @param   wordfile    file containing the wordlist
* @param   encoding    encoding used (win-1250, iso-8859-2, ...), null for default system encoding
*/
public void loadstopwords  inputstream wordfile  string encoding
setprevioustokenstream null      force a new stopfilter to be created
if   wordfile    null
stoptable   new hashset
return
try
// clear any previous table (if present)
stoptable   new hashset
inputstreamreader isr
if  encoding    null
isr   new inputstreamreader wordfile
else
isr   new inputstreamreader wordfile  encoding
linenumberreader lnr   new linenumberreader isr
string word
while     word   lnr readline        null
stoptable add word
catch   ioexception e
// clear any previous table (if present)
// todo: throw ioexception
stoptable   new hashset
/**
* creates a {@link tokenstream} which tokenizes all the text in the provided {@link reader}.
*
* @return  a {@link tokenstream} built from a {@link standardtokenizer} filtered with
* 			{@link standardfilter}, {@link lowercasefilter}, and {@link stopfilter}
*/
public final tokenstream tokenstream  string fieldname  reader reader
tokenstream result   new standardtokenizer  reader
result   new standardfilter  result
result   new lowercasefilter  result
result   new stopfilter  result  stoptable
return result
private class savedstreams
tokenizer source
tokenstream result
/**
* returns a (possibly reused) {@link tokenstream} which tokenizes all the text in
* the provided {@link reader}.
*
* @return  a {@link tokenstream} built from a {@link standardtokenizer} filtered with
*          {@link standardfilter}, {@link lowercasefilter}, and {@link stopfilter}
*/
public tokenstream reusabletokenstream string fieldname  reader reader
throws ioexception
savedstreams streams    savedstreams  getprevioustokenstream
if  streams    null
streams   new savedstreams
streams source   new standardtokenizer reader
streams result   new standardfilter streams source
streams result   new lowercasefilter streams result
streams result   new stopfilter streams result  stoptable
setprevioustokenstream streams
else
streams source reset reader
return streams result