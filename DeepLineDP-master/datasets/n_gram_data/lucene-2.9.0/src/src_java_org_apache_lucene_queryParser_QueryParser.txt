/* generated by:javacc: do not edit this line. queryparser.java */
package org apache lucene queryparser
import java io ioexception
import java io stringreader
import java text collator
import java text dateformat
import java util arraylist
import java util calendar
import java util date
import java util hashmap
import java util list
import java util locale
import java util map
import java util vector
import org apache lucene analysis analyzer
import org apache lucene analysis cachingtokenfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenattributes positionincrementattribute
import org apache lucene analysis tokenattributes termattribute
import org apache lucene document datefield
import org apache lucene document datetools
import org apache lucene index term
import org apache lucene search booleanclause
import org apache lucene search booleanquery
import org apache lucene search fuzzyquery
import org apache lucene search multitermquery
import org apache lucene search matchalldocsquery
import org apache lucene search multiphrasequery
import org apache lucene search phrasequery
import org apache lucene search prefixquery
import org apache lucene search query
import org apache lucene search termrangequery
import org apache lucene search termquery
import org apache lucene search wildcardquery
import org apache lucene util parameter
/**
* this class is generated by javacc.  the most important method is
* {@link #parse(string)}.
*
* the syntax for query strings is as follows:
* a query is a series of clauses.
* a clause may be prefixed by:
* <ul>
* <li> a plus (<code>+</code>) or a minus (<code>-</code>) sign, indicating
* that the clause is required or prohibited respectively; or
* <li> a term followed by a colon, indicating the field to be searched.
* this enables one to construct queries which search multiple fields.
* </ul>
*
* a clause may be either:
* <ul>
* <li> a term, indicating all the documents that contain this term; or
* <li> a nested query, enclosed in parentheses.  note that this may be used
* with a <code>+</code>/<code>-</code> prefix to require any of a set of
* terms.
* </ul>
*
* thus, in bnf, the query grammar is:
* <pre>
*   query  ::= ( clause )*
*   clause ::= ["+", "-"] [&lt;term&gt; ":"] ( &lt;term&gt; | "(" query ")" )
* </pre>
*
* <p>
* examples of appropriately formatted queries can be found in the <a
* href="../../../../../../queryparsersyntax.html">query syntax
* documentation</a>.
* </p>
*
* <p>
* in {@link termrangequery}s, queryparser tries to detect date values, e.g.
* <tt>date:[6/1/2005 to 6/4/2005]</tt> produces a range query that searches
* for "date" fields between 2005-06-01 and 2005-06-04. note that the format
* of the accepted input depends on {@link #setlocale(locale) the locale}.
* by default a date is converted into a search term using the deprecated
* {@link datefield} for compatibility reasons.
* to use the new {@link datetools} to convert dates, a
* {@link org.apache.lucene.document.datetools.resolution} has to be set.
* </p>
* <p>
* the date resolution that shall be used for rangequeries can be set
* using {@link #setdateresolution(datetools.resolution)}
* or {@link #setdateresolution(string, datetools.resolution)}. the former
* sets the default date resolution for all fields, whereas the latter can
* be used to set field specific date resolutions. field specific date
* resolutions take, if set, precedence over the default date resolution.
* </p>
* <p>
* if you use neither {@link datefield} nor {@link datetools} in your
* index, you can create your own
* query parser that inherits queryparser and overwrites
* {@link #getrangequery(string, string, string, boolean)} to
* use a different method for date conversion.
* </p>
*
* <p>note that queryparser is <em>not</em> thread-safe.</p>
*
* <p><b>note</b>: there is a new queryparser in contrib, which matches
* the same syntax as this class, but is more modular,
* enabling substantial customization to how a query is created.
*/
public class queryparser implements queryparserconstants
private static final int conj_none     0
private static final int conj_and      1
private static final int conj_or       2
private static final int mod_none      0
private static final int mod_not       10
private static final int mod_req       11
// make it possible to call setdefaultoperator() without accessing
// the nested class:
/** alternative form of queryparser.operator.and */
public static final operator and_operator   operator and
/** alternative form of queryparser.operator.or */
public static final operator or_operator   operator or
/** the actual operator that parser uses to combine query terms */
private operator operator   or_operator
boolean lowercaseexpandedterms   true
multitermquery rewritemethod multitermrewritemethod   multitermquery constant_score_auto_rewrite_default
boolean allowleadingwildcard   false
boolean enablepositionincrements   false
analyzer analyzer
string field
int phraseslop   0
float fuzzyminsim   fuzzyquery defaultminsimilarity
int fuzzyprefixlength   fuzzyquery defaultprefixlength
locale locale   locale getdefault
// the default date resolution
datetools resolution dateresolution   null
// maps field names to date resolutions
map fieldtodateresolution   null
// the collator to use when determining range inclusion,
// for use when constructing rangequerys.
collator rangecollator   null
/** the default operator for parsing queries.
* use {@link queryparser#setdefaultoperator} to change it.
*/
static public final class operator extends parameter
private operator string name
super name
static public final operator or   new operator
static public final operator and   new operator
/** constructs a query parser.
*  @param f  the default field for query terms.
*  @param a   used to find terms in the query text.
*/
public queryparser string f  analyzer a
this new fastcharstream new stringreader
analyzer   a
field   f
/** parses a query string, returning a {@link org.apache.lucene.search.query}.
*  @param query  the query string to be parsed.
*  @throws parseexception if the parsing fails
*/
public query parse string query  throws parseexception
reinit new fastcharstream new stringreader query
try
// toplevelquery is a query followed by the end-of-input (eof)
query res   toplevelquery field
return res  null ? res   newbooleanquery false
catch  parseexception tme
// rethrow to include the original query:
parseexception e   new parseexception    query      tme getmessage
e initcause tme
throw e
catch  tokenmgrerror tme
parseexception e   new parseexception    query      tme getmessage
e initcause tme
throw e
catch  booleanquery toomanyclauses tmc
parseexception e   new parseexception    query
e initcause tmc
throw e
/**
* @return returns the analyzer.
*/
public analyzer getanalyzer
return analyzer
/**
* @return returns the field.
*/
public string getfield
return field
/**
* get the minimal similarity for fuzzy queries.
*/
public float getfuzzyminsim
return fuzzyminsim
/**
* set the minimum similarity for fuzzy queries.
* default is 0.5f.
*/
public void setfuzzyminsim float fuzzyminsim
this fuzzyminsim   fuzzyminsim
/**
* get the prefix length for fuzzy queries.
* @return returns the fuzzyprefixlength.
*/
public int getfuzzyprefixlength
return fuzzyprefixlength
/**
* set the prefix length for fuzzy queries. default is 0.
* @param fuzzyprefixlength the fuzzyprefixlength to set.
*/
public void setfuzzyprefixlength int fuzzyprefixlength
this fuzzyprefixlength   fuzzyprefixlength
/**
* sets the default slop for phrases.  if zero, then exact phrase matches
* are required.  default value is zero.
*/
public void setphraseslop int phraseslop
this phraseslop   phraseslop
/**
* gets the default slop for phrases.
*/
public int getphraseslop
return phraseslop
/**
* set to <code>true</code> to allow leading wildcard characters.
* <p>
* when set, <code>*</code> or <code>?</code> are allowed as
* the first character of a prefixquery and wildcardquery.
* note that this can produce very slow
* queries on big indexes.
* <p>
* default: false.
*/
public void setallowleadingwildcard boolean allowleadingwildcard
this allowleadingwildcard   allowleadingwildcard
/**
* @see #setallowleadingwildcard(boolean)
*/
public boolean getallowleadingwildcard
return allowleadingwildcard
/**
* set to <code>true</code> to enable position increments in result query.
* <p>
* when set, result phrase and multi-phrase queries will
* be aware of position increments.
* useful when e.g. a stopfilter increases the position increment of
* the token that follows an omitted token.
* <p>
* default: false.
*/
public void setenablepositionincrements boolean enable
this enablepositionincrements   enable
/**
* @see #setenablepositionincrements(boolean)
*/
public boolean getenablepositionincrements
return enablepositionincrements
/**
* sets the boolean operator of the queryparser.
* in default mode (<code>or_operator</code>) terms without any modifiers
* are considered optional: for example <code>capital of hungary</code> is equal to
* <code>capital or of or hungary</code>.<br/>
* in <code>and_operator</code> mode terms are considered to be in conjunction: the
* above mentioned query is parsed as <code>capital and of and hungary</code>
*/
public void setdefaultoperator operator op
this operator   op
/**
* gets implicit operator setting, which will be either and_operator
* or or_operator.
*/
public operator getdefaultoperator
return operator
/**
* whether terms of wildcard, prefix, fuzzy and range queries are to be automatically
* lower-cased or not.  default is <code>true</code>.
*/
public void setlowercaseexpandedterms boolean lowercaseexpandedterms
this lowercaseexpandedterms   lowercaseexpandedterms
/**
* @see #setlowercaseexpandedterms(boolean)
*/
public boolean getlowercaseexpandedterms
return lowercaseexpandedterms
/**
* @deprecated please use {@link #setmultitermrewritemethod} instead.
*/
public void setuseoldrangequery boolean useoldrangequery
if  useoldrangequery
setmultitermrewritemethod multitermquery scoring_boolean_query_rewrite
else
setmultitermrewritemethod multitermquery constant_score_auto_rewrite_default
/**
* @deprecated please use {@link #getmultitermrewritemethod} instead.
*/
public boolean getuseoldrangequery
if  getmultitermrewritemethod      multitermquery scoring_boolean_query_rewrite
return true
else
return false
/**
* by default queryparser uses {@link multitermquery#constant_score_auto_rewrite_default}
* when creating a prefixquery, wildcardquery or rangequery. this implementation is generally preferable because it
* a) runs faster b) does not have the scarcity of terms unduly influence score
* c) avoids any "toomanybooleanclauses" exception.
* however, if your application really needs to use the
* old-fashioned booleanquery expansion rewriting and the above
* points are not relevant then use this to change
* the rewrite method.
*/
public void setmultitermrewritemethod multitermquery rewritemethod method
multitermrewritemethod   method
/**
* @see #setmultitermrewritemethod
*/
public multitermquery rewritemethod getmultitermrewritemethod
return multitermrewritemethod
/**
* set locale used by date range parsing.
*/
public void setlocale locale locale
this locale   locale
/**
* returns current locale, allowing access by subclasses.
*/
public locale getlocale
return locale
/**
* sets the default date resolution used by rangequeries for fields for which no
* specific date resolutions has been set. field specific resolutions can be set
* with {@link #setdateresolution(string, datetools.resolution)}.
*
* @param dateresolution the default date resolution to set
*/
public void setdateresolution datetools resolution dateresolution
this dateresolution   dateresolution
/**
* sets the date resolution used by rangequeries for a specific field.
*
* @param fieldname field for which the date resolution is to be set
* @param dateresolution date resolution to set
*/
public void setdateresolution string fieldname  datetools resolution dateresolution
if  fieldname    null
throw new illegalargumentexception
if  fieldtodateresolution    null
// lazily initialize hashmap
fieldtodateresolution   new hashmap
fieldtodateresolution put fieldname  dateresolution
/**
* returns the date resolution that is used by rangequeries for the given field.
* returns null, if no default or field specific date resolution has been set
* for the given field.
*
*/
public datetools resolution getdateresolution string fieldname
if  fieldname    null
throw new illegalargumentexception
if  fieldtodateresolution    null
// no field specific date resolutions set; return default date resolution instead
return this dateresolution
datetools resolution resolution    datetools resolution  fieldtodateresolution get fieldname
if  resolution    null
// no date resolutions set for the given field; return default date resolution instead
resolution   this dateresolution
return resolution
/**
* sets the collator used to determine index term inclusion in ranges
* for rangequerys.
* <p/>
* <strong>warning:</strong> setting the rangecollator to a non-null
* collator using this method will cause every single index term in the
* field referenced by lowerterm and/or upperterm to be examined.
* depending on the number of index terms in this field, the operation could
* be very slow.
*
*  @param rc  the collator to use when constructing rangequerys
*/
public void setrangecollator collator rc
rangecollator   rc
/**
* @return the collator used to determine index term inclusion in ranges
* for rangequerys.
*/
public collator getrangecollator
return rangecollator
/**
* @deprecated use {@link #addclause(list, int, int, query)} instead.
*/
protected void addclause vector clauses  int conj  int mods  query q
addclause  list  clauses  conj  mods  q
protected void addclause list clauses  int conj  int mods  query q
boolean required  prohibited
// if this term is introduced by and, make the preceding term required,
// unless it's already prohibited
if  clauses size   > 0    conj    conj_and
booleanclause c    booleanclause  clauses get clauses size   1
if   c isprohibited
c setoccur booleanclause occur must
if  clauses size   > 0    operator    and_operator    conj    conj_or
// if this term is introduced by or, make the preceding term optional,
// unless it's prohibited (that means we leave -a or b but +a or b-->a or b)
// notice if the input is a or b, first term is parsed as required; without
// this modification a or b would parsed as +a or b
booleanclause c    booleanclause  clauses get clauses size   1
if   c isprohibited
c setoccur booleanclause occur should
// we might have been passed a null query; the term might have been
// filtered away by the analyzer.
if  q    null
return
if  operator    or_operator
// we set required if we're introduced by and or +; prohibited if
// introduced by not or -; make sure not to set both.
prohibited    mods    mod_not
required    mods    mod_req
if  conj    conj_and     prohibited
required   true
else
// we set prohibited if we're introduced by not or -; we set required
// if not prohibited and not introduced by or
prohibited    mods    mod_not
required       prohibited    conj    conj_or
if  required     prohibited
clauses add newbooleanclause q  booleanclause occur must
else if   required     prohibited
clauses add newbooleanclause q  booleanclause occur should
else if   required    prohibited
clauses add newbooleanclause q  booleanclause occur must_not
else
throw new runtimeexception
/**
* @exception parseexception throw in overridden method to disallow
*/
protected query getfieldquery string field  string querytext   throws parseexception
// use the analyzer to get all the tokens, and then build a termquery,
// phrasequery, or nothing based on the term count
tokenstream source
try
source   analyzer reusabletokenstream field  new stringreader querytext
source reset
catch  ioexception e
source   analyzer tokenstream field  new stringreader querytext
cachingtokenfilter buffer   new cachingtokenfilter source
termattribute termatt   null
positionincrementattribute posincratt   null
int numtokens   0
boolean success   false
try
buffer reset
success   true
catch  ioexception e
// success==false if we hit an exception
if  success
if  buffer hasattribute termattribute class
termatt    termattribute  buffer getattribute termattribute class
if  buffer hasattribute positionincrementattribute class
posincratt    positionincrementattribute  buffer getattribute positionincrementattribute class
int positioncount   0
boolean severaltokensatsameposition   false
boolean hasmoretokens   false
if  termatt    null
try
hasmoretokens   buffer incrementtoken
while  hasmoretokens
numtokens
int positionincrement    posincratt    null  ? posincratt getpositionincrement     1
if  positionincrement    0
positioncount    positionincrement
else
severaltokensatsameposition   true
hasmoretokens   buffer incrementtoken
catch  ioexception e
// ignore
try
// rewind the buffer stream
buffer reset
// close original stream - all tokens buffered
source close
catch  ioexception e
// ignore
if  numtokens    0
return null
else if  numtokens    1
string term   null
try
boolean hasnext   buffer incrementtoken
assert hasnext    true
term   termatt term
catch  ioexception e
// safe to ignore, because we know the number of tokens
return newtermquery new term field  term
else
if  severaltokensatsameposition
if  positioncount    1
// no phrase query:
booleanquery q   newbooleanquery true
for  int i   0  i < numtokens  i
string term   null
try
boolean hasnext   buffer incrementtoken
assert hasnext    true
term   termatt term
catch  ioexception e
// safe to ignore, because we know the number of tokens
query currentquery   newtermquery
new term field  term
q add currentquery  booleanclause occur should
return q
else
// phrase query:
multiphrasequery mpq   newmultiphrasequery
mpq setslop phraseslop
list multiterms   new arraylist
int position    1
for  int i   0  i < numtokens  i
string term   null
int positionincrement   1
try
boolean hasnext   buffer incrementtoken
assert hasnext    true
term   termatt term
if  posincratt    null
positionincrement   posincratt getpositionincrement
catch  ioexception e
// safe to ignore, because we know the number of tokens
if  positionincrement > 0    multiterms size   > 0
if  enablepositionincrements
mpq add  term multiterms toarray new term  position
else
mpq add  term multiterms toarray new term
multiterms clear
position    positionincrement
multiterms add new term field  term
if  enablepositionincrements
mpq add  term multiterms toarray new term  position
else
mpq add  term multiterms toarray new term
return mpq
else
phrasequery pq   newphrasequery
pq setslop phraseslop
int position    1
for  int i   0  i < numtokens  i
string term   null
int positionincrement   1
try
boolean hasnext   buffer incrementtoken
assert hasnext    true
term   termatt term
if  posincratt    null
positionincrement   posincratt getpositionincrement
catch  ioexception e
// safe to ignore, because we know the number of tokens
if  enablepositionincrements
position    positionincrement
pq add new term field  term  position
else
pq add new term field  term
return pq
/**
* base implementation delegates to {@link #getfieldquery(string,string)}.
* this method may be overridden, for example, to return
* a spannearquery instead of a phrasequery.
*
* @exception parseexception throw in overridden method to disallow
*/
protected query getfieldquery string field  string querytext  int slop
throws parseexception
query query   getfieldquery field  querytext
if  query instanceof phrasequery
phrasequery  query  setslop slop
if  query instanceof multiphrasequery
multiphrasequery  query  setslop slop
return query
/**
* @exception parseexception throw in overridden method to disallow
*/
protected query getrangequery string field
string part1
string part2
boolean inclusive  throws parseexception
if  lowercaseexpandedterms
part1   part1 tolowercase
part2   part2 tolowercase
try
dateformat df   dateformat getdateinstance dateformat short  locale
df setlenient true
date d1   df parse part1
date d2   df parse part2
if  inclusive
// the user can only specify the date, not the time, so make sure
// the time is set to the latest possible time of that date to really
// include all documents:
calendar cal   calendar getinstance locale
cal settime d2
cal set calendar hour_of_day  23
cal set calendar minute  59
cal set calendar second  59
cal set calendar millisecond  999
d2   cal gettime
datetools resolution resolution   getdateresolution field
if  resolution    null
// no default or field specific date resolution has been set,
// use deprecated datefield to maintain compatibilty with
// pre-1.9 lucene versions.
part1   datefield datetostring d1
part2   datefield datetostring d2
else
part1   datetools datetostring d1  resolution
part2   datetools datetostring d2  resolution
catch  exception e
return newrangequery field  part1  part2  inclusive
/**
* builds a new booleanquery instance
* @param disablecoord disable coord
* @return new booleanquery instance
*/
protected booleanquery newbooleanquery boolean disablecoord
return new booleanquery disablecoord
/**
* builds a new booleanclause instance
* @param q sub query
* @param occur how this clause should occur when matching documents
* @return new booleanclause instance
*/
protected booleanclause newbooleanclause query q  booleanclause occur occur
return new booleanclause q  occur
/**
* builds a new termquery instance
* @param term term
* @return new termquery instance
*/
protected query newtermquery term term
return new termquery term
/**
* builds a new phrasequery instance
* @return new phrasequery instance
*/
protected phrasequery newphrasequery
return new phrasequery
/**
* builds a new multiphrasequery instance
* @return new multiphrasequery instance
*/
protected multiphrasequery newmultiphrasequery
return new multiphrasequery
/**
* builds a new prefixquery instance
* @param prefix prefix term
* @return new prefixquery instance
*/
protected query newprefixquery term prefix
prefixquery query   new prefixquery prefix
query setrewritemethod multitermrewritemethod
return query
/**
* builds a new fuzzyquery instance
* @param term term
* @param minimumsimilarity minimum similarity
* @param prefixlength prefix length
* @return new fuzzyquery instance
*/
protected query newfuzzyquery term term  float minimumsimilarity  int prefixlength
// fuzzyquery doesn't yet allow constant score rewrite
return new fuzzyquery term minimumsimilarity prefixlength
/**
* builds a new termrangequery instance
* @param field field
* @param part1 min
* @param part2 max
* @param inclusive true if range is inclusive
* @return new termrangequery instance
*/
protected query newrangequery string field  string part1  string part2  boolean inclusive
final termrangequery query   new termrangequery field  part1  part2  inclusive  inclusive  rangecollator
query setrewritemethod multitermrewritemethod
return query
/**
* builds a new matchalldocsquery instance
* @return new matchalldocsquery instance
*/
protected query newmatchalldocsquery
return new matchalldocsquery
/**
* builds a new wildcardquery instance
* @param t wildcard term
* @return new wildcardquery instance
*/
protected query newwildcardquery term t
wildcardquery query   new wildcardquery t
query setrewritemethod multitermrewritemethod
return query
/**
* factory method for generating query, given a set of clauses.
* by default creates a boolean query composed of clauses passed in.
*
* can be overridden by extending classes, to modify query being
* returned.
*
* @param clauses list that contains {@link booleanclause} instances
*    to join.
*
* @return resulting {@link query} object.
* @exception parseexception throw in overridden method to disallow
* @deprecated use {@link #getbooleanquery(list)} instead
*/
protected query getbooleanquery vector clauses  throws parseexception
return getbooleanquery  list  clauses  false
/**
* factory method for generating query, given a set of clauses.
* by default creates a boolean query composed of clauses passed in.
*
* can be overridden by extending classes, to modify query being
* returned.
*
* @param clauses list that contains {@link booleanclause} instances
*    to join.
*
* @return resulting {@link query} object.
* @exception parseexception throw in overridden method to disallow
*/
protected query getbooleanquery list clauses  throws parseexception
return getbooleanquery clauses  false
/**
* factory method for generating query, given a set of clauses.
* by default creates a boolean query composed of clauses passed in.
*
* can be overridden by extending classes, to modify query being
* returned.
*
* @param clauses list that contains {@link booleanclause} instances
*    to join.
* @param disablecoord true if coord scoring should be disabled.
*
* @return resulting {@link query} object.
* @exception parseexception throw in overridden method to disallow
* @deprecated use {@link #getbooleanquery(list, boolean)} instead
*/
protected query getbooleanquery vector clauses  boolean disablecoord
throws parseexception
return getbooleanquery  list  clauses  disablecoord
/**
* factory method for generating query, given a set of clauses.
* by default creates a boolean query composed of clauses passed in.
*
* can be overridden by extending classes, to modify query being
* returned.
*
* @param clauses list that contains {@link booleanclause} instances
*    to join.
* @param disablecoord true if coord scoring should be disabled.
*
* @return resulting {@link query} object.
* @exception parseexception throw in overridden method to disallow
*/
protected query getbooleanquery list clauses  boolean disablecoord
throws parseexception
if  clauses size    0
return null     all clause words were filtered away by the analyzer
booleanquery query   newbooleanquery disablecoord
for  int i   0  i < clauses size    i
query add  booleanclause clauses get i
return query
/**
* factory method for generating a query. called when parser
* parses an input term token that contains one or more wildcard
* characters (? and *), but is not a prefix term token (one
* that has just a single * character at the end)
*<p>
* depending on settings, prefix term may be lower-cased
* automatically. it will not go through the default analyzer,
* however, since normal analyzers are unlikely to work properly
* with wildcard templates.
*<p>
* can be overridden by extending classes, to provide custom handling for
* wildcard queries, which may be necessary due to missing analyzer calls.
*
* @param field name of the field query will use.
* @param termstr term token that contains one or more wild card
*   characters (? or *), but is not simple prefix term
*
* @return resulting {@link query} built for the term
* @exception parseexception throw in overridden method to disallow
*/
protected query getwildcardquery string field  string termstr  throws parseexception
if    equals field
if    equals termstr   return newmatchalldocsquery
if   allowleadingwildcard     termstr startswith       termstr startswith
throw new parseexception
if  lowercaseexpandedterms
termstr   termstr tolowercase
term t   new term field  termstr
return newwildcardquery t
/**
* factory method for generating a query (similar to
* {@link #getwildcardquery}). called when parser parses an input term
* token that uses prefix notation; that is, contains a single '*' wildcard
* character as its last character. since this is a special case
* of generic wildcard term, and such a query can be optimized easily,
* this usually results in a different query object.
*<p>
* depending on settings, a prefix term may be lower-cased
* automatically. it will not go through the default analyzer,
* however, since normal analyzers are unlikely to work properly
* with wildcard templates.
*<p>
* can be overridden by extending classes, to provide custom handling for
* wild card queries, which may be necessary due to missing analyzer calls.
*
* @param field name of the field query will use.
* @param termstr term token to use for building term for the query
*    (<b>without</b> trailing '*' character!)
*
* @return resulting {@link query} built for the term
* @exception parseexception throw in overridden method to disallow
*/
protected query getprefixquery string field  string termstr  throws parseexception
if   allowleadingwildcard    termstr startswith
throw new parseexception
if  lowercaseexpandedterms
termstr   termstr tolowercase
term t   new term field  termstr
return newprefixquery t
/**
* factory method for generating a query (similar to
* {@link #getwildcardquery}). called when parser parses
* an input term token that has the fuzzy suffix (~) appended.
*
* @param field name of the field query will use.
* @param termstr term token to use for building term for the query
*
* @return resulting {@link query} built for the term
* @exception parseexception throw in overridden method to disallow
*/
protected query getfuzzyquery string field  string termstr  float minsimilarity  throws parseexception
if  lowercaseexpandedterms
termstr   termstr tolowercase
term t   new term field  termstr
return newfuzzyquery t  minsimilarity  fuzzyprefixlength
/**
* returns a string where the escape char has been
* removed, or kept only once if there was a double escape.
*
* supports escaped unicode characters, e. g. translates
* <code>\\u0041</code> to <code>a</code>.
*
*/
private string discardescapechar string input  throws parseexception
// create char array to hold unescaped char sequence
char output   new char
// the length of the output can be less than the input
// due to discarded escape chars. this variable holds
// the actual length of the output
int length   0
// we remember whether the last processed character was
// an escape character
boolean lastcharwasescapechar   false
// the multiplier the current unicode digit must be multiplied with.
// e. g. the first digit must be multiplied with 16^3, the second with 16^2...
int codepointmultiplier   0
// used to calculate the codepoint of the escaped unicode character
int codepoint   0
for  int i   0  i < input length    i
char curchar   input charat i
if  codepointmultiplier > 0
codepoint    hextoint curchar    codepointmultiplier
codepointmultiplier >>>  4
if  codepointmultiplier    0
output    char codepoint
codepoint   0
else if  lastcharwasescapechar
if  curchar
// found an escaped unicode character
codepointmultiplier   16   16   16
else
// this character was escaped
output   curchar
length
lastcharwasescapechar   false
else
if  curchar
lastcharwasescapechar   true
else
output   curchar
length
if  codepointmultiplier > 0
throw new parseexception
if  lastcharwasescapechar
throw new parseexception
return new string output  0  length
/** returns the numeric value of the hexadecimal character */
private static final int hextoint char c  throws parseexception
if    <  c    c <
return c
else if    <  c    c <
return c       10
else if    <  c    c <
return c       10
else
throw new parseexception     c
/**
* returns a string where those characters that queryparser
* expects to be escaped are escaped by a preceding <code>\</code>.
*/
public static string escape string s
stringbuffer sb   new stringbuffer
for  int i   0  i < s length    i
char c   s charat i
// these characters are part of the query syntax and must be escaped
if  c         c         c         c         c         c         c
c         c         c         c         c         c         c
c         c         c         c
sb append
sb append c
return sb tostring
/**
* command line tool to test queryparser, using {@link org.apache.lucene.analysis.simpleanalyzer}.
* usage:<br>
* <code>java org.apache.lucene.queryparser.queryparser &lt;input&gt;</code>
*/
public static void main string args  throws exception
if  args length    0
system out println
system exit 0
queryparser qp   new queryparser
new org apache lucene analysis simpleanalyzer
query q   qp parse args
system out println q tostring
// *   query  ::= ( clause )*
// *   clause ::= ["+", "-"] [<term> ":"] ( <term> | "(" query ")" )
final public int conjunction   throws parseexception
int ret   conj_none
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case and
case or
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case and
jj_consume_token and
ret   conj_and
break
case or
jj_consume_token or
ret   conj_or
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
break
default
jj_la1   jj_gen
if  true  return ret
throw new error
final public int modifiers   throws parseexception
int ret   mod_none
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case not
case plus
case minus
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case plus
jj_consume_token plus
ret   mod_req
break
case minus
jj_consume_token minus
ret   mod_not
break
case not
jj_consume_token not
ret   mod_not
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
break
default
jj_la1   jj_gen
if  true  return ret
throw new error
// this makes sure that there is no garbage after the query string
final public query toplevelquery string field  throws parseexception
query q
q   query field
jj_consume_token 0
if  true  return q
throw new error
final public query query string field  throws parseexception
list clauses   new arraylist
query q  firstquery null
int conj  mods
mods   modifiers
q   clause field
addclause clauses  conj_none  mods  q
if  mods    mod_none
firstquery q
label_1
while  true
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case and
case or
case not
case plus
case minus
case lparen
case star
case quoted
case term
case prefixterm
case wildterm
case rangein_start
case rangeex_start
case number
break
default
jj_la1   jj_gen
break label_1
conj   conjunction
mods   modifiers
q   clause field
addclause clauses  conj  mods  q
if  clauses size      1    firstquery    null
if  true  return firstquery
else
if  true  return getbooleanquery clauses
throw new error
final public query clause string field  throws parseexception
query q
token fieldtoken null  boost null
if  jj_2_1 2
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case term
fieldtoken   jj_consume_token term
jj_consume_token colon
field discardescapechar fieldtoken image
break
case star
jj_consume_token star
jj_consume_token colon
field
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
else
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case star
case quoted
case term
case prefixterm
case wildterm
case rangein_start
case rangeex_start
case number
q   term field
break
case lparen
jj_consume_token lparen
q   query field
jj_consume_token rparen
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case carat
jj_consume_token carat
boost   jj_consume_token number
break
default
jj_la1   jj_gen
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
if  boost    null
float f    float 1 0
try
f   float valueof boost image  floatvalue
q setboost f
catch  exception ignored
if  true  return q
throw new error
final public query term string field  throws parseexception
token term  boost null  fuzzyslop null  goop1  goop2
boolean prefix   false
boolean wildcard   false
boolean fuzzy   false
query q
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case star
case term
case prefixterm
case wildterm
case number
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case term
term   jj_consume_token term
break
case star
term   jj_consume_token star
wildcard true
break
case prefixterm
term   jj_consume_token prefixterm
prefix true
break
case wildterm
term   jj_consume_token wildterm
wildcard true
break
case number
term   jj_consume_token number
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case fuzzy_slop
fuzzyslop   jj_consume_token fuzzy_slop
fuzzy true
break
default
jj_la1   jj_gen
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case carat
jj_consume_token carat
boost   jj_consume_token number
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case fuzzy_slop
fuzzyslop   jj_consume_token fuzzy_slop
fuzzy true
break
default
jj_la1   jj_gen
break
default
jj_la1   jj_gen
string termimage discardescapechar term image
if  wildcard
q   getwildcardquery field  termimage
else if  prefix
q   getprefixquery field
discardescapechar term image substring
0  term image length   1
else if  fuzzy
float fms   fuzzyminsim
try
fms   float valueof fuzzyslop image substring 1   floatvalue
catch  exception ignored
if fms < 0 0f    fms > 1 0f
if  true  throw new parseexception
q   getfuzzyquery field  termimage fms
else
q   getfieldquery field  termimage
break
case rangein_start
jj_consume_token rangein_start
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case rangein_goop
goop1   jj_consume_token rangein_goop
break
case rangein_quoted
goop1   jj_consume_token rangein_quoted
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case rangein_to
jj_consume_token rangein_to
break
default
jj_la1   jj_gen
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case rangein_goop
goop2   jj_consume_token rangein_goop
break
case rangein_quoted
goop2   jj_consume_token rangein_quoted
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
jj_consume_token rangein_end
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case carat
jj_consume_token carat
boost   jj_consume_token number
break
default
jj_la1   jj_gen
if  goop1 kind    rangein_quoted
goop1 image   goop1 image substring 1  goop1 image length   1
if  goop2 kind    rangein_quoted
goop2 image   goop2 image substring 1  goop2 image length   1
q   getrangequery field  discardescapechar goop1 image   discardescapechar goop2 image   true
break
case rangeex_start
jj_consume_token rangeex_start
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case rangeex_goop
goop1   jj_consume_token rangeex_goop
break
case rangeex_quoted
goop1   jj_consume_token rangeex_quoted
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case rangeex_to
jj_consume_token rangeex_to
break
default
jj_la1   jj_gen
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case rangeex_goop
goop2   jj_consume_token rangeex_goop
break
case rangeex_quoted
goop2   jj_consume_token rangeex_quoted
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
jj_consume_token rangeex_end
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case carat
jj_consume_token carat
boost   jj_consume_token number
break
default
jj_la1   jj_gen
if  goop1 kind    rangeex_quoted
goop1 image   goop1 image substring 1  goop1 image length   1
if  goop2 kind    rangeex_quoted
goop2 image   goop2 image substring 1  goop2 image length   1
q   getrangequery field  discardescapechar goop1 image   discardescapechar goop2 image   false
break
case quoted
term   jj_consume_token quoted
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case fuzzy_slop
fuzzyslop   jj_consume_token fuzzy_slop
break
default
jj_la1   jj_gen
switch   jj_ntk   1 ?jj_ntk   jj_ntk
case carat
jj_consume_token carat
boost   jj_consume_token number
break
default
jj_la1   jj_gen
int s   phraseslop
if  fuzzyslop    null
try
s   float valueof fuzzyslop image substring 1   intvalue
catch  exception ignored
q   getfieldquery field  discardescapechar term image substring 1  term image length   1    s
break
default
jj_la1   jj_gen
jj_consume_token  1
throw new parseexception
if  boost    null
float f    float  1 0
try
f   float valueof boost image  floatvalue
catch  exception ignored
/* should this be handled somehow? (defaults to "no boost", if
* boost number is invalid)
*/
// avoid boosting null queries, such as those caused by stop words
if  q    null
q setboost f
if  true  return q
throw new error
private boolean jj_2_1 int xla
jj_la   xla  jj_lastpos   jj_scanpos   token
try   return  jj_3_1
catch lookaheadsuccess ls    return true
finally   jj_save 0  xla
private boolean jj_3_1
token xsp
xsp   jj_scanpos
if  jj_3r_2
jj_scanpos   xsp
if  jj_3r_3    return true
return false
private boolean jj_3r_3
if  jj_scan_token star   return true
if  jj_scan_token colon   return true
return false
private boolean jj_3r_2
if  jj_scan_token term   return true
if  jj_scan_token colon   return true
return false
/** generated token manager. */
public queryparsertokenmanager token_source
/** current token. */
public token token
/** next token. */
public token jj_nt
private int jj_ntk
private token jj_scanpos  jj_lastpos
private int jj_la
private int jj_gen
final private int jj_la1   new int
static private int jj_la1_0
static private int jj_la1_1
static
jj_la1_init_0
jj_la1_init_1
private static void jj_la1_init_0
jj_la1_0   new int  0x300 0x300 0x1c00 0x1c00 0x3ed3f00 0x90000 0x20000 0x3ed2000 0x2690000 0x100000 0x100000 0x20000 0x30000000 0x4000000 0x30000000 0x20000 0x0 0x40000000 0x0 0x20000 0x100000 0x20000 0x3ed0000
private static void jj_la1_init_1
jj_la1_1   new int  0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x3 0x0 0x3 0x0 0x0 0x0 0x0
final private jjcalls jj_2_rtns   new jjcalls
private boolean jj_rescan   false
private int jj_gc   0
/** constructor with user supplied charstream. */
public queryparser charstream stream
token_source   new queryparsertokenmanager stream
token   new token
jj_ntk    1
jj_gen   0
for  int i   0  i < 23  i    jj_la1    1
for  int i   0  i < jj_2_rtns length  i    jj_2_rtns   new jjcalls
/** reinitialise. */
public void reinit charstream stream
token_source reinit stream
token   new token
jj_ntk    1
jj_gen   0
for  int i   0  i < 23  i    jj_la1    1
for  int i   0  i < jj_2_rtns length  i    jj_2_rtns   new jjcalls
/** constructor with generated token manager. */
public queryparser queryparsertokenmanager tm
token_source   tm
token   new token
jj_ntk    1
jj_gen   0
for  int i   0  i < 23  i    jj_la1    1
for  int i   0  i < jj_2_rtns length  i    jj_2_rtns   new jjcalls
/** reinitialise. */
public void reinit queryparsertokenmanager tm
token_source   tm
token   new token
jj_ntk    1
jj_gen   0
for  int i   0  i < 23  i    jj_la1    1
for  int i   0  i < jj_2_rtns length  i    jj_2_rtns   new jjcalls
private token jj_consume_token int kind  throws parseexception
token oldtoken
if   oldtoken   token  next    null  token   token next
else token   token next   token_source getnexttoken
jj_ntk    1
if  token kind    kind
jj_gen
if    jj_gc > 100
jj_gc   0
for  int i   0  i < jj_2_rtns length  i
jjcalls c   jj_2_rtns
while  c    null
if  c gen < jj_gen  c first   null
c   c next
return token
token   oldtoken
jj_kind   kind
throw generateparseexception
static private final class lookaheadsuccess extends java lang error
final private lookaheadsuccess jj_ls   new lookaheadsuccess
private boolean jj_scan_token int kind
if  jj_scanpos    jj_lastpos
jj_la
if  jj_scanpos next    null
jj_lastpos   jj_scanpos   jj_scanpos next   token_source getnexttoken
else
jj_lastpos   jj_scanpos   jj_scanpos next
else
jj_scanpos   jj_scanpos next
if  jj_rescan
int i   0  token tok   token
while  tok    null    tok    jj_scanpos    i    tok   tok next
if  tok    null  jj_add_error_token kind  i
if  jj_scanpos kind    kind  return true
if  jj_la    0    jj_scanpos    jj_lastpos  throw jj_ls
return false
/** get the next token. */
final public token getnexttoken
if  token next    null  token   token next
else token   token next   token_source getnexttoken
jj_ntk    1
jj_gen
return token
/** get the specific token. */
final public token gettoken int index
token t   token
for  int i   0  i < index  i
if  t next    null  t   t next
else t   t next   token_source getnexttoken
return t
private int jj_ntk
if   jj_nt token next     null
return  jj_ntk    token next token_source getnexttoken    kind
else
return  jj_ntk   jj_nt kind
private java util list jj_expentries   new java util arraylist
private int jj_expentry
private int jj_kind    1
private int jj_lasttokens   new int
private int jj_endpos
private void jj_add_error_token int kind  int pos
if  pos >  100  return
if  pos    jj_endpos   1
jj_lasttokens   kind
else if  jj_endpos    0
jj_expentry   new int
for  int i   0  i < jj_endpos  i
jj_expentry   jj_lasttokens
jj_entries_loop  for  java util iterator it   jj_expentries iterator    it hasnext
int oldentry    int  it next
if  oldentry length    jj_expentry length
for  int i   0  i < jj_expentry length  i
if  oldentry    jj_expentry
continue jj_entries_loop
jj_expentries add jj_expentry
break jj_entries_loop
if  pos    0  jj_lasttokens   kind
/** generate parseexception. */
public parseexception generateparseexception
jj_expentries clear
boolean la1tokens   new boolean
if  jj_kind >  0
la1tokens   true
jj_kind    1
for  int i   0  i < 23  i
if  jj_la1    jj_gen
for  int j   0  j < 32  j
if   jj_la1_0    1<<j      0
la1tokens   true
if   jj_la1_1    1<<j      0
la1tokens   true
for  int i   0  i < 34  i
if  la1tokens
jj_expentry   new int
jj_expentry   i
jj_expentries add jj_expentry
jj_endpos   0
jj_rescan_token
jj_add_error_token 0  0
int exptokseq   new int
for  int i   0  i < jj_expentries size    i
exptokseq    int jj_expentries get i
return new parseexception token  exptokseq  tokenimage
/** enable tracing. */
final public void enable_tracing
/** disable tracing. */
final public void disable_tracing
private void jj_rescan_token
jj_rescan   true
for  int i   0  i < 1  i
try
jjcalls p   jj_2_rtns
do
if  p gen > jj_gen
jj_la   p arg  jj_lastpos   jj_scanpos   p first
switch  i
case 0  jj_3_1    break
p   p next
while  p    null
catch lookaheadsuccess ls
jj_rescan   false
private void jj_save int index  int xla
jjcalls p   jj_2_rtns
while  p gen > jj_gen
if  p next    null    p   p next   new jjcalls    break
p   p next
p gen   jj_gen   xla   jj_la  p first   token  p arg   xla
static final class jjcalls
int gen
token first
int arg
jjcalls next