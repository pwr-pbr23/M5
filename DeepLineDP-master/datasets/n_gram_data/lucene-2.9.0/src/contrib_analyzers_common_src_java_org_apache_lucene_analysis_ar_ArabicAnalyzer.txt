package org apache lucene analysis ar
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io file
import java io ioexception
import java io inputstream
import java io inputstreamreader
import java io reader
import java util hashset
import java util hashtable
import java util set
import org apache lucene analysis analyzer
import org apache lucene analysis lowercasefilter
import org apache lucene analysis stopfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenizer
import org apache lucene analysis wordlistloader
/**
* {@link analyzer} for arabic.
* <p>
* this analyzer implements light-stemming as specified by:
* <i>
* light stemming for arabic information retrieval
* </i>
* http://www.mtholyoke.edu/~lballest/pubs/arab_stem05.pdf
* <p>
* the analysis package contains three primary components:
* <ul>
*  <li>{@link arabicnormalizationfilter}: arabic orthographic normalization.
*  <li>{@link arabicstemfilter}: arabic light stemming
*  <li>arabic stop words file: a set of default arabic stop words.
* </ul>
*
*/
public final class arabicanalyzer extends analyzer
/**
* file containing default arabic stopwords.
*
* default stopword list is from http://members.unine.ch/jacques.savoy/clef/index.html
* the stopword list is bsd-licensed.
*/
public final static string default_stopword_file
/**
* contains the stopwords used with the stopfilter.
*/
private set stoptable   new hashset
/**
* the comment character in the stopwords file.  all lines prefixed with this will be ignored
*/
public static final string stopwords_comment
/**
* builds an analyzer with the default stop words: {@link #default_stopword_file}.
*/
public arabicanalyzer
try
inputstream stream   arabicanalyzer class getresourceasstream default_stopword_file
inputstreamreader reader   new inputstreamreader stream
stoptable   wordlistloader getwordset reader  stopwords_comment
reader close
stream close
catch  ioexception e
// todo: throw ioexception
throw new runtimeexception e
/**
* builds an analyzer with the given stop words.
*/
public arabicanalyzer  string stopwords
stoptable   stopfilter makestopset  stopwords
/**
* builds an analyzer with the given stop words.
*/
public arabicanalyzer  hashtable stopwords
stoptable   new hashset stopwords keyset
/**
* builds an analyzer with the given stop words.  lines can be commented out using {@link #stopwords_comment}
*/
public arabicanalyzer  file stopwords   throws ioexception
stoptable   wordlistloader getwordset  stopwords  stopwords_comment
/**
* creates a {@link tokenstream} which tokenizes all the text in the provided {@link reader}.
*
* @return  a {@link tokenstream} built from an {@link arabiclettertokenizer} filtered with
* 			{@link stopfilter}, {@link lowercasefilter}, {@link arabicnormalizationfilter}
*            and {@link arabicstemfilter}.
*/
public final tokenstream tokenstream string fieldname  reader reader
tokenstream result   new arabiclettertokenizer  reader
result   new stopfilter  result  stoptable
result   new lowercasefilter result
result   new arabicnormalizationfilter  result
result   new arabicstemfilter  result
return result
private class savedstreams
tokenizer source
tokenstream result
/**
* returns a (possibly reused) {@link tokenstream} which tokenizes all the text
* in the provided {@link reader}.
*
* @return  a {@link tokenstream} built from an {@link arabiclettertokenizer} filtered with
*            {@link stopfilter}, {@link lowercasefilter}, {@link arabicnormalizationfilter}
*            and {@link arabicstemfilter}.
*/
public tokenstream reusabletokenstream string fieldname  reader reader
throws ioexception
savedstreams streams    savedstreams  getprevioustokenstream
if  streams    null
streams   new savedstreams
streams source   new arabiclettertokenizer reader
streams result   new stopfilter streams source  stoptable
streams result   new lowercasefilter streams result
streams result   new arabicnormalizationfilter streams result
streams result   new arabicstemfilter streams result
setprevioustokenstream streams
else
streams source reset reader
return streams result