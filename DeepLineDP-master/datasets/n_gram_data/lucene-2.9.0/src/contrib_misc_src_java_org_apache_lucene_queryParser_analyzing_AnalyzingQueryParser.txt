package org apache lucene queryparser analyzing
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import java io ioexception
import java io stringreader
import java util arraylist
import java util list
import org apache lucene analysis analyzer
import org apache lucene analysis token
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenattributes termattribute
import org apache lucene queryparser parseexception
import org apache lucene search query
/**
* overrides lucene's default queryparser so that fuzzy-, prefix-, range-, and wildcardquerys
* are also passed through the given analyzer, but wild card characters (like <code>*</code>)
* don't get removed from the search terms.
*
* <p><b>warning:</b> this class should only be used with analyzers that do not use stopwords
* or that add tokens. also, several stemming analyzers are inappropriate: for example, germananalyzer
* will turn <code>h&auml;user</code> into <code>hau</code>, but <code>h?user</code> will
* become <code>h?user</code> when using this parser and thus no match would be found (i.e.
* using this parser will be no improvement over queryparser in such cases).
*
* @version $revision$, $date$
*/
public class analyzingqueryparser extends org apache lucene queryparser queryparser
/**
* constructs a query parser.
* @param field    the default field for query terms.
* @param analyzer used to find terms in the query text.
*/
public analyzingqueryparser string field  analyzer analyzer
super field  analyzer
/**
* called when parser
* parses an input term token that contains one or more wildcard
* characters (like <code>*</code>), but is not a prefix term token (one
* that has just a single * character at the end).
* <p>
* example: will be called for <code>h?user</code> or for <code>h*user</code>
* but not for <code>*user</code>.
* <p>
* depending on analyzer and settings, a wildcard term may (most probably will)
* be lower-cased automatically. it <b>will</b> go through the default analyzer.
* <p>
* overrides super class, by passing terms through analyzer.
*
* @param  field   name of the field query will use.
* @param  termstr term token that contains one or more wild card
*                 characters (? or *), but is not simple prefix term
*
* @return resulting {@link query} built for the term
* @throws parseexception
*/
protected query getwildcardquery string field  string termstr  throws parseexception
list tlist   new arraylist
list wlist   new arraylist
/* somewhat a hack: find/store wildcard chars
* in order to put them back after analyzing */
boolean iswithintoken     termstr startswith        termstr startswith
stringbuffer tmpbuffer   new stringbuffer
char chars   termstr tochararray
for  int i   0  i < termstr length    i
if  chars         chars
if  iswithintoken
tlist add tmpbuffer tostring
tmpbuffer setlength 0
iswithintoken   false
else
if   iswithintoken
wlist add tmpbuffer tostring
tmpbuffer setlength 0
iswithintoken   true
tmpbuffer append chars
if  iswithintoken
tlist add tmpbuffer tostring
else
wlist add tmpbuffer tostring
// get analyzer from superclass and tokenize the term
tokenstream source   getanalyzer   tokenstream field  new stringreader termstr
termattribute termatt    termattribute  source addattribute termattribute class
int counttokens   0
while  true
try
if   source incrementtoken    break
catch  ioexception e
break
string term   termatt term
if     equals term
try
tlist set counttokens    term
catch  indexoutofboundsexception ioobe
counttokens    1
try
source close
catch  ioexception e
// ignore
if  counttokens    tlist size
/* this means that the analyzer used either added or consumed
* (common for a stemmer) tokens, and we can't build a wildcardquery */
throw new parseexception
getanalyzer   getclass
if  tlist size      0
return null
else if  tlist size      1
if  wlist    null    wlist size      1
/* if wlist contains one wildcard, it must be at the end, because:
* 1) wildcards are not allowed in 1st position of a term by queryparser
* 2) if wildcard was *not* in end, there would be *two* or more tokens */
return super getwildcardquery field   string  tlist get 0
string  wlist get 0   tostring
else
/* we should never get here! if so, this method was called
* with a termstr containing no wildcard ... */
throw new illegalargumentexception
else
/* the term was tokenized, let's rebuild to one token
* with wildcards put back in postion */
stringbuffer sb   new stringbuffer
for  int i   0  i < tlist size    i
sb append  string  tlist get i
if  wlist    null    wlist size   > i
sb append  string  wlist get i
return super getwildcardquery field  sb tostring
/**
* called when parser parses an input term
* token that uses prefix notation; that is, contains a single '*' wildcard
* character as its last character. since this is a special case
* of generic wildcard term, and such a query can be optimized easily,
* this usually results in a different query object.
* <p>
* depending on analyzer and settings, a prefix term may (most probably will)
* be lower-cased automatically. it <b>will</b> go through the default analyzer.
* <p>
* overrides super class, by passing terms through analyzer.
*
* @param  field   name of the field query will use.
* @param  termstr term token to use for building term for the query
*                 (<b>without</b> trailing '*' character!)
*
* @return resulting {@link query} built for the term
* @throws parseexception
*/
protected query getprefixquery string field  string termstr  throws parseexception
// get analyzer from superclass and tokenize the term
tokenstream source   getanalyzer   tokenstream field  new stringreader termstr
list tlist   new arraylist
termattribute termatt    termattribute  source addattribute termattribute class
while  true
try
if   source incrementtoken    break
catch  ioexception e
break
tlist add termatt term
try
source close
catch  ioexception e
// ignore
if  tlist size      1
return super getprefixquery field   string  tlist get 0
else
/* this means that the analyzer used either added or consumed
* (common for a stemmer) tokens, and we can't build a prefixquery */
throw new parseexception
getanalyzer   getclass
tlist size   > 1 ?
/**
* called when parser parses an input term token that has the fuzzy suffix (~) appended.
* <p>
* depending on analyzer and settings, a fuzzy term may (most probably will)
* be lower-cased automatically. it <b>will</b> go through the default analyzer.
* <p>
* overrides super class, by passing terms through analyzer.
*
* @param field name of the field query will use.
* @param termstr term token to use for building term for the query
*
* @return resulting {@link query} built for the term
* @exception parseexception
*/
protected query getfuzzyquery string field  string termstr  float minsimilarity
throws parseexception
// get analyzer from superclass and tokenize the term
tokenstream source   getanalyzer   tokenstream field  new stringreader termstr
termattribute termatt    termattribute  source addattribute termattribute class
string nexttoken   null
boolean multipletokens   false
try
if  source incrementtoken
nexttoken   termatt term
multipletokens   source incrementtoken
catch  ioexception e
nexttoken   null
try
source close
catch  ioexception e
// ignore
if  multipletokens
throw new parseexception     getanalyzer   getclass
return  nexttoken    null  ? null   super getfuzzyquery field  nexttoken  minsimilarity
/**
* overrides super class, by passing terms through analyzer.
* @exception parseexception
*/
protected query getrangequery string field  string part1  string part2  boolean inclusive
throws parseexception
// get analyzer from superclass and tokenize the terms
tokenstream source   getanalyzer   tokenstream field  new stringreader part1
termattribute termatt    termattribute  source addattribute termattribute class
boolean multipletokens   false
// part1
try
if  source incrementtoken
part1   termatt term
multipletokens   source incrementtoken
catch  ioexception e
// ignore
try
source close
catch  ioexception e
// ignore
if  multipletokens
throw new parseexception     getanalyzer   getclass
// part2
source   getanalyzer   tokenstream field  new stringreader part2
termatt    termattribute  source addattribute termattribute class
try
if  source incrementtoken
part2   termatt term
multipletokens   source incrementtoken
catch  ioexception e
// ignore
try
source close
catch  ioexception e
// ignore
if  multipletokens
throw new parseexception     getanalyzer   getclass
return super getrangequery field  part1  part2  inclusive