package org apache lucene analysis nl
/**
* licensed to the apache software foundation (asf) under one or more
* contributor license agreements.  see the notice file distributed with
* this work for additional information regarding copyright ownership.
* the asf licenses this file to you under the apache license, version 2.0
* (the "license"); you may not use this file except in compliance with
* the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
import org apache lucene analysis analyzer
import org apache lucene analysis stopfilter
import org apache lucene analysis tokenstream
import org apache lucene analysis tokenizer
import org apache lucene analysis standard standardfilter
import org apache lucene analysis standard standardtokenizer
import java io file
import java io ioexception
import java io reader
import java util hashmap
import java util hashset
import java util set
import java util map
/**
* {@link analyzer} for dutch language.
* <p>
* supports an external list of stopwords (words that
* will not be indexed at all), an external list of exclusions (word that will
* not be stemmed, but indexed) and an external list of word-stem pairs that overrule
* the algorithm (dictionary stemming).
* a default set of stopwords is used unless an alternative list is specified, but the
* exclusion list is empty by default.
* </p>
*/
public class dutchanalyzer extends analyzer
/**
* list of typical dutch stopwords.
*/
public final static string dutch_stop_words
/**
* contains the stopwords used with the stopfilter.
*/
private set stoptable   new hashset
/**
* contains words that should be indexed but not stemmed.
*/
private set excltable   new hashset
private map stemdict   new hashmap
/**
* builds an analyzer with the default stop words ({@link #dutch_stop_words})
* and a few default entries for the stem exclusion table.
*
*/
public dutchanalyzer
setoverridestokenstreammethod dutchanalyzer class
stoptable   stopfilter makestopset dutch_stop_words
stemdict put          otherwise fiet
stemdict put          otherwise bromfiet
stemdict put
stemdict put
/**
* builds an analyzer with the given stop words.
*
* @param stopwords
*/
public dutchanalyzer string stopwords
setoverridestokenstreammethod dutchanalyzer class
stoptable   stopfilter makestopset stopwords
/**
* builds an analyzer with the given stop words.
*
* @param stopwords
*/
public dutchanalyzer hashset stopwords
setoverridestokenstreammethod dutchanalyzer class
stoptable   stopwords
/**
* builds an analyzer with the given stop words.
*
* @param stopwords
*/
public dutchanalyzer file stopwords
setoverridestokenstreammethod dutchanalyzer class
try
stoptable   org apache lucene analysis wordlistloader getwordset stopwords
catch  ioexception e
// todo: throw ioexception
throw new runtimeexception e
/**
* builds an exclusionlist from an array of strings.
*
* @param exclusionlist
*/
public void setstemexclusiontable string exclusionlist
excltable   stopfilter makestopset exclusionlist
setprevioustokenstream null      force a new stemmer to be created
/**
* builds an exclusionlist from a hashtable.
*/
public void setstemexclusiontable hashset exclusionlist
excltable   exclusionlist
setprevioustokenstream null      force a new stemmer to be created
/**
* builds an exclusionlist from the words contained in the given file.
*/
public void setstemexclusiontable file exclusionlist
try
excltable   org apache lucene analysis wordlistloader getwordset exclusionlist
setprevioustokenstream null      force a new stemmer to be created
catch  ioexception e
// todo: throw ioexception
throw new runtimeexception e
/**
* reads a stemdictionary file , that overrules the stemming algorithm
* this is a textfile that contains per line
* <tt>word<b>\t</b>stem</tt>, i.e: two tab seperated words
*/
public void setstemdictionary file stemdictfile
try
stemdict   org apache lucene analysis wordlistloader getstemdict stemdictfile
setprevioustokenstream null      force a new stemmer to be created
catch  ioexception e
// todo: throw ioexception
throw new runtimeexception e
/**
* creates a {@link tokenstream} which tokenizes all the text in the
* provided {@link reader}.
*
* @return a {@link tokenstream} built from a {@link standardtokenizer}
*   filtered with {@link standardfilter}, {@link stopfilter},
*   and {@link dutchstemfilter}
*/
public tokenstream tokenstream string fieldname  reader reader
tokenstream result   new standardtokenizer reader
result   new standardfilter result
result   new stopfilter result  stoptable
result   new dutchstemfilter result  excltable  stemdict
return result
private class savedstreams
tokenizer source
tokenstream result
/**
* returns a (possibly reused) {@link tokenstream} which tokenizes all the
* text in the provided {@link reader}.
*
* @return a {@link tokenstream} built from a {@link standardtokenizer}
*   filtered with {@link standardfilter}, {@link stopfilter},
*   and {@link dutchstemfilter}
*/
public tokenstream reusabletokenstream string fieldname  reader reader
throws ioexception
if  overridestokenstreammethod
// lucene-1678: force fallback to tokenstream() if we
// have been subclassed and that subclass overrides
// tokenstream but not reusabletokenstream
return tokenstream fieldname  reader
savedstreams streams    savedstreams  getprevioustokenstream
if  streams    null
streams   new savedstreams
streams source   new standardtokenizer reader
streams result   new standardfilter streams source
streams result   new stopfilter streams result  stoptable
streams result   new dutchstemfilter streams result  excltable  stemdict
setprevioustokenstream streams
else
streams source reset reader
return streams result