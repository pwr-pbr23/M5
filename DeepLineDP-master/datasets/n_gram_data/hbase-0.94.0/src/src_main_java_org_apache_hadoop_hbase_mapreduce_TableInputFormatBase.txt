/**
* copyright 2009 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase mapreduce
import java io ioexception
import java net inetaddress
import java util arraylist
import java util hashmap
import java util list
import javax naming namingexception
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop hbase hconstants
import org apache hadoop hbase hserveraddress
import org apache hadoop hbase client htable
import org apache hadoop hbase client result
import org apache hadoop hbase client scan
import org apache hadoop hbase io immutablebyteswritable
import org apache hadoop hbase util bytes
import org apache hadoop hbase util pair
import org apache hadoop mapreduce inputformat
import org apache hadoop mapreduce inputsplit
import org apache hadoop mapreduce jobcontext
import org apache hadoop mapreduce recordreader
import org apache hadoop mapreduce taskattemptcontext
import org apache hadoop net dns
/**
* a base for {@link tableinputformat}s. receives a {@link htable}, an
* {@link scan} instance that defines the input columns etc. subclasses may use
* other tablerecordreader implementations.
* <p>
* an example of a subclass:
* <pre>
*   class exampletif extends tableinputformatbase implements jobconfigurable {
*
*     public void configure(jobconf job) {
*       htable exampletable = new htable(hbaseconfiguration.create(job),
*         bytes.tobytes("exampletable"));
*       // mandatory
*       sethtable(exampletable);
*       text[] inputcolumns = new byte [][] { bytes.tobytes("columna"),
*         bytes.tobytes("columnb") };
*       // mandatory
*       setinputcolumns(inputcolumns);
*       rowfilterinterface examplefilter = new regexprowfilter("keyprefix.*");
*       // optional
*       setrowfilter(examplefilter);
*     }
*
*     public void validateinput(jobconf job) throws ioexception {
*     }
*  }
* </pre>
*/
public abstract class tableinputformatbase
extends inputformat<immutablebyteswritable  result>
final log log   logfactory getlog tableinputformatbase class
/** holds the details for the internal scanner. */
private scan scan   null
/** the table to scan. */
private htable table   null
/** the reader scanning the table, can be a custom one. */
private tablerecordreader tablerecordreader   null
/** the reverse dns lookup cache mapping: ipaddress => hostname */
private hashmap<inetaddress  string> reversednscachemap
new hashmap<inetaddress  string>
/** the nameserver address */
private string nameserver   null
/**
* builds a tablerecordreader. if no tablerecordreader was provided, uses
* the default.
*
* @param split  the split to work with.
* @param context  the current context.
* @return the newly created record reader.
* @throws ioexception when creating the reader fails.
* @see org.apache.hadoop.mapreduce.inputformat#createrecordreader(
*   org.apache.hadoop.mapreduce.inputsplit,
*   org.apache.hadoop.mapreduce.taskattemptcontext)
*/
@override
public recordreader<immutablebyteswritable  result> createrecordreader
inputsplit split  taskattemptcontext context
throws ioexception
if  table    null
throw new ioexception
tablesplit tsplit    tablesplit  split
tablerecordreader trr   this tablerecordreader
// if no table record reader was provided use default
if  trr    null
trr   new tablerecordreader
scan sc   new scan this scan
sc setstartrow tsplit getstartrow
sc setstoprow tsplit getendrow
trr setscan sc
trr sethtable table
return trr
/**
* calculates the splits that will serve as input for the map tasks. the
* number of splits matches the number of regions in a table.
*
* @param context  the current job context.
* @return the list of input splits.
* @throws ioexception when creating the list of splits fails.
* @see org.apache.hadoop.mapreduce.inputformat#getsplits(
*   org.apache.hadoop.mapreduce.jobcontext)
*/
@override
public list<inputsplit> getsplits jobcontext context  throws ioexception
if  table    null
throw new ioexception
// get the name server address and the default value is null.
this nameserver
context getconfiguration   get    null
pair<byte  byte> keys   table getstartendkeys
if  keys    null    keys getfirst      null
keys getfirst   length    0
throw new ioexception
list<inputsplit> splits   new arraylist<inputsplit> keys getfirst   length
for  int i   0  i < keys getfirst   length  i
if    includeregioninsplit keys getfirst    keys getsecond
continue
hserveraddress regionserveraddress
table getregionlocation keys getfirst    getserveraddress
inetaddress regionaddress
regionserveraddress getinetsocketaddress   getaddress
string regionlocation
try
regionlocation   reversedns regionaddress
catch  namingexception e
log error     regionaddress
e
regionlocation   regionserveraddress gethostname
byte startrow   scan getstartrow
byte stoprow   scan getstoprow
// determine if the given start an stop key fall into the region
if   startrow length    0    keys getsecond   length    0
bytes compareto startrow  keys getsecond    < 0
stoprow length    0
bytes compareto stoprow  keys getfirst    > 0
byte splitstart   startrow length    0
bytes compareto keys getfirst    startrow  >  0 ?
keys getfirst     startrow
byte splitstop    stoprow length    0
bytes compareto keys getsecond    stoprow  <  0
keys getsecond   length > 0 ?
keys getsecond     stoprow
inputsplit split   new tablesplit table gettablename
splitstart  splitstop  regionlocation
splits add split
if  log isdebugenabled
log debug     i       split
return splits
private string reversedns inetaddress ipaddress  throws namingexception
string hostname   this reversednscachemap get ipaddress
if  hostname    null
hostname   dns reversedns ipaddress  this nameserver
this reversednscachemap put ipaddress  hostname
return hostname
/**
*
*
* test if the given region is to be included in the inputsplit while splitting
* the regions of a table.
* <p>
* this optimization is effective when there is a specific reasoning to exclude an entire region from the m-r job,
* (and hence, not contributing to the inputsplit), given the start and end keys of the same. <br>
* useful when we need to remember the last-processed top record and revisit the [last, current) interval for m-r processing,
* continuously. in addition to reducing inputsplits, reduces the load on the region server as well, due to the ordering of the keys.
* <br>
* <br>
* note: it is possible that <code>endkey.length() == 0 </code> , for the last (recent) region.
* <br>
* override this method, if you want to bulk exclude regions altogether from m-r. by default, no region is excluded( i.e. all regions are included).
*
*
* @param startkey start key of the region
* @param endkey end key of the region
* @return true, if this region needs to be included as part of the input (default).
*
*/
protected boolean includeregioninsplit final byte startkey  final byte  endkey
return true
/**
* allows subclasses to get the {@link htable}.
*/
protected htable gethtable
return this table
/**
* allows subclasses to set the {@link htable}.
*
* @param table  the table to get the data from.
*/
protected void sethtable htable table
this table   table
/**
* gets the scan defining the actual details like columns etc.
*
* @return the internal scan instance.
*/
public scan getscan
if  this scan    null  this scan   new scan
return scan
/**
* sets the scan defining the actual details like columns etc.
*
* @param scan  the scan to set.
*/
public void setscan scan scan
this scan   scan
/**
* allows subclasses to set the {@link tablerecordreader}.
*
* @param tablerecordreader a different {@link tablerecordreader}
*   implementation.
*/
protected void settablerecordreader tablerecordreader tablerecordreader
this tablerecordreader   tablerecordreader