/**
* copyright 2011 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase client
import java io ioexception
import java lang interruptedexception
import java util arraylist
import java util hashmap
import java util list
import java util map
import org apache hadoop hbase hregionlocation
import org apache hadoop hbase client htable
import org apache hadoop hbase client put
import org apache hadoop hbase client row
/**
* utility class for htable.
*
*
*/
public class htableutil
private static final int initial_list_size   250
/**
* processes a list of puts and writes them to an htable instance in regionserver buckets via the htable.put method.
* this will utilize the writebuffer, thus the writebuffer flush frequency may be tuned accordingly via htable.setwritebuffersize.
* <br><br>
* the benefit of submitting puts in this manner is to minimize the number of regionserver rpcs in each flush.
* <br><br>
* assumption #1:  regions have been pre-created for the table.  if they haven't, then all of the puts will go to the same region,
* defeating the purpose of this utility method. see the apache hbase book for an explanation of how to do this.
* <br>
* assumption #2:  row-keys are not monotonically increasing.  see the apache hbase book for an explanation of this problem.
* <br>
* assumption #3:  that the input list of puts is big enough to be useful (in the thousands or more).  the intent of this
* method is to process larger chunks of data.
* <br>
* assumption #4:  htable.setautoflush(false) has been set.  this is a requirement to use the writebuffer.
* <br><br>
* @param htable htable instance for target hbase table
* @param puts list of put instances
* @throws ioexception if a remote or network exception occurs
*
*/
public static void bucketrsput htable htable  list<put> puts  throws ioexception
map<string  list<put>> putmap   creatersputmap htable  puts
for  list<put> rsputs  putmap values
htable put  rsputs
htable flushcommits
/**
* processes a list of rows (put, delete) and writes them to an htable instance in regionserver buckets via the htable.batch method.
* <br><br>
* the benefit of submitting puts in this manner is to minimize the number of regionserver rpcs, thus this will
* produce one rpc of puts per regionserver.
* <br><br>
* assumption #1:  regions have been pre-created for the table.  if they haven't, then all of the puts will go to the same region,
* defeating the purpose of this utility method. see the apache hbase book for an explanation of how to do this.
* <br>
* assumption #2:  row-keys are not monotonically increasing.  see the apache hbase book for an explanation of this problem.
* <br>
* assumption #3:  that the input list of rows is big enough to be useful (in the thousands or more).  the intent of this
* method is to process larger chunks of data.
* <br><br>
* this method accepts a list of row objects because the underlying .batch method accepts a list of row objects.
* <br><br>
* @param htable htable instance for target hbase table
* @param rows list of row instances
* @throws ioexception if a remote or network exception occurs
*/
public static void bucketrsbatch htable htable  list<row> rows  throws ioexception
try
map<string  list<row>> rowmap   creatersrowmap htable  rows
for  list<row> rsrows  rowmap values
htable batch  rsrows
catch  interruptedexception e
throw new ioexception e
private static map<string list<put>> creatersputmap htable htable  list<put> puts  throws ioexception
map<string  list<put>> putmap   new hashmap<string  list<put>>
for  put put  puts
hregionlocation rl   htable getregionlocation  put getrow
string hostname   rl gethostname
list<put> recs   putmap get  hostname
if  recs    null
recs   new arraylist<put> initial_list_size
putmap put  hostname  recs
recs add put
return putmap
private static map<string list<row>> creatersrowmap htable htable  list<row> rows  throws ioexception
map<string  list<row>> rowmap   new hashmap<string  list<row>>
for  row row  rows
hregionlocation rl   htable getregionlocation  row getrow
string hostname   rl gethostname
list<row> recs   rowmap get  hostname
if  recs    null
recs   new arraylist<row> initial_list_size
rowmap put  hostname  recs
recs add row
return rowmap