/**
* copyright 2010 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase mapreduce
import org apache hadoop hbase util base64
import java io ioexception
import java util arraylist
import java util hashset
import java util set
import org apache hadoop conf configuration
import org apache hadoop fs path
import org apache hadoop hbase hbaseconfiguration
import org apache hadoop hbase hcolumndescriptor
import org apache hadoop hbase hconstants
import org apache hadoop hbase htabledescriptor
import org apache hadoop hbase client hbaseadmin
import org apache hadoop hbase client htable
import org apache hadoop hbase client put
import org apache hadoop hbase io immutablebyteswritable
import org apache hadoop hbase util bytes
import org apache hadoop mapreduce job
import org apache hadoop mapreduce lib input fileinputformat
import org apache hadoop mapreduce lib input textinputformat
import org apache hadoop mapreduce lib output fileoutputformat
import org apache hadoop util genericoptionsparser
import com google common base preconditions
import com google common base splitter
import com google common collect lists
/**
* tool to import data from a tsv file.
*
* this tool is rather simplistic - it doesn't do any quoting or
* escaping, but is useful for many data loads.
*
* @see importtsv#usage(string)
*/
public class importtsv
final static string name
final static string mapper_conf_key
final static string skip_lines_conf_key
final static string bulk_output_conf_key
final static string columns_conf_key
final static string separator_conf_key
final static string timestamp_conf_key
final static string default_separator
final static class default_mapper   tsvimportermapper class
private static hbaseadmin hbaseadmin
static class tsvparser
/**
* column families and qualifiers mapped to the tsv columns
*/
private final byte families
private final byte qualifiers
private final byte separatorbyte
private int rowkeycolumnindex
public static string rowkey_column_spec
/**
* @param columnsspecification the list of columns to parser out, comma separated.
* the row key should be the special token tsvparser.rowkey_column_spec
*/
public tsvparser string columnsspecification  string separatorstr
// configure separator
byte separator   bytes tobytes separatorstr
preconditions checkargument separator length    1
separatorbyte   separator
// configure columns
arraylist<string> columnstrings   lists newarraylist
splitter on    trimresults   split columnsspecification
families   new byte
qualifiers   new byte
for  int i   0  i < columnstrings size    i
string str   columnstrings get i
if  rowkey_column_spec equals str
rowkeycolumnindex   i
continue
string parts   str split    2
if  parts length    1
families   str getbytes
qualifiers   hconstants empty_byte_array
else
families   parts getbytes
qualifiers   parts getbytes
public int getrowkeycolumnindex
return rowkeycolumnindex
public byte getfamily int idx
return families
public byte getqualifier int idx
return qualifiers
public parsedline parse byte linebytes  int length
throws badtsvlineexception
// enumerate separator offsets
arraylist<integer> taboffsets   new arraylist<integer> families length
for  int i   0  i < length  i
if  linebytes    separatorbyte
taboffsets add i
if  taboffsets isempty
throw new badtsvlineexception
taboffsets add length
if  taboffsets size   > families length
throw new badtsvlineexception
else if  taboffsets size   <  getrowkeycolumnindex
throw new badtsvlineexception
return new parsedline taboffsets  linebytes
class parsedline
private final arraylist<integer> taboffsets
private byte linebytes
parsedline arraylist<integer> taboffsets  byte linebytes
this taboffsets   taboffsets
this linebytes   linebytes
public int getrowkeyoffset
return getcolumnoffset rowkeycolumnindex
public int getrowkeylength
return getcolumnlength rowkeycolumnindex
public int getcolumnoffset int idx
if  idx > 0
return taboffsets get idx   1    1
else
return 0
public int getcolumnlength int idx
return taboffsets get idx    getcolumnoffset idx
public int getcolumncount
return taboffsets size
public byte getlinebytes
return linebytes
public static class badtsvlineexception extends exception
public badtsvlineexception string err
super err
private static final long serialversionuid   1l
/**
* sets up the actual job.
*
* @param conf  the current configuration.
* @param args  the command line parameters.
* @return the newly created job.
* @throws ioexception when setting up the job fails.
*/
public static job createsubmittablejob configuration conf  string args
throws ioexception  classnotfoundexception
// support non-xml supported characters
// by re-encoding the passed separator as a base64 string.
string actualseparator   conf get separator_conf_key
if  actualseparator    null
conf set separator_conf_key
base64 encodebytes actualseparator getbytes
// see if a non-default mapper was set
string mapperclassname   conf get mapper_conf_key
class mapperclass   mapperclassname    null ?
class forname mapperclassname    default_mapper
string tablename   args
path inputdir   new path args
job job   new job conf  name       tablename
job setjarbyclass mapperclass
fileinputformat setinputpaths job  inputdir
job setinputformatclass textinputformat class
job setmapperclass mapperclass
string hfileoutpath   conf get bulk_output_conf_key
if  hfileoutpath    null
if   doestableexist tablename
createtable conf  tablename
htable table   new htable conf  tablename
job setreducerclass putsortreducer class
path outputdir   new path hfileoutpath
fileoutputformat setoutputpath job  outputdir
job setmapoutputkeyclass immutablebyteswritable class
job setmapoutputvalueclass put class
hfileoutputformat configureincrementalload job  table
else
// no reducers.  just write straight to table.  call inittablereducerjob
// to set up the tableoutputformat.
tablemapreduceutil inittablereducerjob tablename  null  job
job setnumreducetasks 0
tablemapreduceutil adddependencyjars job
tablemapreduceutil adddependencyjars job getconfiguration
com google common base function class    guava used by tsvparser
return job
private static boolean doestableexist string tablename  throws ioexception
return hbaseadmin tableexists tablename getbytes
private static void createtable configuration conf  string tablename
throws ioexception
htabledescriptor htd   new htabledescriptor tablename getbytes
string columns   conf getstrings columns_conf_key
set<string> cfset   new hashset<string>
for  string acolumn   columns
if  tsvparser rowkey_column_spec equals acolumn   continue
// we are only concerned with the first one (in case this is a cf:cq)
cfset add acolumn split    2
for  string cf   cfset
hcolumndescriptor hcd   new hcolumndescriptor bytes tobytes cf
htd addfamily hcd
hbaseadmin createtable htd
/*
* @param errormsg error message.  can be null.
*/
private static void usage final string errormsg
if  errormsg    null    errormsg length   > 0
system err println     errormsg
string usage
name
bulk_output_conf_key
skip_lines_conf_key
separator_conf_key
timestamp_conf_key
mapper_conf_key       default_mapper getname
system err println usage
/**
* used only by test method
* @param conf
*/
static void createhbaseadmin configuration conf  throws ioexception
hbaseadmin   new hbaseadmin conf
/**
* main entry point.
*
* @param args  the command line parameters.
* @throws exception when running the job fails.
*/
public static void main string args  throws exception
configuration conf   hbaseconfiguration create
string otherargs   new genericoptionsparser conf  args  getremainingargs
if  otherargs length < 2
usage     otherargs length
system exit  1
// make sure columns are specified
string columns   conf getstrings columns_conf_key
if  columns    null
usage
columns_conf_key
system exit  1
// make sure they specify exactly one column as the row key
int rowkeysfound 0
for  string col   columns
if  col equals tsvparser rowkey_column_spec   rowkeysfound
if  rowkeysfound    1
usage     tsvparser rowkey_column_spec
system exit  1
// make sure one or more columns are specified
if  columns length < 2
usage
system exit  1
hbaseadmin   new hbaseadmin conf
job job   createsubmittablejob conf  otherargs
system exit job waitforcompletion true  ? 0   1