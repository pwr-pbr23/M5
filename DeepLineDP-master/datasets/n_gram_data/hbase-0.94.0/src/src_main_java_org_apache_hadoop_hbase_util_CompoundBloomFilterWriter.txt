/*
* copyright 2011 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase util
import java io datainput
import java io dataoutput
import java io ioexception
import java util arrays
import java util linkedlist
import java util queue
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop hbase io hfile blocktype
import org apache hadoop hbase io hfile hfileblockindex
import org apache hadoop hbase io hfile inlineblockwriter
import org apache hadoop io rawcomparator
import org apache hadoop io writable
/**
* adds methods required for writing a compound bloom filter to the data
* section of an {@link org.apache.hadoop.hbase.io.hfile.hfile} to the
* {@link compoundbloomfilter} class.
*/
public class compoundbloomfilterwriter extends compoundbloomfilterbase
implements bloomfilterwriter  inlineblockwriter
protected static final log log
logfactory getlog compoundbloomfilterwriter class
/** the current chunk being written to */
private bytebloomfilter chunk
/** previous chunk, so that we can create another similar chunk */
private bytebloomfilter prevchunk
/** maximum fold factor */
private int maxfold
/** the size of individual bloom filter chunks to create */
private int chunkbytesize
/** a bloom filter chunk enqueued for writing */
private static class readychunk
int chunkid
byte firstkey
bytebloomfilter chunk
private queue<readychunk> readychunks   new linkedlist<readychunk>
/** the first key in the current bloom filter chunk. */
private byte firstkeyinchunk   null
private hfileblockindex blockindexwriter bloomblockindexwriter
new hfileblockindex blockindexwriter
/** whether to cache-on-write compound bloom filter chunks */
private boolean cacheonwrite
/**
* @param chunkbytesizehint
*          each chunk's size in bytes. the real chunk size might be different
*          as required by the fold factor.
* @param errorrate
*          target false positive rate
* @param hashtype
*          hash function type to use
* @param maxfold
*          maximum degree of folding allowed
*/
public compoundbloomfilterwriter int chunkbytesizehint  float errorrate
int hashtype  int maxfold  boolean cacheonwrite
rawcomparator<byte> comparator
chunkbytesize   bytebloomfilter computefoldablebytesize
chunkbytesizehint   8  maxfold
this errorrate   errorrate
this hashtype   hashtype
this maxfold   maxfold
this cacheonwrite   cacheonwrite
this comparator   comparator
@override
public boolean shouldwriteblock boolean closing
enqueuereadychunk closing
return  readychunks isempty
/**
* enqueue the current chunk if it is ready to be written out.
*
* @param closing true if we are closing the file, so we do not expect new
*        keys to show up
*/
private void enqueuereadychunk boolean closing
if  chunk    null
chunk getkeycount   < chunk getmaxkeys       closing
return
if  firstkeyinchunk    null
throw new nullpointerexception
closing
chunk getkeycount         chunk getmaxkeys
readychunk readychunk   new readychunk
readychunk chunkid   numchunks   1
readychunk chunk   chunk
readychunk firstkey   firstkeyinchunk
readychunks add readychunk
long prevmaxkeys   chunk getmaxkeys
long prevbytesize   chunk getbytesize
chunk compactbloom
if  log isdebugenabled      prevbytesize    chunk getbytesize
log debug     readychunk chunkid
prevmaxkeys       prevbytesize
chunk getmaxkeys         chunk getbytesize
totalmaxkeys    chunk getmaxkeys
totalbytesize    chunk getbytesize
firstkeyinchunk   null
prevchunk   chunk
chunk   null
/**
* adds a bloom filter key. this key must be greater than the previous key,
* as defined by the comparator this compound bloom filter is configured
* with. for efficiency, key monotonicity is not checked here. see
* {@link org.apache.hadoop.hbase.regionserver.storefile.writer#append(
* org.apache.hadoop.hbase.keyvalue)} for the details of deduplication.
*/
@override
public void add byte bloomkey  int keyoffset  int keylength
if  bloomkey    null
throw new nullpointerexception
enqueuereadychunk false
if  chunk    null
if  firstkeyinchunk    null
throw new illegalstateexception
bytes tostringbinary firstkeyinchunk
firstkeyinchunk   arrays copyofrange bloomkey  keyoffset  keyoffset
keylength
if  prevchunk    null
// first chunk
chunk   bytebloomfilter createbysize chunkbytesize  errorrate
hashtype  maxfold
else
// use the same parameters as the last chunk, but a new array and
// a zero key count.
chunk   prevchunk createanother
if  chunk getkeycount      0
throw new illegalstateexception     chunk getkeycount
chunk allocbloom
numchunks
chunk add bloomkey  keyoffset  keylength
totalkeycount
@override
public void writeinlineblock dataoutput out  throws ioexception
// we don't remove the chunk from the queue here, because we might need it
// again for cache-on-write.
readychunk readychunk   readychunks peek
bytebloomfilter readychunkbloom   readychunk chunk
readychunkbloom getdatawriter   write out
@override
public void blockwritten long offset  int ondisksize  int uncompressedsize
readychunk readychunk   readychunks remove
bloomblockindexwriter addentry readychunk firstkey  offset  ondisksize
@override
public blocktype getinlineblocktype
return blocktype bloom_chunk
private class metawriter implements writable
protected metawriter
@override
public void readfields datainput in  throws ioexception
throw new ioexception
/**
* this is modeled after {@link bytebloomfilter.metawriter} for simplicity,
* although the two metadata formats do not have to be consistent. this
* does have to be consistent with how {@link
* compoundbloomfilter#compoundbloomfilter(datainput,
* org.apache.hadoop.hbase.io.hfile.hfile.reader)} reads fields.
*/
@override
public void write dataoutput out  throws ioexception
out writeint version
out writelong getbytesize
out writeint prevchunk gethashcount
out writeint prevchunk gethashtype
out writelong getkeycount
out writelong getmaxkeys
// fields that don't have equivalents in bytebloomfilter.
out writeint numchunks
bytes writebytearray out
bytes tobytes comparator getclass   getname
// write a single-level index without compression or block header.
bloomblockindexwriter writesinglelevelindex out
@override
public writable getmetawriter
return new metawriter
@override
public void compactbloom
@override
public void allocbloom
// nothing happens here. all allocation happens on demand.
@override
public writable getdatawriter
return null
@override
public boolean cacheonwrite
return cacheonwrite