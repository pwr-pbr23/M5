/**
* copyright 2010 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase mapred
import java io ioexception
import org apache hadoop hbase client htable
import org apache hadoop hbase client result
import org apache hadoop hbase filter filter
import org apache hadoop hbase io immutablebyteswritable
import org apache hadoop mapred recordreader
/**
* iterate over an hbase table data, return (text, rowresult) pairs
*/
public class tablerecordreader
implements recordreader<immutablebyteswritable  result>
private tablerecordreaderimpl recordreaderimpl   new tablerecordreaderimpl
/**
* restart from survivable exceptions by creating a new scanner.
*
* @param firstrow
* @throws ioexception
*/
public void restart byte firstrow  throws ioexception
this recordreaderimpl restart firstrow
/**
* build the scanner. not done in constructor to allow for extension.
*
* @throws ioexception
*/
public void init   throws ioexception
this recordreaderimpl restart this recordreaderimpl getstartrow
/**
* @param htable the {@link htable} to scan.
*/
public void sethtable htable htable
this recordreaderimpl sethtable htable
/**
* @param inputcolumns the columns to be placed in {@link result}.
*/
public void setinputcolumns final byte  inputcolumns
this recordreaderimpl setinputcolumns inputcolumns
/**
* @param startrow the first row in the split
*/
public void setstartrow final byte  startrow
this recordreaderimpl setstartrow startrow
/**
*
* @param endrow the last row in the split
*/
public void setendrow final byte  endrow
this recordreaderimpl setendrow endrow
/**
* @param rowfilter the {@link filter} to be used.
*/
public void setrowfilter filter rowfilter
this recordreaderimpl setrowfilter rowfilter
public void close
this recordreaderimpl close
/**
* @return immutablebyteswritable
*
* @see org.apache.hadoop.mapred.recordreader#createkey()
*/
public immutablebyteswritable createkey
return this recordreaderimpl createkey
/**
* @return rowresult
*
* @see org.apache.hadoop.mapred.recordreader#createvalue()
*/
public result createvalue
return this recordreaderimpl createvalue
public long getpos
// this should be the ordinal tuple in the range;
// not clear how to calculate...
return this recordreaderimpl getpos
public float getprogress
// depends on the total number of tuples and getpos
return this recordreaderimpl getpos
/**
* @param key hstorekey as input key.
* @param value mapwritable as input value
* @return true if there was more data
* @throws ioexception
*/
public boolean next immutablebyteswritable key  result value
throws ioexception
return this recordreaderimpl next key  value