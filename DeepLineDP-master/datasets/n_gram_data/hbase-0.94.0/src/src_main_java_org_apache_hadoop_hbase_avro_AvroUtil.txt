/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase avro
import java io ioexception
import java nio bytebuffer
import java util collection
import java util list
import org apache avro schema
import org apache avro generic genericarray
import org apache avro generic genericdata
import org apache avro util utf8
import org apache hadoop hbase clusterstatus
import org apache hadoop hbase hcolumndescriptor
import org apache hadoop hbase hserveraddress
import org apache hadoop hbase hserverload
import org apache hadoop hbase htabledescriptor
import org apache hadoop hbase keyvalue
import org apache hadoop hbase servername
import org apache hadoop hbase avro generated aclusterstatus
import org apache hadoop hbase avro generated acolumn
import org apache hadoop hbase avro generated acolumnvalue
import org apache hadoop hbase avro generated acompressionalgorithm
import org apache hadoop hbase avro generated adelete
import org apache hadoop hbase avro generated afamilydescriptor
import org apache hadoop hbase avro generated aget
import org apache hadoop hbase avro generated aillegalargument
import org apache hadoop hbase avro generated aput
import org apache hadoop hbase avro generated aregionload
import org apache hadoop hbase avro generated aresult
import org apache hadoop hbase avro generated aresultentry
import org apache hadoop hbase avro generated ascan
import org apache hadoop hbase avro generated aserveraddress
import org apache hadoop hbase avro generated aserverinfo
import org apache hadoop hbase avro generated aserverload
import org apache hadoop hbase avro generated atabledescriptor
import org apache hadoop hbase client delete
import org apache hadoop hbase client get
import org apache hadoop hbase client put
import org apache hadoop hbase client result
import org apache hadoop hbase client scan
import org apache hadoop hbase io hfile compression
import org apache hadoop hbase util bytes
public class avroutil
//
// cluster metadata
//
static public aserveraddress hsatoasa hserveraddress hsa  throws ioexception
aserveraddress asa   new aserveraddress
asa hostname   new utf8 hsa gethostname
asa inetsocketaddress   new utf8 hsa getinetsocketaddress   tostring
asa port   hsa getport
return asa
static public aregionload hrltoarl hserverload regionload rl  throws ioexception
aregionload arl   new aregionload
arl memstoresizemb   rl getmemstoresizemb
arl name   bytebuffer wrap rl getname
arl storefileindexsizemb   rl getstorefileindexsizemb
arl storefiles   rl getstorefiles
arl storefilesizemb   rl getstorefilesizemb
arl stores   rl getstores
return arl
static public aserverload hsltoasl hserverload hsl  throws ioexception
aserverload asl   new aserverload
asl load   hsl getload
asl maxheapmb   hsl getmaxheapmb
asl memstoresizeinmb   hsl getmemstoresizeinmb
asl numberofregions   hsl getnumberofregions
asl numberofrequests   hsl getnumberofrequests
collection<hserverload regionload> regionloads   hsl getregionsload   values
schema s   schema createarray aregionload schema$
genericdata array<aregionload> aregionloads   null
if  regionloads    null
aregionloads   new genericdata array<aregionload> regionloads size    s
for  hserverload regionload rl   regionloads
aregionloads add hrltoarl rl
else
aregionloads   new genericdata array<aregionload> 0  s
asl regionsload   aregionloads
asl storefileindexsizeinmb   hsl getstorefileindexsizeinmb
asl storefiles   hsl getstorefiles
asl storefilesizeinmb   hsl getstorefilesizeinmb
asl usedheapmb   hsl getusedheapmb
return asl
static public aserverinfo hsitoasi servername sn  hserverload hsl  throws ioexception
aserverinfo asi   new aserverinfo
asi infoport    1
asi load   hsltoasl hsl
asi serveraddress   hsatoasa new hserveraddress sn gethostname    sn getport
asi servername   new utf8 sn tostring
asi startcode   sn getstartcode
return asi
static public aclusterstatus cstoacs clusterstatus cs  throws ioexception
aclusterstatus acs   new aclusterstatus
acs averageload   cs getaverageload
collection<servername> deadservernames   cs getdeadservernames
schema stringarrayschema   schema createarray schema create schema type string
genericdata array<charsequence> adeadservernames   null
if  deadservernames    null
adeadservernames   new genericdata array<charsequence> deadservernames size    stringarrayschema
for  servername deadservername   deadservernames
adeadservernames add new utf8 deadservername tostring
else
adeadservernames   new genericdata array<charsequence> 0  stringarrayschema
acs deadservernames   adeadservernames
acs deadservers   cs getdeadservers
acs hbaseversion   new utf8 cs gethbaseversion
acs regionscount   cs getregionscount
acs requestscount   cs getrequestscount
collection<servername> hserverinfos   cs getservers
schema s   schema createarray aserverinfo schema$
genericdata array<aserverinfo> aserverinfos   null
if  hserverinfos    null
aserverinfos   new genericdata array<aserverinfo> hserverinfos size    s
for  servername hsi   hserverinfos
aserverinfos add hsitoasi hsi  cs getload hsi
else
aserverinfos   new genericdata array<aserverinfo> 0  s
acs serverinfos   aserverinfos
acs servers   cs getservers   size
return acs
//
// table metadata
//
static public atabledescriptor htdtoatd htabledescriptor table  throws ioexception
atabledescriptor atd   new atabledescriptor
atd name   bytebuffer wrap table getname
collection<hcolumndescriptor> families   table getfamilies
schema afdschema   schema createarray afamilydescriptor schema$
genericdata array<afamilydescriptor> afamilies   null
if  families size   > 0
afamilies   new genericdata array<afamilydescriptor> families size    afdschema
for  hcolumndescriptor hcd   families
afamilydescriptor afamily   hcdtoafd hcd
afamilies add afamily
else
afamilies   new genericdata array<afamilydescriptor> 0  afdschema
atd families   afamilies
atd maxfilesize   table getmaxfilesize
atd memstoreflushsize   table getmemstoreflushsize
atd rootregion   table isrootregion
atd metaregion   table ismetaregion
atd metatable   table ismetatable
atd readonly   table isreadonly
atd deferredlogflush   table isdeferredlogflush
return atd
static public htabledescriptor atdtohtd atabledescriptor atd  throws ioexception  aillegalargument
htabledescriptor htd   new htabledescriptor bytes tobytes atd name
if  atd families    null    atd families size   > 0
for  afamilydescriptor afd   atd families
htd addfamily afdtohcd afd
if  atd maxfilesize    null
htd setmaxfilesize atd maxfilesize
if  atd memstoreflushsize    null
htd setmemstoreflushsize atd memstoreflushsize
if  atd readonly    null
htd setreadonly atd readonly
if  atd deferredlogflush    null
htd setdeferredlogflush atd deferredlogflush
if  atd rootregion    null    atd metaregion    null    atd metatable    null
aillegalargument aie   new aillegalargument
aie message   new utf8
throw aie
return htd
//
// family metadata
//
static public afamilydescriptor hcdtoafd hcolumndescriptor hcd  throws ioexception
afamilydescriptor afamily   new afamilydescriptor
afamily name   bytebuffer wrap hcd getname
string compressionalgorithm   hcd getcompressiontype   getname
if  compressionalgorithm
afamily compression   acompressionalgorithm lzo
else if  compressionalgorithm
afamily compression   acompressionalgorithm gz
else
afamily compression   acompressionalgorithm none
afamily maxversions   hcd getmaxversions
afamily blocksize   hcd getblocksize
afamily inmemory   hcd isinmemory
afamily timetolive   hcd gettimetolive
afamily blockcacheenabled   hcd isblockcacheenabled
return afamily
static public hcolumndescriptor afdtohcd afamilydescriptor afd  throws ioexception
hcolumndescriptor hcd   new hcolumndescriptor bytes tobytes afd name
acompressionalgorithm compressionalgorithm   afd compression
if  compressionalgorithm    acompressionalgorithm lzo
hcd setcompressiontype compression algorithm lzo
else if  compressionalgorithm    acompressionalgorithm gz
hcd setcompressiontype compression algorithm gz
else
hcd setcompressiontype compression algorithm none
if  afd maxversions    null
hcd setmaxversions afd maxversions
if  afd blocksize    null
hcd setblocksize afd blocksize
if  afd inmemory    null
hcd setinmemory afd inmemory
if  afd timetolive    null
hcd settimetolive afd timetolive
if  afd blockcacheenabled    null
hcd setblockcacheenabled afd blockcacheenabled
return hcd
//
// single-row dml (get)
//
// todo(hammer): more concise idiom than if not null assign?
static public get agettoget aget aget  throws ioexception
get get   new get bytes tobytes aget row
if  aget columns    null
for  acolumn acolumn   aget columns
if  acolumn qualifier    null
get addcolumn bytes tobytes acolumn family   bytes tobytes acolumn qualifier
else
get addfamily bytes tobytes acolumn family
if  aget timestamp    null
get settimestamp aget timestamp
if  aget timerange    null
get settimerange aget timerange minstamp  aget timerange maxstamp
if  aget maxversions    null
get setmaxversions aget maxversions
return get
// todo(hammer): pick one: timestamp or timestamp
static public aresult resulttoaresult result result
aresult aresult   new aresult
byte row   result getrow
aresult row   bytebuffer wrap row    null ? row   new byte
schema s   schema createarray aresultentry schema$
genericdata array<aresultentry> entries   null
list<keyvalue> resultkeyvalues   result list
if  resultkeyvalues    null    resultkeyvalues size   > 0
entries   new genericdata array<aresultentry> resultkeyvalues size    s
for  keyvalue resultkeyvalue   resultkeyvalues
aresultentry entry   new aresultentry
entry family   bytebuffer wrap resultkeyvalue getfamily
entry qualifier   bytebuffer wrap resultkeyvalue getqualifier
entry value   bytebuffer wrap resultkeyvalue getvalue
entry timestamp   resultkeyvalue gettimestamp
entries add entry
else
entries   new genericdata array<aresultentry> 0  s
aresult entries   entries
return aresult
//
// single-row dml (put)
//
static public put aputtoput aput aput  throws ioexception
put put   new put bytes tobytes aput row
for  acolumnvalue acv   aput columnvalues
if  acv timestamp    null
put add bytes tobytes acv family
bytes tobytes acv qualifier
acv timestamp
bytes tobytes acv value
else
put add bytes tobytes acv family
bytes tobytes acv qualifier
bytes tobytes acv value
return put
//
// single-row dml (delete)
//
static public delete adeletetodelete adelete adelete  throws ioexception
delete delete   new delete bytes tobytes adelete row
if  adelete columns    null
for  acolumn acolumn   adelete columns
if  acolumn qualifier    null
delete deletecolumns bytes tobytes acolumn family   bytes tobytes acolumn qualifier
else
delete deletefamily bytes tobytes acolumn family
return delete
//
// multi-row dml (scan)
//
static public scan ascantoscan ascan ascan  throws ioexception
scan scan   new scan
if  ascan startrow    null
scan setstartrow bytes tobytes ascan startrow
if  ascan stoprow    null
scan setstoprow bytes tobytes ascan stoprow
if  ascan columns    null
for  acolumn acolumn   ascan columns
if  acolumn qualifier    null
scan addcolumn bytes tobytes acolumn family   bytes tobytes acolumn qualifier
else
scan addfamily bytes tobytes acolumn family
if  ascan timestamp    null
scan settimestamp ascan timestamp
if  ascan timerange    null
scan settimerange ascan timerange minstamp  ascan timerange maxstamp
if  ascan maxversions    null
scan setmaxversions ascan maxversions
return scan
// todo(hammer): better to return null or empty array?
static public genericarray<aresult> resultstoaresults result results
schema s   schema createarray aresult schema$
genericdata array<aresult> aresults   null
if  results    null    results length > 0
aresults   new genericdata array<aresult> results length  s
for  result result   results
aresults add resulttoaresult result
else
aresults   new genericdata array<aresult> 0  s
return aresults