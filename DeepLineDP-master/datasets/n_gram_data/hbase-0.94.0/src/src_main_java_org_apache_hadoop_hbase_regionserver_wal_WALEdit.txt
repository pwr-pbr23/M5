/**
* copyright 2009 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase regionserver wal
import java io datainput
import java io dataoutput
import java io ioexception
import java util arraylist
import java util list
import java util navigablemap
import java util treemap
import org apache hadoop hbase io heapsize
import org apache hadoop hbase keyvalue
import org apache hadoop hbase util bytes
import org apache hadoop hbase util classsize
import org apache hadoop io writable
/**
* waledit: used in hbase's transaction log (wal) to represent
* the collection of edits (keyvalue objects) corresponding to a
* single transaction. the class implements "writable" interface
* for serializing/deserializing a set of keyvalue items.
*
* previously, if a transaction contains 3 edits to c1, c2, c3 for a row r,
* the hlog would have three log entries as follows:
*
*    <logseq1-for-edit1>:<keyvalue-for-edit-c1>
*    <logseq2-for-edit2>:<keyvalue-for-edit-c2>
*    <logseq3-for-edit3>:<keyvalue-for-edit-c3>
*
* this presents problems because row level atomicity of transactions
* was not guaranteed. if we crash after few of the above appends make
* it, then recovery will restore a partial transaction.
*
* in the new world, all the edits for a given transaction are written
* out as a single record, for example:
*
*   <logseq#-for-entire-txn>:<waledit-for-entire-txn>
*
* where, the waledit is serialized as:
*   <-1, # of edits, <keyvalue>, <keyvalue>, ... >
* for example:
*   <-1, 3, <keyvalue-for-edit-c1>, <keyvalue-for-edit-c2>, <keyvalue-for-edit-c3>>
*
* the -1 marker is just a special way of being backward compatible with
* an old hlog which would have contained a single <keyvalue>.
*
* the deserializer for waledit backward compatibly detects if the record
* is an old style keyvalue or the new style waledit.
*
*/
public class waledit implements writable  heapsize
private final int version_2    1
private final arraylist<keyvalue> kvs   new arraylist<keyvalue>
private navigablemap<byte  integer> scopes
private compressioncontext compressioncontext
public waledit
public void setcompressioncontext final compressioncontext compressioncontext
this compressioncontext   compressioncontext
public void add keyvalue kv
this kvs add kv
public boolean isempty
return kvs isempty
public int size
return kvs size
public list<keyvalue> getkeyvalues
return kvs
public navigablemap<byte  integer> getscopes
return scopes
public void setscopes  navigablemap<byte  integer> scopes
// we currently process the map outside of waledit,
// todo revisit when replication is part of core
this scopes   scopes
public void readfields datainput in  throws ioexception
kvs clear
if  scopes    null
scopes clear
int versionorlength   in readint
if  versionorlength    version_2
// this is new style hlog entry containing multiple keyvalues.
int numedits   in readint
for  int idx   0  idx < numedits  idx
if  compressioncontext    null
this add keyvaluecompression readkv in  compressioncontext
else
keyvalue kv   new keyvalue
kv readfields in
this add kv
int numfamilies   in readint
if  numfamilies > 0
if  scopes    null
scopes   new treemap<byte  integer> bytes bytes_comparator
for  int i   0  i < numfamilies  i
byte fam   bytes readbytearray in
int scope   in readint
scopes put fam  scope
else
// this is an old style hlog entry. the int that we just
// read is actually the length of a single keyvalue
keyvalue kv   new keyvalue
kv readfields versionorlength  in
this add kv
public void write dataoutput out  throws ioexception
out writeint version_2
out writeint kvs size
// we interleave the two lists for code simplicity
for  keyvalue kv   kvs
if  compressioncontext    null
keyvaluecompression writekv out  kv  compressioncontext
else
kv write out
if  scopes    null
out writeint 0
else
out writeint scopes size
for  byte key   scopes keyset
bytes writebytearray out  key
out writeint scopes get key
public long heapsize
long ret   0
for  keyvalue kv   kvs
ret    kv heapsize
if  scopes    null
ret    classsize treemap
ret    classsize align scopes size     classsize map_entry
// todo this isn't quite right, need help here
return ret
public string tostring
stringbuilder sb   new stringbuilder
sb append     kvs size
for  keyvalue kv   kvs
sb append kv tostring
sb append
if  scopes    null
sb append     scopes tostring
sb append
return sb tostring