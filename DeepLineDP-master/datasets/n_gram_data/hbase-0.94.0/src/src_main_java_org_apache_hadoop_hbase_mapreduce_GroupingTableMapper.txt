/**
* copyright 2007 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase mapreduce
import java io ioexception
import java io unsupportedencodingexception
import java util arraylist
import org apache hadoop conf configurable
import org apache hadoop conf configuration
import org apache hadoop hbase keyvalue
import org apache hadoop hbase hconstants
import org apache hadoop hbase client result
import org apache hadoop hbase client scan
import org apache hadoop hbase io immutablebyteswritable
import org apache hadoop hbase util bytes
import org apache hadoop mapreduce job
/**
* extract grouping columns from input record.
*/
public class groupingtablemapper
extends tablemapper<immutablebyteswritable result> implements configurable
/**
* jobconf parameter to specify the columns used to produce the key passed to
* collect from the map phase.
*/
public static final string group_columns
/** the grouping columns. */
protected byte  columns
/** the current configuration. */
private configuration conf   null
/**
* use this before submitting a tablemap job. it will appropriately set up
* the job.
*
* @param table the table to be processed.
* @param scan  the scan with the columns etc.
* @param groupcolumns  a space separated list of columns used to form the
* key used in collect.
* @param mapper  the mapper class.
* @param job  the current job.
* @throws ioexception when setting up the job fails.
*/
@suppresswarnings
public static void initjob string table  scan scan  string groupcolumns
class<? extends tablemapper> mapper  job job  throws ioexception
tablemapreduceutil inittablemapperjob table  scan  mapper
immutablebyteswritable class  result class  job
job getconfiguration   set group_columns  groupcolumns
/**
* extract the grouping columns from value to construct a new key. pass the
* new key and value to reduce. if any of the grouping columns are not found
* in the value, the record is skipped.
*
* @param key  the current key.
* @param value  the current value.
* @param context  the current context.
* @throws ioexception when writing the record fails.
* @throws interruptedexception when the job is aborted.
*/
@override
public void map immutablebyteswritable key  result value  context context
throws ioexception  interruptedexception
byte keyvals   extractkeyvalues value
if keyvals    null
immutablebyteswritable tkey   creategroupkey keyvals
context write tkey  value
/**
* extract columns values from the current record. this method returns
* null if any of the columns are not found.
* <p>
* override this method if you want to deal with nulls differently.
*
* @param r  the current values.
* @return array of byte values.
*/
protected byte extractkeyvalues result r
byte keyvals   null
arraylist<byte> foundlist   new arraylist<byte>
int numcols   columns length
if  numcols > 0
for  keyvalue value  r list
byte  column   keyvalue makecolumn value getfamily
value getqualifier
for  int i   0  i < numcols  i
if  bytes equals column  columns
foundlist add value getvalue
break
if foundlist size      numcols
keyvals   foundlist toarray new byte
return keyvals
/**
* create a key by concatenating multiple column values.
* <p>
* override this function in order to produce different types of keys.
*
* @param vals  the current key/values.
* @return a key generated by concatenating multiple column values.
*/
protected immutablebyteswritable creategroupkey byte vals
if vals    null
return null
stringbuilder sb    new stringbuilder
for int i   0  i < vals length  i
if i > 0
sb append
try
sb append new string vals  hconstants utf8_encoding
catch  unsupportedencodingexception e
throw new runtimeexception e
return new immutablebyteswritable bytes tobytes sb tostring
/**
* returns the current configuration.
*
* @return the current configuration.
* @see org.apache.hadoop.conf.configurable#getconf()
*/
@override
public configuration getconf
return conf
/**
* sets the configuration. this is used to set up the grouping details.
*
* @param configuration  the configuration to set.
* @see org.apache.hadoop.conf.configurable#setconf(
*   org.apache.hadoop.conf.configuration)
*/
@override
public void setconf configuration configuration
this conf   configuration
string cols   conf get group_columns     split
columns   new byte
for int i   0  i < cols length  i
columns   bytes tobytes cols