/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase mapreduce hadoopbackport
import java io ioexception
import java lang reflect constructor
import java util arraylist
import java util arrays
import java util list
import java util random
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop conf configuration
import org apache hadoop conf configured
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop io nullwritable
import org apache hadoop io rawcomparator
import org apache hadoop io sequencefile
import org apache hadoop io writablecomparable
import org apache hadoop mapreduce inputformat
import org apache hadoop mapreduce inputsplit
import org apache hadoop mapreduce job
import org apache hadoop mapreduce recordreader
import org apache hadoop mapreduce taskattemptcontext
import org apache hadoop mapreduce taskattemptid
import org apache hadoop mapreduce lib input fileinputformat
import org apache hadoop util reflectionutils
import org apache hadoop util tool
import org apache hadoop util toolrunner
/**
* utility for collecting samples and writing a partition file for
* {@link totalorderpartitioner}.
*
* this is an identical copy of o.a.h.mapreduce.lib.partition.totalorderpartitioner
* from hadoop trunk at r961542, with the exception of replacing
* taskattemptcontextimpl with taskattemptcontext.
*/
public class inputsampler<k v> extends configured implements tool
private static final log log   logfactory getlog inputsampler class
static int printusage
system out println
system out println
toolrunner printgenericcommandusage system out
return  1
public inputsampler configuration conf
setconf conf
/**
* interface to sample using an
* {@link org.apache.hadoop.mapreduce.inputformat}.
*/
public interface sampler<k v>
/**
* for a given job, collect and return a subset of the keys from the
* input data.
*/
k getsample inputformat<k v> inf  job job
throws ioexception  interruptedexception
/**
* samples the first n records from s splits.
* inexpensive way to sample random data.
*/
public static class splitsampler<k v> implements sampler<k v>
private final int numsamples
private final int maxsplitssampled
/**
* create a splitsampler sampling <em>all</em> splits.
* takes the first numsamples / numsplits records from each split.
* @param numsamples total number of samples to obtain from all selected
*                   splits.
*/
public splitsampler int numsamples
this numsamples  integer max_value
/**
* create a new splitsampler.
* @param numsamples total number of samples to obtain from all selected
*                   splits.
* @param maxsplitssampled the maximum number of splits to examine.
*/
public splitsampler int numsamples  int maxsplitssampled
this numsamples   numsamples
this maxsplitssampled   maxsplitssampled
/**
* from each split sampled, take the first numsamples / numsplits records.
*/
@suppresswarnings       arraylist  toarray doesn't preserve type
public k getsample inputformat<k v> inf  job job
throws ioexception  interruptedexception
list<inputsplit> splits   inf getsplits job
arraylist<k> samples   new arraylist<k> numsamples
int splitstosample   math min maxsplitssampled  splits size
int samplespersplit   numsamples   splitstosample
long records   0
for  int i   0  i < splitstosample    i
taskattemptcontext samplingcontext   gettaskattemptcontext job
recordreader<k v> reader   inf createrecordreader
splits get i   samplingcontext
reader initialize splits get i   samplingcontext
while  reader nextkeyvalue
samples add reflectionutils copy job getconfiguration
reader getcurrentkey    null
records
if   i 1    samplespersplit <  records
break
reader close
return  k samples toarray
/**
* this method is about making hbase portable, making it so it can run on
* more than just hadoop 0.20.  in later hadoops, taskattemptcontext became
* an interface.  but in hadoops where tac is an interface, we shouldn't
* be using the classes that are in this package; we should be using the
* native hadoop ones (we'll throw a classnotfoundexception if end up in
* here when we should be using native hadoop totalorderpartitioner).
* @param job
* @return context
* @throws ioexception
*/
public static taskattemptcontext gettaskattemptcontext final job job
throws ioexception
constructor<taskattemptcontext> c
try
c   taskattemptcontext class getconstructor configuration class  taskattemptid class
catch  exception e
throw new ioexception    e
try
return c newinstance job getconfiguration    new taskattemptid
catch  exception e
throw new ioexception    e
/**
* sample from random points in the input.
* general-purpose sampler. takes numsamples / maxsplitssampled inputs from
* each split.
*/
public static class randomsampler<k v> implements sampler<k v>
private double freq
private final int numsamples
private final int maxsplitssampled
/**
* create a new randomsampler sampling <em>all</em> splits.
* this will read every split at the client, which is very expensive.
* @param freq probability with which a key will be chosen.
* @param numsamples total number of samples to obtain from all selected
*                   splits.
*/
public randomsampler double freq  int numsamples
this freq  numsamples  integer max_value
/**
* create a new randomsampler.
* @param freq probability with which a key will be chosen.
* @param numsamples total number of samples to obtain from all selected
*                   splits.
* @param maxsplitssampled the maximum number of splits to examine.
*/
public randomsampler double freq  int numsamples  int maxsplitssampled
this freq   freq
this numsamples   numsamples
this maxsplitssampled   maxsplitssampled
/**
* randomize the split order, then take the specified number of keys from
* each split sampled, where each key is selected with the specified
* probability and possibly replaced by a subsequently selected key when
* the quota of keys from that split is satisfied.
*/
@suppresswarnings       arraylist  toarray doesn't preserve type
public k getsample inputformat<k v> inf  job job
throws ioexception  interruptedexception
list<inputsplit> splits   inf getsplits job
arraylist<k> samples   new arraylist<k> numsamples
int splitstosample   math min maxsplitssampled  splits size
random r   new random
long seed   r nextlong
r setseed seed
log debug     seed
// shuffle splits
for  int i   0  i < splits size      i
inputsplit tmp   splits get i
int j   r nextint splits size
splits set i  splits get j
splits set j  tmp
// our target rate is in terms of the maximum number of sample splits,
// but we accept the possibility of sampling additional splits to hit
// the target sample keyset
for  int i   0  i < splitstosample
i < splits size      samples size   < numsamples     i
taskattemptcontext samplingcontext   gettaskattemptcontext job
recordreader<k v> reader   inf createrecordreader
splits get i   samplingcontext
reader initialize splits get i   samplingcontext
while  reader nextkeyvalue
if  r nextdouble   <  freq
if  samples size   < numsamples
samples add reflectionutils copy job getconfiguration
reader getcurrentkey    null
else
// when exceeding the maximum number of samples, replace a
// random element with this one, then adjust the frequency
// to reflect the possibility of existing elements being
// pushed out
int ind   r nextint numsamples
if  ind    numsamples
samples set ind  reflectionutils copy job getconfiguration
reader getcurrentkey    null
freq     numsamples   1     double  numsamples
reader close
return  k samples toarray
/**
* sample from s splits at regular intervals.
* useful for sorted data.
*/
public static class intervalsampler<k v> implements sampler<k v>
private final double freq
private final int maxsplitssampled
/**
* create a new intervalsampler sampling <em>all</em> splits.
* @param freq the frequency with which records will be emitted.
*/
public intervalsampler double freq
this freq  integer max_value
/**
* create a new intervalsampler.
* @param freq the frequency with which records will be emitted.
* @param maxsplitssampled the maximum number of splits to examine.
* @see #getsample
*/
public intervalsampler double freq  int maxsplitssampled
this freq   freq
this maxsplitssampled   maxsplitssampled
/**
* for each split sampled, emit when the ratio of the number of records
* retained to the total record count is less than the specified
* frequency.
*/
@suppresswarnings       arraylist  toarray doesn't preserve type
public k getsample inputformat<k v> inf  job job
throws ioexception  interruptedexception
list<inputsplit> splits   inf getsplits job
arraylist<k> samples   new arraylist<k>
int splitstosample   math min maxsplitssampled  splits size
long records   0
long kept   0
for  int i   0  i < splitstosample    i
taskattemptcontext samplingcontext   gettaskattemptcontext job
recordreader<k v> reader   inf createrecordreader
splits get i   samplingcontext
reader initialize splits get i   samplingcontext
while  reader nextkeyvalue
records
if   double  kept   records < freq
samples add reflectionutils copy job getconfiguration
reader getcurrentkey    null
kept
reader close
return  k samples toarray
/**
* write a partition file for the given job, using the sampler provided.
* queries the sampler for a sample keyset, sorts by the output key
* comparator, selects the keys for each rank, and writes to the destination
* returned from {@link totalorderpartitioner#getpartitionfile}.
*/
@suppresswarnings       getinputformat  getoutputkeycomparator
public static <k v> void writepartitionfile job job  sampler<k v> sampler
throws ioexception  classnotfoundexception  interruptedexception
configuration conf   job getconfiguration
final inputformat inf
reflectionutils newinstance job getinputformatclass    conf
int numpartitions   job getnumreducetasks
k samples   sampler getsample inf  job
log info     samples length
rawcomparator<k> comparator
rawcomparator<k>  job getsortcomparator
arrays sort samples  comparator
path dst   new path totalorderpartitioner getpartitionfile conf
filesystem fs   dst getfilesystem conf
if  fs exists dst
fs delete dst  false
sequencefile writer writer   sequencefile createwriter fs
conf  dst  job getmapoutputkeyclass    nullwritable class
nullwritable nullvalue   nullwritable get
float stepsize   samples length    float  numpartitions
int last    1
for int i   1  i < numpartitions    i
int k   math round stepsize   i
while  last >  k    comparator compare samples  samples     0
k
writer append samples  nullvalue
last   k
writer close
/**
* driver for inputsampler from the command line.
* configures a jobconf instance and calls {@link #writepartitionfile}.
*/
public int run string args  throws exception
job job   new job getconf
arraylist<string> otherargs   new arraylist<string>
sampler<k v> sampler   null
for int i 0  i < args length    i
try
if    equals args
job setnumreducetasks integer parseint args
else if    equals args
job setinputformatclass
class forname args  assubclass inputformat class
else if    equals args
job setmapoutputkeyclass
class forname args  assubclass writablecomparable class
else if    equals args
int numsamples   integer parseint args
int maxsplits   integer parseint args
if  0 >  maxsplits  maxsplits   integer max_value
sampler   new splitsampler<k v> numsamples  maxsplits
else if    equals args
double pcnt   double parsedouble args
int numsamples   integer parseint args
int maxsplits   integer parseint args
if  0 >  maxsplits  maxsplits   integer max_value
sampler   new randomsampler<k v> pcnt  numsamples  maxsplits
else if    equals args
double pcnt   double parsedouble args
int maxsplits   integer parseint args
if  0 >  maxsplits  maxsplits   integer max_value
sampler   new intervalsampler<k v> pcnt  maxsplits
else
otherargs add args
catch  numberformatexception except
system out println     args
return printusage
catch  arrayindexoutofboundsexception except
system out println
args
return printusage
if  job getnumreducetasks   <  1
system err println
return printusage
if  otherargs size   < 2
system out println
return printusage
if  null    sampler
sampler   new randomsampler<k v> 0 1  10000  10
path outf   new path otherargs remove otherargs size     1
totalorderpartitioner setpartitionfile getconf    outf
for  string s   otherargs
fileinputformat addinputpath job  new path s
inputsampler <k v>writepartitionfile job  sampler
return 0
public static void main string args  throws exception
inputsampler<? ?> sampler   new inputsampler new configuration
int res   toolrunner run sampler  args
system exit res