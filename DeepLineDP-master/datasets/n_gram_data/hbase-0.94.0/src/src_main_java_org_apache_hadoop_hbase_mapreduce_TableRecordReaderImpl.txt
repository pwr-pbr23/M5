/**
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase mapreduce
import java io ioexception
import java lang reflect method
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop hbase donotretryioexception
import org apache hadoop hbase client htable
import org apache hadoop hbase client result
import org apache hadoop hbase client resultscanner
import org apache hadoop hbase client scan
import org apache hadoop hbase client metrics scanmetrics
import org apache hadoop hbase io immutablebyteswritable
import org apache hadoop hbase util bytes
import org apache hadoop io datainputbuffer
import org apache hadoop mapreduce counter
import org apache hadoop mapreduce inputsplit
import org apache hadoop mapreduce taskattemptcontext
import org apache hadoop metrics util metricstimevaryinglong
import org apache hadoop util stringutils
/**
* iterate over an hbase table data, return (immutablebyteswritable, result)
* pairs.
*/
public class tablerecordreaderimpl
static final log log   logfactory getlog tablerecordreader class
// hbase_counter_group_name is the name of mapreduce counter group for hbase
private static final string hbase_counter_group_name
private resultscanner scanner   null
private scan scan   null
private scan currentscan   null
private htable htable   null
private byte lastsuccessfulrow   null
private immutablebyteswritable key   null
private result value   null
private taskattemptcontext context   null
private method getcounter   null
/**
* restart from survivable exceptions by creating a new scanner.
*
* @param firstrow  the first row to start at.
* @throws ioexception when restarting fails.
*/
public void restart byte firstrow  throws ioexception
currentscan   new scan scan
currentscan setstartrow firstrow
currentscan setattribute scan scan_attributes_metrics_enable
bytes tobytes boolean true
this scanner   this htable getscanner currentscan
/**
* in new mapreduce apis, taskattemptcontext has two getcounter methods
* check if getcounter(string, string) method is available.
* @return the getcounter method or null if not available.
* @throws ioexception
*/
private method retrievegetcounterwithstringsparams taskattemptcontext context
throws ioexception
method m   null
try
m   context getclass   getmethod
new class   string class  string class
catch  securityexception e
throw new ioexception    e
catch  nosuchmethodexception e
// ignore
return m
/**
* sets the hbase table.
*
* @param htable  the {@link htable} to scan.
*/
public void sethtable htable htable
this htable   htable
/**
* sets the scan defining the actual details like columns etc.
*
* @param scan  the scan to set.
*/
public void setscan scan scan
this scan   scan
/**
* build the scanner. not done in constructor to allow for extension.
*
* @throws ioexception, interruptedexception
*/
public void initialize inputsplit inputsplit
taskattemptcontext context  throws ioexception
interruptedexception
if  context    null
this context   context
getcounter   retrievegetcounterwithstringsparams context
restart scan getstartrow
/**
* closes the split.
*
*
*/
public void close
this scanner close
/**
* returns the current key.
*
* @return the current key.
* @throws ioexception
* @throws interruptedexception when the job is aborted.
*/
public immutablebyteswritable getcurrentkey   throws ioexception
interruptedexception
return key
/**
* returns the current value.
*
* @return the current value.
* @throws ioexception when the value is faulty.
* @throws interruptedexception when the job is aborted.
*/
public result getcurrentvalue   throws ioexception  interruptedexception
return value
/**
* positions the record reader to the next record.
*
* @return <code>true</code> if there was another record.
* @throws ioexception when reading the record failed.
* @throws interruptedexception when the job was aborted.
*/
public boolean nextkeyvalue   throws ioexception  interruptedexception
if  key    null  key   new immutablebyteswritable
if  value    null  value   new result
try
value   this scanner next
catch  donotretryioexception e
throw e
catch  ioexception e
log info     stringutils stringifyexception e
if  lastsuccessfulrow    null
log warn
if  lastsuccessfulrow    null
restart scan getstartrow
else
restart lastsuccessfulrow
scanner next          skip presumed already mapped row
value   scanner next
if  value    null    value size   > 0
key set value getrow
lastsuccessfulrow   key get
return true
updatecounters
return false
/**
* if hbase runs on new version of mapreduce, recordreader has access to
* counters thus can update counters based on scanmetrics.
* if hbase runs on old version of mapreduce, it won't be able to get
* access to counters and tablerecorderreader can't update counter values.
* @throws ioexception
*/
private void updatecounters   throws ioexception
// we can get access to counters only if hbase uses new mapreduce apis
if  this getcounter    null
return
byte serializedmetrics   currentscan getattribute
scan scan_attributes_metrics_data
if  serializedmetrics    null    serializedmetrics length    0
return
datainputbuffer in   new datainputbuffer
in reset serializedmetrics  0  serializedmetrics length
scanmetrics scanmetrics   new scanmetrics
scanmetrics readfields in
metricstimevaryinglong mlvs
scanmetrics getmetricstimevaryinglongarray
try
for  metricstimevaryinglong mlv   mlvs
counter ct    counter this getcounter invoke context
hbase_counter_group_name  mlv getname
ct increment mlv getcurrentintervalvalue
catch  exception e
log debug     stringutils stringifyexception e
/**
* the current progress of the record reader through its data.
*
* @return a number between 0.0 and 1.0, the fraction of the data read.
*/
public float getprogress
// depends on the total number of tuples
return 0