/**
* copyright 2010 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase mapred
import java io ioexception
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop hbase donotretryioexception
import org apache hadoop hbase client htable
import org apache hadoop hbase client result
import org apache hadoop hbase client resultscanner
import org apache hadoop hbase client scan
import org apache hadoop hbase filter filter
import org apache hadoop hbase io immutablebyteswritable
import org apache hadoop hbase mapreduce tableinputformat
import org apache hadoop hbase util bytes
import org apache hadoop hbase util writables
import org apache hadoop util stringutils
/**
* iterate over an hbase table data, return (text, rowresult) pairs
*/
public class tablerecordreaderimpl
static final log log   logfactory getlog tablerecordreaderimpl class
private byte  startrow
private byte  endrow
private byte  lastsuccessfulrow
private filter trrrowfilter
private resultscanner scanner
private htable htable
private byte  trrinputcolumns
/**
* restart from survivable exceptions by creating a new scanner.
*
* @param firstrow
* @throws ioexception
*/
public void restart byte firstrow  throws ioexception
if   endrow    null      endrow length > 0
if  trrrowfilter    null
scan scan   new scan firstrow  endrow
tableinputformat addcolumns scan  trrinputcolumns
scan setfilter trrrowfilter
scan setcacheblocks false
this scanner   this htable getscanner scan
else
log debug
bytes tostringbinary firstrow
bytes tostringbinary endrow
scan scan   new scan firstrow  endrow
tableinputformat addcolumns scan  trrinputcolumns
this scanner   this htable getscanner scan
else
log debug
bytes tostringbinary firstrow
scan scan   new scan firstrow
tableinputformat addcolumns scan  trrinputcolumns
scan setfilter trrrowfilter
this scanner   this htable getscanner scan
/**
* build the scanner. not done in constructor to allow for extension.
*
* @throws ioexception
*/
public void init   throws ioexception
restart startrow
byte getstartrow
return this startrow
/**
* @param htable the {@link htable} to scan.
*/
public void sethtable htable htable
this htable   htable
/**
* @param inputcolumns the columns to be placed in {@link result}.
*/
public void setinputcolumns final byte  inputcolumns
this trrinputcolumns   inputcolumns
/**
* @param startrow the first row in the split
*/
public void setstartrow final byte  startrow
this startrow   startrow
/**
*
* @param endrow the last row in the split
*/
public void setendrow final byte  endrow
this endrow   endrow
/**
* @param rowfilter the {@link filter} to be used.
*/
public void setrowfilter filter rowfilter
this trrrowfilter   rowfilter
public void close
this scanner close
/**
* @return immutablebyteswritable
*
* @see org.apache.hadoop.mapred.recordreader#createkey()
*/
public immutablebyteswritable createkey
return new immutablebyteswritable
/**
* @return rowresult
*
* @see org.apache.hadoop.mapred.recordreader#createvalue()
*/
public result createvalue
return new result
public long getpos
// this should be the ordinal tuple in the range;
// not clear how to calculate...
return 0
public float getprogress
// depends on the total number of tuples and getpos
return 0
/**
* @param key hstorekey as input key.
* @param value mapwritable as input value
* @return true if there was more data
* @throws ioexception
*/
public boolean next immutablebyteswritable key  result value
throws ioexception
result result
try
result   this scanner next
catch  donotretryioexception e
throw e
catch  ioexception e
log debug     stringutils stringifyexception e
if  lastsuccessfulrow    null
log warn
if  lastsuccessfulrow    null
restart startrow
else
restart lastsuccessfulrow
this scanner next          skip presumed already mapped row
result   this scanner next
if  result    null    result size   > 0
key set result getrow
lastsuccessfulrow   key get
writables copywritable result  value
return true
return false