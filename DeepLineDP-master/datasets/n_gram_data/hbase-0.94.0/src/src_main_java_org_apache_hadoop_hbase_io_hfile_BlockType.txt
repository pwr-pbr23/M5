/*
* copyright 2011 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase io hfile
import java io datainputstream
import java io dataoutput
import java io ioexception
import java io outputstream
import java nio bytebuffer
import org apache hadoop hbase util bytes
/**
* various types of {@link hfile} blocks. ordinal values of these enum constants
* must not be relied upon. the values in the enum appear in the order they
* appear in a version 2 {@link hfile}.
*/
public enum blocktype
// scanned block section
/** data block, both versions */
data    blockcategory data
/** an encoded data block (e.g. with prefix compression), version 2 */
encoded_data    blockcategory data
@override
public int getid
return data ordinal
/** version 2 leaf index block. appears in the data block section */
leaf_index    blockcategory index
/** bloom filter block, version 2 */
bloom_chunk    blockcategory bloom
// non-scanned block section
/** meta blocks */
meta    blockcategory meta
/** intermediate-level version 2 index in the non-data block section */
intermediate_index    blockcategory index
// load-on-open section.
/** root index block, also used for the single-level meta index, version 2 */
root_index    blockcategory index
/** file info, version 2 */
file_info    blockcategory meta
/** general bloom filter metadata, version 2 */
general_bloom_meta    blockcategory bloom
/** delete family bloom filter metadata, version 2 */
delete_family_bloom_meta    blockcategory bloom
// trailer
/** fixed file trailer, both versions (always just a magic string) */
trailer  $"  blockcategory meta
// legacy blocks
/** block index magic string in version 1 */
index_v1    blockcategory index
public enum blockcategory
data  meta  index  bloom  all_categories  unknown
/**
* throws an exception if the block category passed is the special category
* meaning "all categories".
*/
public void expectspecific
if  this    all_categories
throw new illegalargumentexception
this
public static final int magic_length   8
private final byte magic
private final blockcategory metriccat
private blocktype string magicstr  blockcategory metriccat
magic   bytes tobytes magicstr
this metriccat   metriccat
assert magic length    magic_length
/**
* use this instead of {@link #ordinal()}. they work exactly the same, except
* data and encoded_data get the same id using this method (overridden for
* {@link #encoded_data}).
* @return block type id from 0 to the number of block types - 1
*/
public int getid
// default implementation, can be overridden for individual enum members.
return ordinal
public void writetostream outputstream out  throws ioexception
out write magic
public void write dataoutput out  throws ioexception
out write magic
public void write bytebuffer buf
buf put magic
public blockcategory getcategory
return metriccat
public static blocktype parse byte buf  int offset  int length
throws ioexception
if  length    magic_length
throw new ioexception
bytes tostringbinary buf  offset  length
for  blocktype blocktype   values
if  bytes compareto blocktype magic  0  magic_length  buf  offset
magic_length     0
return blocktype
throw new ioexception
bytes tostringbinary buf  offset  magic_length
public static blocktype read datainputstream in  throws ioexception
byte buf   new byte
in readfully buf
return parse buf  0  buf length
public static blocktype read bytebuffer buf  throws ioexception
blocktype blocktype   parse buf array
buf arrayoffset     buf position
math min buf limit     buf position    magic_length
// if we got here, we have read exactly magic_length bytes.
buf position buf position     magic_length
return blocktype
/**
* put the magic record out to the specified byte array position.
*
* @param bytes the byte array
* @param offset position in the array
* @return incremented offset
*/
public int put byte bytes  int offset
system arraycopy magic  0  bytes  offset  magic_length
return offset   magic_length
/**
* reads a magic record of the length {@link #magic_length} from the given
* stream and expects it to match this block type.
*/
public void readandcheck datainputstream in  throws ioexception
byte buf   new byte
in readfully buf
if  bytes compareto buf  magic     0
throw new ioexception
bytes tostringbinary magic        bytes tostringbinary buf
/**
* reads a magic record of the length {@link #magic_length} from the given
* byte buffer and expects it to match this block type.
*/
public void readandcheck bytebuffer in  throws ioexception
byte buf   new byte
in get buf
if  bytes compareto buf  magic     0
throw new ioexception
bytes tostringbinary magic        bytes tostringbinary buf
/**
* @return whether this block type is encoded or unencoded data block
*/
public final boolean isdata
return this    data    this    encoded_data