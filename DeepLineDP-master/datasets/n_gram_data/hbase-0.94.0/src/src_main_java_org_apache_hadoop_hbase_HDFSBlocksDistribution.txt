/**
* copyright 2011 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase
import java util arraylist
import java util comparator
import java util list
import java util map
import java util navigableset
import java util treemap
import java util treeset
/**
* data structure to describe the distribution of hdfs blocks amount hosts
*/
public class hdfsblocksdistribution
private map<string hostandweight> hostandweights   null
private long uniqueblockstotalweight   0
/**
* stores the hostname and weight for that hostname.
*
* this is used when determining the physical locations of the blocks making
* up a region.
*
* to make a prioritized list of the hosts holding the most data of a region,
* this class is used to count the total weight for each host.  the weight is
* currently just the size of the file.
*/
public static class hostandweight
private string host
private long weight
/**
* constructor
* @param host the host name
* @param weight the weight
*/
public hostandweight string host  long weight
this host   host
this weight   weight
/**
* add weight
* @param weight the weight
*/
public void addweight long weight
this weight    weight
/**
* @return the host name
*/
public string gethost
return host
/**
* @return the weight
*/
public long getweight
return weight
/**
* comparator used to sort hosts based on weight
*/
public static class weightcomparator implements comparator<hostandweight>
@override
public int compare hostandweight l  hostandweight r
if l getweight      r getweight
return l gethost   compareto r gethost
return l getweight   < r getweight   ?  1   1
/**
* constructor
*/
public hdfsblocksdistribution
this hostandweights
new treemap<string hostandweight>
/**
* @see java.lang.object#tostring()
*/
@override
public synchronized string tostring
return
this hostandweights size
/**
* add some weight to a list of hosts, update the value of unique block weight
* @param hosts the list of the host
* @param weight the weight
*/
public void addhostsandblockweight string hosts  long weight
if  hosts    null    hosts length    0
throw new nullpointerexception
adduniqueweight weight
for  string hostname   hosts
addhostandblockweight hostname  weight
/**
* add some weight to the total unique weight
* @param weight the weight
*/
private void adduniqueweight long weight
uniqueblockstotalweight    weight
/**
* add some weight to a specific host
* @param host the host name
* @param weight the weight
*/
private void addhostandblockweight string host  long weight
if  host    null
throw new nullpointerexception
hostandweight hostandweight   this hostandweights get host
if hostandweight    null
hostandweight   new hostandweight host  weight
this hostandweights put host  hostandweight
else
hostandweight addweight weight
/**
* @return the hosts and their weights
*/
public map<string hostandweight> gethostandweights
return this hostandweights
/**
* return the weight for a specific host, that will be the total bytes of all
* blocks on the host
* @param host the host name
* @return the weight of the given host
*/
public long getweight string host
long weight   0
if  host    null
hostandweight hostandweight   this hostandweights get host
if hostandweight    null
weight   hostandweight getweight
return weight
/**
* @return the sum of all unique blocks' weight
*/
public long getuniqueblockstotalweight
return uniqueblockstotalweight
/**
* return the locality index of a given host
* @param host the host name
* @return the locality index of the given host
*/
public float getblocklocalityindex string host
float localityindex   0
hostandweight hostandweight   this hostandweights get host
if  hostandweight    null    uniqueblockstotalweight    0
localityindex  float hostandweight weight  float uniqueblockstotalweight
return localityindex
/**
* this will add the distribution from input to this object
* @param otherblocksdistribution the other hdfs blocks distribution
*/
public void add hdfsblocksdistribution otherblocksdistribution
map<string hostandweight> otherhostandweights
otherblocksdistribution gethostandweights
for  map entry<string  hostandweight> otherhostandweight
otherhostandweights entryset
addhostandblockweight otherhostandweight getvalue   host
otherhostandweight getvalue   weight
adduniqueweight otherblocksdistribution getuniqueblockstotalweight
/**
* return the sorted list of hosts in terms of their weights
*/
public list<string> gettophosts
navigableset<hostandweight> orderedhosts   new treeset<hostandweight>
new hostandweight weightcomparator
orderedhosts addall this hostandweights values
list<string> tophosts   new arraylist<string> orderedhosts size
for hostandweight haw   orderedhosts descendingset
tophosts add haw gethost
return tophosts