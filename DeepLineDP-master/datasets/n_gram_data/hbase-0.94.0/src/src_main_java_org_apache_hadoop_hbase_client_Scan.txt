/*
* copyright 2010 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase client
import org apache hadoop conf configuration
import org apache hadoop hbase hconstants
import org apache hadoop hbase filter filter
import org apache hadoop hbase filter incompatiblefilterexception
import org apache hadoop hbase io timerange
import org apache hadoop hbase util bytes
import org apache hadoop io writable
import org apache hadoop io writablefactories
import java io datainput
import java io dataoutput
import java io ioexception
import java util arraylist
import java util hashmap
import java util list
import java util map
import java util navigableset
import java util treemap
import java util treeset
/**
* used to perform scan operations.
* <p>
* all operations are identical to {@link get} with the exception of
* instantiation.  rather than specifying a single row, an optional startrow
* and stoprow may be defined.  if rows are not specified, the scanner will
* iterate over all rows.
* <p>
* to scan everything for each row, instantiate a scan object.
* <p>
* to modify scanner caching for just this scan, use {@link #setcaching(int) setcaching}.
* if caching is not set, we will use the caching value of the hosting
* {@link htable}.  see {@link htable#setscannercaching(int)}.
* <p>
* to further define the scope of what to get when scanning, perform additional
* methods as outlined below.
* <p>
* to get all columns from specific families, execute {@link #addfamily(byte[]) addfamily}
* for each family to retrieve.
* <p>
* to get specific columns, execute {@link #addcolumn(byte[], byte[]) addcolumn}
* for each column to retrieve.
* <p>
* to only retrieve columns within a specific range of version timestamps,
* execute {@link #settimerange(long, long) settimerange}.
* <p>
* to only retrieve columns with a specific timestamp, execute
* {@link #settimestamp(long) settimestamp}.
* <p>
* to limit the number of versions of each column to be returned, execute
* {@link #setmaxversions(int) setmaxversions}.
* <p>
* to limit the maximum number of values returned for each call to next(),
* execute {@link #setbatch(int) setbatch}.
* <p>
* to add a filter, execute {@link #setfilter(org.apache.hadoop.hbase.filter.filter) setfilter}.
* <p>
* expert: to explicitly disable server-side block caching for this scan,
* execute {@link #setcacheblocks(boolean)}.
*/
public class scan extends operationwithattributes implements writable
private static final string raw_attr
private static final string isolation_level
private static final byte scan_version    byte 2
private byte  startrow   hconstants empty_start_row
private byte  stoprow    hconstants empty_end_row
private int maxversions   1
private int batch    1
// if application wants to collect scan metrics, it needs to
// call scan.setattribute(scan_attributes_enable, bytes.tobytes(boolean.true))
static public string scan_attributes_metrics_enable
static public string scan_attributes_metrics_data
/*
* -1 means no caching
*/
private int caching    1
private boolean cacheblocks   true
private filter filter   null
private timerange tr   new timerange
private map<byte   navigableset<byte >> familymap
new treemap<byte   navigableset<byte >> bytes bytes_comparator
/**
* create a scan operation across all rows.
*/
public scan
public scan byte  startrow  filter filter
this startrow
this filter   filter
/**
* create a scan operation starting at the specified row.
* <p>
* if the specified row does not exist, the scanner will start from the
* next closest row after the specified row.
* @param startrow row to start scanner at or after
*/
public scan byte  startrow
this startrow   startrow
/**
* create a scan operation for the range of rows specified.
* @param startrow row to start scanner at or after (inclusive)
* @param stoprow row to stop scanner before (exclusive)
*/
public scan byte  startrow  byte  stoprow
this startrow   startrow
this stoprow   stoprow
/**
* creates a new instance of this class while copying all values.
*
* @param scan  the scan instance to copy from.
* @throws ioexception when copying the values fails.
*/
public scan scan scan  throws ioexception
startrow   scan getstartrow
stoprow    scan getstoprow
maxversions   scan getmaxversions
batch   scan getbatch
caching   scan getcaching
cacheblocks   scan getcacheblocks
filter   scan getfilter       clone?
timerange ctr   scan gettimerange
tr   new timerange ctr getmin    ctr getmax
map<byte  navigableset<byte>> fams   scan getfamilymap
for  map entry<byte navigableset<byte>> entry   fams entryset
byte  fam   entry getkey
navigableset<byte> cols   entry getvalue
if  cols    null    cols size   > 0
for  byte col   cols
addcolumn fam  col
else
addfamily fam
for  map entry<string  byte> attr   scan getattributesmap   entryset
setattribute attr getkey    attr getvalue
/**
* builds a scan object with the same specs as get.
* @param get get to model scan after
*/
public scan get get
this startrow   get getrow
this stoprow   get getrow
this filter   get getfilter
this cacheblocks   get getcacheblocks
this maxversions   get getmaxversions
this tr   get gettimerange
this familymap   get getfamilymap
public boolean isgetscan
return this startrow    null    this startrow length > 0
bytes equals this startrow  this stoprow
/**
* get all columns from the specified family.
* <p>
* overrides previous calls to addcolumn for this family.
* @param family family name
* @return this
*/
public scan addfamily byte  family
familymap remove family
familymap put family  null
return this
/**
* get the column from the specified family with the specified qualifier.
* <p>
* overrides previous calls to addfamily for this family.
* @param family family name
* @param qualifier column qualifier
* @return this
*/
public scan addcolumn byte  family  byte  qualifier
navigableset<byte > set   familymap get family
if set    null
set   new treeset<byte > bytes bytes_comparator
set add qualifier
familymap put family  set
return this
/**
* get versions of columns only within the specified timestamp range,
* [minstamp, maxstamp).  note, default maximum versions to return is 1.  if
* your time range spans more than one version and you want all versions
* returned, up the number of versions beyond the defaut.
* @param minstamp minimum timestamp value, inclusive
* @param maxstamp maximum timestamp value, exclusive
* @throws ioexception if invalid time range
* @see #setmaxversions()
* @see #setmaxversions(int)
* @return this
*/
public scan settimerange long minstamp  long maxstamp
throws ioexception
tr   new timerange minstamp  maxstamp
return this
/**
* get versions of columns with the specified timestamp. note, default maximum
* versions to return is 1.  if your time range spans more than one version
* and you want all versions returned, up the number of versions beyond the
* defaut.
* @param timestamp version timestamp
* @see #setmaxversions()
* @see #setmaxversions(int)
* @return this
*/
public scan settimestamp long timestamp
try
tr   new timerange timestamp  timestamp 1
catch ioexception e
// will never happen
return this
/**
* set the start row of the scan.
* @param startrow row to start scan on (inclusive)
* note: in order to make startrow exclusive add a trailing 0 byte
* @return this
*/
public scan setstartrow byte  startrow
this startrow   startrow
return this
/**
* set the stop row.
* @param stoprow row to end at (exclusive)
* note: in order to make stoprow inclusive add a trailing 0 byte
* @return this
*/
public scan setstoprow byte  stoprow
this stoprow   stoprow
return this
/**
* get all available versions.
* @return this
*/
public scan setmaxversions
this maxversions   integer max_value
return this
/**
* get up to the specified number of versions of each column.
* @param maxversions maximum versions for each column
* @return this
*/
public scan setmaxversions int maxversions
this maxversions   maxversions
return this
/**
* set the maximum number of values to return for each call to next()
* @param batch the maximum number of values
*/
public void setbatch int batch
if  this hasfilter      this filter hasfilterrow
throw new incompatiblefilterexception
this batch   batch
/**
* set the number of rows for caching that will be passed to scanners.
* if not set, the default setting from {@link htable#getscannercaching()} will apply.
* higher caching values will enable faster scanners but will use more memory.
* @param caching the number of rows for caching
*/
public void setcaching int caching
this caching   caching
/**
* apply the specified server-side filter when performing the scan.
* @param filter filter to run on the server
* @return this
*/
public scan setfilter filter filter
this filter   filter
return this
/**
* setting the familymap
* @param familymap map of family to qualifier
* @return this
*/
public scan setfamilymap map<byte   navigableset<byte >> familymap
this familymap   familymap
return this
/**
* getting the familymap
* @return familymap
*/
public map<byte   navigableset<byte >> getfamilymap
return this familymap
/**
* @return the number of families in familymap
*/
public int numfamilies
if hasfamilies
return this familymap size
return 0
/**
* @return true if familymap is non empty, false otherwise
*/
public boolean hasfamilies
return  this familymap isempty
/**
* @return the keys of the familymap
*/
public byte getfamilies
if hasfamilies
return this familymap keyset   toarray new byte
return null
/**
* @return the startrow
*/
public byte  getstartrow
return this startrow
/**
* @return the stoprow
*/
public byte  getstoprow
return this stoprow
/**
* @return the max number of versions to fetch
*/
public int getmaxversions
return this maxversions
/**
* @return maximum number of values to return for a single call to next()
*/
public int getbatch
return this batch
/**
* @return caching the number of rows fetched when calling next on a scanner
*/
public int getcaching
return this caching
/**
* @return timerange
*/
public timerange gettimerange
return this tr
/**
* @return rowfilter
*/
public filter getfilter
return filter
/**
* @return true is a filter has been specified, false if not
*/
public boolean hasfilter
return filter    null
/**
* set whether blocks should be cached for this scan.
* <p>
* this is true by default.  when true, default settings of the table and
* family are used (this will never override caching blocks if the block
* cache is disabled for that family or entirely).
*
* @param cacheblocks if false, default settings are overridden and blocks
* will not be cached
*/
public void setcacheblocks boolean cacheblocks
this cacheblocks   cacheblocks
/**
* get whether blocks should be cached for this scan.
* @return true if default caching should be used, false if blocks should not
* be cached
*/
public boolean getcacheblocks
return cacheblocks
/**
* compile the table and column family (i.e. schema) information
* into a string. useful for parsing and aggregation by debugging,
* logging, and administration tools.
* @return map
*/
@override
public map<string  object> getfingerprint
map<string  object> map   new hashmap<string  object>
list<string> families   new arraylist<string>
if this familymap size      0
map put
return map
else
map put    families
for  map entry<byte   navigableset<byte>> entry
this familymap entryset
families add bytes tostringbinary entry getkey
return map
/**
* compile the details beyond the scope of getfingerprint (row, columns,
* timestamps, etc.) into a map along with the fingerprinted information.
* useful for debugging, logging, and administration tools.
* @param maxcols a limit on the number of columns output prior to truncation
* @return map
*/
@override
public map<string  object> tomap int maxcols
// start with the fingerpring map and build on top of it
map<string  object> map   getfingerprint
// map from families to column list replaces fingerprint's list of families
map<string  list<string>> familycolumns
new hashmap<string  list<string>>
map put    familycolumns
// add scalar information first
map put    bytes tostringbinary this startrow
map put    bytes tostringbinary this stoprow
map put    this maxversions
map put    this batch
map put    this caching
map put    this cacheblocks
list<long> timerange   new arraylist<long>
timerange add this tr getmin
timerange add this tr getmax
map put    timerange
int colcount   0
// iterate through affected families and list out up to maxcols columns
for  map entry<byte   navigableset<byte>> entry
this familymap entryset
list<string> columns   new arraylist<string>
familycolumns put bytes tostringbinary entry getkey     columns
if entry getvalue      null
colcount
maxcols
columns add
else
colcount    entry getvalue   size
if  maxcols <  0
continue
for  byte  column   entry getvalue
if    maxcols <  0
continue
columns add bytes tostringbinary column
map put    colcount
if  this filter    null
map put    this filter tostring
return map
@suppresswarnings
private writable createforname string classname
try
class<? extends writable> clazz
class<? extends writable>  class forname classname
return writablefactories newinstance clazz  new configuration
catch  classnotfoundexception e
throw new runtimeexception     classname
//writable
public void readfields final datainput in
throws ioexception
int version   in readbyte
if  version >  int scan_version
throw new ioexception
this startrow   bytes readbytearray in
this stoprow   bytes readbytearray in
this maxversions   in readint
this batch   in readint
this caching   in readint
this cacheblocks   in readboolean
if in readboolean
this filter    filter createforname bytes tostring bytes readbytearray in
this filter readfields in
this tr   new timerange
tr readfields in
int numfamilies   in readint
this familymap
new treemap<byte   navigableset<byte >> bytes bytes_comparator
for int i 0  i<numfamilies  i
byte  family   bytes readbytearray in
int numcolumns   in readint
treeset<byte > set   new treeset<byte > bytes bytes_comparator
for int j 0  j<numcolumns  j
byte  qualifier   bytes readbytearray in
set add qualifier
this familymap put family  set
if  version > 1
readattributes in
public void write final dataoutput out
throws ioexception
out writebyte scan_version
bytes writebytearray out  this startrow
bytes writebytearray out  this stoprow
out writeint this maxversions
out writeint this batch
out writeint this caching
out writeboolean this cacheblocks
if this filter    null
out writeboolean false
else
out writeboolean true
bytes writebytearray out  bytes tobytes filter getclass   getname
filter write out
tr write out
out writeint familymap size
for map entry<byte   navigableset<byte >> entry   familymap entryset
bytes writebytearray out  entry getkey
navigableset<byte > columnset   entry getvalue
if columnset    null
out writeint columnset size
for byte  qualifier   columnset
bytes writebytearray out  qualifier
else
out writeint 0
writeattributes out
/**
* enable/disable "raw" mode for this scan.
* if "raw" is enabled the scan will return all
* delete marker and deleted rows that have not
* been collected, yet.
* this is mostly useful for scan on column families
* that have keep_deleted_rows enabled.
* it is an error to specify any column when "raw" is set.
* @param raw true/false to enable/disable "raw" mode.
*/
public void setraw boolean raw
setattribute raw_attr  bytes tobytes raw
/**
* @return true if this scan is in "raw" mode.
*/
public boolean israw
byte attr   getattribute raw_attr
return attr    null ? false   bytes toboolean attr
/*
* set the isolation level for this scan. if the
* isolation level is set to read_uncommitted, then
* this scan will return data from committed and
* uncommitted transactions. if the isolation level
* is set to read_committed, then this scan will return
* data from committed transactions only. if a isolation
* level is not explicitly set on a scan, then it
* is assumed to be read_committed.
* @param level isolationlevel for this scan
*/
public void setisolationlevel isolationlevel level
setattribute isolation_level  level tobytes
/*
* @return the isolation level of this scan.
* if no isolation level was set for this scan object,
* then it returns read_committed.
* @return the isolationlevel for this scan
*/
public isolationlevel getisolationlevel
byte attr   getattribute isolation_level
return attr    null ? isolationlevel read_committed
isolationlevel frombytes attr