/**
* copyright 2009 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase mapreduce
import java io ioexception
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop conf configurable
import org apache hadoop conf configuration
import org apache hadoop hbase hbaseconfiguration
import org apache hadoop hbase hconstants
import org apache hadoop hbase client delete
import org apache hadoop hbase client htable
import org apache hadoop hbase client put
import org apache hadoop hbase zookeeper zkutil
import org apache hadoop io writable
import org apache hadoop mapreduce jobcontext
import org apache hadoop mapreduce outputcommitter
import org apache hadoop mapreduce outputformat
import org apache hadoop mapreduce recordwriter
import org apache hadoop mapreduce taskattemptcontext
/**
* convert map/reduce output and write it to an hbase table. the key is ignored
* while the output value <u>must</u> be either a {@link put} or a
* {@link delete} instance.
*
* @param <key>  the type of the key. ignored in this class.
*/
public class tableoutputformat<key> extends outputformat<key  writable>
implements configurable
private final log log   logfactory getlog tableoutputformat class
/** job parameter that specifies the output table. */
public static final string output_table
/**
* optional job parameter to specify a peer cluster.
* used specifying remote cluster when copying between hbase clusters (the
* source is picked up from <code>hbase-site.xml</code>).
* @see tablemapreduceutil#inittablereducerjob(string, class, org.apache.hadoop.mapreduce.job, class, string, string, string)
*/
public static final string quorum_address
/** optional job parameter to specify peer cluster's zk client port */
public static final string quorum_port
/** optional specification of the rs class name of the peer cluster */
public static final string
region_server_class
/** optional specification of the rs impl name of the peer cluster */
public static final string
region_server_impl
/** the configuration. */
private configuration conf   null
private htable table
/**
* writes the reducer output to an hbase table.
*
* @param <key>  the type of the key.
*/
protected static class tablerecordwriter<key>
extends recordwriter<key  writable>
/** the table to write to. */
private htable table
/**
* instantiate a tablerecordwriter with the hbase hclient for writing.
*
* @param table  the table to write to.
*/
public tablerecordwriter htable table
this table   table
/**
* closes the writer, in this case flush table commits.
*
* @param context  the context.
* @throws ioexception when closing the writer fails.
* @see org.apache.hadoop.mapreduce.recordwriter#close(org.apache.hadoop.mapreduce.taskattemptcontext)
*/
@override
public void close taskattemptcontext context
throws ioexception
table close
/**
* writes a key/value pair into the table.
*
* @param key  the key.
* @param value  the value.
* @throws ioexception when writing fails.
* @see org.apache.hadoop.mapreduce.recordwriter#write(java.lang.object, java.lang.object)
*/
@override
public void write key key  writable value
throws ioexception
if  value instanceof put  this table put new put  put value
else if  value instanceof delete  this table delete new delete  delete value
else throw new ioexception
/**
* creates a new record writer.
*
* @param context  the current task context.
* @return the newly created writer instance.
* @throws ioexception when creating the writer fails.
* @throws interruptedexception when the jobs is cancelled.
* @see org.apache.hadoop.mapreduce.lib.output.fileoutputformat#getrecordwriter(org.apache.hadoop.mapreduce.taskattemptcontext)
*/
@override
public recordwriter<key  writable> getrecordwriter
taskattemptcontext context
throws ioexception  interruptedexception
return new tablerecordwriter<key> this table
/**
* checks if the output target exists.
*
* @param context  the current context.
* @throws ioexception when the check fails.
* @throws interruptedexception when the job is aborted.
* @see org.apache.hadoop.mapreduce.outputformat#checkoutputspecs(org.apache.hadoop.mapreduce.jobcontext)
*/
@override
public void checkoutputspecs jobcontext context  throws ioexception
interruptedexception
// todo check if the table exists?
/**
* returns the output committer.
*
* @param context  the current context.
* @return the committer.
* @throws ioexception when creating the committer fails.
* @throws interruptedexception when the job is aborted.
* @see org.apache.hadoop.mapreduce.outputformat#getoutputcommitter(org.apache.hadoop.mapreduce.taskattemptcontext)
*/
@override
public outputcommitter getoutputcommitter taskattemptcontext context
throws ioexception  interruptedexception
return new tableoutputcommitter
public configuration getconf
return conf
@override
public void setconf configuration otherconf
this conf   hbaseconfiguration create otherconf
string tablename   this conf get output_table
if tablename    null    tablename length   <  0
throw new illegalargumentexception
string address   this conf get quorum_address
int zkclientport   conf getint quorum_port  0
string serverclass   this conf get region_server_class
string serverimpl   this conf get region_server_impl
try
if  address    null
zkutil applyclusterkeytoconf this conf  address
if  serverclass    null
this conf set hconstants region_server_class  serverclass
this conf set hconstants region_server_impl  serverimpl
if  zkclientport    0
conf setint hconstants zookeeper_client_port  zkclientport
this table   new htable this conf  tablename
this table setautoflush false
log info      tablename
catch ioexception e
log error e
throw new runtimeexception e