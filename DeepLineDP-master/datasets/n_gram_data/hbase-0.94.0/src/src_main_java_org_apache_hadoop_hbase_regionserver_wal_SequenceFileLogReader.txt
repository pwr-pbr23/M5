/**
* copyright 2010 the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase regionserver wal
import java io filterinputstream
import java io ioexception
import java lang reflect field
import java lang reflect method
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop conf configuration
import org apache hadoop fs fsdatainputstream
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop io sequencefile
public class sequencefilelogreader implements hlog reader
private static final log log   logfactory getlog sequencefilelogreader class
/**
* hack just to set the correct file length up in sequencefile.reader.
* see hadoop-6307.  the below is all about setting the right length on the
* file we are reading.  fs.getfilestatus(file).getlen() is passed down to
* a private sequencefile.reader constructor.  this won't work.  need to do
* the available on the stream.  the below is ugly.  it makes getpos, the
* first time its called, return length of the file -- i.e. tell a lie -- just
* so this line up in sf.reader's constructor ends up with right answer:
*
*         this.end = in.getpos() + length;
*
*/
static class walreader extends sequencefile reader
walreader final filesystem fs  final path p  final configuration c
throws ioexception
super fs  p  c
@override
protected fsdatainputstream openfile filesystem fs  path file
int buffersize  long length
throws ioexception
return new walreaderfsdatainputstream super openfile fs  file
buffersize  length   length
/**
* call this method after init() has been executed
*
* @return whether wal compression is enabled
*/
public boolean iswalcompressionenabled
return sequencefilelogwriter iswalcompressionenabled this getmetadata
/**
* override just so can intercept first call to getpos.
*/
static class walreaderfsdatainputstream extends fsdatainputstream
private boolean firstgetposinvocation   true
private long length
walreaderfsdatainputstream final fsdatainputstream is  final long l
throws ioexception
super is
this length   l
// this section can be confusing.  it is specific to how hdfs works.
// let me try to break it down.  this is the problem:
//
//  1. hdfs datanodes update the namenode about a filename's length
//     on block boundaries or when a file is closed. therefore,
//     if an rs dies, then the nn's fs.getlength() can be out of date
//  2. this.in.available() would work, but it returns int &
//     therefore breaks for files > 2gb (happens on big clusters)
//  3. dfsinputstream.getfilelength() gets the actual length from the dns
//  4. dfsinputstream is wrapped 2 levels deep : this.in.in
//
// so, here we adjust getpos() using getfilelength() so the
// sequencefile.reader constructor (aka: first invocation) comes out
// with the correct end of the file:
//         this.end = in.getpos() + length;
@override
public long getpos   throws ioexception
if  this firstgetposinvocation
this firstgetposinvocation   false
long adjust   0
try
field fin   filterinputstream class getdeclaredfield
fin setaccessible true
object realin   fin get this in
// in hadoop 0.22, dfsinputstream is a standalone class.  before this,
// it was an inner class of dfsclient.
if  realin getclass   getname   endswith
method getfilelength   realin getclass
getdeclaredmethod    new class<?>
getfilelength setaccessible true
long reallength     long getfilelength
invoke realin  new object      longvalue
assert reallength >  this length
adjust   reallength   this length
else
log info     realin getclass   getname
catch exception e
sequencefilelogreader log warn
e
return adjust   super getpos
return super getpos
configuration conf
walreader reader
// needed logging exceptions
path path
int edit   0
long entrystart   0
/**
* compression context to use reading.  can be null if no compression.
*/
private compressioncontext compressioncontext   null
protected class<? extends hlogkey> keyclass
/**
* default constructor.
*/
public sequencefilelogreader
/**
* this constructor allows a specific hlogkey implementation to override that
* which would otherwise be chosen via configuration property.
*
* @param keyclass
*/
public sequencefilelogreader class<? extends hlogkey> keyclass
this keyclass   keyclass
@override
public void init filesystem fs  path path  configuration conf
throws ioexception
this conf   conf
this path   path
reader   new walreader fs  path  conf
// if compression is enabled, new dictionaries are created here.
boolean compression   reader iswalcompressionenabled
if  compression
try
if  compressioncontext    null
compressioncontext   new compressioncontext lrudictionary class
else
compressioncontext clear
catch  exception e
throw new ioexception    e
@override
public void close   throws ioexception
try
if  reader    null
this reader close
this reader   null
catch  ioexception ioe
throw addfileinfotoexception ioe
@override
public hlog entry next   throws ioexception
return next null
@override
public hlog entry next hlog entry reuse  throws ioexception
this entrystart   this reader getposition
hlog entry e   reuse
if  e    null
hlogkey key
if  keyclass    null
key   hlog newkey conf
else
try
key   keyclass newinstance
catch  instantiationexception ie
throw new ioexception ie
catch  illegalaccessexception iae
throw new ioexception iae
waledit val   new waledit
e   new hlog entry key  val
boolean b   false
try
if  compressioncontext    null
e setcompressioncontext compressioncontext
b   this reader next e getkey    e getedit
catch  ioexception ioe
throw addfileinfotoexception ioe
edit
return b? e  null
@override
public void seek long pos  throws ioexception
try
reader seek pos
catch  ioexception ioe
throw addfileinfotoexception ioe
@override
public long getposition   throws ioexception
return reader getposition
protected ioexception addfileinfotoexception final ioexception ioe
throws ioexception
long pos    1
try
pos   getposition
catch  ioexception e
log warn    e
// see what sequencefile.reader thinks is the end of the file
long end   long max_value
try
field fend   sequencefile reader class getdeclaredfield
fend setaccessible true
end   fend getlong this reader
catch exception e       reflection fail  keep going
string msg    this path    null?    this path tostring
entrystart       pos
end    long max_value  ?         end
this edit
// enhance via reflection so we don't change the original class type
try
return  ioexception  ioe getclass
getconstructor string class
newinstance msg
initcause ioe
catch exception e       reflection fail  keep going
return ioe