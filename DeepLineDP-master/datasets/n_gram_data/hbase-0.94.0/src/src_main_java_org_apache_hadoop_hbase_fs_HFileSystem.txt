/*
* copyright the apache software foundation
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase fs
import java io ioexception
import java net uri
import org apache hadoop conf configuration
import org apache hadoop fs filesystem
import org apache hadoop fs filterfilesystem
import org apache hadoop fs fsdatainputstream
import org apache hadoop fs fsdataoutputstream
import org apache hadoop fs localfilesystem
import org apache hadoop fs path
import org apache hadoop util reflectionutils
import org apache hadoop util progressable
/**
* an encapsulation for the filesystem object that hbase uses to access
* data. this class allows the flexibility of using
* separate filesystem objects for reading and writing hfiles and hlogs.
* in future, if we want to make hlogs be in a different filesystem,
* this is the place to make it happen.
*/
public class hfilesystem extends filterfilesystem
private final filesystem nochecksumfs       read hfile data from storage
private final boolean usehbasechecksum
/**
* create a filesystem object for hbase regionservers.
* @param conf the configuration to be used for the filesystem
* @param usehbasechecksums if true, then use
*        checksum verfication in hbase, otherwise
*        delegate checksum verification to the filesystem.
*/
public hfilesystem configuration conf  boolean usehbasechecksum
throws ioexception
// create the default filesystem with checksum verification switched on.
// by default, any operation to this filterfilesystem occurs on
// the underlying filesystem that has checksums switched on.
this fs   filesystem get conf
this usehbasechecksum   usehbasechecksum
fs initialize getdefaulturi conf   conf
// if hbase checksum verification is switched on, then create a new
// filesystem object that has cksum verification turned off.
// we will avoid verifying checksums in the fs client, instead do it
// inside of hbase.
// if this is the local file system hadoop has a bug where seeks
// do not go to the correct location if setverifychecksum(false) is called.
// this manifests itself in that incorrect data is read and hfileblocks won't be able to read
// their header magic numbers. see hbase-5885
if  usehbasechecksum      fs instanceof localfilesystem
this nochecksumfs   newinstancefilesystem conf
this nochecksumfs setverifychecksum false
else
this nochecksumfs   fs
/**
* wrap a filesystem object within a hfilesystem. the nochecksumfs and
* writefs are both set to be the same specified fs.
* do not verify hbase-checksums while reading data from filesystem.
* @param fs set the nochecksumfs and writefs to this specified filesystem.
*/
public hfilesystem filesystem fs
this fs   fs
this nochecksumfs   fs
this usehbasechecksum   false
/**
* returns the filesystem that is specially setup for
* doing reads from storage. this object avoids doing
* checksum verifications for reads.
* @return the filesystem object that can be used to read data
*         from files.
*/
public filesystem getnochecksumfs
return nochecksumfs
/**
* returns the underlying filesystem
* @return the underlying filesystem for this filterfilesystem object.
*/
public filesystem getbackingfs   throws ioexception
return fs
/**
* are we verifying checksums in hbase?
* @return true, if hbase is configured to verify checksums,
*         otherwise false.
*/
public boolean usehbasechecksum
return usehbasechecksum
/**
* close this filesystem object
*/
@override
public void close   throws ioexception
super close
if  this nochecksumfs    fs
this nochecksumfs close
/**
* returns a brand new instance of the filesystem. it does not use
* the filesystem.cache. in newer versions of hdfs, we can directly
* invoke filesystem.newinstance(configuration).
*
* @param conf configuration
* @return a new instance of the filesystem
*/
private static filesystem newinstancefilesystem configuration conf
throws ioexception
uri uri   filesystem getdefaulturi conf
class<?> clazz   conf getclass     uri getscheme        null
if  clazz    null
throw new ioexception     uri getscheme
filesystem fs    filesystem reflectionutils newinstance clazz  conf
fs initialize uri  conf
return fs
/**
* create a new hfilesystem object, similar to filesystem.get().
* this returns a filesystem object that avoids checksum
* verification in the filesystem for hfileblock-reads.
* for these blocks, checksum verification is done by hbase.
*/
static public filesystem get configuration conf  throws ioexception
return new hfilesystem conf  true
/**
* wrap a localfilesystem within a hfilesystem.
*/
static public filesystem getlocalfs configuration conf  throws ioexception
return new hfilesystem filesystem getlocal conf
/**
* the org.apache.hadoop.fs.filterfilesystem does not yet support
* createnonrecursive. this is a hadoop bug and when it is fixed in hadoop,
* this definition will go away.
*/
public fsdataoutputstream createnonrecursive path f
boolean overwrite
int buffersize  short replication  long blocksize
progressable progress  throws ioexception
return fs createnonrecursive f  overwrite  buffersize  replication
blocksize  progress