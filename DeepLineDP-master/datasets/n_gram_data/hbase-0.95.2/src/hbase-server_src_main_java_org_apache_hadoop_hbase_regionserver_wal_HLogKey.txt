/**
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase regionserver wal
import java io datainput
import java io dataoutput
import java io eofexception
import java io ioexception
import java util hashmap
import java util map
import java util navigablemap
import java util treemap
import java util uuid
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop classification interfaceaudience
import org apache hadoop hbase tablename
import org apache hadoop hbase hconstants
import org apache hadoop hbase protobuf generated hbaseprotos
import org apache hadoop hbase protobuf generated walprotos familyscope
import org apache hadoop hbase protobuf generated walprotos scopetype
import org apache hadoop hbase protobuf generated walprotos walkey
import org apache hadoop hbase util bytes
import org apache hadoop io writablecomparable
import org apache hadoop io writableutils
import com google protobuf bytestring
/**
* a key for an entry in the change log.
*
* the log intermingles edits to many tables and rows, so each log entry
* identifies the appropriate table and row.  within a table and row, they're
* also sorted.
*
* <p>some transactional edits (start, commit, abort) will not have an
* associated row.
*/
// todo: key and waledit are never used separately, or in one-to-many relation, for practical
//       purposes. they need to be merged into hlogentry.
@interfaceaudience private
public class hlogkey implements writablecomparable<hlogkey>
public static final log log   logfactory getlog hlogkey class
// should be < 0 (@see #readfields(datainput))
// version 2 supports hlog compression
enum version
unversioned 0
// initial number we put on hlogkey when we introduced versioning.
initial  1
// version -2 introduced a dictionary compression facility.  only this
// dictionary-based compression is available in version -2.
compressed  2
final int code
static final version bycode
static
bycode   version values
for  int i   0  i < bycode length  i
if  bycode code     1   i
throw new assertionerror
version int code
this code   code
boolean atleast version other
return code <  other code
static version fromcode int code
return bycode
private static final version version   version compressed
//  the encoded region name.
private byte  encodedregionname
private tablename tablename
private long logseqnum
// time at which this edit was written.
private long writetime
private uuid clusterid
private navigablemap<byte  integer> scopes
private compressioncontext compressioncontext
public hlogkey
this null  null  0l  hconstants latest_timestamp
hconstants default_cluster_id
/**
* create the log key for writing to somewhere.
* we maintain the tablename mainly for debugging purposes.
* a regionname is always a sub-table object.
*
* @param encodedregionname encoded name of the region as returned by
* <code>hregioninfo#getencodednameasbytes()</code>.
* @param tablename   - name of table
* @param logseqnum   - log sequence number
* @param now time at which this edit was written.
* @param clusterid of the cluster (used in replication)
*/
public hlogkey final byte  encodedregionname  final tablename tablename
long logseqnum  final long now  uuid clusterid
this logseqnum   logseqnum
this writetime   now
this clusterid   clusterid
this encodedregionname   encodedregionname
this tablename   tablename
/**
* create hlogkey wrapper around protobuf wal key; takes care of compression.
* @throws ioexception never, as the compression is not enabled.
*/
public hlogkey walkey walkey  throws ioexception
readfieldsfrompb walkey  null
/**
* @param compressioncontext compression context to use
*/
public void setcompressioncontext compressioncontext compressioncontext
this compressioncontext   compressioncontext
/** @return encoded region name */
public byte  getencodedregionname
return encodedregionname
/** @return table name */
public tablename gettablename
return tablename
/** @return log sequence number */
public long getlogseqnum
return this logseqnum
/**
* @return the write time
*/
public long getwritetime
return this writetime
/**
* get the id of the original cluster
* @return cluster id.
*/
public uuid getclusterid
return clusterid
public navigablemap<byte  integer> getscopes
return scopes
public void setscopes navigablemap<byte  integer> scopes
this scopes   scopes
/**
* set the cluster id of this key.
* @param clusterid
*/
public void setclusterid uuid clusterid
this clusterid   clusterid
@override
public string tostring
return tablename       bytes tostring encodedregionname
logseqnum
/**
* produces a string map for this key. useful for programmatic use and
* manipulation of the data stored in an hlogkey, for example, printing
* as json.
*
* @return a map containing data from this key
*/
public map<string  object> tostringmap
map<string  object> stringmap   new hashmap<string  object>
stringmap put    tablename
stringmap put    bytes tostringbinary encodedregionname
stringmap put    logseqnum
return stringmap
@override
public boolean equals object obj
if  this    obj
return true
if  obj    null    getclass      obj getclass
return false
return compareto  hlogkey obj     0
@override
public int hashcode
int result   bytes hashcode this encodedregionname
result ^  this logseqnum
result ^  this writetime
result ^  this clusterid hashcode
return result
public int compareto hlogkey o
int result   bytes compareto this encodedregionname  o encodedregionname
if  result    0
if  this logseqnum < o logseqnum
result    1
else if  this logseqnum  > o logseqnum
result   1
if  result    0
if  this writetime < o writetime
result    1
else if  this writetime > o writetime
return 1
// why isn't cluster id accounted for?
return result
/**
* drop this instance's tablename byte array and instead
* hold a reference to the provided tablename. this is not
* meant to be a general purpose setter - it's only used
* to collapse references to conserve memory.
*/
void interntablename tablename tablename
// we should not use this as a setter - only to swap
// in a new reference to the same table name.
assert tablename equals this tablename
this tablename   tablename
/**
* drop this instance's region name byte array and instead
* hold a reference to the provided region name. this is not
* meant to be a general purpose setter - it's only used
* to collapse references to conserve memory.
*/
void internencodedregionname byte encodedregionname
// we should not use this as a setter - only to swap
// in a new reference to the same table name.
assert bytes equals this encodedregionname  encodedregionname
this encodedregionname   encodedregionname
@override
@deprecated
public void write dataoutput out  throws ioexception
log warn
writableutils writevint out  version code
if  compressioncontext    null
bytes writebytearray out  this encodedregionname
bytes writebytearray out  this tablename getname
else
compressor writecompressed this encodedregionname  0
this encodedregionname length  out
compressioncontext regiondict
compressor writecompressed this tablename getname    0  this tablename getname   length  out
compressioncontext tabledict
out writelong this logseqnum
out writelong this writetime
// avoid storing 16 bytes when replication is not enabled
if  this clusterid    hconstants default_cluster_id
out writeboolean false
else
out writeboolean true
out writelong this clusterid getmostsignificantbits
out writelong this clusterid getleastsignificantbits
@override
public void readfields datainput in  throws ioexception
version version   version unversioned
// hlogkey was not versioned in the beginning.
// in order to introduce it now, we make use of the fact
// that encodedregionname was written with bytes.writebytearray,
// which encodes the array length as a vint which is >= 0.
// hence if the vint is >= 0 we have an old version and the vint
// encodes the length of encodedregionname.
// if < 0 we just read the version and the next vint is the length.
// @see bytes#readbytearray(datainput)
this scopes   null     writable hlogkey does not contain scopes
int len   writableutils readvint in
if  len < 0
// what we just read was the version
version   version fromcode len
// we only compress v2 of hlogkey.
// if compression is on, the length is handled by the dictionary
if  compressioncontext    null     version atleast version compressed
len   writableutils readvint in
if  compressioncontext    null     version atleast version compressed
this encodedregionname   new byte
in readfully this encodedregionname
byte tablenamebytes   bytes readbytearray in
this tablename   tablename valueof tablenamebytes
else
this encodedregionname   compressor readcompressed in  compressioncontext regiondict
byte tablenamebytes   compressor readcompressed in  compressioncontext tabledict
this tablename    tablename valueof tablenamebytes
this logseqnum   in readlong
this writetime   in readlong
this clusterid   hconstants default_cluster_id
if  version atleast version initial
if  in readboolean
this clusterid   new uuid in readlong    in readlong
else
try
// dummy read (former byte cluster id)
in readbyte
catch eofexception e
// means it's a very old key, just continue
public walkey builder getbuilder
walcellcodec bytestringcompressor compressor  throws ioexception
walkey builder builder   walkey newbuilder
if  compressioncontext    null
builder setencodedregionname bytestring copyfrom this encodedregionname
builder settablename bytestring copyfrom this tablename getname
else
builder setencodedregionname
compressor compress this encodedregionname  compressioncontext regiondict
builder settablename compressor compress this tablename getname
compressioncontext tabledict
builder setlogsequencenumber this logseqnum
builder setwritetime writetime
if  this clusterid    hconstants default_cluster_id
builder setclusterid hbaseprotos uuid newbuilder
setleastsigbits this clusterid getleastsignificantbits
setmostsigbits this clusterid getmostsignificantbits
if  scopes    null
for  map entry<byte  integer> e   scopes entryset
bytestring family    compressioncontext    null  ? bytestring copyfrom e getkey
compressor compress e getkey    compressioncontext familydict
builder addscopes familyscope newbuilder
setfamily family  setscopetype scopetype valueof e getvalue
return builder
public void readfieldsfrompb
walkey walkey  walcellcodec bytestringuncompressor uncompressor  throws ioexception
if  this compressioncontext    null
this encodedregionname   uncompressor uncompress
walkey getencodedregionname    compressioncontext regiondict
byte tablenamebytes   uncompressor uncompress
walkey gettablename    compressioncontext tabledict
this tablename   tablename valueof tablenamebytes
else
this encodedregionname   walkey getencodedregionname   tobytearray
this tablename   tablename valueof walkey gettablename   tobytearray
this clusterid   hconstants default_cluster_id
if  walkey hasclusterid
this clusterid   new uuid
walkey getclusterid   getmostsigbits    walkey getclusterid   getleastsigbits
this scopes   null
if  walkey getscopescount   > 0
this scopes   new treemap<byte  integer> bytes bytes_comparator
for  familyscope scope   walkey getscopeslist
byte family    compressioncontext    null  ? scope getfamily   tobytearray
uncompressor uncompress scope getfamily    compressioncontext familydict
this scopes put family  scope getscopetype   getnumber
this logseqnum   walkey getlogsequencenumber
this writetime   walkey getwritetime