/*
*
* licensed to the apache software foundation (asf) under one
* or more contributor license agreements.  see the notice file
* distributed with this work for additional information
* regarding copyright ownership.  the asf licenses this file
* to you under the apache license, version 2.0 (the
* "license"); you may not use this file except in compliance
* with the license.  you may obtain a copy of the license at
*
*     http://www.apache.org/licenses/license-2.0
*
* unless required by applicable law or agreed to in writing, software
* distributed under the license is distributed on an "as is" basis,
* without warranties or conditions of any kind, either express or implied.
* see the license for the specific language governing permissions and
* limitations under the license.
*/
package org apache hadoop hbase replication regionserver
import java io eofexception
import java io filenotfoundexception
import java io ioexception
import java net connectexception
import java net sockettimeoutexception
import java util arrays
import java util comparator
import java util list
import java util navigablemap
import java util uuid
import java util concurrent priorityblockingqueue
import java util concurrent timeunit
import org apache commons logging log
import org apache commons logging logfactory
import org apache hadoop classification interfaceaudience
import org apache hadoop conf configuration
import org apache hadoop fs filestatus
import org apache hadoop fs filesystem
import org apache hadoop fs path
import org apache hadoop hbase hconstants
import org apache hadoop hbase keyvalue
import org apache hadoop hbase stoppable
import org apache hadoop hbase tablename
import org apache hadoop hbase tablenotfoundexception
import org apache hadoop hbase client hconnection
import org apache hadoop hbase client hconnectionmanager
import org apache hadoop hbase protobuf replicationprotbufutil
import org apache hadoop hbase protobuf generated adminprotos adminservice blockinginterface
import org apache hadoop hbase regionserver wal hlog
import org apache hadoop hbase regionserver wal hlogkey
import org apache hadoop hbase regionserver wal waledit
import org apache hadoop hbase replication replicationpeers
import org apache hadoop hbase replication replicationqueueinfo
import org apache hadoop hbase replication replicationqueues
import org apache hadoop hbase replication regionserver replicationsinkmanager sinkpeer
import org apache hadoop hbase util bytes
import org apache hadoop hbase util threads
import org apache hadoop ipc remoteexception
import org apache zookeeper keeperexception
/**
* class that handles the source of a replication stream.
* currently does not handle more than 1 slave
* for each slave cluster it selects a random number of peers
* using a replication ratio. for example, if replication ration = 0.1
* and slave cluster has 100 region servers, 10 will be selected.
* <p/>
* a stream is considered down when we cannot contact a region server on the
* peer cluster for more than 55 seconds by default.
* <p/>
*
*/
@interfaceaudience private
public class replicationsource extends thread
implements replicationsourceinterface
public static final log log   logfactory getlog replicationsource class
// queue of logs to process
private priorityblockingqueue<path> queue
// container of entries to replicate
private hlog entry entriesarray
private hconnection conn
private replicationqueues replicationqueues
private replicationpeers replicationpeers
private configuration conf
private replicationqueueinfo replicationqueueinfo
// id of the peer cluster this source replicates to
private string peerid
// the manager of all sources to which we ping back our progress
private replicationsourcemanager manager
// should we stop everything?
private stoppable stopper
// how long should we sleep for each retry
private long sleepforretries
// max size in bytes of entriesarray
private long replicationqueuesizecapacity
// max number of entries in entriesarray
private int replicationqueuenbcapacity
// our reader for the current log
private hlog reader reader
// last position in the log that we sent to zookeeper
private long lastloggedposition    1
// path of the current log
private volatile path currentpath
private filesystem fs
// id of this cluster
private uuid clusterid
// id of the other cluster
private uuid peerclusterid
// total number of edits we replicated
private long totalreplicatededits   0
// total number of edits we replicated
private long totalreplicatedoperations   0
// the znode we currently play with
private string peerclusterznode
// maximum number of retries before taking bold actions
private int maxretriesmultiplier
// socket timeouts require even bolder actions since we don't want to ddos
private int sockettimeoutmultiplier
// current number of entries that we need to replicate
private int currentnbentries   0
// current number of operations (put/delete) that we need to replicate
private int currentnboperations   0
// current size of data we need to replicate
private int currentsize   0
// indicates if this particular source is running
private volatile boolean running   true
// metrics for this source
private metricssource metrics
// handle on the log reader helper
private replicationhlogreadermanager replogreader
// handles connecting to peer region servers
private replicationsinkmanager replicationsinkmgr
//warn threshold for the number of queued logs, defaults to 2
private int logqueuewarnthreshold
/**
* instantiation method used by region servers
*
* @param conf configuration to use
* @param fs file system to use
* @param manager replication manager to ping to
* @param stopper     the atomic boolean to use to stop the regionserver
* @param peerclusterznode the name of our znode
* @throws ioexception
*/
public void init final configuration conf  final filesystem fs
final replicationsourcemanager manager  final replicationqueues replicationqueues
final replicationpeers replicationpeers  final stoppable stopper
final string peerclusterznode  final uuid clusterid  throws ioexception
this stopper   stopper
this conf   conf
this replicationqueuesizecapacity
this conf getlong    1024 1024 64
this replicationqueuenbcapacity
this conf getint    25000
this entriesarray   new hlog entry
for  int i   0  i < this replicationqueuenbcapacity  i
this entriesarray   new hlog entry
this maxretriesmultiplier   this conf getint    10
this sockettimeoutmultiplier   this conf getint
maxretriesmultiplier   maxretriesmultiplier
this queue
new priorityblockingqueue<path>
conf getint    32
new logscomparator
// todo: this connection is replication specific or we should make it particular to
// replication and make replication specific settings such as compression or codec to use
// passing cells.
this conn   hconnectionmanager getconnection conf
this replicationqueues   replicationqueues
this replicationpeers   replicationpeers
this manager   manager
this sleepforretries
this conf getlong    1000
this fs   fs
this metrics   new metricssource peerclusterznode
this replogreader   new replicationhlogreadermanager this fs  this conf
this clusterid   clusterid
this peerclusterznode   peerclusterznode
this replicationqueueinfo   new replicationqueueinfo peerclusterznode
// replicationqueueinfo parses the peerid out of the znode for us
this peerid   this replicationqueueinfo getpeerid
this replicationsinkmgr   new replicationsinkmanager conn  peerid  replicationpeers  conf
this logqueuewarnthreshold   this conf getint    2
@override
public void enqueuelog path log
this queue put log
int queuesize   queue size
this metrics setsizeoflogqueue queuesize
// this will log a warning for each new log that gets created above the warn threshold
if  queuesize > this logqueuewarnthreshold
log warn     queuesize
logqueuewarnthreshold
@override
public void run
connecttopeers
// we were stopped while looping to connect to sinks, just abort
if   this isactive
metrics clear
return
int sleepmultiplier   1
// delay this until we are in an asynchronous thread
while  this peerclusterid    null
this peerclusterid   replicationpeers getpeeruuid this peerid
if  this peerclusterid    null
if  sleepforretries    sleepmultiplier
sleepmultiplier
// resetting to 1 to reuse later
sleepmultiplier   1
log info   clusterid       peerclusterid
// if this is recovered, the queue is already full and the first log
// normally has a position (unless the rs failed between 2 logs)
if  this replicationqueueinfo isqueuerecovered
try
this replogreader setposition this replicationqueues getlogposition this peerclusterznode
this queue peek   getname
if  log istraceenabled
log trace     this queue peek
this replogreader getposition
catch  keeperexception e
this terminate
this peerclusterznode  e
// loop until we close down
while  isactive
// sleep until replication is enabled again
if   ispeerenabled
if  sleepforretries    sleepmultiplier
sleepmultiplier
continue
path oldpath   getcurrentpath      note that in the current scenario
//oldpath will be null when a log roll
//happens.
// get a new path
boolean hascurrentpath   getnextpath
if  getcurrentpath      null    oldpath    null
sleepmultiplier   1    reset the sleepmultiplier on a path change
if   hascurrentpath
if  sleepforretries    sleepmultiplier
sleepmultiplier
continue
boolean currentwalisbeingwrittento   false
//for wal files we own (rather than recovered), take a snapshot of whether the
//current wal file (this.currentpath) is in use (for writing) now!
//since the new wal paths are enqueued only after the prev wal file
//is 'closed', presence of an element in the queue means that
//the previous wal file was closed, else the file is in use (currentpath)
//we take the snapshot now so that we are protected against races
//where a new file gets enqueued while the current file is being processed
//(and where we just finished reading the current file).
if   this replicationqueueinfo isqueuerecovered      queue size      0
currentwalisbeingwrittento   true
// open a reader on it
if   openreader sleepmultiplier
// reset the sleep multiplier, else it'd be reused for the next file
sleepmultiplier   1
continue
// if we got a null reader but didn't continue, then sleep and continue
if  this reader    null
if  sleepforretries    sleepmultiplier
sleepmultiplier
continue
boolean gotioe   false
currentnboperations   0
currentnbentries   0
currentsize   0
try
if  readallentriestoreplicateornextfile currentwalisbeingwrittento
continue
catch  ioexception ioe
log warn this peerclusterznode      ioe
gotioe   true
if  ioe getcause   instanceof eofexception
boolean considerdumping   false
if  this replicationqueueinfo isqueuerecovered
try
filestatus stat   this fs getfilestatus this currentpath
if  stat getlen      0
log warn this peerclusterznode
considerdumping   true
catch  ioexception e
log warn this peerclusterznode      e
else if  currentnbentries    0
log warn this peerclusterznode
currentpath
considerdumping   true
currentnbentries   0
if  considerdumping
sleepmultiplier    this maxretriesmultiplier
processendoffile
continue
finally
try
this reader   null
this replogreader closereader
catch  ioexception e
gotioe   true
log warn    e
// if we didn't get anything to replicate, or if we hit a ioe,
// wait a bit and retry.
// but if we need to stop, don't bother sleeping
if  this isactive       gotioe    currentnbentries    0
if  this lastloggedposition    this replogreader getposition
this manager logpositionandcleanoldlogs this currentpath
this peerclusterznode  this replogreader getposition
this replicationqueueinfo isqueuerecovered    currentwalisbeingwrittento
this lastloggedposition   this replogreader getposition
// reset the sleep multiplier if nothing has actually gone wrong
if   gotioe
sleepmultiplier   1
if  sleepforretries    sleepmultiplier
sleepmultiplier
continue
sleepmultiplier   1
shipedits currentwalisbeingwrittento
if  this conn    null
try
this conn close
catch  ioexception e
log debug    e
log debug     this peerid
metrics clear
/**
* read all the entries from the current log files and retain those
* that need to be replicated. else, process the end of the current file.
* @param currentwalisbeingwrittento is the current wal being written to
* @return true if we got nothing and went to the next file, false if we got
* entries
* @throws ioexception
*/
protected boolean readallentriestoreplicateornextfile boolean currentwalisbeingwrittento
throws ioexception
long seenentries   0
if  log istraceenabled
log trace     this currentpath
this replogreader getposition
this replogreader seek
hlog entry entry
this replogreader readnextandsetposition this entriesarray  this currentnbentries
while  entry    null
waledit edit   entry getedit
this metrics incrlogeditsread
seenentries
// remove all kvs that should not be replicated
hlogkey logkey   entry getkey
// don't replicate if the log entries originated in the peer
if   logkey getclusterid   equals peerclusterid
removenonreplicableedits entry
// don't replicate catalog entries, if the waledit wasn't
// containing anything to replicate and if we're currently not set to replicate
if    logkey gettablename   equals tablename root_table_name
logkey gettablename   equals tablename meta_table_name
edit size      0
// only set the clusterid if is a local key.
// this ensures that the originator sets the cluster id
// and all replicas retain the initial cluster id.
// this is *only* place where a cluster id other than the default is set.
if  hconstants default_cluster_id    logkey getclusterid
logkey setclusterid this clusterid
currentnboperations    countdistinctrowkeys edit
currentnbentries
currentsize    entry getedit   size
else
this metrics incrlogeditsfiltered
// stop if too many entries or too big
if  currentsize >  this replicationqueuesizecapacity
currentnbentries >  this replicationqueuenbcapacity
break
try
entry   this replogreader readnextandsetposition this entriesarray  this currentnbentries
catch  ioexception ie
log debug     ie getmessage
break
if  currentwalisbeingwrittento
return false
// if we didn't get anything and the queue has an object, it means we
// hit the end of the file for sure
return seenentries    0    processendoffile
private void connecttopeers
int sleepmultiplier   1
// connect to peer cluster first, unless we have to stop
while  this isactive      replicationsinkmgr getsinks   size      0
replicationsinkmgr choosesinks
if  this isactive      replicationsinkmgr getsinks   size      0
if  sleepforretries    sleepmultiplier
sleepmultiplier
/**
* poll for the next path
* @return true if a path was obtained, false if not
*/
protected boolean getnextpath
try
if  this currentpath    null
this currentpath   queue poll this sleepforretries  timeunit milliseconds
this metrics setsizeoflogqueue queue size
if  this currentpath    null
this manager cleanoldlogs this currentpath getname
this peerid
this replicationqueueinfo isqueuerecovered
if  log istraceenabled
log trace     this currentpath
catch  interruptedexception e
log warn    e
return this currentpath    null
/**
* open a reader on the current path
*
* @param sleepmultiplier by how many times the default sleeping time is augmented
* @return true if we should continue with that file, false if we are over with it
*/
protected boolean openreader int sleepmultiplier
try
try
if  log istraceenabled
log trace     this currentpath
this reader   replogreader openreader this currentpath
catch  filenotfoundexception fnfe
if  this replicationqueueinfo isqueuerecovered
// we didn't find the log in the archive directory, look if it still
// exists in the dead rs folder (there could be a chain of failures
// to look at)
list<string> deadregionservers   this replicationqueueinfo getdeadregionservers
log info     deadregionservers size
for  string curdeadservername   deadregionservers
path deadrsdirectory
new path manager getlogdir   getparent    curdeadservername
path locs   new path
new path deadrsdirectory  currentpath getname
new path deadrsdirectory suffix hlog splitting_ext
currentpath getname
for  path possibleloglocation   locs
log info     possibleloglocation touri   tostring
if  this manager getfs   exists possibleloglocation
// we found the right new location
log info     this currentpath
possibleloglocation
// breaking here will make us sleep since reader is null
return true
// todo what happens if the log was missing from every single location?
// although we need to check a couple of times as the log could have
// been moved by the master between the checks
// it can also happen if a recovered queue wasn't properly cleaned,
// such that the znode pointing to a log exists but the log was
// deleted a long time ago.
// for the moment, we'll throw the io and processendoffile
throw new ioexception
fnfe
else
// if the log was archived, continue reading from there
path archivedloglocation
new path manager getoldlogdir    currentpath getname
if  this manager getfs   exists archivedloglocation
currentpath   archivedloglocation
log info     this currentpath
archivedloglocation
// open the log at the new location
this openreader sleepmultiplier
// todo what happens the log is missing in both places?
catch  ioexception ioe
if  ioe instanceof eofexception    iscurrentlogempty    return true
log warn this peerclusterznode      ioe
this reader   null
if  ioe getcause   instanceof nullpointerexception
// workaround for race condition in hdfs-4380
// which throws a npe if we open a file before any data node has the most recent block
// just sleep and retry. will require re-reading compressed hlogs for compressioncontext.
log warn
else if  sleepmultiplier    this maxretriesmultiplier
// todo need a better way to determine if a file is really gone but
// todo without scanning all logs dir
log warn
return  processendoffile
return true
/*
* checks whether the current log file is empty, and it is not a recovered queue. this is to
* handle scenario when in an idle cluster, there is no entry in the current log and we keep on
* trying to read the log file and get eofeception. in case of a recovered queue the last log file
* may be empty, and we don't want to retry that.
*/
private boolean iscurrentlogempty
return  this replogreader getposition      0
this replicationqueueinfo isqueuerecovered      queue size      0
/**
* do the sleeping logic
* @param msg why we sleep
* @param sleepmultiplier by how many times the default sleeping time is augmented
* @return true if <code>sleepmultiplier</code> is &lt; <code>maxretriesmultiplier</code>
*/
protected boolean sleepforretries string msg  int sleepmultiplier
try
log debug msg       sleepforretries       sleepmultiplier
thread sleep this sleepforretries   sleepmultiplier
catch  interruptedexception e
log debug
return sleepmultiplier < maxretriesmultiplier
/**
* we only want kvs that are scoped other than local
* @param entry the entry to check for replication
*/
protected void removenonreplicableedits hlog entry entry
navigablemap<byte  integer> scopes   entry getkey   getscopes
list<keyvalue> kvs   entry getedit   getkeyvalues
for  int i   kvs size   1  i >  0  i
keyvalue kv   kvs get i
// the scope will be null or empty if
// there's nothing to replicate in that waledit
if  scopes    null     scopes containskey kv getfamily
kvs remove i
/**
* count the number of different row keys in the given edit because of
* mini-batching. we assume that there's at least one kv in the waledit.
* @param edit edit to count row keys from
* @return number of different row keys
*/
private int countdistinctrowkeys waledit edit
list<keyvalue> kvs   edit getkeyvalues
int distinctrowkeys   1
keyvalue lastkv   kvs get 0
for  int i   0  i < edit size    i
if   kvs get i  matchingrow lastkv
distinctrowkeys
return distinctrowkeys
/**
* do the shipping logic
* @param currentwalisbeingwrittento was the current wal being (seemingly)
* written to when this method was called
*/
protected void shipedits boolean currentwalisbeingwrittento
int sleepmultiplier   1
if  this currentnbentries    0
log warn
return
while  this isactive
if   ispeerenabled
if  sleepforretries    sleepmultiplier
sleepmultiplier
continue
sinkpeer sinkpeer   null
try
sinkpeer   replicationsinkmgr getreplicationsink
blockinginterface rrs   sinkpeer getregionserver
if  log istraceenabled
log trace     this currentnbentries
replicationprotbufutil replicatewalentry rrs
arrays copyof this entriesarray  currentnbentries
if  this lastloggedposition    this replogreader getposition
this manager logpositionandcleanoldlogs this currentpath
this peerclusterznode  this replogreader getposition
this replicationqueueinfo isqueuerecovered    currentwalisbeingwrittento
this lastloggedposition   this replogreader getposition
this totalreplicatededits    currentnbentries
this totalreplicatedoperations    currentnboperations
this metrics shipbatch this currentnboperations
this metrics setageoflastshippedop
this entriesarray getkey   getwritetime
if  log istraceenabled
log trace     this totalreplicatededits
this totalreplicatedoperations
break
catch  ioexception ioe
// didn't ship anything, but must still age the last time we did
this metrics refreshageoflastshippedop
if  ioe instanceof remoteexception
ioe     remoteexception  ioe  unwrapremoteexception
log warn    ioe
if  ioe instanceof tablenotfoundexception
if  sleepforretries
sleepmultiplier
sleepmultiplier
else
if  ioe instanceof sockettimeoutexception
// this exception means we waited for more than 60s and nothing
// happened, the cluster is alive and calling it right away
// even for a test just makes things worse.
sleepforretries
this sockettimeoutmultiplier
else if  ioe instanceof connectexception
log warn    ioe
replicationsinkmgr choosesinks
else
log warn    ioe
if  sinkpeer    null
replicationsinkmgr reportbadsink sinkpeer
if  sleepforretries    sleepmultiplier
sleepmultiplier
/**
* check whether the peer is enabled or not
*
* @return true if the peer is enabled, otherwise false
*/
protected boolean ispeerenabled
return this replicationpeers getstatusofconnectedpeer this peerid
/**
* if the queue isn't empty, switch to the next one
* else if this is a recovered queue, it means we're done!
* else we'll just continue to try reading the log file
* @return true if we're done with the current file, false if we should
* continue trying to read from it
*/
protected boolean processendoffile
if  this queue size      0
if  log istraceenabled
string filesize
try
filestatus stat   this fs getfilestatus this currentpath
filesize   stat getlen
catch  ioexception ex
log trace     getstats
filesize
this currentpath   null
this replogreader finishcurrentfile
this reader   null
return true
else if  this replicationqueueinfo isqueuerecovered
this manager closerecoveredqueue this
log info     getstats
this running   false
return true
return false
public void startup
string n   thread currentthread   getname
thread uncaughtexceptionhandler handler
new thread uncaughtexceptionhandler
public void uncaughtexception final thread t  final throwable e
log error
currentpath  e
threads setdaemonthreadrunning
this  n
this peerclusterznode  handler
public void terminate string reason
terminate reason  null
public void terminate string reason  exception cause
if  cause    null
log info
this peerclusterznode       reason
else
log error     this peerclusterznode
reason  cause
this running   false
threads shutdown this  this sleepforretries
public string getpeerclusterznode
return this peerclusterznode
public string getpeerclusterid
return this peerid
public path getcurrentpath
return this currentpath
private boolean isactive
return  this stopper isstopped      this running
/**
* comparator used to compare logs together based on their start time
*/
public static class logscomparator implements comparator<path>
@override
public int compare path o1  path o2
return long valueof getts o1   compareto getts o2
/**
* split a path to get the start time
* for example: 10.20.20.171%3a60020.1277499063250
* @param p path to split
* @return start time
*/
private long getts path p
string parts   p getname   split
return long parselong parts
@override
public string getstats
long position   this replogreader getposition
return     totalreplicatededits
this currentpath
position